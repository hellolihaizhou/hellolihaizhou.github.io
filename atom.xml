<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>李海洲</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://lihaizhou.top/"/>
  <updated>2020-12-01T09:16:44.479Z</updated>
  <id>http://lihaizhou.top/</id>
  
  <author>
    <name>Steven Lee</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>对投屏工作的回顾小结(持续补充)</title>
    <link href="http://lihaizhou.top/2020/12/01/%E5%AF%B9%E6%8A%95%E5%B1%8F%E5%B7%A5%E4%BD%9C%E7%9A%84%E5%9B%9E%E9%A1%BE%E5%B0%8F%E7%BB%93-%E6%8C%81%E7%BB%AD%E8%A1%A5%E5%85%85/"/>
    <id>http://lihaizhou.top/2020/12/01/对投屏工作的回顾小结-持续补充/</id>
    <published>2020-12-01T09:08:00.000Z</published>
    <updated>2020-12-01T09:16:44.479Z</updated>
    
    <content type="html"><![CDATA[<p>前言<br>主要针对高通平台上的miracast投屏遇到的问题，顺便对miracast投屏的一点归纳总结，以便后续如再处理miracast投屏相关的工作，通过本篇文章能够快速重新开始。</p><p>以下主要通过一些QA方式来概述 </p><p>Q：高通上的投屏和谷歌原生的投屏有什么差别吗？</p><p>A：Google WFD 支持AVC, LPCM, and AAC 编码 并支持HDCP加密, 但是缺少对内容保护的支持<br>      通过使用Presentation、MediaRouter和DisplayManager api，它可以作为一个外部WFD提供给应用程序使用。<br>      按照高通文档的解释，谷歌的miracast和高通的相比，缺乏内容保护支持，性能较低，功耗较高，高通提供了一个增强的Miracast解决方案。</p><p>Q：Miracast Source 软件架构是怎样的？</p><p>A：<br><img src="https://raw.githubusercontent.com/hellolihaizhou/saveImg/master/miracast.png" alt=""><br>个人理解红色标准1和2的代表视频数据的两种来源，分别是USB/摄像头和录制屏幕，4标注代表的是经过V4L2编码后的视频数据从给混合起Mux，5标注代表音频数据送给Mux，合成后压缩成MPEG-2格式的ts流，再通过RTP server即UDP传送，6标注代表的是RTSP的协议栈，RTSP是基于tcp的，主要是客户端和sink端的一系列交互和协商等。</p><p>Q：如果投屏失败了，从tcpdump上如何分析出是哪一步出错了？</p><p>A：正确的流程参见：<a href="http://lihaizhou.top/2020/11/30/%E4%BB%8Etcpdump%E7%9C%8Bmiracast%E7%9A%84play%E6%B5%81%E7%A8%8B/#more">http://lihaizhou.top/2020/11/30/%E4%BB%8Etcpdump%E7%9C%8Bmiracast%E7%9A%84play%E6%B5%81%E7%A8%8B/#more</a>  对照着看就行</p><p>Q：怎么看SessionManagerService在miracast投屏环节中扮演的角色？</p><p>A：个人理解这个类承担的角色比较重要，实现是在vendor中，是一个binder的服务端，起到一个承上启下的作用。<br>      承上的是应用层以及fwk，承下的是主要native层的wifisession打交道。<br>      其实不妨看下这个类中的方法，比如startWfdSession，startUibcSession，setSurface，play, pause，tcpPlaybackControl等几乎都是对WFDSession中的接口所做的一层封装。<br>      所以比较核心的方法还得接着看native层的WFDSession，高通的真正实现封装在so中</p><p>Q：如果投屏遇到花屏了或者其他画面异常的情况，该如何判断是sink还是source的问题，如果是source的话，是哪一步的问题呢？</p><p>A：目前遇到的画面显示异常除了小部分是非问题比如输入法状态栏等隐私保护设计导致的，其他大部分都是网络环境导致的。这里先不考虑可能是sink端解码的问题，假如问题就出在source或者网络，可以先获取发送前的视频流dump.ts，这个ts流已经是音视频合成后的准备通过网络发送的数据。<br>如果这个ts流是正常的，就可以排除是source的问题了，如果这个ts流是有问题的话，就要考虑是不是V4L2编码后的数据是否是正常的了,这个时候可以抓取V4l2 dump获取到编码后的视频数据，这个数据是发给mux的，然后和av数据混合成ts流</p><p>Q：如何判断花屏是否因为是丢包率高导致的？</p><p>A：wireshark打开抓取的tcpdump，选择UDP packet，Right click -&gt; Decode as -&gt; RTP  Then from the tool bar, select Telephony -&gt; RTP-&gt;Stream analysis -&gt; Save Payload<br>. This will open a pop-up which shows the packet loss % rate.</p><p>Q: VirtualDisplay在miracast投屏中是何时创建的，扮演的作用？</p><p>A: 我们先说下手机普通录制视频的流程，一般会先用<code>MediaProjection</code>的<code>createVirtualDisplay</code>创建一个VirtualDisplay，createVirtualDisplay的参数有宽高dpi啥的，还有一个最重要的参数就是surface，这玩意其实就是指向一块内存，surface怎么创建呢，可以使用MediaCodec的createInputSurface创建一个输入surface，也可以自己创建，使用MediaCodec的API创建的话缺乏灵活性，没有办法对一帧一帧数据进行处理。录制屏幕的数据从而而来的呢？MediaCodec的createByCodecName创建一个编码器，然后调用其setCallback，在onOutputBufferAvailable中获取到buffer数据，然后这个时候就可以处理这些录屏数据了。<br>对于VirtualDisplay来说，帧数据的生产者是MediaProjection对象，消费者是向它注册的MediaCodec的Surface对象。</p><p>在miracast投屏环节中，VirtualDisplay是何时创建的呢？<br>WFDSession.java中的notify函数中如下方式：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">                            <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">notify</span><span class="params">(Bundle b, <span class="keyword">int</span> SessionId)</span> </span>&#123;</span><br><span class="line">                            <span class="comment">//....</span></span><br><span class="line">                            Surface surface = (Surface) (b</span><br><span class="line">                                    .getParcelable(<span class="string">"surface"</span>));</span><br><span class="line">                            <span class="keyword">if</span> (surface != <span class="keyword">null</span>) &#123;</span><br><span class="line">                                Log.d(mTAG, <span class="string">"Surface supplied by source modules"</span>);</span><br><span class="line">                                <span class="keyword">int</span> flags = <span class="number">0</span>;</span><br><span class="line">                                <span class="comment">// MIUI MOD: START</span></span><br><span class="line">                                <span class="comment">//flags |= DisplayManager.VIRTUAL_DISPLAY_FLAG_PUBLIC</span></span><br><span class="line">                                <span class="comment">//        | DisplayManager.VIRTUAL_DISPLAY_FLAG_PRESENTATION;</span></span><br><span class="line">                                flags |= DisplayManager.VIRTUAL_DISPLAY_FLAG_PUBLIC</span><br><span class="line">                                        | DisplayManager.VIRTUAL_DISPLAY_FLAG_PRESENTATION</span><br><span class="line">                                        | VIRTUAL_DISPLAY_FLAG_THE_THIRD_SCREEN_PROJECTION;</span><br><span class="line">                                <span class="comment">// END</span></span><br><span class="line">                                <span class="keyword">if</span> (secure == <span class="number">1</span>) &#123;</span><br><span class="line">                                    flags |= DisplayManager.VIRTUAL_DISPLAY_FLAG_SECURE;</span><br><span class="line"><span class="comment">//                                            | DisplayManager.VIRTUAL_DISPLAY_FLAG_SUPPORTS_PROTECTED_BUFFERS;</span></span><br><span class="line">                                &#125;</span><br><span class="line">                                mVirtualDisplayDPI = Math.min(width, height)</span><br><span class="line">                                        * DisplayMetrics.DENSITY_XHIGH / <span class="number">1080</span>;</span><br><span class="line">                                <span class="keyword">if</span> (mDisplayManager != <span class="keyword">null</span>) &#123;</span><br><span class="line">                                    mVirtualDisplay = mDisplayManager</span><br><span class="line">                                            .createVirtualDisplay(</span><br><span class="line">                                                    mPeerDevice.deviceName,</span><br><span class="line">                                                    width,</span><br><span class="line">                                                    height,</span><br><span class="line">                                                    mVirtualDisplayDPI,</span><br><span class="line">                                                    surface, flags);</span><br><span class="line">                                &#125;</span><br><span class="line">                            &#125;</span><br></pre></td></tr></table></figure></p><p>当上层调用创建好WFD session后才会创建这个VirtualDisplay</p><p>Q：隐私投屏是如何实现的？如何做到有些界面在sink端不显示？</p><p>A：我们在WFDSession中createVirtualDisplay时需要传入一个flag参数，文章便在这个flag上，这里新加一个针对隐私的flag，其他界面中的window如果配置了隐私flag的话就不会显示在sink端，fwk端在VirtualDisplayAdapter#performTraversalLocked中判断当前创建的virtualdisplay是否有这个flag，有的话就使能隐私投屏功能</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;前言&lt;br&gt;主要针对高通平台上的miracast投屏遇到的问题，顺便对miracast投屏的一点归纳总结，以便后续如再处理miracast投屏相关的工作，通过本篇文章能够快速重新开始。&lt;/p&gt;
&lt;p&gt;以下主要通过一些QA方式来概述 &lt;/p&gt;
&lt;p&gt;Q：高通上的投屏和谷歌原生
      
    
    </summary>
    
      <category term="WFD" scheme="http://lihaizhou.top/categories/WFD/"/>
    
    
  </entry>
  
  <entry>
    <title>从tcpdump看miracast的play流程(工具篇)</title>
    <link href="http://lihaizhou.top/2020/11/30/%E4%BB%8Etcpdump%E7%9C%8Bmiracast%E7%9A%84play%E6%B5%81%E7%A8%8B/"/>
    <id>http://lihaizhou.top/2020/11/30/从tcpdump看miracast的play流程/</id>
    <published>2020-11-30T03:01:15.000Z</published>
    <updated>2020-11-30T03:22:29.725Z</updated>
    
    <content type="html"><![CDATA[<p>前言：<br>基于高通平台，其他平台都是类似的<br>本文作为工具篇，记录下来的目的是以便后续如再接触投屏工作能够快速对照上手</p><p>当我们开始准备连接sink设备时，开始的时候，source会创建一个socket监听着并等待sink端过来连接，sink端会触发”connect”的socket函数并开始tcp 握手之路，这个时候source接收到之后，它会触发”accept”的socket函数来处理sink发过俩的连接请求</p><p>开始是握手 Key Message #1~#4<br><img src="https://raw.githubusercontent.com/hellolihaizhou/saveImg/master/miracast-play01.png" alt=""></p><p>RTSP connect M1~M8:<br><img src="https://raw.githubusercontent.com/hellolihaizhou/saveImg/master/miracast-play02.png" alt=""></p><p>DHCP ACK<br><img src="https://raw.githubusercontent.com/hellolihaizhou/saveImg/master/miracast-play03.png" alt=""></p><p>如果这里DHCP Discover -&gt; DHCP ACK耗时超过 5s, 对于一些sink设备来说它就不会继续发 SYN 消息了 ，因此连接会阻塞在这里<br>所以如果遇到sink没有发送SYN的话就要看看这里的DHCP是否耗时太久了</p><p>SYN handshake Sink should send SYN message to 7236 port at this step:<br><img src="https://raw.githubusercontent.com/hellolihaizhou/saveImg/master/miracast-play04.png" alt=""></p><p>Get/Set parameter<br><img src="https://raw.githubusercontent.com/hellolihaizhou/saveImg/master/miracast-play05.png" alt=""></p><p>Play<br><img src="https://raw.githubusercontent.com/hellolihaizhou/saveImg/master/miracast-play06.png" alt=""></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;前言：&lt;br&gt;基于高通平台，其他平台都是类似的&lt;br&gt;本文作为工具篇，记录下来的目的是以便后续如再接触投屏工作能够快速对照上手&lt;/p&gt;
&lt;p&gt;当我们开始准备连接sink设备时，开始的时候，source会创建一个socket监听着并等待sink端过来连接，sink端会触发”c
      
    
    </summary>
    
      <category term="WFD" scheme="http://lihaizhou.top/categories/WFD/"/>
    
    
  </entry>
  
  <entry>
    <title>一次SystemServer OOM导致的系统重启分析之路</title>
    <link href="http://lihaizhou.top/2020/11/25/%E4%B8%80%E6%AC%A1SystemServer-OOM%E5%AF%BC%E8%87%B4%E7%9A%84%E7%B3%BB%E7%BB%9F%E9%87%8D%E5%90%AF%E5%88%86%E6%9E%90%E4%B9%8B%E8%B7%AF/"/>
    <id>http://lihaizhou.top/2020/11/25/一次SystemServer-OOM导致的系统重启分析之路/</id>
    <published>2020-11-25T00:59:48.000Z</published>
    <updated>2020-11-25T01:26:11.263Z</updated>
    
    <content type="html"><![CDATA[<p><strong>测试步骤</strong></p><p><code>MTBF测试(Mean Time Between Failure)</code></p><p>主要测试终端在连续工作状态下，出现死机、重启、冻屏、应用强制关闭等严重故障的概率。通过在一个周期内以自动化方式反复执行规定用例，记录测试过程中被测终端出现的故障数</p><p><strong>复现概率</strong></p><p>1/200</p><p><strong>问题现象</strong></p><p>机器出现重启</p><h1 id="初步分析"><a href="#初步分析" class="headerlink" title="初步分析"></a>初步分析</h1><p>从现象上来看，机器发生重启，从日志中看是SystemServer重启，附近有OutOfMemoryError片段打出，猜测是OOM killer起来工作，说明问题发生时候的SystemServer占据的内存已经超出限制值，并且再请求的内存已无法得到继续满足<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">11</span>-<span class="number">12</span> <span class="number">03</span>:<span class="number">26</span>:<span class="number">30.488</span>  <span class="number">1000</span>  <span class="number">2203</span>  <span class="number">5788</span> E AndroidRuntime: *** FATAL EXCEPTION IN SYSTEM PROCESS: Binder:<span class="number">2203_13</span></span><br><span class="line"><span class="number">11</span>-<span class="number">12</span> <span class="number">03</span>:<span class="number">26</span>:<span class="number">30.488</span>  <span class="number">1000</span>  <span class="number">2203</span>  <span class="number">5788</span> E AndroidRuntime: java.lang.OutOfMemoryError: Failed to allocate a <span class="number">328080</span> <span class="keyword">byte</span> allocation with <span class="number">216856</span> free bytes and <span class="number">211</span>KB until OOM, target footprint <span class="number">536870912</span>, growth limit <span class="number">536870912</span></span><br><span class="line"><span class="number">11</span>-<span class="number">12</span> <span class="number">03</span>:<span class="number">26</span>:<span class="number">30.488</span>  <span class="number">1000</span>  <span class="number">2203</span>  <span class="number">5788</span> E AndroidRuntime:  at android.util.ArrayMap.allocArrays(ArrayMap.java:<span class="number">276</span>)</span><br><span class="line"><span class="number">11</span>-<span class="number">12</span> <span class="number">03</span>:<span class="number">26</span>:<span class="number">30.488</span>  <span class="number">1000</span>  <span class="number">2203</span>  <span class="number">5788</span> E AndroidRuntime:  at android.util.ArrayMap.put(ArrayMap.java:<span class="number">596</span>)</span><br><span class="line"><span class="number">11</span>-<span class="number">12</span> <span class="number">03</span>:<span class="number">26</span>:<span class="number">30.488</span>  <span class="number">1000</span>  <span class="number">2203</span>  <span class="number">5788</span> E AndroidRuntime:  at android.service.autofill.FillContext.findViewNodesByAutofillIds(FillContext.java:<span class="number">155</span>)</span><br><span class="line"><span class="number">11</span>-<span class="number">12</span> <span class="number">03</span>:<span class="number">26</span>:<span class="number">30.488</span>  <span class="number">1000</span>  <span class="number">2203</span>  <span class="number">5788</span> E AndroidRuntime:  at com.android.server.autofill.Session.fillContextWithAllowedValuesLocked(Session.java:<span class="number">639</span>)</span><br><span class="line"><span class="number">11</span>-<span class="number">12</span> <span class="number">03</span>:<span class="number">26</span>:<span class="number">30.488</span>  <span class="number">1000</span>  <span class="number">2203</span>  <span class="number">5788</span> E AndroidRuntime:  at com.android.server.autofill.Session.access$<span class="number">1300</span>(Session.java:<span class="number">135</span>)</span><br><span class="line"><span class="number">11</span>-<span class="number">12</span> <span class="number">03</span>:<span class="number">26</span>:<span class="number">30.488</span>  <span class="number">1000</span>  <span class="number">2203</span>  <span class="number">5788</span> E AndroidRuntime:  at com.android.server.autofill.Session$AssistDataReceiverImpl.onHandleAssistData(Session.java:<span class="number">502</span>)</span><br><span class="line"><span class="number">11</span>-<span class="number">12</span> <span class="number">03</span>:<span class="number">26</span>:<span class="number">30.488</span>  <span class="number">1000</span>  <span class="number">2203</span>  <span class="number">5788</span> E AndroidRuntime:  at com.android.server.wm.ActivityTaskManagerService.reportAssistContextExtras(ActivityTaskManagerService.java:<span class="number">3332</span>)</span><br><span class="line"><span class="number">11</span>-<span class="number">12</span> <span class="number">03</span>:<span class="number">26</span>:<span class="number">30.488</span>  <span class="number">1000</span>  <span class="number">2203</span>  <span class="number">5788</span> E AndroidRuntime:  at android.app.IActivityTaskManager$Stub.onTransact(IActivityTaskManager.java:<span class="number">2484</span>)</span><br><span class="line"><span class="number">11</span>-<span class="number">12</span> <span class="number">03</span>:<span class="number">26</span>:<span class="number">30.488</span>  <span class="number">1000</span>  <span class="number">2203</span>  <span class="number">5788</span> E AndroidRuntime:  at android.os.Binder.execTransactInternal(Binder.java:<span class="number">1157</span>)</span><br><span class="line"><span class="number">11</span>-<span class="number">12</span> <span class="number">03</span>:<span class="number">26</span>:<span class="number">30.488</span>  <span class="number">1000</span>  <span class="number">2203</span>  <span class="number">5788</span> E AndroidRuntime:  at android.os.Binder.execTransact(Binder.java:<span class="number">1126</span>)</span><br><span class="line"><span class="number">11</span>-<span class="number">12</span> <span class="number">03</span>:<span class="number">26</span>:<span class="number">34.685</span>  <span class="number">1000</span>  <span class="number">2203</span>  <span class="number">5788</span> D OOMEventManagerFK: dumpheap success : /data/anr/system_server_2203.hprof</span><br><span class="line"><span class="number">11</span>-<span class="number">12</span> <span class="number">03</span>:<span class="number">26</span>:<span class="number">34.687</span>  <span class="number">1000</span>  <span class="number">2203</span>  <span class="number">5788</span> I am_crash: [<span class="number">16189</span>,<span class="number">0</span>,system_server,-<span class="number">1</span>,java.lang.OutOfMemoryError,</span><br><span class="line">Failed to allocate a <span class="number">328080</span> <span class="keyword">byte</span> allocation with <span class="number">216856</span> free bytes and <span class="number">211</span>KB until OOM, target footprint <span class="number">536870912</span>, </span><br><span class="line">growth limit <span class="number">536870912</span>,ArrayMap.java,<span class="number">276</span>]</span><br></pre></td></tr></table></figure></p><p>字面上看很好理解，申请分配328080 byte，但是实际free的只有216856  bytes，直到内存溢出OOM</p><p>关于<code>FillContext</code>的解释<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * This class represents a context for each fill request made via &#123;<span class="doctag">@link</span></span></span><br><span class="line"><span class="comment"> * AutofillService#onFillRequest(FillRequest, CancellationSignal, FillCallback)&#125;.</span></span><br><span class="line"><span class="comment"> * It contains a snapshot of the UI state, the view ids that were returned by</span></span><br><span class="line"><span class="comment"> * the &#123;<span class="doctag">@link</span> AutofillService autofill service&#125; as both required to trigger a save</span></span><br><span class="line"><span class="comment"> * and optional that can be saved, and the id of the corresponding &#123;<span class="doctag">@link</span></span></span><br><span class="line"><span class="comment"> * FillRequest&#125;.</span></span><br><span class="line"><span class="comment"> * &lt;p&gt;</span></span><br><span class="line"><span class="comment"> * This context allows you to inspect the values for the interesting views</span></span><br><span class="line"><span class="comment"> * in the context they appeared. Also a reference to the corresponding fill</span></span><br><span class="line"><span class="comment"> * request is useful to store meta-data in the client state bundle passed</span></span><br><span class="line"><span class="comment"> * to &#123;<span class="doctag">@link</span> FillResponse.Builder#setClientState(Bundle)&#125; to avoid interpreting</span></span><br><span class="line"><span class="comment"> * the UI state again while saving.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">final</span> <span class="class"><span class="keyword">class</span> <span class="title">FillContext</span> <span class="keyword">implements</span> <span class="title">Parcelable</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">int</span> mRequestId;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="meta">@NonNull</span> AssistStructure mStructure;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="meta">@NonNull</span> AutofillId mFocusedId;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * Lookup table AutofillId-&gt;ViewNode to speed up &#123;<span class="doctag">@link</span> #findViewNodesByAutofillIds&#125;</span></span><br><span class="line"><span class="comment">     * This is purely a cache and can be deleted at any time</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Nullable</span> <span class="keyword">private</span> ArrayMap&lt;AutofillId, AssistStructure.ViewNode&gt; mViewNodeLookupTable;</span><br></pre></td></tr></table></figure></p><p>代表一种context，即通过<code>AutofillService#onFillRequest(FillRequest, CancellationSignal, FillCallback)</code>构建的context</p><p>包含UI状态的快照，view的id等…..这个context允许你检查感兴趣的视图的值……</p><h1 id="MAT分析"><a href="#MAT分析" class="headerlink" title="MAT分析"></a>MAT分析</h1><p>这个时候根据上面的堆栈日志中列出的，直接去看<code>system_server_2203.hprof</code>这个文件<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">11</span>-<span class="number">12</span> <span class="number">03</span>:<span class="number">26</span>:<span class="number">34.685</span>  <span class="number">1000</span>  <span class="number">2203</span>  <span class="number">5788</span> D OOMEventManagerFK: dumpheap success : /data/anr/system_server_2203.hprof</span><br></pre></td></tr></table></figure></p><p>这个文件直接用MAT打不开，使用Android SDK中的转换工具<code>hprof-conv</code>，将hprof文件转换为标准格式，hprof-conv位于SDK的platform-tools目录下</p><p>命令格式如下：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hprof-conv A.hprof B.hprof</span><br></pre></td></tr></table></figure></p><p>在MAT中打开转换后的B.hprof文件，即可对heap信息进行进一步详细分析</p><p>关于MAT的窗口下方的Action标签功能：</p><ol><li>Histogram可以列出内存中的对象，对象的个数以及大小。</li><li>Dominator Tree可以列出那个线程，以及线程下面的那些对象占用的空间。</li><li>Top consumers通过图形列出最大的object。</li><li>Leak Suspects通过MA自动分析泄漏的原因。</li></ol><p>详细可以参见官方文档：<a href="https://help.eclipse.org/2020-09/index.jsp?topic=/org.eclipse.mat.ui.help/welcome.html" target="_blank" rel="noopener">MAT官方使用文档说明</a></p><p>可以直接使用Histogram，搜索autofill关键字，再按照<code>Retained Heap</code>排序<br><img src="https://raw.githubusercontent.com/hellolihaizhou/saveImg/master/OOM-1.png" alt=""></p><p>注：</p><ol><li>Shallow Heap ：一个对象所占用的内存，不包含对其他对象的引用</li><li>Retained Heap ：是shallow Heap的总和（单个对象占用内存*此对象的个数），也就是该对象被GC之后所能回收到内存的总和</li></ol><p>也可以通过<code>Leak Suspects</code>，会展示可能的泄漏点，第一个占据最大的就是和我们日志中对应的<code>FillContext</code>泄漏，共计650个实例被持有，一共占据达到了253M</p><p><img src="https://raw.githubusercontent.com/hellolihaizhou/saveImg/master/OOM-2.png" alt=""></p><p>点击Details后，可以看到有650个实例<br><img src="https://raw.githubusercontent.com/hellolihaizhou/saveImg/master/OOM-3.png" alt=""></p><p>随便点击一个查看引用链选择outgoing引用<br><img src="https://raw.githubusercontent.com/hellolihaizhou/saveImg/master/OOM-4.png" alt=""></p><p>其中的每一个mStructure中都包含<code>WifiConfigActivity</code>，压力测试下出现如此之多的这个Activity实例，说明很可能存在泄露<br><img src="https://raw.githubusercontent.com/hellolihaizhou/saveImg/master/OOM-5.png" alt=""></p><p>这是一个Dialog样式的Activity，但是这个Activity当初设计时存在一个弊端，就是在Activity的onResume中弹出一个Dialog，其实完全可以在Manifest中指定这个Activity为DialogActivity的样式，然后在布局文件中设计为Dialog的样式即可, 这里暂不会重新修改这个Activity的架构，目前先对这个Activity进行测试，看看是否真的会泄露</p><p>测试发现当该Dialog消失后，<code>adb shell dumpsys meminfo com.android.settings</code>打印出来的Activity实例个数并没有减少，说明存在Activity泄露。 引用链为：listener-&gt;AlertDialog-&gt;Activity ,当触碰dialog之外位置或按Home键后，因为设置应用的设计是每次启动都会从主界面开始, 这个文件在onDestory中执行的将Listener置为null并没有走</p><h1 id="修改方案"><a href="#修改方案" class="headerlink" title="修改方案"></a>修改方案</h1><p>修改方案如下：<br>新增一个文件继承自DialogInterface.OnDismissListener<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DetachWifiDialogListener</span> <span class="keyword">implements</span> <span class="title">DialogInterface</span>.<span class="title">OnDismissListener</span></span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">static</span> String TAG = DetachWifiDialogListener.class.getSimpleName();</span><br><span class="line">    <span class="keyword">private</span> Activity mActivity;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">DetachWifiDialogListener</span><span class="params">(Activity activity)</span> </span>&#123;</span><br><span class="line">        mActivity = activity;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onDismiss</span><span class="params">(DialogInterface dialog)</span> </span>&#123;</span><br><span class="line">       Log.d(TAG,<span class="string">"Dialog onDismiss"</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">clearOnDetach</span><span class="params">(Dialog dialog)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (dialog.getWindow() == <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        dialog.getWindow()</span><br><span class="line">                .getDecorView()</span><br><span class="line">                .getViewTreeObserver()</span><br><span class="line">                .addOnWindowAttachListener(<span class="keyword">new</span> ViewTreeObserver.OnWindowAttachListener() &#123;</span><br><span class="line">                    <span class="meta">@Override</span></span><br><span class="line">                    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onWindowAttached</span><span class="params">()</span> </span>&#123;</span><br><span class="line">                       Log.d(TAG, <span class="string">"dialog Attached to Window"</span>);</span><br><span class="line">                    &#125;</span><br><span class="line">                    <span class="meta">@Override</span></span><br><span class="line">                    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onWindowDetached</span><span class="params">()</span> </span>&#123;</span><br><span class="line">                        Log.d(TAG,<span class="string">"dialog Detached to Window"</span>);</span><br><span class="line">                        <span class="keyword">if</span>(mActivity != <span class="keyword">null</span>) &#123;</span><br><span class="line">                           mActivity.finish();</span><br><span class="line">                           mActivity = <span class="keyword">null</span>;</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>在弹出Dialog后执行clearOnDetach，及时的将Activity finish掉，并且在onPause中(这里因为此处场景特殊，一般在onDestory中)将Listener置空<br>目的是剪断这个引用链<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">dismissListener = <span class="keyword">new</span> DetachWifiDialogListener(mWifiConfigActivity.get());</span><br><span class="line"><span class="comment">//....</span></span><br><span class="line">mDialog.show();</span><br><span class="line">dismissListener.clearOnDetach(mDialog);</span><br></pre></td></tr></table></figure></p><p>本地测试下来，<code>dumpsys meminfo</code>出的Activity实例个数在Dialog消失后会减少，说明不存在内存泄露了</p><h1 id="常见示例"><a href="#常见示例" class="headerlink" title="常见示例"></a>常见示例</h1><p>再例举一个最常见的非静态内部类Handler泄漏例子，延迟发送一个消息，此时在消息处理之前退出该界面，就会存在该Activity泄漏的情形</p><p>此时在onDestory内执行<code>removeCallbacksAndMessages</code>，这样的话每次退出界面后就会清空该handler上所有的callback和消息，这样就不会存在<code>MessageQueue-&gt;Handler-&gt;Activity</code>这个引用链</p><p><img src="https://raw.githubusercontent.com/hellolihaizhou/saveImg/master/OOM-6.png" alt=""></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;strong&gt;测试步骤&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;MTBF测试(Mean Time Between Failure)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;主要测试终端在连续工作状态下，出现死机、重启、冻屏、应用强制关闭等严重故障的概率。通过在一个周期内以自动化方
      
    
    </summary>
    
      <category term="性能" scheme="http://lihaizhou.top/categories/%E6%80%A7%E8%83%BD/"/>
    
    
  </entry>
  
  <entry>
    <title>MediaCodec的学习之路(一)</title>
    <link href="http://lihaizhou.top/2020/11/06/MediaCodec%E7%9A%84%E5%AD%A6%E4%B9%A0%E4%B9%8B%E8%B7%AF-%E4%B8%80/"/>
    <id>http://lihaizhou.top/2020/11/06/MediaCodec的学习之路-一/</id>
    <published>2020-11-06T07:21:02.000Z</published>
    <updated>2020-11-06T08:13:41.357Z</updated>
    
    <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>MediaPlayer这个接口很多人都用过，位于APP层属于封装比较深的接口，使用上只要遵循开发者文档调用即可，创建播放器对象，注入URL，播放，播放完毕之后release等，这一层纯粹的就是API调用，应用开发者完全不用了解其实现细节。但是MediaPlayer对于视频编解码协议支持较少，只提供三种媒体格式：MP4、3GPP 和 MKV（从Android 4.0开始）。<br>为了播放不支持的格式，许多开发人员使用了FFmpeg软件解码器，本文暂不讨论软解，MediaPlayer还有一点弊端就是深度封装导致不好扩展，比如自定义缓冲的大小，下载进度等，当出现一些奇奇怪怪的接口自身问题也不好debug，因为这玩意很多方法稍微一跟就会发现都是native方法</p><p>MediaPlayer本身的实现对开发者是完全透明的，应付普通要求不高的业务还可以，比如只是单纯的播放本地或服务器视频，但是很多时候业务上需要扩展，这个时候就跟不上业务对播放器的需求了。MediaCodec 则具备很高的拓展性，支持的协议较多，我们可以根据流媒体的协议和设备硬件本身来自定义硬件解码<br>关于MediaCodec的资料网上一抓一大把，建议直接先看谷歌开发者文档 ，源码MediaCodec.java这个文件的开头注释多达一千多行也可以看下</p><h1 id="谷歌开发者文档阅读笔记"><a href="#谷歌开发者文档阅读笔记" class="headerlink" title="谷歌开发者文档阅读笔记"></a>谷歌开发者文档阅读笔记</h1><h2 id="MediaCodec的定义"><a href="#MediaCodec的定义" class="headerlink" title="MediaCodec的定义"></a>MediaCodec的定义</h2><p><a href="https://developer.android.google.cn/reference/android/media/MediaCodec" target="_blank" rel="noopener">谷歌开发者文档关于MediaCodec的定义</a></p><p><code>MediaCodec class can be used to access low-level media codecs, i.e. encoder/decoder components.It is part of the Android low-level multimedia support infrastructure (normally used together with MediaExtractor, MediaSync, MediaMuxer, MediaCrypto, MediaDrm, Image, Surface, and AudioTrack.)</code></p><p><img src="https://raw.githubusercontent.com/hellolihaizhou/saveImg/master/MediaCodec1_1_MediaPlayerFactory.png" alt=""></p><p><code>In broad terms, a codec processes input data to generate output data. It processes data asynchronously and uses a set of input and output buffers. At a simplistic level, you request (or receive) an empty input buffer, fill it up with data and send it to the codec for processing. The codec uses up the data and transforms it into one of its empty output buffers. Finally, you request (or receive) a filled output buffer, consume its contents and release it back to the codec.</code><br>上面说的很简单，看下上面的图就明白了</p><h2 id="Data-Types"><a href="#Data-Types" class="headerlink" title="Data Types"></a>Data Types</h2><p><code>Codecs operate on three kinds of data: compressed data, raw audio data and raw video data. All three kinds of data can be processed using ByteBuffer, but you should use a Surface for raw video data to improve codec performance. Surface uses native video buffers without mapping or copying them to ByteBuffers; thus, it is much more efficient.</code></p><p><code>You normally cannot access the raw video data when using a Surface, but you can use the ImageReader class to access unsecured decoded (raw) video frames. This may still be more efficient than using ByteBuffers, as some native buffers may be mapped into ByteBuffer#isDirect ByteBuffers. When using ByteBuffer mode, you can access raw video frames using the Image class and getInput/OutputImage(int).</code></p><p>这段主要说的是支持的数据类型，初看之后有点云里雾里，不用担心，实操后自然会明白，大致的翻译如下</p><p>编解码器可以处理三种类型的数据：</p><ol><li>压缩数据（即为经过H254. H265. 等编码的视频数据或AAC等编码的音频数据）    </li><li>原始音频数据</li><li>原始视频数据。</li></ol><p>三种类型的数据均可以利用ByteBuffers进行处理，但是对于原始视频数据应提供一个Surface以提高编解码器的性能。Surface直接使用本地视频数据缓存（native video buffers），而没有映射或复制数据到ByteBuffers，因此，这种方式会更加高效。</p><p>在使用Surface的时候，通常不能直接访问原始视频数据，但是可以使用ImageReader类来访问非安全的解码（原始）视频帧。这仍然比使用ByteBuffers更加高效，因为一些本地缓存（native buffer）可以被映射到 direct ByteBuffers。当使用ByteBuffer模式，你可以利用Image类和getInput/OutputImage(int)方法来访问到原始视频数据帧</p><p>开发者文档上对这三种数据类型分别进行了介绍，光看没多大意思，这里跳过，实践时自然会明白</p><h2 id="States"><a href="#States" class="headerlink" title="States"></a>States</h2><p><code>During its life a codec conceptually exists in one of three states: Stopped, Executing or Released.The Stopped collective state is actually the conglomeration of three states: Uninitialized, Configured and Error,whereas the Executing state conceptually progresses through three sub-states: Flushed, Running and End-of-Stream.</code></p><p><img src="https://raw.githubusercontent.com/hellolihaizhou/saveImg/master/MediaCodec1_2.png" alt=""></p><p>后面有一段是对上面生命周期的描述，比较好理解，快速浏览下即可，大致翻译如下<br><strong>在编解码器的生命周期内有三种理论状态</strong><br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">停止态-Stopped、执行态-Executing、释放态-Released</span><br></pre></td></tr></table></figure></p><p>停止状态（Stopped）包括了三种子状态：<br><code>未初始化（Uninitialized）</code>、<code>配置（Configured）</code>、<code>错误（Error）</code>。<br>执行状态（Executing）在概念上会经历三种子状态：<br><code>刷新（Flushed）</code>、<code>运行（Running）</code>、<code>流结束（End-of-Stream）</code></p><p>当你使用任意一种工厂方法（factory methods）创建了一个编解码器，此时编解码器处于未初始化状态（Uninitialized）。首先，你需要使用configure(…)方法对编解码器进行配置，这将使编解码器转为配置状态（Configured）。然后调用start()方法使其转入执行状态（Executing）。在这种状态下你可以通过上述的缓存队列操作处理数据。<br><strong>执行状态（Executing）包含三个子状态</strong><br><code>刷新（Flushed）</code>、<code>运行（ Running）</code> 以及<code>流结束（End-of-Stream）</code>。</p><ol><li>在调用start()方法后编解码器立即进入刷新子状态（Flushed），此时编解码器会拥有所有的缓存。一旦第一个输入缓存（input buffer）被移出队列，编解码器就转入运行子状态（Running），编解码器的大部分生命周期会在此状态下度过。当你将一个带有end-of-stream 标记的输入缓存入队列时，编解码器将转入流结束子状态（End-of-Stream）。在这种状态下，编解码器不再接收新的输入缓存，但它仍然产生输出缓存（output buffers）直到end-of- stream标记到达输出端。你可以在执行状态（Executing）下的任何时候通过调用flush()方法使编解码器重新返回到刷新子状态（Flushed）。</li><li>通过调用stop()方法使编解码器返回到未初始化状态（Uninitialized），此时这个编解码器可以再次重新配置 。当你使用完编解码器后，你必须调用release()方法释放其资源。<br>在极少情况下编解码器会遇到错误并进入错误状态（Error）。这个错误可能是在队列操作时返回一个错误的值或者有时候产生了一个异常导致的。通过调用 reset()方法使编解码器再次可用。你可以在任何状态调用reset()方法使编解码器返回到未初始化状态（Uninitialized）。否则，调用 release()方法进入最终的Released状态</li></ol><h2 id="数据处理"><a href="#数据处理" class="headerlink" title="数据处理"></a>数据处理</h2><p>每一个编解码器都包含一组输入和输出缓存（input and output buffers），这些缓存在API调用中通过buffer-id进行引用。当成功调用start()方法后客户端将不会“拥有”输入或输出buffers。在同步模式下，通过调用dequeue Input/OutputBuffer(…) 方法从编解码器获得一个输入或输出buffer的所有权。在异步模式下，你可以通过MediaCodec.Callback.onInput/OutputBufferAvailable(…)的回调方法自动地获得可用的buffers。</p><p>在获得一个输入buffer后，向其中填充数据，并利用queueInputBuffer方法将其提交给编解码器，若使用解密，则利用queueSecureInputBuffer方法提交。不要提交多个具有相同时间戳的输入buffers（除非它是也被同样标记的codec-specific data）。</p><p>在异步模式下通过onOutputBufferAvailable方法的回调或者在同步模式下响应dequeueOutputBuffer的调用，编解码器返回一个只读的output buffer。在这个output buffer被处理后，调用一个releaseOutputBuffer方法将这个buffer返回给编解码器。</p><p>当你不需要立即向编解码器重新提交或释放buffers时，保持对输入或输出buffers的所有权可使编解码器停止工作，当然这些行为依赖于设备情况。特别地，编解码器可能延迟产生输出buffers直到输出的buffers被释放或重新提交。因此，尽可能短时间地持有可用的buffers。根据API版本情况，你有三种处理相关数据的方式：</p><ol><li>Synchronous API using buffer arrays(Android 5.0之前，之后弃用)</li><li>Synchronous API using buffers(适用于Android 5.0之后)</li><li>Asynchronous API using buffers(适用于Android 5.0之后)</li></ol><p><strong>使用缓存的异步处理方式(Asynchronous Processing using Buffers)</strong></p><p>从Android 5.0（LOLLIPOP）开始，首选的方法是调用configure之前通过设置回调异步地处理数据。异步模式稍微改变了状态转换方式，因为你必须在调用flush()方法后再调用start()方法才能使编解码器的状态转换为Running子状态并开始接收输入buffers。同样，初始调用start方法将编解码器的状态直接变化为Running 子状态并通过回调方法开始传递可用的输入buffers。</p><p>异步模式下，典型的使用示例如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">MediaCodec codec = MediaCodec.createByCodecName(name);</span><br><span class="line"> MediaFormat mOutputFormat; <span class="comment">// member variable</span></span><br><span class="line"> codec.setCallback(<span class="keyword">new</span> MediaCodec.Callback() &#123;</span><br><span class="line">   <span class="meta">@Override</span></span><br><span class="line">   <span class="function"><span class="keyword">void</span> <span class="title">onInputBufferAvailable</span><span class="params">(MediaCodec mc, <span class="keyword">int</span> inputBufferId)</span> </span>&#123;</span><br><span class="line">     ByteBuffer inputBuffer = codec.getInputBuffer(inputBufferId);</span><br><span class="line">     <span class="comment">// fill inputBuffer with valid data</span></span><br><span class="line">     …</span><br><span class="line">     codec.queueInputBuffer(inputBufferId, …);</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">   <span class="meta">@Override</span></span><br><span class="line">   <span class="function"><span class="keyword">void</span> <span class="title">onOutputBufferAvailable</span><span class="params">(MediaCodec mc, <span class="keyword">int</span> outputBufferId, …)</span> </span>&#123;</span><br><span class="line">     ByteBuffer outputBuffer = codec.getOutputBuffer(outputBufferId);</span><br><span class="line">     MediaFormat bufferFormat = codec.getOutputFormat(outputBufferId); <span class="comment">// option A</span></span><br><span class="line">     <span class="comment">// bufferFormat is equivalent to mOutputFormat</span></span><br><span class="line">     <span class="comment">// outputBuffer is ready to be processed or rendered.</span></span><br><span class="line">     …</span><br><span class="line">     codec.releaseOutputBuffer(outputBufferId, …);</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">   <span class="meta">@Override</span></span><br><span class="line">   <span class="function"><span class="keyword">void</span> <span class="title">onOutputFormatChanged</span><span class="params">(MediaCodec mc, MediaFormat format)</span> </span>&#123;</span><br><span class="line">     <span class="comment">// Subsequent data will conform to new format.</span></span><br><span class="line">     <span class="comment">// Can ignore if using getOutputFormat(outputBufferId)</span></span><br><span class="line">     mOutputFormat = format; <span class="comment">// option B</span></span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">   <span class="meta">@Override</span></span><br><span class="line">   <span class="function"><span class="keyword">void</span> <span class="title">onError</span><span class="params">(…)</span> </span>&#123;</span><br><span class="line">     …</span><br><span class="line">   &#125;</span><br><span class="line"> &#125;);</span><br><span class="line"> codec.configure(format, …);</span><br><span class="line"> mOutputFormat = codec.getOutputFormat(); <span class="comment">// option B</span></span><br><span class="line"> codec.start();</span><br><span class="line"> <span class="comment">// wait for processing to complete</span></span><br><span class="line"> codec.stop();</span><br><span class="line"> codec.release();</span><br></pre></td></tr></table></figure><p>开发者文档上还介绍了一种同步模式的代码示例，这里不copy过来了<br>上面这段个人理解下来：<br><code>在API21之前，MediaCodec的解码需要上层自己来控制时序，主动调用enqueInputbuffer以及dequeueOutputbuffer同步的主流程是在一个循环内不断调用dequeueInputBuffer -&gt; queueInputBuffer填充数据 -&gt; dequeueOutputBuffer -&gt; releaseOutputBuffer显示画面在API21之后引入了像上面的这种callback之后，就不需要自己控制时序了，设置callback即可，底层会在buffer就绪的时候回调上层，设置的callback会触发，所以上层只需要被动的在onOutputBufferAvailable或者onInputBufferAvailable中做处理，当inuput buffer可用时，就把MediaExtractor提取的数据填充给指定buffer；当output buffer可用时，决定是否显示该帧（实际应用中，不会立即显示它，而是要根据fps控制显示速度）</code></p><p>关于开发者文档上关于MediaCodec就介绍到这里，快速稍微浏览下就可以了，没必要细看，当作查阅文档即可</p><p><strong>MediaCodec在Android上的实现</strong></p><p>与Android其他API类似，MediaCodec主要分为API、JNI、Native、Server四个部分。</p><p>本文主要分析其API、JNI、Native三部分的结构，也就是在客户进程中运行的代码。</p><p>MediaCodec源码的主要结构如下：</p><p><img src="https://raw.githubusercontent.com/hellolihaizhou/saveImg/master/MediaCodec1_3.png" alt=""></p><p>应用代码编写时使用的是java层MediaCodec的接口。这里主要是通过JNI调用Native代码。</p><p>进入JNI代码后，主要与JMediaCodec打交道，JMediaCodec负责调用MediaCodec(c++)的方法。</p><p>在MediaCodec(c++)和ACodec中包含了解码器（客户端）的主要逻辑。最后ACodec作为MediaCodec与OMX的桥梁，负责调用OMX服务端的功能</p><p>具体源码分析自行参阅源码即可，网上看到一篇分析源码还不错的：<a href="https://zhuanlan.zhihu.com/p/47129044" target="_blank" rel="noopener">MediaCodec源码浅析</a></p><p>有了上面这些理论基础之后，其实对于MediaCodec的工程级还远远不够，我们前面其实也提到了MediaCodec其实只是编解码，还需要配合其他的一些API的使用才行。</p><p>诸如MediaExtractor，MediaCodecList等，还有很多的播放问题需要关注：视频诸多封装的兼容性、音视频同步、播放速率控制、视频详细信息的获取、csd配置、seek处理等。</p><p>这些问题的处理往往依靠MediaExtractor和MediaCodec的组合是不足以处理的。</p><p>这些知识点零散且多，很多坑往往只有踩了才会理解深刻，单单看别人示例代码还有理论知识是没有多大意义</p><p>下一篇文章将继续MediaCodec的分析，通过实际的案例谷歌开源项目ExoPlayer进一步的理解其使用</p><h1 id="Ref"><a href="#Ref" class="headerlink" title="Ref:"></a>Ref:</h1><p><a href="https://developer.android.google.cn/reference/android/media/MediaCodec" target="_blank" rel="noopener">谷歌开发者文档</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h1&gt;&lt;p&gt;MediaPlayer这个接口很多人都用过，位于APP层属于封装比较深的接口，使用上只要遵循开发者文档调用即可，创建播放器对象，注入URL，
      
    
    </summary>
    
      <category term="音视频" scheme="http://lihaizhou.top/categories/%E9%9F%B3%E8%A7%86%E9%A2%91/"/>
    
    
  </entry>
  
  <entry>
    <title>对SurfaceView原理性内容的一点回顾</title>
    <link href="http://lihaizhou.top/2020/10/31/%E5%AF%B9SurfaceView%E5%8E%9F%E7%90%86%E6%80%A7%E5%86%85%E5%AE%B9%E7%9A%84%E4%B8%80%E7%82%B9%E5%9B%9E%E9%A1%BE/"/>
    <id>http://lihaizhou.top/2020/10/31/对SurfaceView原理性内容的一点回顾/</id>
    <published>2020-10-31T06:58:46.000Z</published>
    <updated>2020-10-31T07:21:17.550Z</updated>
    
    <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>之前使用SurfaceView主要就是绘制动画配合canvas还有配合mediaplayer播放视频做引导页，时间间隔比较久了，当时只是api的调用，对其原理没有仔细看过。最近在看音视频这方面的内容，频频看到SurfaceView的身影。<br>打算再回顾一下，不会对如何使用做过多介绍，使用上很简单，可以参见开发者文档的API介绍，本文侧重对其原理进行介绍，温故而知新</p><p>在StackOverflow上搜索到这样的一个提问 Difference between SurfaceView and View?</p><p>下面的最佳评论是：<br><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Views are all drawn on the same GUI thread which is also used <span class="keyword">for</span> all user interaction.</span><br><span class="line">So <span class="keyword">if</span> you need to update GUI rapidly or <span class="keyword">if</span> the rendering takes too much time and affects user experience then use SurfaceView.</span><br></pre></td></tr></table></figure></p><p>大意说的是View是绘制在主线程的，如果需要频繁绘制界面或者比较复杂耗时的不妨试试<code>SurfaceView</code></p><p>SurfaceView出现最早，解决类似视频播放的问题，可以用单独一个线程来渲染UI，对一些游戏、视频等性能相关的应用非常有益，因为它不会影响主线程对事件的响应。但也有缺点，因为这个Surface不在View hierarchy中，它的显示也不受View的属性控制，所以不能进行平移、缩放等变换，也不能放在其它ViewGroup中，一些View的特性也无法使用。需要注意的是SurfaceHolder.Callback的所有回调方法都是在主线程中回调的。</p><h1 id="概念简介"><a href="#概念简介" class="headerlink" title="概念简介"></a>概念简介</h1><p>Surface官方介绍:<br><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Handle onto a raw buffer that is being managed by the screen compositor.</span><br></pre></td></tr></table></figure></p><p>意思就是Surface是一个raw buffer的句柄,我们可以通过它在raw buffer上进行绘制．</p><p>对应到代码其实就是可以通过Surface获得一个Canvas:<br><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Canvas canvas = mSurface.lockCanvas(<span class="literal">null</span>);</span><br><span class="line"><span class="comment">//使用Canvas进行绘制</span></span><br><span class="line">mSurface.unlockCanvasAndPost(canvas);</span><br></pre></td></tr></table></figure></p><p>而SurfaceView其实就是对Surface进行了一次封装,它内部帮我们管理了一个Surface．我们使用SurfaceView其实最终都是获取到这个Surface去绘制．绘制啥的其实都是在canvas上画的</p><p><strong>SurfaceView、SurfaceHolder、Surface的关系可概括为以下几点</strong><br><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1.</span> SurfaceView是拥有独立绘图层的特殊View，它具有两个Surface，也就是我们所说的双缓冲机制</span><br><span class="line"><span class="number">2.</span> Surface就是指SurfaceView所拥有的那个绘图层，其实它就是内存中的一段绘图缓冲区。它是在SurfaceView所在的<span class="built_in">window</span>可见时创建的，可使用SurfaceHolder.addCallback方法监听Surface的创建与销毁的事件</span><br><span class="line"><span class="number">3.</span> SurfaceHolder是Surface的持有者，SurfaceView通过SurfaceHolder对Surface进行管理控制</span><br></pre></td></tr></table></figure></p><h1 id="View和SurfaceView的差异"><a href="#View和SurfaceView的差异" class="headerlink" title="View和SurfaceView的差异"></a>View和SurfaceView的差异</h1><ol><li>普通View绘制：<br>我们知道View是通过刷新来重绘视图，系统通过发出Vsync信号来进行屏幕的重绘，刷新的时间间隔的话对于60hz屏来说是大概16ms,如果我们可以在16ms以内将绘制工作完成，则没有任何问题，如果我们绘制过程某一些帧耗时较长，则这个时候就有可能会出现掉帧的现象，表现出来的话就是界面有卡顿，影响用户体验</li><li>SurfaceView绘制：SurfaceView的出现正是Android推出用来解决上面问题的<br>看开发者文档上关于SurfaceView的介绍就知道SurfaceView继承自View，所以它本质也是一个 View 组件，可用于在 View 层次结构中嵌入其他合成层。SurfaceView 采用与其他 View 相同的布局参数，因此可以像对待其他任何 View 一样对其进行操作，但 SurfaceView 的内容是透明的。<br>SurfaceView提供了一个专有的Surface来进行绘制，因为不与宿主Windows共用一个Surface，所以可以不在主线程里面进行绘制，在实现复杂的UI同时不会影响到主线程的响应。</li></ol><p><strong>常见使用场景有相机，视频，需要频繁刷新的动画（游戏）</strong></p><p>SurfaceView一个主要目的是可以在第二线程渲染内容，所以要注意：</p><ol><li>SurfaceView与SurfaceHolder.Callback均运行在主线程，在其他线程渲染要注意同步</li><li>要在Surface有效的情况下进行绘制（SurfaceHolder.Callback#surfaceCreated - SurfaceHolder.Callback#surfaceDestroyed）</li></ol><p>SurfaceView和普通View最大的区别归纳就是一句话：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">最显著的区别就是普通view和它的宿主窗口共享一个绘图表面（Surface），SurfaceView虽然也在View的树形结构中，但是它有属于自己的绘图Surface，Surface 内部持有一个Canvas，可以利用这个Canvas绘制。</span><br></pre></td></tr></table></figure></p><p>还有一个区别是：<br>SurfaceView的窗口刷新的时候不需要重绘应用程序的窗口而android普通窗口的视图绘制机制是一层一层的，任何一个子元素或者是局部的刷新都会导致整个视图结构全部重绘一次。</p><p>还有一个非常类似的名词就是<code>GLSurfaceView</code><br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">GLSurfaceView是继承子SurfaceView的子类，SurfaceView相比view，最重要的区别是SurafaceView上是自己通过SurfaceFlinger创建了Layer，可以通过各种渲染方法对Surface操作后，直接推送给SurfaceFlinger合成。</span><br><span class="line"></span><br><span class="line">因此，SurfaceView的刷新属于主动刷新，与view不同，view刷新需要等VSYNC之后，才进行绘制操作，进行刷新。GLSurfaceView相比SurfaceView，自己内部已经包含了GLThread线程，不需要自己再创建渲染线程。</span><br><span class="line"></span><br><span class="line">GLSurfaceView在是实现上创建了整套的EGL的环境，因此，我们在渲染的时候，直接使用EGL的操作即可。GLSurfaceView最终的绘制结果，也是绑定到SurfaceView上的</span><br></pre></td></tr></table></figure></p><h2 id="SurfaceView所谓的“挖洞”原理"><a href="#SurfaceView所谓的“挖洞”原理" class="headerlink" title="SurfaceView所谓的“挖洞”原理"></a>SurfaceView所谓的“挖洞”原理</h2><p>SurfaceView里面镶嵌的Surface是在包含SurfaceView的宿主Activity窗口（顶层视图对应的Surface）后面，用来描述SurfaceView的Layer的Z轴位置是小于用来描述其宿主Activity窗口的Layer的Z轴位置的，这样SurfaceView的Layer就被挡住看不见了，SurfaceView提供了一个可见区域，只有在这个可见区域内的surface部分内容才可见，就好像SurfaceView会在宿主Activity窗口上面挖一个“洞”出来，以便它的UI可以漏出来对用户可见，实际上，SurfaceView只不过是在其宿主Activity窗口上设置了一块透明区域</p><p><img src="https://raw.githubusercontent.com/hellolihaizhou/saveImg/master/surfaceView-1.png" alt=""></p><p><img src="https://raw.githubusercontent.com/hellolihaizhou/saveImg/master/SurfaceView-2.jpeg" alt=""></p><p>如上Activity窗口的顶层视图DecorView及其两个TextView控件都是通过窗口的Surface对应的Canvas绘制在SurfaceFlinger服务中的同一个Layer上，而SurfaceView的UI是通过其自己的Surface对应的Canvas绘制在SurfaceFlinger服务中的另外一个Layer上。</p><p>要了解 SurfaceView ，还须了解它的另外两个组件：Surface 和 SurfaceHolder<br>他们三者之间的关系实质上就是<code>MVC</code>，Model就是数据模型的意思也就是这里的Surface；View即视图也就是这里的SurfaceView；SurfaceHolder很明显可以理解为Controller（控制器）。</p><p>在SurfaceView中你可以通过SurfaceHolder接口访问它内部的surface，而我们执行绘制的方法就是操作这个 Surface内部的Canvas，处理Canvas画的效果和动画，大小，像素等，getHolder()方法可以得到这个SurfaceHolder，通过SurfaceHolder来控制surface的尺寸和格式，或者修改监视surface的变化等等</p><p>SurfaceHolder有三个回调方法可以监听SurfaceView中的surface的生命周期，SurfaceView一开始创建出来后，它拥有的Surface不一定会一起创建出来，SurfaceView变得可见时，surface被创建，SurfaceView隐藏前，surface被销毁，被创建了表示可以开始准备绘制了，而被销毁后我们要释放其他资源，Surfaceview一般会继承SurfaceHolder的Callback接口，SurfaceHolder.Callback具有如下的方法：<br>   surfaceCreated(SurfaceHolder holder)：当Surface第一次创建后会立即调用该函数，可以在该函数中做些和绘制界面相关的初始化工作，一般情况下都是在新线程来绘制界面，所以不要在这个函数中绘制Surface。<br>   surfaceChanged(SurfaceHolder holder, int format, int width,int height)：当Surface的状态（大小和格式）发生变化的时候会调用该函数，在surfaceCreated调用后该函数至少会被调用一次。<br>   surfaceDestroyed(SurfaceHolder holder)：当Surface被摧毁前会调用该函数，该函数被调用后就不能继续使用Surface了，一般在该函数中来清理使用的资源。 </p><p>特别需要注意的是SurfaceView和SurfaceHolder.Callback的所有回调方法都是在主线程中回调的，在绘制前必须先合法的获取 Surface 才能开始绘制内容， SurfaceHolder.Callback.surfaceCreated() 和 SurfaceHolder.Callback.surfaceDestroyed() 之间的状态为合法的，在这之外使用Surface都会出错。</p><p>在使用SurfaceView过程中是不直接和Surface打交道的，由SurfaceHolder的Canvas lockCanvas()或则Canvas lockCanvas(Rect dirty)函数来锁定并且获取Surface中的Canvas画布对象，通过在Canvas上绘制内容来修改Surface中的数据，如果Surface被别的线程占有不可编辑或则尚未创建或者已经被销毁，调用该函数会返回null。</p><h2 id="SurfaceView双缓冲区"><a href="#SurfaceView双缓冲区" class="headerlink" title="SurfaceView双缓冲区"></a>SurfaceView双缓冲区</h2><p>SurfaceView 在更新视图时用到了两张 Canvas对应于两个 Surface，一张 frontCanvas 和一张 backCanvas，每次实际显示的是 frontCanvas，backCanvas 存储的是上一次更改前的视图，当使用 lockCanvas() 获取画布时，得到的实际上是 backCanvas 而不是正在显示的 frontCanvas，之后你在获取到的 backCanvas 上绘制新视图，再 unlockCanvasAndPost(Canvas) 此视图，那么上传的这张 Canvas将替换原来的 frontCanvas 作为新的 frontCanvas，原来的 frontCanvas 将切换到后台作为 backCanvas。例如，如果你已经先后两次绘制了视图 A 和 B，那么你再调用 lockCanvas() 获取视图，获得的将是 A 而不是正在显示的 B，之后你将重绘的 C 视图上传，那么 C 将取代 B 作为新的 frontCanvas 显示在 SurfaceView 上，原来的 B 则转换为 backCanvas。</p><h2 id="如何选择？"><a href="#如何选择？" class="headerlink" title="如何选择？"></a>如何选择？</h2><p>谷歌官方：在 API 24 及更高版本中，建议实现 SurfaceView 而不是 TextureView。</p><p>根据谷歌官方的建议，api 24及以上的版本使用 SurfaceView 而在其他版本的话可以根据二者的特性选择对应的控件。下表为二者正常情况下一些参数的对比情况(仅供参考)。</p><p><img src="https://raw.githubusercontent.com/hellolihaizhou/saveImg/master/SurfaceView-3.png" alt=""></p><p>从性能和安全性角度出发，使用播放器优先选SurfaceView。</p><ol><li><p>在android 7.0上系统surfaceview的性能比TextureView更有优势，支持对象的内容位置和包含的应用内容同步更新，平移、缩放不会产生黑边。 在7.0以下系统如果使用场景有动画效果，可以选择性使用TextureView</p></li><li><p>由于失效(invalidation)和缓冲的特性，TextureView增加了额外1~3帧的延迟显示画面更新</p></li><li><p>TextureView总是使用GL合成，而SurfaceView可以使用硬件overlay后端，可以占用更少的内存带宽，消耗更少的能量</p></li><li><p>TextureView的内部缓冲队列导致比SurfaceView使用更多的内存</p></li><li><p>SurfaceView： 内部自己持有surface，surface 创建、销毁、大小改变时系统来处理的，通过surfaceHolder 的callback回调通知。当画布创建好时，可以将surface绑定到MediaPlayer中。SurfaceView如果为用户可见的时候，创建SurfaceView的SurfaceHolder用于显示视频流解析的帧图片，如果发现SurfaceView变为用户不可见的时候，则立即销毁SurfaceView的SurfaceHolder，以达到节约系统资源的目的</p></li></ol><h1 id="参考文章："><a href="#参考文章：" class="headerlink" title="参考文章："></a>参考文章：</h1><p><a href="https://juejin.im/entry/6844903465261465613" target="_blank" rel="noopener">https://juejin.im/entry/6844903465261465613</a><br><a href="https://www.jianshu.com/p/b037249e6d31" target="_blank" rel="noopener">https://www.jianshu.com/p/b037249e6d31</a><br><a href="https://www.jianshu.com/p/90a75b9b7115" target="_blank" rel="noopener">https://www.jianshu.com/p/90a75b9b7115</a></p><p><a href="https://blog.csdn.net/u010126792/article/details/86249399" target="_blank" rel="noopener">https://blog.csdn.net/u010126792/article/details/86249399</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h1&gt;&lt;p&gt;之前使用SurfaceView主要就是绘制动画配合canvas还有配合mediaplayer播放视频做引导页，时间间隔比较久了，当时只是ap
      
    
    </summary>
    
      <category term="Android" scheme="http://lihaizhou.top/categories/Android/"/>
    
    
  </entry>
  
  <entry>
    <title>臭名昭著的bufferbloat</title>
    <link href="http://lihaizhou.top/2020/08/27/%E8%87%AD%E5%90%8D%E6%98%AD%E8%91%97%E7%9A%84bufferbloat/"/>
    <id>http://lihaizhou.top/2020/08/27/臭名昭著的bufferbloat/</id>
    <published>2020-08-27T09:47:35.000Z</published>
    <updated>2020-08-27T10:05:24.457Z</updated>
    
    <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>之前看tcp拥塞算法时了解过bufferbloat，明白网络设备的缓冲区是为了让丢包尽量晚点到来，但是大的缓冲区又加重了延时。<br>知乎有一个问题：<br>既然害怕缓冲区膨胀，为啥现在的路由器缓冲区要弄这么大？<br>本文参考很多网络上优秀的文章，希望借此能够比较全面的了解下bufferbloat</p><h1 id="出现背景"><a href="#出现背景" class="headerlink" title="出现背景"></a>出现背景</h1><p>1980s 以来，基于遗失 (Loss-based) 一直作为拥塞控制的算法标准，并沿用至今 (e.g., 慢启动、拥塞避免、快速重送/恢复)。<br>为使拥塞控制正常运作，必须及时回馈封包遗失的信息，使传送端能选择合适的传输速率。<br>随著科技进步，内存价格下跌，处处充满了大型缓冲区的网路设备，这对基于遗失的拥塞控制算法造成巨大的问题。<br>大型的缓存区使数据包不易被丢弃，而是在队列中缓慢地等待，TCP 传送端并不知道拥塞的发生，仍持续成长传输速率，<br>使网路产生高延迟、吞吐量下降的恶性循环，这就是恶名昭彰的 — — 缓冲区膨胀 (bufferbloat)</p><p><strong>摘抄维基百科上关于bufferbloat的定义</strong></p><p>缓冲膨胀是一种因数据包过度缓冲而引起的数据包交换网络高延迟原因。缓冲膨胀还可能导致数据包延迟变化（也称为抖动），并降低整体网络吞吐量。当路由器或交换机配置了过大的缓冲区时，对于许多交互式应用程序，例如IP语音（VoIP），在线游戏，甚至普通的网页浏览，即使是非常高速的网络也几乎无法使用。</p><p>一些通信设备制造商在他们的某些网络产品中不必要地设计了过大的缓冲区。在这种设备中，当网络链路拥塞时，就会发生缓冲膨胀，从而导致数据包在这些超大缓冲区中长时间排队。在先进先出队列系统中，过大的缓冲区会导致更长的队列和更高的延迟，并且不会提高网络吞吐量。</p><p>早在1985年就已经有人发现并描述了这种缓冲膨胀现象。从2009年开始，它受到了越来越广泛的关注</p><p>大多数TCP拥塞控制算法都依靠测量丢包的发生来确定连接两端之间的可用带宽。该算法会加快数据传输速度，直到数据包开始丢失，然后降低传输速率。理想情况下，他们会不断调整传输速率，直到达到链路的平衡速度为止。为了使算法能够选择合适的传输速度，必须及时收到有关丢包的反馈。使用已满的大缓冲区时，数据包虽然最后会到达目的地，但延迟较高。因为数据包没有丢失，所以即使上行链路饱和，TCP也不会减慢速度，从而进一步导致缓冲区饱和。仅在缓冲区完全饱和时才丢弃新到达的数据包。一旦发生这种情况，TCP可能认为连接的路径已更改而决定更激进地搜索寻找新的工作点</p><p>其实我们经常会陷入一个错误的做法：遇到缓存满的问题我们遇到后通常的简单做法就是先调大缓存，殊不知这种不经意的“偷懒”的做法对于整个网络可能是一种“作恶”。不仅仅是网络，我们程序中各种队列也可能面临这个问题，比如线程间的消息队列，当队列满的时候，问题的根本可能不是队列太小，而是生产线程产出的速度大于消费线程消费的速度，这时候应该：</p><p>（1）检查并解决消费线程的瓶颈；</p><p>（2）反馈给生产线程，如果就是性能/资源达到上限，要从源头慢下来；</p><p>bufferbloat现象不仅存在于路由器、交换机中，Linux操作系统对接收和发送队列的处理也同样会导致该现象的出现</p><p>至少到这儿我们明白了路由器携带很大的Buffer，是错误的！路由器Buffer在够用前提下越小越好，没有Buffer，自然就不会bloat, 但是不能没有Buffer，Buffer到底是用来干什么的？到底多少合适？<br>基于存储/转发TCP/IP网络上的路由器其根本任务不是做存储，而是做转发，存储只是在理论上不得已的一个手段，为什么这么说呢？<br>路由器的入口和出口分别接收到达的数据包和转发数据包，一台路由器上往往有多个接口同时全双工地进行接收/转发，数据包的到达频率是统计意义上的，符合泊松分布，然而数据包的发送则是固有的接口速率，这是分组交换网的核心根基！路由器扮演什么角色？它是一个典型的多服务台排队系统！所以路由器必须携带一个Buffer用来平滑泊松分布的包到达和固定速率的包发送之间的关系<br>其实这里和Andorid的渲染中的buffer生产消耗中间有个bufferqueue很像啊！归根结底这玩意就是为了平衡生产者消费者而诞生的</p><p>那么，设计多大的Buffer合适呢？按照排队理论的现成公式计算，够用即可！<br>其实我们可以想象一下极端的情况，把存储队列的Buffer设计成无穷大，从而转发延迟也将是无穷大(因为排队延迟会趋向无穷大)，会发生什么？无疑，这台路由器将会变成一个超级存储器，它将会拥有全世界所有的信息！<br>但是，它只是个转发设备啊，却装模作样当起了存储设备，这就是声名狼藉的Bufferbloat<br>Bufferbloat的恶劣影响并不是会造成丢包，而是会无端增加无辜连接的延迟，危害在于，由于Bufferbloat造成了整个大Buffer被填充，所有的数据包都将等待一个固有的排队延迟，这会严重影响任意经过的实时类应用！</p><p><strong>bufferbloat真的是网络设备商故意为之？</strong></p><p>很多文章只提到了是buffer愈来愈大导致，却没有或者很少提到为何会越来越大，有些文章只是讲述为了减少丢包，却没有讲述这种情况出现的背景缘由。其实这是一种不得已的行为，真正的原因也是最本质的原因在于：</p><p><strong>早期计算机的处理器性能决定了发包的速率，像思科这种厂商，他们的路由器，交换机的处理能力是发包的终端计算机难以企及的，这个阶段中间节点的高端设备只需要不多且固定数量的缓存，就可以暂时存储还没有来得及处理的数据包。<br>所以在那个计算机终端和网络核心交换设备处理性能差异巨大的年代，所有的计算机终端均采用“尽可能快”的方式发包时，这显然是提高效率的最佳做法。<br>但是后来时代变了！计算机终端的处理器，网卡性能和中间转发设备的距离越来越近，而中间转发设备的性能已经快达到极限，增加处理器和线卡的数量性价比远不如将来不及处理的数据暂时存起来，这带来了一种解决方案：增加缓存大小！这并没有解决问题，而是引入了问题，网络不再是一个用完即走的设施，而成了一个巨大的缓存设施，这就是人人唾弃的Bufferbloat！</strong></p><p>摘取Linux中国的一篇文章《从网络代码中移除“尽可能快”这个目标》中的一段内容<br>在演讲中，Van Jacobson 说互联网的这些已经发生了改变：</p><p><strong>在以前的互联网上，交换机可能总是拥有比服务器更快的网卡，所以这些位于互联网中间层的服务器也可能比客户端更快，并且并不能对客户端发送信息包的速率有多大影响。<br>很显然今天已经不是这样的了！众所周知，今天的计算机相比于 5 年前的计算机在速度上并没有多大的提升（我们遇到了某些有关光速的问题）。所以我想路由器上的大型交换机并不会在速度上大幅领先于数据中心里服务器上的网卡</strong></p><p>这篇文章同时提到了解决Bufferbloat的办法，就是：<strong>以更慢的速率发送更多的信息包以达到更好的性能！</strong></p><p>对于拥塞控制推出的背景历史，可以查看Van Jacobson在1988年推出的Congestion Avoidance and Control，文章开头就介绍了这篇论文的写作背景缘由</p><p>In October of ‘86, the Internet had the first of what became a series of ‘congestion collapses’. During this period, the data throughput from LBL to UC Berke- ley (sites separated by 400 yards and three IMP hops) dropped from 32 Kbps to 40 bps. Mike Karels 1 and I were fascinated by this sudden factor-of-thousand drop in bandwidth and embarked on an investigation of why things had gotten so bad. We wondered, in particular, if the 4.3BSD (Berkeley UNIX) TCP was mis-behaving or if it could be tuned to work better under abysmal net- work conditions. The answer to both of these questions was “yes”.</p><p>也正是在这一年拥塞控制被引入TCP，有点感慨，这是1988年推出的论文，中国进入互联网是在94年！</p><p><strong>摘自一篇比较喜欢的文章里的一句话：</strong><br>TCP拥塞控制的终极目标绝对不是加快数据发送的速度，这种理解非常自私且肤浅！它的终结目标是在公平占有带宽的前提下无限度提高带宽的利用率！<br>恰恰相反，所有的拥塞控制算法都是为了TCP可以在贪婪的时候悬崖勒马，大多数时候，拥塞控制是降低了数据发送的速度</p><p>如果不把公平性作为基本原则，那么整个环将不是闭合的，带宽资源早晚会用尽，此时盲目的AI非MD过程将会促使大家都想往前抢，最后谁也过不去，如此一来，互联网将完全不可用！基于这点，所有搞“TCP单边加速”的个人和厂商都是在做钻空子的坏事，其出发点就是错误的。当然，这类厂商的出发点往往不是TCP层面的，而是业务层面的，这倒是无可厚非，毕竟不是一个领域，我也无权过问太多，TCP对于它们而言只是工具，真到哪天互联网崩溃了，他们还是会用卡车运硬盘的方式来进行数据传输的，到时候，高速公路上堵的水泄不通的运硬盘的卡车与TCP一样，也只是个工具，而已</p><p>在BBR之前，Vegas算法则代表了一种正确的做法，它最终没有上位是因为Vegas部署有个前提，那就是同一时间全部部署成Vegas，然而这是不可能的，只要有Reno或者CUBIC在，Vegas的“正确做法”就会吃亏。现实就是这样，劣币驱良币，CUBIC明明是错误的算法，但因为它可以利用率很低但很简单的方法快速收敛到可用带宽，所以就一直是大家认可的算法，所有人都在默默忍受着Bufferbloat，而这个问题带来的额外排队延迟会大大降低交互式TCP连接的交互体验，同时严重影响实时性的协议，比如NTP之类。<br> CUBIC是一定会堵路的，Buffer被堵了之后，交互应用的数据就会被排队，时延增加，交互性自然下降。<br>我一直好奇的问题是，为什么Reno，CUBIC之流在经过慢启动之后的AI增窗过程叫做拥塞避免，相反，这种盲目的一路走到黑的增窗方式一定会导致拥塞的，即拥塞不可避免。这个过程是玷污了“拥塞避免”这个词呢，还是说仅仅是一个定义呢？</p><p>真正的拥塞控制就应该像城市快速路那样，在拥塞时排队缓行而不是造成bufferbloat！</p><p><strong>小结：</strong><br>TCP几乎全部都是以AIMD原则来运作的，UDP则是无限贪婪的。TCP的AI会造成主动丢包，这也是基于丢包的拥塞控制算法的核心，而MD会造成全局同步，这两点无疑造成了带宽利用率的低下，这是TCP的硬伤，不得不靠不断加大的路由器Buffer来弥补，至少是延迟了悲剧的发生，在延迟悲剧的这段时间内，路由器当然希望端系统可以意识到事情正在悄悄起变化并采取一些措施<br>或许TCP/IP的框架不该这么复杂，或许AIMD根本就不需要，事实上，是路由器不断加大的Buffer和AIMD一起纵容了坏事的频繁发生<br>路由器Buffer减小有什么好处呢？好处在于，即使有连接拼命去AI添堵，那么丢包会很快到来，并且很快反馈给发送方，于是发送方会执行MD以表示忏悔，整个过程中，实时流量不会受到丝毫影响</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h1&gt;&lt;p&gt;之前看tcp拥塞算法时了解过bufferbloat，明白网络设备的缓冲区是为了让丢包尽量晚点到来，但是大的缓冲区又加重了延时。&lt;br&gt;知乎有
      
    
    </summary>
    
      <category term="网络" scheme="http://lihaizhou.top/categories/%E7%BD%91%E7%BB%9C/"/>
    
    
  </entry>
  
  <entry>
    <title>BBR论文之读后感(三)</title>
    <link href="http://lihaizhou.top/2020/08/27/BBR%E8%AE%BA%E6%96%87%E4%B9%8B%E8%AF%BB%E5%90%8E%E6%84%9F-%E4%B8%89/"/>
    <id>http://lihaizhou.top/2020/08/27/BBR论文之读后感-三/</id>
    <published>2020-08-27T04:53:38.000Z</published>
    <updated>2020-08-27T10:59:05.938Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Matching-the-Packet-Flow-to-the-Delivery-Path"><a href="#Matching-the-Packet-Flow-to-the-Delivery-Path" class="headerlink" title="Matching the Packet Flow to the Delivery Path"></a>Matching the Packet Flow to the Delivery Path</h1><p>The core BBR algorithm has two parts:<br>When an ack is received</p><p>Each ack provides new RTT and average delivery rate measurements that update the RTprop and BtlBw estimates:</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">onAck</span>(<span class="params">packet</span>)</span></span><br><span class="line"><span class="function">  <span class="title">rtt</span> = <span class="title">now</span> - <span class="title">packet</span>.<span class="title">sendtime</span></span></span><br><span class="line"><span class="function">  <span class="title">update_min_filter</span>(<span class="params">RTpropFilter, rtt</span>)</span></span><br><span class="line"><span class="function">  <span class="title">delivered</span> += <span class="title">packet</span>.<span class="title">size</span></span></span><br><span class="line"><span class="function">  <span class="title">delivered_time</span> = <span class="title">now</span></span></span><br><span class="line"><span class="function">  <span class="title">deliveryRate</span> = (<span class="params">delivered - packet.delivered</span>) / (<span class="params">delivered_time - packet.delivered_time</span>)</span></span><br><span class="line"><span class="function">  <span class="title">if</span> (<span class="params">deliveryRate &gt; BtlBwFilter.currentMax || ! packet.app_limited</span>)</span></span><br><span class="line"><span class="function">     <span class="title">update_max_filter</span>(<span class="params">BtlBwFilter, deliveryRate</span>)</span></span><br><span class="line"><span class="function">  <span class="title">if</span> (<span class="params">app_limited_until &gt; <span class="number">0</span></span>)</span></span><br><span class="line"><span class="function">     <span class="title">app_limited_until</span> = <span class="title">app_limited_until</span> - <span class="title">packet</span>.<span class="title">size</span></span></span><br></pre></td></tr></table></figure><p>The if checks address the uncertainty issue described in the last paragraph: senders can be application limited, meaning the application runs out of data to fill the network. This is quite common because of request/response traffic. When there is a send opportunity but no data to send, BBR marks the corresponding bandwidth sample(s) as application limited (see send() pseudocode to follow). The code here decides which samples to include in the bandwidth model so it reflects network, not application, limits.<br>BtlBw is a hard upper bound on the delivery rate so a measured delivery rate larger than the current BtlBw estimate must mean the estimate is too low, whether or not the sample was app-limited. Otherwise, application-limited samples are discarded. (Figure 1 shows that in the app-limited region deliveryRate underestimates BtlBw. These checks prevent filling the BtlBw filter with underestimates which would cause data to be sent too slowly.)</p><p><strong>翻译：</strong> </p><p>BBR核心算法包含两大部分：<br>当收到一个ACK报文时：<br>每一个ACK提供了一个新的RTT和新的发送速率估计，BBR将以此为根据来更新RTprop和BtlBw<br>这里略去上面的英文中的伪代码部分<br>伪代码中的if语句是对上一段所讲的不确定性进行估计的：发送方可能受限于应用，发送数据太少，而并没有将管道填满。<br>当发送方采取的协议是request/response类时，这种现象是非常常见的。当没有数据可以发送时，BBR会将对应的带宽估计标志为是应用限制的（见下文伪代码中的send()）。这里的算法是为了决定流应该采集哪些数据，而避免采集那些被应用限制的而不是被网络限制的采集数据。<br>BtlBw是发送速率的上界，所以如果计算出的发送速率大于当前所估计的BtlBw值，那么这表示这个估计值太小了（无论该发送速率是否是应用限制的），我们都应该更新它。否则，那些被应用限制的采集数据将会被丢弃。（如图1所示，在app-limited区域中，deliveryRate低估了BtlBw。这些if判断避免BBR低估了BtlBw而导致发送低速率）。</p><p><strong>额外添加:</strong><br>这里计算发送速率的伪代码算法如此的通俗易懂，当然实际的源代码肯定是很复杂的，不过任何复杂算法最初的雏形一定是像这样简单纯朴</p><h1 id="When-data-is-sent"><a href="#When-data-is-sent" class="headerlink" title="When data is sent"></a>When data is sent</h1><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">To match the packet-arrival rate to the bottleneck link<span class="string">'s departure rate, BBR paces every data packet. (BBR must match the bottleneck rate, which means pacing is integral to the design and fundamental to operation—pacing_rate is BBR'</span>s primary control parameter. A secondary parameter, cwnd_gain, bounds inflight to a small multiple <span class="keyword">of</span> the BDP to handle common network and receiver pathologies (see the later section on Delayed and Stretched ACKs). Conceptually, the TCP send routine looks like the following code. (In Linux, sending uses the efficient FQ/pacing queuing discipline,<span class="number">4</span> which gives BBR line-rate single-connection performance on multigigabit links and handles thousands <span class="keyword">of</span> lower-rate paced connections <span class="keyword">with</span> negligible CPU overhead.)</span><br></pre></td></tr></table></figure><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">send</span>(<span class="params">packet</span>)</span></span><br><span class="line"><span class="function">  <span class="title">bdp</span> = <span class="title">BtlBwFilter</span>.<span class="title">currentMax</span> × <span class="title">RTpropFilter</span>.<span class="title">currentMin</span></span></span><br><span class="line"><span class="function">  <span class="title">if</span> (<span class="params">inflight &gt;= cwnd_gain × bdp</span>)</span></span><br><span class="line"><span class="function">     // <span class="title">wait</span> <span class="title">for</span> <span class="title">ack</span> <span class="title">or</span> <span class="title">retransmission</span> <span class="title">timeout</span></span></span><br><span class="line"><span class="function">     <span class="title">return</span></span></span><br><span class="line"><span class="function">  <span class="title">if</span> (<span class="params">now &gt;= nextSendTime</span>)</span></span><br><span class="line"><span class="function">     <span class="title">packet</span> = <span class="title">nextPacketToSend</span>(<span class="params"></span>)</span></span><br><span class="line"><span class="function">     <span class="title">if</span> (<span class="params">! packet</span>)</span></span><br><span class="line"><span class="function">        <span class="title">app_limited_until</span> = <span class="title">inflight</span></span></span><br><span class="line"><span class="function">        <span class="title">return</span></span></span><br><span class="line"><span class="function">     <span class="title">packet</span>.<span class="title">app_limited</span> = (<span class="params">app_limited_until &gt; <span class="number">0</span></span>)</span></span><br><span class="line"><span class="function">     <span class="title">packet</span>.<span class="title">sendtime</span> = <span class="title">now</span></span></span><br><span class="line"><span class="function">     <span class="title">packet</span>.<span class="title">delivered</span> = <span class="title">delivered</span></span></span><br><span class="line"><span class="function">     <span class="title">packet</span>.<span class="title">delivered_time</span> = <span class="title">delivered_time</span></span></span><br><span class="line"><span class="function">     <span class="title">ship</span>(<span class="params">packet</span>)</span></span><br><span class="line"><span class="function">     <span class="title">nextSendTime</span> = <span class="title">now</span> + <span class="title">packet</span>.<span class="title">size</span> / (<span class="params">pacing_gain × BtlBwFilter.currentMax</span>)</span></span><br><span class="line"><span class="function">  <span class="title">timerCallbackAt</span>(<span class="params">send, nextSendTime</span>)</span></span><br></pre></td></tr></table></figure><p><strong>翻译：</strong> </p><p>为了使得bottleneck链路的报文到达速率和报文离开速率相等，BBR必须进行packet paced。<br>BBR的发送速率必须与bottleneck的速率相等，这意味着BBR的实现需要pacing的支持——pacing_rate是BBR的一个主要控制参数！<br>第二个参数，cwnd_gain，将inflight控制为比BDP稍大一些，从而处理常见的网络机制和接收方机制（参见后文Dealyedand Stretched ACKs）。<br>TCP发送的时候做的事大概如上面的伪代码所示（在Linux中，可以使用FQ/pacing qdisc来发送数据，这可以使得BBR在与几千个低速率的paced流在千兆链路上很好地共存，并且使用FQ这种机制也不会额外造成CPU的负担）。</p><p><strong>额外添加：</strong></p><p>上面说的感觉听上去上挺合理，但是很容易产生这样的疑问：<br>端到端的TCP如何知道带宽到底是多少？如果用测量的话结果具有一个RTT的滞后性。因此你测得的结果永远都是以前的结果而不是现在的结果，由于网络情况存在随机性，更无法预测未来的情景，于是乎，完全按照瓶颈带宽来发送数据是不可能的，我们不得不承认这个结果是滞后的，或者说我们采集到的信息仅仅够算一个所谓的均值，不管怎么样，我们依然会选择Pacing的方式来发送数据，至少在没有新的有别于AIMD的全新数学模型出现之前吧。<br>如此一来，只要我们选择了Pacing，那么就必然要在TCP发送端内置一套数据采集和计算引擎，这是AIMD模型所不需要的。</p><h1 id="Steady-state-behavior"><a href="#Steady-state-behavior" class="headerlink" title="Steady-state behavior"></a>Steady-state behavior</h1><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">The rate and amount BBR sends is solely a <span class="function"><span class="keyword">function</span> <span class="title">of</span> <span class="title">the</span> <span class="title">estimated</span> <span class="title">BtlBw</span> <span class="title">and</span> <span class="title">RTprop</span>, <span class="title">so</span> <span class="title">the</span> <span class="title">filters</span> <span class="title">control</span> <span class="title">adaptation</span> <span class="title">in</span> <span class="title">addition</span> <span class="title">to</span> <span class="title">estimating</span> <span class="title">the</span> <span class="title">bottleneck</span> <span class="title">constraints</span>. <span class="title">This</span> <span class="title">creates</span> <span class="title">the</span> <span class="title">novel</span> <span class="title">control</span> <span class="title">loop</span> <span class="title">shown</span> <span class="title">in</span> <span class="title">figure</span> 2, <span class="title">which</span> <span class="title">illustrates</span> <span class="title">the</span> <span class="title">RTT</span> (<span class="params">blue</span>), <span class="title">inflight</span> (<span class="params">green</span>) <span class="title">and</span> <span class="title">delivery</span> <span class="title">rate</span> (<span class="params">red</span>) <span class="title">detail</span> <span class="title">from</span> 700 <span class="title">ms</span> <span class="title">of</span> <span class="title">a</span> 10-<span class="title">Mbps</span>, 40-<span class="title">ms</span> <span class="title">flow</span>. <span class="title">The</span> <span class="title">thick</span> <span class="title">gray</span> <span class="title">line</span> <span class="title">above</span> <span class="title">the</span> <span class="title">delivery</span>-<span class="title">rate</span> <span class="title">data</span> <span class="title">is</span> <span class="title">the</span> <span class="title">state</span> <span class="title">of</span> <span class="title">the</span> <span class="title">BtlBw</span> <span class="title">max</span> <span class="title">filter</span>. <span class="title">The</span> <span class="title">triangular</span> <span class="title">structures</span> <span class="title">result</span> <span class="title">from</span> <span class="title">BBR</span> <span class="title">cycling</span> <span class="title">pacing_gain</span> <span class="title">to</span> <span class="title">determine</span> <span class="title">if</span> <span class="title">BtlBw</span> <span class="title">has</span> <span class="title">increased</span>. <span class="title">The</span> <span class="title">gain</span> <span class="title">used</span> <span class="title">for</span> <span class="title">each</span> <span class="title">part</span> <span class="title">of</span> <span class="title">the</span> <span class="title">cycle</span> <span class="title">is</span> <span class="title">shown</span> <span class="title">time</span>-<span class="title">aligned</span> <span class="title">with</span> <span class="title">the</span> <span class="title">data</span> <span class="title">it</span> <span class="title">influenced</span>. <span class="title">The</span> <span class="title">gain</span> <span class="title">is</span> <span class="title">applied</span> <span class="title">an</span> <span class="title">RTT</span> <span class="title">earlier</span>, <span class="title">when</span> <span class="title">the</span> <span class="title">data</span> <span class="title">is</span> <span class="title">sent</span>. <span class="title">This</span> <span class="title">is</span> <span class="title">indicated</span> <span class="title">by</span> <span class="title">the</span> <span class="title">horizontal</span> <span class="title">jog</span> <span class="title">in</span> <span class="title">the</span> <span class="title">event</span> <span class="title">sequence</span> <span class="title">description</span> <span class="title">running</span> <span class="title">up</span> <span class="title">the</span> <span class="title">left</span> <span class="title">side</span>.</span></span><br></pre></td></tr></table></figure><p><strong>翻译：</strong></p><p>BBR的发送速率和发送数量完全就是一个关于BtlBw和RTprop的函数，所以BBR应该小心地估计这两个值。这创造了一种新型的闭环控制，如图2所示。图2显示了一个10Mbps，40ms的流在700ms中的RTT（蓝线），inflight（绿线）和发送速率（红线）变化过程。</p><p>注意图中在发送速率上方的灰线是BtlBw最大化滤波器的状态。图中产生的三角形形状是因为BBR的pacing_gain周期性的变化产生的，因为BBR必须以此来探测BtlBw是否提高了。图中展示了该增益值在一个周期不同时间的变化和其影响的数据变化</p><p><img src="https://raw.githubusercontent.com/hellolihaizhou/saveImg/master/BBRpart3-1.png.png" alt=""></p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">BBR minimizes delay by spending most <span class="keyword">of</span> its time <span class="keyword">with</span> one BDP <span class="keyword">in</span> flight, paced at the BtlBw estimate. This moves the bottleneck to the sender so it can<span class="string">'t observe BtlBw increases. Consequently, BBR periodically spends an RTprop interval at a pacing_gain &gt; 1, which increases the sending rate and inflight. If BtlBw hasn'</span>t changed, then a queue is created at the bottleneck, increasing RTT, which keeps deliveryRate constant. (This queue is removed by sending at a compensating pacing_gain &lt; <span class="number">1</span> <span class="keyword">for</span> the next RTprop.) If BtlBw has increased, deliveryRate increases and the <span class="keyword">new</span> max immediately increases the BtlBw filter output, increasing the base pacing rate. Thus, BBR converges to the <span class="keyword">new</span> bottleneck rate exponentially fast. Figure <span class="number">3</span> shows the effect on a <span class="number">10</span>-Mbps, <span class="number">40</span>-ms flow <span class="keyword">of</span> BtlBw abruptly doubling to <span class="number">20</span> Mbps after <span class="number">20</span> seconds <span class="keyword">of</span> steady operation (left graph) then dropping to <span class="number">10</span> Mbps after another <span class="number">20</span> seconds <span class="keyword">of</span> steady operation at <span class="number">20</span> Mbps (right graph).</span><br></pre></td></tr></table></figure><p><strong>翻译：</strong></p><p>BBR将它的大部分时间的在外发送数据都保持为一个BDP大小，并且发送速率保持在估计得BtlBw值，这将会最小化时延。<br>但是这会把网络中的瓶颈链路移动到BBR发送方本身，所以BBR无法察觉BtlBw是否上升了。</p><p>所以，BBR周期性的在一个RTprop时间内将pacing_gain设为一个大于1的值，这将会增加发送速率和在外报文。如果BtlBw没有改变，那么这意味着BBR在网络中制造了队列，增大了RTT，而deliveryRate仍然没有改变。（这个队列将会在下个RTprop周期被BBR使用小于1的pacing_gain来消除）。</p><p>如果BtlBw增大了，那么deliveryRate增大了，并且BBR会立即更新BtlBw的估计值，从而增大了发送速率。通过这种机制，BBR可以以指数速度非常快地收敛到瓶颈链路。如图3显示的，我们在1条10Mbps，40ms的流在20s稳定运行之后将BtlBw提高了1倍（20Mbps），然后在第40s又将BtlBw恢复至20Mbps<br><img src="https://raw.githubusercontent.com/hellolihaizhou/saveImg/master/BBRpart3-2.png.png" alt=""></p><p><strong>额外添加</strong></p><p><a href="https://blog.csdn.net/dog250/article/details/52972502?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522159850579919725211953968%2522%252C%2522scm%2522%253A%252220140713.130102334.pc%255Fblog.%2522%257D&amp;request_id=159850579919725211953968&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~blog~first_rank_v2~rank_blog_v1-13-52972502.pc_v2_rank_blog_v1&amp;utm_term=BBR&amp;spm=1018.2118.3001.4187" target="_blank" rel="noopener">https://blog.csdn.net/dog250/article/details/52972502?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522159850579919725211953968%2522%252C%2522scm%2522%253A%252220140713.130102334.pc%255Fblog.%2522%257D&amp;request_id=159850579919725211953968&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~blog~first_rank_v2~rank_blog_v1-13-52972502.pc_v2_rank_blog_v1&amp;utm_term=BBR&amp;spm=1018.2118.3001.4187</a></p><p>(BBR is a simple instance of a Max-plus control system, a new approach to control based on nonstandard algebra.12 This approach allows the adaptation rate [controlled by the max gain] to be independent of the queue growth [controlled by the average gain]. Applied to this problem, it results in a simple, implicit control loop where the adaptation to physical constraint changes is automatically handled by the filters representing those constraints. A conventional control system would require multiple loops connected by a complex state machine to accomplish the same result.)</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Matching-the-Packet-Flow-to-the-Delivery-Path&quot;&gt;&lt;a href=&quot;#Matching-the-Packet-Flow-to-the-Delivery-Path&quot; class=&quot;headerlink&quot; title=&quot;Ma
      
    
    </summary>
    
      <category term="网络" scheme="http://lihaizhou.top/categories/%E7%BD%91%E7%BB%9C/"/>
    
    
  </entry>
  
  <entry>
    <title>BBR论文之读后感(二)</title>
    <link href="http://lihaizhou.top/2020/08/27/BBR%E8%AE%BA%E6%96%87%E4%B9%8B%E8%AF%BB%E5%90%8E%E6%84%9F-%E4%BA%8C/"/>
    <id>http://lihaizhou.top/2020/08/27/BBR论文之读后感-二/</id>
    <published>2020-08-27T02:50:37.000Z</published>
    <updated>2020-08-27T04:52:38.647Z</updated>
    
    <content type="html"><![CDATA[<p>Characterizing the Bottleneck</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">A connection runs <span class="keyword">with</span> the highest throughput and lowest delay when (rate balance) the bottleneck packet arrival rate equals BtlBw and (full pipe) the total data <span class="keyword">in</span> flight is equal to the BDP (= BtlBw × RTprop).</span><br><span class="line"></span><br><span class="line">The first condition guarantees that the bottleneck can run at <span class="number">100</span> percent utilization. The second guarantees there is enough data to prevent bottleneck starvation but not overfill the pipe. The rate balance condition alone does not ensure there is no queue, only that it can<span class="string">'t change size (e.g., if a connection starts by sending its 10-packet Initial Window into a five-packet BDP, then runs at exactly the bottleneck rate, five of the 10 initial packets fill the pipe so the excess forms a standing queue at the bottleneck that cannot dissipate).</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Similarly, the full pipe condition does not guarantee there is no queue (e.g., a connection sending a BDP in BDP/2 bursts gets full bottleneck utilization, but with an average queue of BDP/4). The only way to minimize the queue at the bottleneck and all along the path is to meet both conditions simultaneously.</span></span><br></pre></td></tr></table></figure><p><strong>翻译：</strong></p><p>当一个连接满足以下两个条件时，它可以在达到最高的吞吐量的同时保持最低时延：</p><ol><li>速率平衡：瓶颈带宽的数据到达速率与BtlBw相等；</li><li>填满管道：所有的在外数据（inflight data）与BDP（带宽与时延的乘积）相等</li></ol><p>其中第一个约束保证了瓶颈带宽可以得到100%利用。而第二个约束保证了流有足够的数据来填满瓶颈链路而且同时不会溢出（排队）。</p><p>第一个条件本身并无法保证路径中不存在队列，它只能保证流的速率不发生改变（例如，考虑一个连接在一开始就发送了10个报文到一个BDP只有5个网络中，并且接下来一直保持瓶颈速率发送。这样子会导致在一开始就填满了管道，并且制造了5个报文的队列，并且这个队列永远不会被消灭）。</p><p>相似地，第二个条件也不能保证链路中没有队列。比如，一个连接可以以burst方式发送BDP数量的报文，若该连接每次发二分之一BDP来达到瓶颈带宽，并且发两次，此时full pipe条件得到满足了，然而网络中的平均队列长度是BDP/4。为了最小化网络中的队列长度，唯一的方式是同时满足以上两个条件。</p><p><strong>额外添加：</strong></p><p>两个条件缺一不可，如果只满足第一个条件，可能会出现实际发送数据超过BDP的情况，这样就会出现排队，如果只满足第二点的话，可能会存在数据包突发的情况，可以理解为中间网络设备转发处理速度赶不上发送端发送的速度了，这样也会有排队。<br>所以要想达到最优的情况，就是同时满足以上两个条件，多么理想的想法！</p><p>BtlBw and RTprop vary over the life of a connection, so they must be continuously estimated. TCP currently tracks RTT (the time interval from sending a data packet until it is acknowledged) since it’s required for loss detection. At any time t,</p><p><img src="https://raw.githubusercontent.com/hellolihaizhou/saveImg/master/BBRpart2-1.png.png" alt=""></p><p>where 𝛈 ≥ 0 represents the “noise” introduced by queues along the path, the receiver’s delayed ack strategy, ack aggregation, etc. RTprop is a physical property of the connection’s path and changes only when the path changes. Since path changes happen on time scales » RTprop, an unbiased, efficient estimator at time T is</p><p><img src="https://raw.githubusercontent.com/hellolihaizhou/saveImg/master/BBRpart2-2.png.png" alt=""></p><p>(i.e., a running min over time window WR (which is typically tens of seconds to minutes)</p><p><strong>翻译：</strong></p><p>然而，BtlBw和RTprop在整个连接的生命周期中可能是动态变化的，所以我们需要实时地对它们进行估计。<br>目前TCP为了检测丢包，必须实时地跟踪RTT的大小（发送数据到收到这个包的ack的时间），在任意的时间t</p><p>其中，最后一项表示“噪声”。造成噪声的因素主要有：链路队列，接收方的时延ACK配置，ACK聚合等因素等待。<br>RTprop是路径的物理特性，并且只有路径变化才会改变。由于一般来说路径变化的时间尺度远远大于RTprop（这说的是啥玩意，待理解）<br>所以RTprop可以由以下公式进行估计：</p><p>（在一个时间窗口中对RTT取最小值。一般将该窗口大小设置为几十秒至几分钟）</p><p>Unlike RTT, nothing in the TCP spec requires implementations to track bottleneck bandwidth, but a good estimate results from tracking delivery rate. When the ack for some packet arrives back at the sender, it conveys that packet’s RTT and announces the delivery of data inflight when that packet departed. Average delivery rate between send and ack is the ratio of data delivered to time elapsed: deliveryRate = Δdelivered/Δt. This rate must be ≤ the bottleneck rate (the arrival amount is known exactly so all the uncertainty is in the Δt, which must be ≥ the true arrival interval; thus, the ratio must be ≤ the true delivery rate, which is, in turn, upper-bounded by the bottleneck capacity). Therefore, a windowed-max of delivery rate is an efficient, unbiased estimator of BtlBw: </p><p><img src="https://raw.githubusercontent.com/hellolihaizhou/saveImg/master/BBRpart2-3.png.png" alt=""></p><p>where the time window WB is typically six to ten RTTs.</p><p><strong>翻译：</strong></p><p>然而，bottleneck bandwidth的估计不像RTT那样方便，没有一种TCP spec要求实现算法来跟踪估计bottleneck带宽，但是，我们可以通过跟踪发送速率来估计bottleneck带宽。<br>当发送方收到一个ACK报文时，它可以计算出该报文的RTT，并且从发出报文到收到ack报文这段时间的data Inflight。这段时间内的平均发送速率就可以以此计算出来：deliveryRate = delta delivered/ delta t。这个计算出的速率必定小于bottleneck速率（因为delta delivered是确定的，但是delta t会较大）。因此，BtwBw可以根据以下公式进行估计</p><p>其中，时间窗口大小的值一般为6~10个RTT。</p><p><strong>额外增加：</strong><br>这里提到了BBR的deliveryRate的计算方式，这个公式看起来是如此的简单<br>1).应答了多少数据，记为delivered；<br>2).应答1)中的delivered这么多数据所用的时间，记为interval_us。<br>将上述二者相除，就能得到带宽：<code>bw = delivered/interval_us</code><br>这里的delivered只关注数据的大小，不关注数据的含义，比如delivered的采集中，bbr根本不管某一个应答是重传后的ACK确认的，正常ACK确认的，还是说SACK确认的。bbr只关心被应答了多少！<br>至于为什么能够不关注数据的含义，可以参考这篇文章：<br><a href="https://blog.csdn.net/dog250/article/details/52830576" target="_blank" rel="noopener">来自Google的TCP BBR拥塞控制算法解析</a><br>按照这个公式的计算方式其实是完全忽略了系统层面的TCP状态，计算带宽时它仅仅需要两个值就够了</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">TCP must record the departure time <span class="keyword">of</span> each packet to compute RTT. BBR augments that record <span class="keyword">with</span> the total data delivered so each ack arrival yields both an RTT and a delivery rate measurement that the filters convert to RTprop and BtlBw estimates.</span><br><span class="line"></span><br><span class="line">Note that these values are completely independent: RTprop can change (<span class="keyword">for</span> example, on a route change) but still have the same bottleneck, or BtlBw can change (<span class="keyword">for</span> example, when a wireless link changes rate) without the path changing. (This independence is why both constraints have to be known to match sending behavior to delivery path.) Since RTprop is visible only to the left <span class="keyword">of</span> BDP and BtlBw only to the right <span class="keyword">in</span> figure <span class="number">1</span>, they obey an uncertainty principle: whenever one can be measured, the other cannot. Intuitively, <span class="keyword">this</span> is because the pipe has to be overfilled to find its capacity, which creates a queue that obscures the length <span class="keyword">of</span> the pipe. For example, an application running a request/response protocol might never send enough data to fill the pipe and observe BtlBw.</span><br><span class="line"></span><br><span class="line">A multi-hour bulk data transfer might spend its entire lifetime <span class="keyword">in</span> the bandwidth-limited region and have only a single sample <span class="keyword">of</span> RTprop <span class="keyword">from</span> the first packet<span class="string">'s RTT. This intrinsic uncertainty means that in addition to estimators to recover the two path parameters, there must be states that track both what can be learned at the current operating point and, as information becomes stale, how to get to an operating point where it can be relearned.</span></span><br></pre></td></tr></table></figure><p><strong>翻译：</strong></p><p>TCP必须记录每个报文的离开时间从而计算RTT。BBR必须额外记录已经发送的数据大小，使得在收到每一个ACK之后，计算RTT及发送速率的值，最后得到RTprop和BtlBw的估计值。</p><p>值得注意的是，这两个值是完全独立的：RTprop可以发生变化然而保持bottleneck不变（比如发生路由变化），或者BtlBw可以变化而路径不变（比如无线链路速率发生变化）。（This independence is why both constraints have tobe known to match sending behavior to delivery path.）</p><p>如图1所示，只有在BDP的左边，才能观测到RTprop，并且只有在BDP的右边才能观测到BtlBw，他们遵循了一个不确定性原则：当其中一个可以被观测的时候，另外一个并不能。直觉地，这是因为为了观测出管道的容量，必须填满管道，而这会创造出一个队列从而无法观测到管道的长度。</p><p>例如，一个使用request/response协议的应用可能永远不会发送足够的数据来填满管道，并且观测到BtlBw。一个持续几个小时的大文件传输应用可能永远处在bandwidth-limited区域，而仅仅在第一个报文中的RTT采集到RTprop。这种不确定性机制意味着，在信息变得不明确的时候，必须要有机制来从当前的工作状态中学习到这两个值的其中一个，并且进入对应的工作区来重新学习这两个值。</p><p>下一篇讲进入公式的细节部分</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Characterizing the Bottleneck&lt;/p&gt;
&lt;figure class=&quot;highlight javascript&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;
      
    
    </summary>
    
      <category term="网络" scheme="http://lihaizhou.top/categories/%E7%BD%91%E7%BB%9C/"/>
    
    
  </entry>
  
  <entry>
    <title>BBR论文之读后感(一)</title>
    <link href="http://lihaizhou.top/2020/08/27/BBR%E8%AE%BA%E6%96%87%E4%B9%8B%E8%AF%BB%E5%90%8E%E6%84%9F-%E4%B8%80/"/>
    <id>http://lihaizhou.top/2020/08/27/BBR论文之读后感-一/</id>
    <published>2020-08-27T02:19:27.000Z</published>
    <updated>2020-08-27T10:31:20.333Z</updated>
    
    <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>拥塞控制本身是个比较发散的话题，首先需要说明一点我对这方面其实一窍不通，为了找资料在网上也看了不少文章，但是很多文章都是平铺直叙的讲述，所以很多没看完就放弃了。<br>于是打算看下论文《BBR: Congestion-Based Congestion Control》，这篇文章还是比较有意思，看完多少知道了一点BBR的皮毛。</p><p>因整篇论文内容较多，将分为六篇读后感</p><h1 id="BBR论文部分-1-6"><a href="#BBR论文部分-1-6" class="headerlink" title="BBR论文部分(1/6)"></a>BBR论文部分(1/6)</h1><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Measuring bottleneck bandwidth and round-trip propagation time</span><br><span class="line">Neal Cardwell, Yuchung Cheng, C. Stephen Gunn, Soheil Hassas Yeganeh, Van Jacobson</span><br><span class="line"></span><br><span class="line">By all accounts, today<span class="string">'s Internet is not moving data as well as it should. Most of the world'</span>s cellular users experience delays <span class="keyword">of</span> seconds to minutes; public Wi-Fi <span class="keyword">in</span> airports and conference venues is often worse. Physics and climate researchers need to exchange petabytes <span class="keyword">of</span> data <span class="keyword">with</span> global collaborators but find their carefully engineered multi-Gbps infrastructure often delivers at only a few Mbps over intercontinental distances<span class="number">.6</span></span><br><span class="line"></span><br><span class="line">These problems result <span class="keyword">from</span> a design choice made when TCP congestion control was created <span class="keyword">in</span> the <span class="number">1980</span>s—interpreting packet loss <span class="keyword">as</span> <span class="string">"congestion."</span><span class="number">13</span> This equivalence was <span class="literal">true</span> at the time but was because <span class="keyword">of</span> technology limitations, not first principles. As NICs (network interface controllers) evolved <span class="keyword">from</span> Mbps to Gbps and memory chips <span class="keyword">from</span> KB to GB, the relationship between packet loss and congestion became more tenuous.</span><br><span class="line"></span><br><span class="line">Today TCP<span class="string">'s loss-based congestion control—even with the current best of breed, CUBIC11—is the primary cause of these problems. When bottleneck buffers are large, loss-based congestion control keeps them full, causing bufferbloat. When bottleneck buffers are small, loss-based congestion control misinterprets loss as a signal of congestion, leading to low throughput. Fixing these problems requires an alternative to loss-based congestion control. Finding this alternative requires an understanding of where and how network congestion originates.</span></span><br></pre></td></tr></table></figure><p><strong>翻译</strong></p><p>因为各种原因，今天的互联网并不能像我们所期望的那样很好地传输数据。世界上大部分蜂窝网络用户都会经历几秒乃至几分钟的时延；在公共局域如机场和会议厅等，WIFI质量经常是非常差的。物理和气候学者想要与全球范围内的合作者传输千兆字节级别的数据，但可能会发现他们精心准备的Gbps级别的底层网络在洲际传输中只能达到Mbps级别。这些问题之所以会发生，是因为在80年代设计TCP拥塞控制的时候，TCP将丢包作为“拥塞”的信号。在那个年代，这个假设确实是正确的，但这是因为受限于技术原因。而当网卡的速率从Mbps级别进化为Gbps级别，内存从KB级别进化到GB级别之后，丢包与拥塞的关系变得不那么紧密了。</p><p>今天的这些TCP拥塞控制算法，包括至今为止最好的算法CUBIC，都是基于丢包的。他们是造成这些问题的主要元凶。当瓶颈链路的缓存较大时，这些基于丢包的拥塞控制算法流填满了缓存，造成了bufferbloat。当瓶颈链路的缓存较小时，这些算法会又将丢包作为发生拥塞的信号，从而降低速率导致了较低的吞吐量。</p><p>为了解决这些问题，必须提出一种不是基于丢包的拥塞控制算法，这需要设计者对网络拥塞是如何并且在哪里产生的有非常深刻的理解</p><p><strong>额外添加</strong></p><p>终端设备发的越来越快，中间网络设备的缓冲区越来越大，依靠丢包的算法不是那么明智了，所以需要一种新的拥塞控制算法，就是后面会提到的BBR</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">Congestion and Bottlenecks</span><br><span class="line"></span><br><span class="line">At any time, a (full-duplex) TCP connection has exactly one slowest link or bottleneck <span class="keyword">in</span> each direction. The bottleneck is important because:</span><br><span class="line"></span><br><span class="line">• It determines the connection<span class="string">'s maximum data-delivery rate. This is a general property of incompressible flow (e.g., picture a six-lane freeway at rush hour where an accident has reduced one short section to a single lane. The traffic upstream of the accident moves no faster than the traffic through that lane).</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">• It'</span>s where persistent queues form. Queues shrink only when a link<span class="string">'s departure rate exceeds its arrival rate. For a connection running at maximum delivery rate, all links upstream of the bottleneck have a faster departure rate so their queues migrate to the bottleneck.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Regardless of how many links a connection traverses or what their individual speeds are, from TCP'</span>s viewpoint an arbitrarily complex path behaves <span class="keyword">as</span> a single link <span class="keyword">with</span> the same RTT (round-trip time) and bottleneck rate. Two physical constraints, RTprop (round-trip propagation time) and BtlBw (bottleneck bandwidth), bound transport performance. (If the network path were a physical pipe, RTprop would be its length and BtlBw its minimum diameter.)</span><br><span class="line"></span><br><span class="line">Figure <span class="number">1</span> shows RTT and delivery rate variation <span class="keyword">with</span> the amount <span class="keyword">of</span> data <span class="keyword">in</span> flight (data sent but not yet acknowledged). Blue lines show the RTprop constraint, green lines the BtlBw constraint, and red lines the bottleneck buffer. Operation <span class="keyword">in</span> the shaded regions isn<span class="string">'t possible since it would violate at least one constraint. Transitions between constraints result in three different regions (app-limited, bandwidth-limited, and buffer-limited) with qualitatively different behavior.</span></span><br></pre></td></tr></table></figure><p><strong>翻译</strong></p><p>在一个TCP连接中，每个传输方向都存在一个最慢的链路，或者说瓶颈链路（bottleneck）。Bottleneck很重要！这是因为：</p><ol><li><p>它决定了该连接的最大传输速率（举个例子：如果高速公路上的某一段路发生了车祸，将会导致该道上的车速降低至那一段路的车速）。</p></li><li><p>它是造成队列的元凶！因为只有一个链路的离开速率大于它的到达速率，队列才会缩短。对于一个尽力传输最大速率的连接来说，因为其他的链路速率都比bottleneck大，所以最后会造成bottleneck的队列。</p></li></ol><p>无论一个TCP连接需要穿越多少链路，也无论这些链路的速率各自是多少，从TCP的角度来说，一个极其复杂路径的行为跟一条与它拥有相同RTT和bottleneck速率的简单链路一样（这句话不太好翻译，意思就是不管这条链路多么复杂，在tcp眼里和一条与这条复杂链路同样的RTT及bottleneck的简单链路是一样的）</p><p>这两个参数，RTprop（Round-trippropagation time）和BtlBw（bottleneck bandwidth），决定了传输的性能。</p><p>（打个比方，如果将一条网络路径类比为一个管道，RTprop就是管道的长度，BtlBw就是管道中最短的半径。）</p><p>图1展示了RTT和发送速率与发送数据大小的关系。</p><p>图中的蓝线受到了RTprop的约束，绿线受到BtlBw约束，红线受到瓶颈链路的缓存约束。注意阴影区域的部分是不可达的，因为这会至少违反一项约束。这三种约束形成了3不同的区域，分别为app-limited，bandwidth-limited，buffer-limited。在三种区域，流的行为是完全不同的</p><p><img src="https://raw.githubusercontent.com/hellolihaizhou/saveImg/master/BBRpart1-1.png" alt=""></p><p><strong>额外添加</strong></p><p>这里重点提到了bottleneck，其实我们很容易想到如果这条链路上如果传输速率和瓶颈速度相近，是否会降低bottlebloat的概率呢？其实这只是其中一个条件，后面会提到。这里提到的两个参数后面会贯穿整篇论文：RTprop（Round-trippropagation time）和BtlBw（bottleneck bandwidth）</p><p>RTprop：光信号从A端到B端的最小时延（因为是一个来回其实是2倍时延），这取决于物理距离<br>BtlBw：在A到B的链路中，它的带宽取决于最慢的那段链路的带宽，称为瓶颈带宽，可以想象为光纤的粗细</p><p>上面的图中转折点有个词BDP，后面会频繁提及到：</p><p>BDP Bandwidth and Delay Product (整条物理链路（不含路由器缓存）所能储藏的比特数据之和，BDP = BtlBw * RTprop)，或者可以这样理解：Source 和 Destination 之间允许处在 Flying 状态的最大数据量。Flying 也叫 Inflights，就是发送了但还未收到的 Ack 的数据。</p><p>其实根据这个定义，我们很容易想到：如果当前的实际发送速率乘以延迟得到的值越接近 BDP 说明算法的效率越高。</p><p>再来看下上面的图，下面以上半图和下半图来称呼</p><p>上半图</p><pre><code>当链路上正在传输的比特数据未超过整条链路的物理容量（BDP）之前，传输时延的极限就是RTprop，对应上半图中蓝色的横线当数据塞满了整条链路的物理容量后，路由器开始启用缓存来存储比特数据，这相当于拉长了整个链路，造成传输时延开始变大，偏离了物理极限RTprop，于是有了slope = 1/BtlBw那条绿色斜线当路由器的缓存填满后（BDP+BtlBufSize），整条链路开始丢数据，1/BtlBw斜线消失，对应于上半图中红点虚线</code></pre><p>下半图<br>这里先说明下有一个需要注意的地方，就是下半图的纵坐标delivery rate，这里是BBR中定义的带宽，和我们平时理解的带宽可能还不太一样，我们平时直观上理解是数据在网线中的传输速率，这里指的是：数据量/从发送出去至收到ACK的时长</p><pre><code>当链路上正在传输的比特数据未超过整条链路的物理容量（BDP）之前，在B端观察到的数据带宽是逐渐往上涨的，对应下半图中蓝色斜线当数据塞满了整条链路的物理容量后，路由器开始启用缓存来存储比特数据，但不影响B端观察到的带宽，这个带宽的极限就是BtlBw，对应于图中那条绿色的BtlBw横线当路由器的缓存填满后（BDP+BtlBufSize），整条链路开始丢数据，但B端观察到的带宽极限还是BtlBw，对应于下半图中红点虚线</code></pre><p>上半图和下半图的斜率是怎么来的呢，我是这么理解的：<br>横坐标实际发送数据大小设为S，实际带宽这里设为R必定是小于等于<code>BtlBw</code>，实际时延这里设为T肯定是大于等于RTprop<br><code>S=T*R</code> 所以这里<code>T/S=1/R&gt;=1/BtlBw</code>,所以实际情况下斜率往往是比上半图中的更陡峭<br>同理下半图的斜率 <code>R/S=1/T&lt;=1/RTprop</code>,所以实际情况下下半图的斜率往往会更平缓些<br>上下半图的阴影部分是不可达，这个图画的真的是太棒了，一图胜千句！</p><p>当到达最大带宽的时候，RTT开始增长(所有不以增加速率为目的的缓存都是耍流氓！缓存不直接增加速率，缓存通过降低丢包来提高网络利用率！)，无论从RTT视图还是从带宽视图来看，两个操作点都是一致的，这是基本！那么bbr是怎么测量的呢？<br><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">先稳定住带宽，当带宽不再增加的时候，bbr认为已经达到最大带宽可，然后在此基础上测量RTT，带宽的RTT的操作点是重合的！就是这么简单且直接。</span><br></pre></td></tr></table></figure></p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">When there isn<span class="string">'t enough data in flight to fill the pipe, RTprop determines behavior; otherwise, BtlBw dominates. Constraint lines intersect at inflight = BtlBw × RTprop, a.k.a. the pipe'</span>s BDP (bandwidth-delay product). Since the pipe is full past <span class="keyword">this</span> point, the inflight - BDP excess creates a queue at the bottleneck, which results <span class="keyword">in</span> the linear dependence <span class="keyword">of</span> RTT on inflight data shown <span class="keyword">in</span> the upper graph. Packets are dropped when the excess exceeds the buffer capacity. Congestion is just sustained operation to the right <span class="keyword">of</span> the BDP line, and congestion control is some scheme to bound how far to the right a connection operates on average.</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure><p><strong>翻译</strong></p><p>当没有足够的数据来填满管道时，RTprop决定了流的行为（说的啥玩意没看懂）；<br>当有足够的数据填满时，那就变成了BtlBw来决定。这两条约束交汇在点inflight=BtlBw*RTprop，也就是管道的BDP（带宽与时延的乘积）。</p><p>当管道被填满时，那些超过的部分（inflight-BDP）就会在瓶颈链路中制造了一个队列，从而导致了RTT的增大，如上面那个图所示，当数据继续增加直到填满了缓存时，多余的报文就会被丢弃了。拥塞就是发生在BDP点的右边，而拥塞控制算法就是来控制流的平均工作点离BDP点有多远。</p><p><strong>额外添加</strong><br>带宽与时延的乘积-&gt;这里如果说是瓶颈带宽乘上最小时延会不会更好点？<br>这里的说的多余的报文就会被丢弃了就是我们经常说的缓冲区肿胀到一定程度，超过了缓冲区大小的报文被丢弃</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Loss-based congestion control operates at the right edge <span class="keyword">of</span> the bandwidth-limited region, delivering full bottleneck bandwidth at the cost <span class="keyword">of</span> high delay and frequent packet loss. When memory was expensive buffer sizes were only slightly larger than the BDP, which minimized loss-based congestion control<span class="string">'s excess delay. Subsequent memory price decreases resulted in buffers orders of magnitude larger than ISP link BDPs, and the resulting bufferbloat yielded RTTs of seconds instead of milliseconds.9</span></span><br></pre></td></tr></table></figure><p><strong>翻译</strong></p><p>基于丢包的拥塞控制算法工作在bandwidth-limited区域的右边界区域，尽管这种算法可以达到最大的传输速率，但是它是以高延迟和高丢包率作为代价的。在存储介质较为昂贵的时候，缓存大小只比BDP大一点，此时这种算法的时延并不会很高。然而，当存储介质变得便宜之后，交换机的缓存大小已经是ISP链路BDP的很多很多倍了，这导致了bufferbloat，从而导致了RTT从毫秒级升到了秒级</p><p><strong>额外添加</strong></p><p>bandwidth-limited区域就是开始缓存了排队了，但是还没超过最大缓存也就是还没丢白<br>它的右边区域说的就是填满缓冲区之后的片段，对应着高延迟和高丢包率<br>这里说的：当存储介质变得便宜之后，交换机的缓存大小已经是ISP链路BDP的很多很多倍了，这导致了bufferbloat<br>个人感觉说的不太好，倒不是说有错误，存储便宜所以缓存搞得大点只是一方面原因，还有更重要的一方面原因是</p><p>现在的终端设备比如计算机的性能已经今非昔比，和中间网络设备的差距越来越小，可以这样理解，终端设备发的越来越快，中间网络设备比如路由器转发的速度逐渐快被终端设备赶上来了，这个时候逼不得已就得加大缓存了，不然转发不过来了就得丢包，实则无奈之举</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">The left edge <span class="keyword">of</span> the bandwidth-limited region is a better operating point than the right. In <span class="number">1979</span> Leonard Kleinrock16 showed <span class="keyword">this</span> operating point was optimal, maximizing delivered bandwidth <span class="keyword">while</span> minimizing delay and loss, both <span class="keyword">for</span> individual connections and <span class="keyword">for</span> the network <span class="keyword">as</span> a whole8. Unfortunately, around the same time Jeffrey M. Jaffe14 proved it was impossible to create a distributed algorithm that converged to <span class="keyword">this</span> operating point. This result changed the direction <span class="keyword">of</span> research <span class="keyword">from</span> finding a distributed algorithm that achieved Kleinrock<span class="string">'s optimal operating point to investigating different approaches to congestion control.</span></span><br></pre></td></tr></table></figure><p><strong>翻译</strong></p><p>工作在bandwidth-limited区域的左边界比工作在右边界好。在1979年Leonard Kleinrock就展示了，无论是对流自身而言，或是对整个网络来说，工作在左边界是最优点，这个点在实现最大传输速率的同时，保持了低时延和低丢包。不幸的是，当时Jeffrey M.Jaffe也同时证明了不可能存在一个分布式算法可以收敛到这个边界点，这使得学术研究不再尝试去设计可以工作在该边界点的分布式算法</p><p><strong>额外添加</strong><br>bandwidth-limited区域的左边界临界点是最佳的，这个看图很直观，此时数据量刚好是BDP</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Our group at Google spends hours each day examining TCP packet header captures <span class="keyword">from</span> all over the world, making sense <span class="keyword">of</span> behavior anomalies and pathologies. Our usual first step is finding the essential path characteristics, RTprop and BtlBw. That these can be inferred <span class="keyword">from</span> traces suggests that Jaffe<span class="string">'s result might not be as limiting as it once appeared. His result rests on fundamental measurement ambiguities (e.g., whether a measured RTT increase is caused by a path-length change, bottleneck bandwidth decrease, or queuing delay increase from another connection'</span>s traffic). Although it is impossible to disambiguate any single measurement, a connection<span class="string">'s behavior over time tells a clearer story, suggesting the possibility of measurement strategies designed to resolve ambiguity.</span></span><br><span class="line"><span class="string">&#125;);</span></span><br></pre></td></tr></table></figure><p><strong>翻译</strong></p><p>我们谷歌工作组每天花了大量的时间来查看从世界各地发来的TCP报文头部，从而对流的异常行为有了很深的了解。<br>我们通常首先计算出流最重要的两个参数：RTprop和BtlBw，这两个参数都可以从trace中推断出来。这表明Jaffe的结论可能不再适用。他当时做出这个结论是因为测量具有模糊性（例如，RTT的增加有可能是因为流的路径改变了，也有可能是瓶颈链路的带宽减少了，也有可能是因为别的流竞争而导致队列等等）。尽管不可能在单次测量中得到非常可靠的值，但是一个持续时间较长的连接会告诉你很多信息，从中或许可以设法来估计得到一个可靠的值</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Combining these measurements <span class="keyword">with</span> a robust servo loop using recent control systems advances12 could result <span class="keyword">in</span> a distributed congestion-control protocol that reacts to actual congestion, not packet loss or transient queue delay, and converges <span class="keyword">with</span> high probability to Kleinrock<span class="string">'s optimal operating point. Thus began our three-year quest to create a congestion control based on measuring the two parameters that characterize a path: bottleneck bandwidth and round-trip propagation time, or BBR.</span></span><br></pre></td></tr></table></figure><p><strong>翻译</strong></p><p>使用最近在控制领域中提出的鲁棒伺服环来对这些观测结果进行处理(这句话不知道咋翻译)，可以设计出一种分布式拥塞控制协议。该协议可以针对真实的拥塞进行反应，而不是基于丢包或者短暂的队列时延的，它可以大概率收敛到Kleinrock的最优边界点。</p><p>因此这推动了我们近三年的研究——如何基于这两个观测参数bottleneck带宽及RTT（这就是BBR缩写的来源，bottleneck bandwidth and round-trip propagation time）来设计拥塞控制算法。</p><p><strong>额外添加</strong></p><p>因为基于丢包探测的算法总会使inflight的数据量达到BDP+BtlBufSize这个状态，在现代的路由器中由于缓存很大，相当于把物理链路人为的拉长了，使数据传输的延时变大，即RTT变大。</p><p>下一篇将进入今天讨论的主题BBR</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h1&gt;&lt;p&gt;拥塞控制本身是个比较发散的话题，首先需要说明一点我对这方面其实一窍不通，为了找资料在网上也看了不少文章，但是很多文章都是平铺直叙的讲述，所以
      
    
    </summary>
    
      <category term="网络" scheme="http://lihaizhou.top/categories/%E7%BD%91%E7%BB%9C/"/>
    
    
  </entry>
  
  <entry>
    <title>网络系列之三次握手</title>
    <link href="http://lihaizhou.top/2020/08/09/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE%E7%B3%BB%E5%88%97%E4%B9%8B%E8%81%8A%E8%81%8A%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B/"/>
    <id>http://lihaizhou.top/2020/08/09/网络协议系列之聊聊三次握手/</id>
    <published>2020-08-09T09:31:07.000Z</published>
    <updated>2020-08-10T04:44:55.730Z</updated>
    
    <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>三次握手这个话题恐怕是网络问答中最常见的问题了，基本上都能说个大概，但是再往下深究，有些问题可能回答的就不是那么顺畅了<br>所以想着再梳理下这个”简单”的概念</p><h1 id="为什么要三次握手"><a href="#为什么要三次握手" class="headerlink" title="为什么要三次握手"></a>为什么要三次握手</h1><p>首先先了解下TCP这个概念:<br>TCP 是靠谱的协议，但是这不能说明它面临的网络环境好，从IP层面来讲，如果网络状况的确比较差的话，是没有任何可靠性保证的，而作为IP的上一层TCP也无能为力，<br>唯一能做的就是更加努力，不断重传，通过各种算法保证。也就是说，对于 TCP 来讲，IP 层你丢不丢包，我管不着，但是我在我的层面上，会努力保证可靠性</p><p>接下来我们接着讨论为何需要这三次握手呢？类似如下的描述是网上比较常见的回答<br>三次握手的目的是建立可靠的通信信道，说到通讯，简单来说就是数据的发送与接收，而三次握手最主要的目的就是:双方确认自己与对方的发送与接收是正常的</p><ol><li>第一次握手：Client 什么都不能确认；Server 确认了对方发送正常</li><li>第二次握手：Client 确认了：自己发送、接收正常，对方发送、接收正常；Server 确认了：自己接收正常，对方发送正常</li><li>第三次握手：Client 确认了：自己发送、接收正常，对方发送、接收正常；Server 确认了：自己发送、接收正常，对方发送接收正常</li></ol><p>所以三次握手就能确认双发收发功能都正常，缺一不可。</p><p>这个听起来没有问题，如果我们试着用香农的信息论来理解下或许更好理解：<br><code>信息论中，有个很重要的思想：要想消除信息的不确定性，就得引入信息</code><br>将这个思想应用到TCP中，很容易理解TCP的三次握手和四次挥手的必要性：它们的存在以及复杂度，就是为了消除不确定性，这里我们叫「不可靠性」。<br>拿三次握手举例，这里为了描述方便，将通信的两端用字母A和B替代</p><p>A要往B发数据，A要确定两件事：</p><ol><li>B在“那儿”，并且能接受数据 —— B确实存在，并且是活的，能听得见</li><li>B能回应 —— B能发数据，能说话<br>为了消除这两个不确定性，所以必须有前两次握手，即A发送了数据，B收到了，并且能回应——“ACK”<br>同样的，对于B来说，它也要消除以上两个不确定性，通过前两次握手，B知道了A能说，但是不能确定A能听，这就是第三次握手的必要性。</li></ol><h1 id="关于握手的一点问题"><a href="#关于握手的一点问题" class="headerlink" title="关于握手的一点问题"></a>关于握手的一点问题</h1><p>我们都知道TCP连接就是两端的状态维护，中间过程没有所谓的连接，一旦传输失败，一端收到消息，才知道状态的变化</p><p><strong>客户端什么时候建立连接</strong><br>初学时以为是“三次握手”后，双方同时建立连接。显然是做不到的，客户端不知道“应答的应答”有没有到达，以及什么时候到达。<br>同样的问题客户端什么时候断开连接？自然也不能说是四次挥手之后，事实上，客户端发出最后的应答(第四次“挥手”)后，永远无法知道有没有到达。于<br>是有了2MSL的等待，在不确定的网络中，把问题最大程度地解决。</p><p><strong>关于三次握手中如果最后一次丢失了没有传递到服务端会怎么样？</strong><br>回答这个问题之前，我们先看下正常的操作流程是什么样的</p><p>我们先来解释一下这张图：</p><ol><li>在初始时，双端处于 CLOSE 状态，服务端为了提供服务，会主动监听某个端口，进入 LISTEN 状态</li><li>客户端主动发送连接的「SYN」包，之后进入 SYN-SENT 状态，服务端在收到客户端发来的「SYN」包后，回复「SYN,ACK」包，之后进入 SYN-RCVD 状态</li><li>客户端收到服务端发来的「SYN,ACK」包后，可以确认对方存在，此时回复「ACK」包，并进入 ESTABLISHED 状态</li><li>服务端收到最后一个「ACK」包后，也进入 ESTABLISHED 状态</li></ol><p>这是正常的 TCP 三次握手，握手完成后双端都进入 ESTABLISHED 状态，在此之后，就是正常的数据传输过程。</p><p>再回到三次握手中如果出现异常情况会是什么样的，就以最后一次报文丢失为例<br>这个问题查阅了一些过程中，发现是比较有争议的，所以还是以实践出真知为准<br>具体实践例子，可以参见：<a href="https://blog.csdn.net/zerooffdate/article/details/79359726" target="_blank" rel="noopener">TCP三次握手的第三个ack丢了会怎样</a><br>所以有些资料里写的当服务端处于 SYN-RCVD 状态下，收到客户端的数据包后，会直接回复 RTS 包响应，表示服务端错误，并进入 CLOSE 状态。是不对的<br>试想一下，服务端还在通过三次握手阶段确定对方是否真实存在，此时对方的数据已经发来了，那肯定是存在的。<br>所以当服务端处于 SYN-RCVD 状态下时，接收到客户端真实发送来的数据包时，会认为连接已建立，并进入 ESTABLISHED 状态。</p><p>另外这个问题在stackoverflow同样找到了一个比较不错的回答<br><a href="https://stackoverflow.com/questions/16259774/what-if-a-tcp-handshake-segment-is-lost" target="_blank" rel="noopener">What if a TCP handshake segment is lost?</a></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">TCP has a sequence number in all packets. Hence it<span class="string">'s easy to know if a packet was lost or not. If a host doesn'</span>t get an ACK on a packet he just resends it.</span><br><span class="line"></span><br><span class="line">In most cases though, even <span class="keyword">if</span> that ACK was lost, there will be no resending <span class="keyword">for</span> a very simple reason. Directly after the ACK, the host that opened the TCP protocol is likely to start sending data. That data will, as all TCP packets, have an ACK number, so the recipient would get an ACK that way. Hence, the sender of the SYN-ACK should reasonably not care that it didn<span class="string">'t get the ACK, because it gets an "implicit" ACK in the following package.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">The re-send of the SYN-ACK is only necessary of there no data is received at all.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Update: I found the place in the RFC that specified exactly this:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    If our SYN has been acknowledged (perhaps in this incoming segment) the precedence level of the incoming segment must match the local precedence level exactly, if it does not a reset must be sent.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">In other words, if the ACK is dropped but the next packet is not dropped, then everything is fine. Otherwise, the connection must be reset. Which makes perfect sense</span></span><br></pre></td></tr></table></figure><p>这个其实就是tcp的累计ack，我们后面的系列谈tcp时会细谈</p><p>在查找资料的过程中，发现网上有比较常见的一种说法<br>当Client端收到Server的SYN+ACK应答后，其状态变为ESTABLISHED，并发送ACK包给Server；<br>如果此时ACK在网络中丢失，那么Server端该TCP连接的状态为SYN_RECV，并且依次等待3秒、6秒、12秒后重新发送SYN+ACK包，以便Client重新发送ACK包，<br>以便Client重新发送ACK包。Server重发SYN+ACK包的次数，可以通过设置<code>/proc/sys/net/ipv4/tcp_synack_retries</code>修改，默认值为5。如果重发指定次数后，<br>仍然未收到ACK应答，那么一段时间后，Server自动关闭这个连接。<br>但是Client认为这个连接已经建立，如果Client端向Server写数据，Server端将以RST包响应，方能感知到Server的错误。</p><p>这里的最后一句其实是有可能是有问题的，不同的tcp实现可能不同，不一定会直接回复rst，真实的情况很可能是如下这样的<br>当客户端在 ESTABLISHED 状态下，开始发送数据包时，会携带上一个「ACK」的确认序号，所以哪怕客户端响应的「ACK」包丢了，服务端在收到这个数据包时，<br>能够通过包内 ACK 的确认序号，正常进入 ESTABLISHED 状态。</p><p>还有一种安全范畴的非正常情况<br>前面一直在说正常的异常逻辑，双方都还算友善，按规矩做事，出现异常主要也是因为网络等客观问题，接下来说一个恶意的情况。<br>如果客户端是恶意的，在发送「SYN」包后，并收到「SYN,ACK」后就不回复了，那么服务端此时处于一种半连接的状态，<br>虽然服务端会通过 tcp_synack_retries 配置重试的次数，不会无限等待下去，但是这也是有一个时间周期的。<br>如果短时间内存在大量的这种恶意连接，对服务端来说压力就会很大，这就是所谓的 SYN FLOOD 攻击。</p><p>我们上面讨论的都是三次握手过程，四次挥手过程，有兴趣可以参考这篇文章，写的不错<br><a href="https://www.jianshu.com/p/723365a47c6e" target="_blank" rel="noopener">TCP三次握手、四次挥手出现意外情况时，为保证稳定，是如何处理的？</a> </p><h1 id="wireshark看三次握手"><a href="#wireshark看三次握手" class="headerlink" title="wireshark看三次握手"></a>wireshark看三次握手</h1><p>抓了一个投屏的tcpdump，可以看下三次握手的过程<br><img src="https://raw.githubusercontent.com/hellolihaizhou/saveImg/master/TCP%E7%B3%BB%E5%88%97%E4%B9%8B%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B1.png" alt=""></p><p><img src="https://raw.githubusercontent.com/hellolihaizhou/saveImg/master/TCP%E7%B3%BB%E5%88%97%E4%B9%8B%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B2.png" alt=""></p><p><img src="https://raw.githubusercontent.com/hellolihaizhou/saveImg/master/TCP%E7%B3%BB%E5%88%97%E4%B9%8B%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B3.png" alt=""></p><p>参考文章：<br><a href="https://www.jianshu.com/p/723365a47c6e" target="_blank" rel="noopener">TCP三次握手、四次挥手出现意外情况时，为保证稳定，是如何处理的？</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h1&gt;&lt;p&gt;三次握手这个话题恐怕是网络问答中最常见的问题了，基本上都能说个大概，但是再往下深究，有些问题可能回答的就不是那么顺畅了&lt;br&gt;所以想着再梳理
      
    
    </summary>
    
      <category term="网络" scheme="http://lihaizhou.top/categories/%E7%BD%91%E7%BB%9C/"/>
    
    
  </entry>
  
  <entry>
    <title>内存屏障</title>
    <link href="http://lihaizhou.top/2020/06/20/Memory-Barrier%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    <id>http://lihaizhou.top/2020/06/20/Memory-Barrier读书笔记/</id>
    <published>2020-06-20T07:56:03.000Z</published>
    <updated>2020-06-21T08:22:31.360Z</updated>
    
    <content type="html"><![CDATA[<p>本篇文章开始之前需要了解一些背景知识</p><h1 id="Cache-Memory"><a href="#Cache-Memory" class="headerlink" title="Cache Memory"></a>Cache Memory</h1><p>我们都知道程序是运行在 RAM之中，RAM 就是我们常说的DDR（例如 DDR3、DDR4等），我们称之为main memory（主存）当我们需要运行一个进程的时候，首先会从Flash设备（例如，eMMC、UFS等）中将可执行程序load到main memory中，然后开始执行。</p><p>在CPU内部存在一堆的通用寄存器（register），如果CPU需要将一个变量（假设地址是A）加1，一般分为以下3个步骤</p><ol><li>CPU 从主存中读取地址A的数据到内部通用寄存器 x0（ARM64架构的通用寄存器之一）</li><li>通用寄存器 x0 加1</li><li>CPU 将通用寄存器 x0 的值写入主存</li></ol><p>但是存在一个问题，CPU通用寄存器的速度和主存之间存在着太大的差异<br>从这个网址<a href="https://gist.github.com/jboner/2841832" target="_blank" rel="noopener">https://gist.github.com/jboner/2841832</a> 摘了一段数据<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">Latency Comparison <span class="title">Numbers</span> <span class="params">(~<span class="number">2012</span>)</span></span></span><br><span class="line"><span class="function">----------------------------------</span></span><br><span class="line"><span class="function">L1 cache reference                           0.5 ns</span></span><br><span class="line"><span class="function">Branch mispredict                            5   ns</span></span><br><span class="line"><span class="function">L2 cache reference                           7   ns                      14x L1 cache</span></span><br><span class="line"><span class="function">Mutex lock/unlock                           25   ns</span></span><br><span class="line"><span class="function">Main memory reference                      100   ns                      20x L2 cache, 200x L1 cache</span></span><br><span class="line"><span class="function">Compress 1K bytes with Zippy             3,000   ns        3 us</span></span><br><span class="line"><span class="function">Send 1K bytes over 1 Gbps network       10,000   ns       10 us</span></span><br><span class="line"><span class="function">Read 4K randomly from SSD*             150,000   ns      150 us          ~1GB/sec SSD</span></span><br><span class="line"><span class="function">Read 1 MB sequentially from memory     250,000   ns      250 us</span></span><br><span class="line"><span class="function">Round trip within same datacenter      500,000   ns      500 us</span></span><br><span class="line"><span class="function">Read 1 MB sequentially from SSD*     1,000,000   ns    1,000 us    1 ms  ~1GB/sec SSD, 4X memory</span></span><br><span class="line"><span class="function">Disk seek                           10,000,000   ns   10,000 us   10 ms  20x datacenter roundtrip</span></span><br><span class="line"><span class="function">Read 1 MB sequentially from disk    20,000,000   ns   20,000 us   20 ms  80x memory, 20X SSD</span></span><br><span class="line"><span class="function">Send packet CA-&gt;Netherlands-&gt;CA    150,000,000   ns  150,000 us  150 ms</span></span><br></pre></td></tr></table></figure></p><p>这里没有列出寄存器速度，看到L1 cache是0.5ns，可以肯定的是寄存器一定是低于1ns，Main memory是100ns，这里的数据仅供参考<br>所以上面的从主存读取数值三个步骤中的第一和第三步实际上速度很慢相对于寄存器而言</p><p>当CPU试图从主存中load/store 操作时，由于主存的速度限制，CPU不得不等待这漫长的65ns时间。如果我们可以提升主存的速度，那么系统将会获得很大的性能提升。如今的DDR存储设备，动不动就是几个GB，容量很大。如果我们采用更快材料制作更快速度的主存，并且拥有几乎差不多的容量。其成本将会大幅度上升。<br>我们试图提升主存的速度和容量，又期望其成本很低，这就有点难为人了。因此，我们有一种折中的方法，那就是制作一块速度极快但是容量极小的存储设备。那么其成本也不会太高。这块存储设备我们称之为cache memory。在硬件上，我们将cache放置在CPU和主存之间，作为主存数据的缓存。当CPU试图从主存中load/store数据的时候， CPU会首先从cache中查找对应地址的数据是否缓存在cache 中。如果其数据缓存在cache中，直接从cache中拿到数据并返回给CPU。<br><strong>CPU和主存之间直接数据传输的方式转变成CPU和cache之间直接数据传输。cache负责和主存之间数据传输。</strong></p><p>当存在cache的时候，以上程序如何运行的例子的流程将会变成如下：<br><img src="https://raw.githubusercontent.com/hellolihaizhou/saveImg/master/memory-barrier01.png" alt=""></p><p>cahe的速度在一定程度上同样影响着系统的性能。一般情况cache的速度可以达到1ns，几乎可以和CPU寄存器速度媲美。但是，这就满足人们对性能的追求了吗？并没有。当cache中没有缓存我们想要的数据的时候，依然需要漫长的等待从主存中load数据。为了进一步提升性能，引入多级cache。前面提到的cache，称之为L1 cache（第一级cache）。<br>我们在L1 cache 后面连接L2 cache，在L2 cache 和主存之间连接L3 cache。等级越高，速度越慢，容量越大。但是速度相比较主存而言，依然很快</p><p>多级cache不是本文重点，详细可参考如下两篇文章，写的比较详细<br><a href="http://www.wowotech.net/memory_management/458.html" target="_blank" rel="noopener">浅谈Cache Memory</a><br><a href="https://zhuanlan.zhihu.com/cpu-cache" target="_blank" rel="noopener">高速缓存与一致性</a></p><h2 id="Cacheline"><a href="#Cacheline" class="headerlink" title="Cacheline"></a>Cacheline</h2><p>本文后续会涉及到一个名词Cacheline，cache的大小称之为cahe size，代表cache可以缓存最大数据的大小。<br>我们将cache平均分成相等的很多块，每一个块大小称之为cache line，其大小是cache line size。例如一个64 Bytes大小的cache<br>如果我们将64 Bytes平均分成64块，那么cache line就是1字节，总共64行cache line。如果我们将64 Bytes平均分成8块，那么cache line就是8字节，总共8行cache line<br>有一点需要注意，cache line是cache和主存之间数据传输的最小单位。什么意思呢？当CPU试图load一个字节数据的时候，如果cache缺失，那么cache控制器会从主存中一次性的load cache line大小的数据到cache中。</p><p>例如，cache line大小是8字节。CPU即使读取一个byte，在cache缺失后，cache会从主存中load 8字节填充整个cache line，至于原因可以参见这篇文章:<br><a href="http://www.wowotech.net/memory_management/458.html" target="_blank" rel="noopener">浅谈Cache Memory</a></p><p>有了前面的基础知识的认知，不难理解下面这个极简的抽象CPU架构图<br><img src="https://raw.githubusercontent.com/hellolihaizhou/saveImg/master/memory-barrier02.gif" alt=""></p><h1 id="缓存一致性"><a href="#缓存一致性" class="headerlink" title="缓存一致性"></a>缓存一致性</h1><p>考虑到多线程读写环境中，不免会有个疑问，如果一个数据是多个cpu都共享，其中一个修改了是不是要想办法使得其他cpu也能更新<br>一个cpu去读取一个数值时，怎么确定是最新的呢？说到底就是要保证在使用cache后如何确保各 CPU 看到的数据是一致的<br>这个就引出另外一个名词“cache-coherence protocol”即缓存一致性协议<br>其中，MESI protocol 是一个基本版，从 MESI protocol 可以了解 CPU 之间如何维持看到一致的资料，可以参见MESI的维基定义:   <a href="https://zh.wikipedia.org/wiki/MESI%E5%8D%8F%E8%AE%AE" target="_blank" rel="noopener">MESI协议</a></p><p>这里摘取英文文档中的对于MESI拆解开来的四种状态的解释<br><code>A line in the “modified” state has been subject to a recent memory store from the corresponding CPU, and the corresponding memory is guaranteed not to appear in any other CPU’s cache. Cache lines in the “modified”state can thus be said to be “owned” by the CPU. Because this cache holds the only up-to-date copy of the data, thiscache is ultimately responsible for either writing it back to memory or handing it off to some other cache, and must do so before reusing this line to hold other data.</code><br>处于modified状态的cacheline说明近期有过来自对应cpu的写操作，同时也说明该该数据不会存在其他cpu对应的cache中。因此，处于modified状态的cacheline也可以说是被该CPU独占。而又因为只有该CPU的cache保存了最新的数据（最终的memory中都没有更新），所以，该cache需要对该数据负责到底。例如根据请求，该cache将数据及其控制权传递到其他cache中，或者cache需要负责将数据写回到memory中，而这些操作都需要在reuse该cache line之前完成。<br><code>The “exclusive” state is very similar to the “modified”state, the single exception being that the cache line has not yet been modified by the corresponding CPU, which in turn means that the copy of the cache line’s data that resides in memory is up-to-date. However, since the CPU can store to this line at any time, without consulting other CPUs, a line in the “exclusive” state can still be said to be owned by the corresponding CPU. That said, because the corresponding value in memory is up to date, this cache can discard this data without writing it back to memory or handing it off to some other CPU.</code><br>exclusive状态和modified状态非常类似，唯一的区别是对应CPU还没有修改cacheline中的数据，也正因为还没有修改数据，因此memory中对应的data也是最新的。在exclusive状态下，cpu也可以不通知其他CPU cache而直接对cacheline进行操作，因此，exclusive状态也可以被认为是被该CPU独占。由于memory中的数据和cacheline中的数据都是最新的，因此，cpu不需对exclusive状态的cacheline执行写回的操作或者将数据以及归属权转交其他cpu cache，而直接reuse该cacheline（将cacheine中的数据丢弃，用作他用）<br><code>A line in the “shared” state might be replicated in at least one other CPU’s cache, so that this CPU is not permitted to store to the line without first consulting with other CPUs. As with the “exclusive” state, because thecorresponding value in memory is up to date, this cache can discard this data without writing it back to memory or handing it off to some other CPU.</code><br>处于share状态的cacheline，其数据可能在一个或者多个CPU cache中，因此，处于这种状态的cache line，CPU不能直接修改cacheline的数据，而是需要首先和其他CPU cache进行沟通。和exclusive状态类似，处于share状态的cacheline对应的memory中的数据也是最新的，因此，cpu也可以直接丢弃cacheline中的数据而不必将其转交给其他CPU cache或者写回到memory中。<br><code>A line in the “invalid” state is empty, in other words, it holds no data. When new data enters the cache, it is placed into a cache line that was in the “invalid” state if possible. This approach is preferred because replacing a line in any other state could result in an expensive cache miss should the replaced line be referenced in the future.</code><br>处于invalid状态的cacheline是空的，没有数据。当新的数据要进入cache的时候，优选状态是invalid的cacheline，之所以如此是因为如果选中其他状态的cacheline，则说明需要替换cacheline数据，而未来如果再次访问这个被替换掉的cacheline数据的时候将遇到开销非常大的cache miss  </p><font color="red"> 个人理解:<br>1. 对于modified状态的cacheline，别的cpu如果需要其中的数据，必须要写回到memory或者转移<br>2. exclusive可以理解为是modified的轻量版，exclusive状态的cacheline数据此时还没有被cpu修改，也就是说它的数据和memory中是一致的，当别的cpu需要状态是exclusive的cacheline数据时，可以直接提供数据不需要写回到memory<br>3. share状态的cacheline不能直接被修改，如果一个cpu需要对这个cacheline进行修改了，需要先通知其他cpu让他们将各自对应的cacheline置为invalid，然后再切换cacheline的状态到exclusive，再然后就是M状态<br>4. invalid状态的cacheline之前可能是有数据的，比如之前是shared状态，后来其他cpu要修改这个cacheline了，就发通知过来了要求置为invalid的，不然读取出来的就是错误的<br><br> </font><p>有一个MESI动画的网址，可以模拟各个cacheline的状态切换，比起文字描述来讲更好理解，可以不断的模拟测试，对理解MESI很有帮助<br><a href="https://www.scss.tcd.ie/Jeremy.Jones/VivioJS/caches/MESIHelp.htm" target="_blank" rel="noopener">VivioJS - Interactive Reversible E-Learning Animations for the WWW</a></p><p>比如当前状态<br><img src="https://raw.githubusercontent.com/hellolihaizhou/saveImg/master/memory-barrier03.png" alt=""></p><font color="red"><br>个人理解添加<br>此时CPU0上a1数据对应的cacheline此时的状态是M状态，可以看到此时的数值是11，比memory要新，其他两个cpu1，cpu2上的a1对应的cacheline是invalid状态。如果此时cpu2上对a1进行写值加1，会是什么样子的呢？<br>根据上面的理论知识，此时应该会通过总线通知cpu0让其写入到memory中，然后cpu2才能读取到最新的值此时再进行修改此时数值应该是12并将状态置为E并且写回memory，此时CPU0上的a1对应cacheline状态理论上应该是invalid。<br></font><br>实际的cpu2对a1加1后效果图如下：<br><img src="https://raw.githubusercontent.com/hellolihaizhou/saveImg/master/memory-barrier04.png" alt=""><br><font color="red"> 个人理解添加<br>此时如果对cpu2的cacheline进行写加1，cacheline状态会切换到M状态，如果一直写，数值一直增加一直是M状态，其他cpu无变化。因为此时M是最新的，只有其他cpu比如此时cpu1需要读取a1的值，这个时候cpu2会将这个值写回到memory并且此时cpu1和cpu2上a1对应的cacheline状态都是S。<br>如果这个时候，对cpu2的a1进行写操作呢？其状态会切换到E，其他cpu对应的a1-cacheline都切到invalid<br>介绍完MESI后，我们知道有了MESI protocol，任何一个CPU 要写入资料前，都要先确保其它CPU 已invalid 同一位置的cache 后(希望写入的CPU 广播invalidate，其它CPU 回invalidate ack)， 才能写资料到自己的cache，并在稍后补写回memory。<br></font><br>这个设计确保资料的一致性，不用担心同一时间同一个位置的资料会有不同的值，但是代价是写入 cache 的速度会有点慢，让 CPU 闲置，下图中的stall就是cpu等待的时长<br><img src="https://raw.githubusercontent.com/hellolihaizhou/saveImg/master/memory-barrier05.png" alt=""><br><br><font color="red">  个人理解添加<br>想象一下这个场景：<br><em> CPU 0 打算写入值到位置 X，CPU 1 的 cache 有 X 的值。因为缓存一致性的缘故，这个时候CPU0给CPU1发送一个invalid的广播告知其需要将其对应数值置于无效</em> 这个时候呢cpu0就开始傻乎乎的等 CPU 1 回 invalidate ack，但是此时CPU 1 的 cache 可能太忙而拖慢了回覆时间 (比方同时从 cache 大量的读写资料，或是短时间收到大量 invalidate ack)。<br>这样就导致了CPU0白白耗费时间在等待上，这对于宝贵的cpu资源是一种很大的浪费，其实没必要等待这么长的时间，毕竟物理CPU 1中的cacheline保存有什么样子的数据，其实都没有意义，这个值都会被CPU 0新写入的值覆盖的，所以能不能不等呢？这也就引出了另外一个名词StoreBuffer，还有另外一个名词对应刷新的Invalidate Queue<br></font> <h2 id="Store-Buffer-amp-Invalidate-Queue"><a href="#Store-Buffer-amp-Invalidate-Queue" class="headerlink" title="Store Buffer &amp; Invalidate Queue"></a>Store Buffer &amp; Invalidate Queue</h2><p>在CPU和cache之间增加store buffer这个HW block</p><font color="red">  个人理解添加<br>1. CPU 0 不等 invalidate ack：先写入 store buffer，然后继续作事。之后收到 invalidate ack 再更新 cache 的状态。因为最新的资料可能存在 store buffer，CPU 读资料的顺序变成 store buffer → cache → memory。<br>2. CPU 1 立即回 invalidate ack：收到 invalidate 时，记录到 invalidate queue 里，先回 invalidate ack，稍后再处理 invalidate。<br>3. 为啥有了store buffer后还会冒出来一个invalidate queue，因为 store buffer 很小，store buffer 满的时候，CPU 0 还是得等 invalidate ack，所以加上 invalidate queue，双管齐下减少 CPU 0 等待时间<br>这里还有一个细节后面会提到，如果有数据加了写内存屏障的话，加入storebuffer，其后面的写操作不管有没有写屏障都要加到storebuffer中，这就造成了storebuffer更容易满了，一旦满了又要开始等ack了，这就引入了<br>invalidate queue，后面还会继续讲它的作用<br>其实这里出现了一个重排序的“现象”，就是一旦某一条写指令放到storebuffer中了继续后面的指令操作，这就造成了下一条指令跑到这条指令前面执行的”假象”，这种重排序就是为了充分利用cpu的性能避免白白的浪费等待<br>CPU 为了提升效率而出现的这种”改指令”执行的顺序，只要最后結果和 single thread 预期的結果一样即可。这句话可以细品下，所以多线程的情况下需要我们研发人员自己控制<br></font>  <p>有了StoreBuffer以及Invalidate Queue之后的cpu cache架构如下<br><img src="https://raw.githubusercontent.com/hellolihaizhou/saveImg/master/memory-barrier06.png" alt=""></p><p>下面摘自perfbook文档关于StoreBuffer以及Invalidate Queue的解释</p><p><code>These store buffers are local to a given CPU or, on systems with hardware multithreading, local to a given core. Either way, a given CPU is permitted to access only the store buffer assigned to it. For example, in Figure C.5, CPU 0 cannot access CPU 1’s store buffer and vice versa. This restriction simplifies the hardware by separating concerns: The store buffer improves performance for consecutive writes, while the responsibility for communicating among CPUs (or cores, as the case may be) is fully shouldered by the cache-coherence protocol. However, even given this restriction, there are complications that must be addressed, which are covered in the next two sections.</code></p><p>这些store buffer对于cpu而言是local的，如果系统是硬件多线程， 那么每一个cpu core拥有自己私有的stroe buffer，一个cpu只能访问自己私有的那个store buffer。在上图中，cpu 0不能访问cpu1的store buffer，反之亦然。之所以做这样的限制是为了模块划分（各个cpu core模块关心自己的事情，让cache系统维护自己的操作），让硬件设计变得简单一些。store buffer增加了CPU连续写的性能，同时把各个CPU之间的通信的任务交给维护cache一致性的协议。即便给每个CPU分配私有的store buffer，仍然引入了一些复杂性，我们会在下面两个小节中描述。</p><p><code>Unfortunately, each store buffer must be relatively small, which means that a CPU executing a modest sequence of stores can fill its store buffer (for example, if all of them result in cache misses). At that point, the CPU must once again wait for invalidations to complete in order to drain its store buffer before it can continue executing. This same situation can arise immediately after a memory barrier, when all subsequent store instructions must wait for invalidations to complete, regardless of whether or not these stores result in cache misses.</code></p><p>不幸的是：每个cpu的store buffer不能实现的太大，其entry的数目不会太多。当cpu以中等的频率执行store操作的时候（假设所有的store操作导致了cache miss），store buffer会很快的被填满。在这种状况下，CPU只能又进入等待状态，直到cache line完成invalidation和ack的交互之后，可以将store buffer的entry写入cacheline，从而为新的store让出空间之后，CPU才可以继续执行。这种状况也可能发生在调用了memory barrier指令之后，因为一旦store buffer中的某个entry被标记了，那么随后的store都必须等待invalidation完成，因此不管是否cache miss，这些store都必须进入store buffer。</p><p><code>This situation can be improved by making invalidate acknowledge messages arrive more quickly. One way of accomplishing this is to use per-CPU queues of invalidate messages, or “invalidate queues”.</code></p><p>引入invalidate queues可以缓解这个状况。store buffer之所以很容易被填充满，主要是其他CPU回应invalidate acknowledge比较慢，如果能够加快这个过程，让store buffer尽快进入cacheline，那么也就不会那么容易填满了。</p><p><code>Invalidate QueuesOne reason that invalidate acknowledge messages can take so long is that they must ensure that the correspondingcache line is actually invalidated, and this invalidation can be delayed if the cache is busy, for example, if the CPU is intensively loading and storing data, all of which resides in the cache. In addition, if a large number of invalidate messages arrive in a short time period, a given CPU might fall behind in processing them, thus possibly stalling all the other CPUs.</code></p><p>invalidate acknowledge不能尽快回复的主要原因是invalidate cacheline的操作没有那么快完成，特别是cache比较繁忙的时候，这时，CPU往往进行密集的loading和storing的操作，而来自其他CPU的，对本CPU local cacheline的操作需要和本CPU的密集的cache操作进行竞争，只要完成了invalidate操作之后，本CPU才会发生invalidate acknowledge。此外，如果短时间内收到大量的invalidate消息，CPU有可能跟不上处理，从而导致其他CPU不断的等待。</p><p><code>However, the CPU need not actually invalidate the cache line before sending the acknowledgement. It could instead queue the invalidate message with the understanding that the message will be processed before the CPU sends any further messages regarding that cache line.</code></p><p>然而，CPU其实不需要完成invalidate操作就可以回送acknowledgement消息，这样，就不会阻止发生invalidate请求的那个CPU进入无聊的等待状态。CPU可以buffer这些invalidate message（放入Invalidate Queues），然后直接回应acknowledgement，表示自己已经收到请求，随后会慢慢处理。当然，再慢也要有一个度，例如对a变量cacheline的invalidate处理必须在该CPU发送任何关于a变量对应cacheline的操作到bus之前完成。</p><p>有了Invalidate Queue的CPU，在收到invalidate消息的时候首先把它放入Invalidate Queue，同时立刻回送acknowledge 消息，无需等到该cacheline被真正invalidate之后再回应。当然，如果本CPU想要针对某个cacheline向总线发送invalidate消息的时候，那么CPU必须首先去Invalidate Queue中看看是否有相关的cacheline，如果有，那么不能立刻发送，需要等到Invalidate Queue中的cacheline被处理完之后再发送。</p><p><code>Placing an entry into the invalidate queue is essentially a promise by the CPU to process that entry before transmitting any MESI protocol messages regarding that cache line. As long as the corresponding data structures are not highly contended, the CPU will rarely be inconvenienced by such a promise.</code></p><p>一旦将一个invalidate（例如针对变量a的cacheline）消息放入CPU的Invalidate Queue，实际上该CPU就等于作出这样的承诺：在处理完该invalidate消息之前，不会发送任何相关（即针对变量a的cacheline）的MESI协议消息。只要是对该cacheline的竞争不是那么剧烈，CPU还是对这样的承诺很有信心的</p><p>因为多了 store buffer 和 invalidate queue，cache 之间的资料就没有完全一致了</p><h2 id="一个小案例"><a href="#一个小案例" class="headerlink" title="一个小案例"></a>一个小案例</h2><p>有了上面一连串理论知识的铺垫，下面看一个小例子，这个例子是老演员了，其实也是摘自perfbook中的，在查阅资料过程中发现很多博客都是用的这个图</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> a = b = <span class="number">0</span>;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">foo</span><span class="params">(<span class="keyword">void</span>)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  a = <span class="number">1</span>;</span><br><span class="line">  b = <span class="number">1</span>;</span><br><span class="line">&#125;</span><br><span class="line">  </span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">bar</span><span class="params">(<span class="keyword">void</span>)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="keyword">while</span> (b == <span class="number">0</span>) <span class="keyword">continue</span>;</span><br><span class="line">  <span class="keyword">assert</span>(a == <span class="number">1</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>考虑 CPU 0 执行 foo()， CPU 1 执行 bar()，也就是我们常说的多线程环境，假设 cache 的状态如下:<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">        a       b</span><br><span class="line">------------------------</span><br><span class="line">CPU <span class="number">0</span>:  Shared  Modified</span><br><span class="line">CPU <span class="number">1</span>:  Shared  Invalid</span><br></pre></td></tr></table></figure></p><p>其实可以理解为假设 a,b 初始值为 0 ，a 被 CPU0 和 CPU1 共同持有，b 被 CPU0 独占</p><p>试想，即便在多线程环境下，foo 和 bar 如若严格按照理想的顺序执行，是无论如何都不会出现 assert failed 的情况的。但往往事与愿违，这种看似很诡异的且有一定几率发生的 assert failed ，结合上面所说的 Store Buffer 就一点都不难理解了<br>我们来还原 assert failed 的整个过程</p><ol><li>CPU0 处理 a=1 之前发送 Invalidate 消息给 CPU1 ，并将其放入 Store Buffer ，尚未及时刷入缓存，所以这时候 cache 里a的值仍是 0；</li><li>CPU 0 转而处理 b=1 ，注意这里我们上面假设的是此时b 的状态已是 Modified，所以 b=1 直接被刷入缓存；</li><li>CPU 1 发出 Read 消息读取 b 的值，CPU 1 从 CPU 0 的 cache 读到 b = 1 ，跳出 while 语句；</li><li>CPU 1 发出 Read 消息读取 a 的值，发现 a 却为旧值 0，assert failed，然后收到 CPU 0 送来 “invalidate a” 的讯息，但已太迟了</li></ol><p>上面这个还原过程摘自一个台湾人写的博客&lt;從硬體觀點了解 memory barrier 的實作和效果&gt;<br>个人感觉这个描述过程不完全准确，既然已经有了Invalidate Queue，这个时候cpu1理论上是立刻给cpu0发ack的，可能由于当前要回复的ack很多，导致发送给cpu0的ack并没有达到”立刻”的效果<br>所以出现上面描述的过程也是有可能的，但是其实还有一种可能，就是读取a的时候最新值Invalidate Queue中，详细在下面的个人理解环节中  </p><font color="red"><br>个人理解如下<br>1. 大致流程是CPU0这个时候想要对a进行写值，发现a对应的cacheline对应的状态是S，也就是这里的cpu1上也有a的值，所以需要通知cpu1，通过总线发个消息告知cpu1进行invalid，因为有storebuffer这玩意所以直接放到storebuffer，又因为有invalidate queue的存在<br>2. 所以CPU1立刻回复了“已更新”的ack回去了，其实并没有实际更新，只是先放在了invalidate queue中待更改标记为invalid，CPU0收到这个ack后将数据回写到内存中<br>3. 此时CPU0开始了执行下一条对b写值，因为b是M状态也是说是cpu0独占的，所以直接写到缓存就完事了<br>4. 再来到cpu1这边看看，此时cpu1读取b的值，因为cpu1上没有对应的cacheline，cpu0上b对应的cacheline是M状态，所以此时cpu0会将b的值写回到memory,并且这个时候cpu1读取到的值是最新的和memory一样，此时cpu1和cpu0上b对于的cacheline状态变为S<br>5. 这个时候再看assert(a == 1);  此时CPU1读取到的数值a仍然是S状态，所以直接读取了，读取出来自然是0，因为此时并没有去invalidate queue看看有没有值，所以看到的值不是最新的，出现assert fail<br><br>如何解决这个问题呢？可以在foo函数a=1下面加一个写内存屏障，这样的话当a=1的值放到storebuffer中后，发现后面有一个写内存屏障指令，这个时候就会把后面的写指令都会顺序放到storebuffer中。另外在bar函数第二行读取a的时候需要看下invalidqueue中有没有值，有的话一定要将对应值得cacheline标记为无效，然后去读取最新值，这就引入了读内存屏障，强制标记队列中所有的值对应cacheline为无效<br></font> <p>上面的这个程序在实际开发中也是有可能会遇到的，于是 CPU提供了write memory barrier 以及 read memory barrier，让软件有机会避免这个问题</p><h2 id="write-memory-barrier"><a href="#write-memory-barrier" class="headerlink" title="write memory barrier"></a>write memory barrier</h2><p>比如在上面的 foo 方法中，a 的赋值和 b 的赋值之间加上这个write memory barrier<br>会使得 CPU 在后续变量变更写入之前，把 Store Buffer 的变更写入 flush 到缓存；CPU 要么就等待 flush 完成后写入，要么就把后续的写入变更放到 Store Buffer 中，直到 Store Buffer 数据顺序刷到缓存。<br><strong>write memory barrier 确保之前在 store buffer 里的资料会先更新到 cache，然后才能写入 barrier 之后的资料到 cache。</strong></p><p>假设我们在 foo() 的 a=1 和 b=1 之间插一个 write memory barrier，过程变为</p><ol><li>write memory barrier 先设 store buffer 里的资料为 “marked” (即 a=1)</li><li>写入 b 的时候，因为发现 store buffer 里有 marked 的栏位，所以即使 b 已处于 Modified，仍需写入 b=1 到 store buffer，不过状态是 “unmarked”</li><li>待收到 a 的 invalidate ack 后，cache 中 a 的状态改为 Modified，然后先写入有 marked 栏位的值到 cache，再写入 unmarked 栏位的值到 cache。</li></ol><p>这样其它 CPU 就会依序看到 a、b 更新的值了</p><h2 id="read-memory-barrier"><a href="#read-memory-barrier" class="headerlink" title="read memory barrier"></a>read memory barrier</h2><p>还是以上面的例子说明，假设 CPU 1 的 cache 里 a 处于 Shared。 CPU 0 已更新 a、b 到它的 cache，CPU 1 的 invalidate queue 里有 “invalidate a”，但还没处理。<br>这时 CPU 1 依序读 b、a 的值，会从 CPU 0 的 cache 读到 b=1，然后从自己的 cache 读到 a=0 (因为还没 invalidate a)。和上面的写入情况本质一样的，invalidate queue破坏了缓存一致性<br>invalidate queue是最新的，但是 a 处于 Shared，所以会从cache中直接拿，拿得是0，不是最新的<br>所以即便在foo函数给a,b分别赋值中间加上写栅栏，还是不能完全保证得到的结果是我们想要的，其实这个时候，可以猜到需要在assert之前也就是读取a之前加上一个读栅栏read memory barrier<br>目的很明确确保先清空 invalidate queue 再继续读资料。<br>在 assert(a==1) 之前插入 read memory barrier，执行顺序变成这样:</p><ol><li>CPU 1 执行 read memory barrier 时会设 invalidate queue 里的资料为 “marked”</li><li>CPU 1 读 cache 里 a 的值时，发现 invalidate queue 里有标记 a，于是会先执行 invalidate a 再继续读 a 的值</li><li>执行 invalidate a 后，就不会读自己 cache 的值，而改从 CPU 0 的 cache 读到最新的值，达到「依序读 b、a 的值」的效果</li></ol><h2 id="第二个小案例"><a href="#第二个小案例" class="headerlink" title="第二个小案例"></a>第二个小案例</h2><p>再摘一句perfbook的话，说的有点意思</p><p><code>Since the standard synchronization primitives preserve the illusion of ordering, your path of least resistance is to stop reading this section and simply use these primitives.However, if you need to implement the synchronization primitives themselves, or if you are simply interested in understanding how memory ordering and memory barriers work, read on!</code></p><p>你也许面对CPU的这种out of order的行为有本能的抵抗，没有关系，放轻松，你的抵抗之路可以到此结束，只要你愿意使用各种同步原语来保护你程序中的共享资源，因为透过这些标准的同步原语，你看到的是一个顺序执行的世界。当然，这会引入一些小小的遗憾：你不知道底层到底是如何把“乱序”变成“有序”的。不过，实现同步原语的那些软件工程师没有这个豁免权，他们必须要深入理解memory order和memory barrier。此外，那些想要“打破沙锅问到底”以及想要“知其然知其所以然”的工程师也可以跟随我们继续。</p><p>再举一个例子，摘自 perfbook memory barrier（14.2章节）<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1</span> thread0(<span class="keyword">void</span>)</span><br><span class="line"><span class="number">2</span> &#123;</span><br><span class="line"><span class="number">3</span> A = <span class="number">1</span>;</span><br><span class="line"><span class="number">4</span> smp_wmb();</span><br><span class="line"><span class="number">5</span> B = <span class="number">1</span>;</span><br><span class="line"><span class="number">6</span> &#125;</span><br><span class="line"><span class="number">7</span></span><br><span class="line"><span class="number">8</span> thread1(<span class="keyword">void</span>)</span><br><span class="line"><span class="number">9</span> &#123;</span><br><span class="line"><span class="number">10</span> <span class="keyword">while</span> (B != <span class="number">1</span>)</span><br><span class="line"><span class="number">11</span> <span class="keyword">continue</span>;</span><br><span class="line"><span class="number">12</span> barrier();</span><br><span class="line"><span class="number">13</span> C = <span class="number">1</span>;</span><br><span class="line"><span class="number">14</span> &#125;</span><br><span class="line"><span class="number">15</span></span><br><span class="line"><span class="number">16</span> thread2(<span class="keyword">void</span>)</span><br><span class="line"><span class="number">17</span> &#123;</span><br><span class="line"><span class="number">18</span> <span class="keyword">while</span> (C != <span class="number">1</span>)</span><br><span class="line"><span class="number">19</span> <span class="keyword">continue</span>;</span><br><span class="line"><span class="number">20</span> barrier();</span><br><span class="line"><span class="number">21</span> <span class="keyword">assert</span>(A != <span class="number">0</span>);</span><br><span class="line"><span class="number">22</span> &#125;</span><br></pre></td></tr></table></figure></p><p>开始，变量A，B，C的初始值都是0。根据程序逻辑：thread0中，A先于B赋值，thread1中，程序逻辑是一直等到B变量被赋值为1之后，再给C赋值。这里，人类的直觉告诉我们，如果变量C已经被赋值为1的时候（第13行程序），A一定已经被赋值为1了。同样的，在thread2中，第21行程序的assert一定是不会被触发的。</p><p><code>This line of reasoning, intuitively obvious though it may be, is completely and utterly incorrect. Please note that this is not a theoretical assertion: actually running this code on real-world weakly-ordered hardware (a 1.5GHz 16-CPU POWER 5 system) resulted in the assertion firing 16 times out of 10 million runs. Clearly, anyone who produces code with explicit memory barriers should do some extreme testing – although a proof of correctness might be helpful, the strongly counter-intuitive nature of the behavior of memory barriers should in turn strongly limit one’s trust in such proofs. The requirement for extreme testing should not be taken lightly, given that a number of dirty hardware-dependent tricks were used to greatly increase the probability of failure in this run.</code></p><p>上一节的推理从直觉上看是对的，但是在实际的CPU上运行的结果确是完全错误的。特别需要指出的是这个结果不是理论推导得出来的，是在真实的1.5GHz 16核的POWER 5系统（该cpu的内存模型属于weakly order）上观测得到的，平均每1千万次执行会有16次在21行代码处出现assert失败。很显然，当我们撰写显式调用memory barrier的代码的时候，必须进行非常大量的实际测试。在理论上进行正确性的推导是否有意义呢？也许有帮助，但是，你知道的，在使用memory barrier的时候会发生很多和你的直觉相悖的东西，这让理论的推导变得不那么确定。别小看那些看起来愚蠢的、非常重复性的大量测试，要知道不同的CPU会使用不同的硬件设计方法，因此在memory order和memory barrier方面表现各不相同，你的程序想要在各种硬件上，每次都运行成功不是一件容易的事情。</p><font color="red"><br>个人理解:<br>到底发生了什么让程序在21行的assert上失败？我们一起分析一下。我们假设CPU0、CPU1和CPU2分别执行thread0、thread1和thread2<br>1. 对于thread 0，我们假设A在CPU0的local cache中，但是状态是shared，因此当执行A=1的语句的时候，不能立刻执行，需要和其他CPU cache进行沟通（发送invalidate message去其他CPU），当然，cpu不会停下其脚步，将A的新值1放入store buffer，继续执行。<br>2. smp_wmb可以mark store buffer中A值，并且阻止后续的store操作进入cache，这时候，即便B在CPU0的local cache中，B=1的赋值也不能操作到cache，而是要进入store buffer，当然状态是unmarked。前面说过，后面进cache的话是marked先进然后unmarked进，由于存在Invalidate Queue这中东西，因此，CPU 0很快就可以收到来自其他CPU的响应，这时候，CPU0可以越过write memory barrier，完成对B的赋值。此时A的状态切到M，回写到cache中，B也跟着回写到cache中了。<br>3. 因此，对于thread1，很快可以感知B的新值“1”并执行了对C变量的赋值。来到thread2，同样的，对C变量的load操作也可以感知到thread1中的赋值因此跳出while循环。<br>4. 最关键的来了，第20行的barrier这个优化屏障不能阻止CPU对A变量的访问，但是，可能由于这时CPU cache操作非常繁忙，A变量的invalidate message还在其invalidate queue中，因此load A得到了旧的值0。<br><br>当然，要修正这个问题非常简单，修改20行代码为smp_rmb即可。一旦执行了smp_rmb，就会mark invalidate queue中的entry，这时候，CPU执行后续的load操作都必须要等到Invalidate queue中的所有缓存的invalidate message（当然，状态必须是marked）被处理并体现到cache中。因此，使用smp_rmb即可以在21行的load A操作中总是获取A的新值“1”从而避免了assert fail。<br>这里有个疑问就是例子中的barrier();这玩意到底到底代表啥意思，按照作者想要表达的意思是barrier()起不到读屏障的功能，要改为smp_rmb<br></font> <h2 id="简要归纳"><a href="#简要归纳" class="headerlink" title="简要归纳"></a>简要归纳</h2><p>硬件为了减少读写 memory 而有 cache。有 cache 就要确保 cache 之间的资料一致 (同一时间同一位置只有一个值)。但确保 cache 资料完全一致容易让 CPU 闲置，于是有了 store buffer 和 invalidate queue 降少 CPU 闲置。代价是只保证 CPU 自己会读到自己写入的最新数据，但其它 CPU 不一定。<br><strong>为了让其它 CPU 有需要的时候也能读到最新的资料，针对 store buffer 和 invalidate queue 的副作用设计了 write/read memory barrier</strong><br>于是写程序的人在需要的时候可以用 memory barrier 确保关键的数据有依正确的顺序更新 (没保证更新的时间)。 CPU 在多数情况下仍能避免闲置。<br>到此可以了解为什么这两种操作合在一起比较符合 CPU 架构：</p><ul><li>一个 thread 「先 write X 后执行 write memory barrier」</li><li>另一个 thread 「先执行 read memory barrier 后 read X」</li></ul><h1 id="java内存模型"><a href="#java内存模型" class="headerlink" title="java内存模型"></a>java内存模型</h1><p>这里再谈一下java的内存模型，这个模型是抽象出来的，下面这个图网上找的也是老演员了，最初来自深入理解虚拟机一书<br><img src="https://raw.githubusercontent.com/hellolihaizhou/saveImg/master/memory-barrier07.png" alt=""></p><font color="red"><br>个人理解:<br>这里的java线程对应着cpu，工作内存其实是不存在的，可以简单的理解为是cpu的cache，save和load其实对应的是缓存一致性协议<br></font> <h2 id="JVM-barrier"><a href="#JVM-barrier" class="headerlink" title="JVM barrier"></a>JVM barrier</h2><ul><li>LoadLoad：两个 Load 操作之间内存屏障，smp_rmb 就是典型实现；</li><li>StoreStore：两个Store 操作之间的内存屏障，smp_wmb 典型实现；</li><li>LoadStore：在 Load 操作和 Store 操作之间的内存屏障；</li><li>StoreLoad：在 Store 操作和  Load 操作之间的内存屏障</li></ul><font color="red"><br>个人理解添加<br>以StoreLoad为例，这个是上面四个中最重的，最耗性能的，storeload其实能涵盖上面三个，因为它既保证了写也保证了读，它和loadstore的侧重点不一样，loadstore对于后面的那个写什么时候能写进去不是非常要求，更侧重的是前面的写。前一个是写后一个是读，后一个读取不能重排到这个写操作之前，也就是load时要看到前面写的值，这也就要保证前一个写的内容如果在storebuffer中就一定要写到cache中.<br>然后load的时候不能直接去读cache的值，要将invalidqueue中的值处理掉，该标记无效的都要进行标记，确保读取出来的是最新的。<br></font>   <p>对于java中的volatile防止重排网上博客一大堆，有些文章从汇编角度来分析加了volatile前后的对比，本地测试过hsdis可以用来将java转换为对应的汇编，这里就不展开了     </p><p><font color="red"> 个人理解<br>volatile最重要的使命是为了可见性，为了达到可见性这个目的不得不设计出防止指令重排，因为如果不限制重排，就达不到可见性这个目的<br>所以可以理解防止重排只是达到可见性的一个不得已手段<br></font><br><br>   </p><p><strong>参考文章</strong><br><a href="https://www.infoq.com/articles/memory_barriers_jvm_concurrency/" target="_blank" rel="noopener">Memory Barriers and JVM Concurrency</a><br><a href="http://www.wowotech.net/kernel_synchronization/memory-barrier.html" target="_blank" rel="noopener">Linux内核同步机制之（三）：memory barrier</a><br><a href="https://medium.com/fcamels-notes/%E5%BE%9E%E7%A1%AC%E9%AB%94%E8%A7%80%E9%BB%9E%E4%BA%86%E8%A7%A3-memry-barrier-%E7%9A%84%E5%AF%A6%E4%BD%9C%E5%92%8C%E6%95%88%E6%9E%9C-416ff0a64fc1" target="_blank" rel="noopener">從硬體觀點了解 memory barrier 的實作和效果</a><br><a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2015/p0098r0.pdf" target="_blank" rel="noopener">P0098R0: Towards Implementation and Use ofmemoryorderconsume</a><br><a href="https://createpoint.qti.qualcomm.com/search/contentdocument/stream/35553?refererRoute=search%2FsearchArgs%2Fq%7C%7CMemory%20Barriers%7C%7Crows%7C%7C10%7C%7CsortField%7C%7Cscore%7C%7CsortOrder%7C%7Cdesc&amp;dcn=80-N5603-1&amp;currentPage=1&amp;itemTotalIndex=1" target="_blank" rel="noopener">LINUX MEMORY ORDERING ON SCORPION-MP AND KRAIT APPLICATION PROCESSORS</a><br><a href="https://preshing.com/20120710/memory-barriers-are-like-source-control-operations/" target="_blank" rel="noopener">Memory Barriers Are Like Source Control Operations</a><br><a href="https://mp.weixin.qq.com/s?__biz=MzUzMDk3NjM3Mg==&amp;mid=2247483755&amp;idx=1&amp;sn=50f80e73f46fab04d8a799e8731432c6&amp;chksm=fa48da70cd3f5366d9658277cccd9e36fca540276f580822d41aef7d8af4dda480fc85e3bde4&amp;token=630636109&amp;lang=zh_CN#rd" target="_blank" rel="noopener">从 Java 内存模型看内部细节</a><br><a href="http://www.4e00.com/blog/java/2018/10/21/inside-java-memory-model.html" target="_blank" rel="noopener">深入理解 java 内存模型</a><br><a href="http://www.wowotech.net/memory_management/458.html" target="_blank" rel="noopener">浅谈Cache Memory</a><br><a href="http://www.wowotech.net/kernel_synchronization/Why-Memory-Barriers.html" target="_blank" rel="noopener">Why Memory Barriers</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;本篇文章开始之前需要了解一些背景知识&lt;/p&gt;
&lt;h1 id=&quot;Cache-Memory&quot;&gt;&lt;a href=&quot;#Cache-Memory&quot; class=&quot;headerlink&quot; title=&quot;Cache Memory&quot;&gt;&lt;/a&gt;Cache Memory&lt;/h1&gt;&lt;p&gt;我们都知
      
    
    </summary>
    
      <category term="Linux" scheme="http://lihaizhou.top/categories/Linux/"/>
    
    
  </entry>
  
  <entry>
    <title>mmap机制初探</title>
    <link href="http://lihaizhou.top/2020/05/25/mmap%E6%9C%BA%E5%88%B6%E5%88%9D%E6%8E%A2/"/>
    <id>http://lihaizhou.top/2020/05/25/mmap机制初探/</id>
    <published>2020-05-25T11:18:16.000Z</published>
    <updated>2020-06-02T03:37:05.927Z</updated>
    
    <content type="html"><![CDATA[<p>在Unix/Linux系统下读写文件，一般有两种方式</p><p><code>第一种方式：传统的read/write方式</code></p><p>常规文件系统操作的调用过程：</p><ul><li><p>进程发起读文件请求</p></li><li><p>内核通过查找进程文件符表，定位到内核已打开文件集上的文件信息，从而找到此文件的inode</p></li><li><p>inode在address_space上查找要请求的文件页是否已经缓存在页缓存中。如果存在，则直接返回这片文件页的内容。</p></li><li><p>如果不存在，则通过inode定位到文件磁盘地址，将数据从磁盘复制到页缓存。之后再次发起读页面过程，进而将页缓存中的数据发给用户进程。</p></li></ul><p>总结来说，常规文件操作为了提高读写效率和保护磁盘，使用了页缓存机制。这样造成读文件时需要先将文件页从磁盘拷贝到页缓存中，由于页缓存处在内核空间，不能被用户进程直接寻址，所以还需要将页缓存中数据页再次拷贝到内存对应的用户空间中。这样，通过了两次数据拷贝过程，才能完成进程对文件内容的获取任务。写操作也是一样，待写入的buffer在内核空间不能直接访问，必须要先拷贝至内核空间对应的主存，再写回磁盘中（延迟写回），也是需要两次数据拷贝。</p><p>当存在多个进程同时读取同一个文件时，每一个进程中的地址空间都会保存一份副本，这样肯定不是最优方式的，造成了物理内存的浪费</p><p><code>第二种方式：内存映射</code></p><p>具体操作方式是：<br>open一个文件，然后调用mmap系统调用，将文件的内容的全部或一部分直接映射到进程的地址空间，映射完成后，进程可以像访问普通内存一样做其他的操作，比如memcpy等等。</p><p>mmap并不分配物理地址空间，它只是占有进程的虚拟地址空间。这跟第一种方式不一样的，第一种方式需要预先分配好物理内存，内核才能将页高速缓冲中的文件数据拷贝到用户进程指定的内存空间中。</p><p>而第二种方式，当多个进程需要同时访问同一个文件时，每个进程都将文件所存储的内核高速缓冲映射到自己的进程地址空间。当第一个进程访问内核中的缓冲区时候，前面讲过并没有实际拷贝数据，这时MMU在地址映射表中是无法找到与地址空间相对应的物理地址的，也就是MMU失败，就会触发缺页中断。内核将文件的这一页数据读入到内核高速缓冲区中，并更新进程的页表，使页表指向内核缓冲中的这一页。之后有其他的进程再次访问这一页的时候，该页已经在内存中了，内核只需要将进程的页表登记并且指向内核的页高速缓冲区即可</p><p><img src="https://raw.githubusercontent.com/hellolihaizhou/saveImg/master/mmap-1-1.jpg" alt=""></p><p>异步IO<br><img src="https://raw.githubusercontent.com/hellolihaizhou/saveImg/master/mmap-1-2.jpg" alt=""></p><p>mmap内存映射具体流程如下：</p><p>1、用户进程调用内存映射函数库mmap，当前进程在虚拟地址空间中，寻找一段空闲的满足要求的虚拟地址。</p><p>2、此时内核收到相关请求后会调用内核的mmap函数，注意，不同于用户空间库函数。内核mmap函数通过虚拟文件系统定位到文件磁盘物理地址，既实现了文件地址和虚拟地址区域的映射关系。 此时，这片虚拟地址并没有任何数据关联到主存中。</p><p>注意，前两个阶段仅在于创建虚拟区间并完成地址映射，但是并没有将任何文件数据的拷贝至主存。真正的文件读取是当进程发起读或写操作时。</p><p>3、进程的读或写操作访问虚拟地址空间这一段映射地址，现这一段地址并不在物理页面上。因为目前只建立了地址映射，真正的硬盘数据还没有拷贝到内存中，因此引发缺页中断。</p><p>4、由于引发了缺页中断，内核则调用nopage函数把所缺的页从磁盘装入到主存中。</p><p>5、之后用户进程即可对这片主存进行读或者写的操作，如果写操作改变了其内容，一定时间后系统会自动回写脏页面到对应磁盘地址，也即完成了写入到文件的过程。</p><p>注意：这里拷贝磁盘内容到主存，这里的主存是指处于内核空间的Page Cache，而不是用户空间的内存。用户地址要访问内核空间中的数据，需使用MMU把虚拟地址映射到内核的内存地址中，即可对数据进行操作。整个mmap工作流程大体如下：</p><p><img src="https://raw.githubusercontent.com/hellolihaizhou/saveImg/master/mmap-2.png" alt=""></p><p>这里我们可以看出mmap系统调用与read/write调用的区别在于：</p><p>mmap只需要一次系统调用（一次拷贝），后续操作不需要系统调用。访问的数据不需要在page cache和用户缓冲区之间拷贝。 访问的数据不需要在page cache和用户缓冲区之间拷贝。<br>从上所述，当频繁对一个文件进行读取操作时，mmap会比read/write更高效</p><p>既然建立内存映射没有进行实际的数据拷贝，那么进程又怎么能最终直接通过内存操作访问到硬盘上的文件呢？那就要看内存映射之后的几个相关的过程了。</p><p>mmap()会返回一个指针ptr，它指向进程逻辑地址空间中的一个地址，这样以后，进程无需再调用read或write对文件进行读写，而只需要通过ptr就能够操作文件。但是ptr所指向的是一个逻辑地址，要操作其中的数据，必须通过MMU将逻辑地址转换成物理地址，这个过程与内存映射无关。 </p><p>前面讲过，建立内存映射并没有实际拷贝数据，这时，MMU在地址映射表中是无法找到与ptr相对应的物理地址的，也就是MMU失败，将产生一个缺页中断，缺页中断的中断响应函数会在swap中寻找相对应的页面，如果找不到（也就是该文件从来没有被读入内存的情况），则会通过mmap()建立的映射关系，从硬盘上将文件读取到物理内存中，这个过程与内存映射无关。</p><p>如果在拷贝数据时，发现物理内存不够用，则会通过虚拟内存机制（swap）将暂时不用的物理页面交换到硬盘上，这个过程也与内存映射无关。</p><p>使用mmap操作文件中，创建新的虚拟内存区域和建立文件磁盘地址和虚拟内存区域映射这两步，没有任何文件拷贝操作。而之后访问数据时发现内存中并无数据而发起的缺页异常过程，可以通过已经建立好的映射关系，只使用一次数据拷贝，就从磁盘中将数据传入内存的用户空间中，供进程使用。</p><p>总而言之，常规文件操作需要从磁盘到页缓存再到用户主存的两次数据拷贝。而mmap操控文件，只需要从磁盘到用户主存的一次数据拷贝过程。说白了，mmap的关键点是实现了用户空间和内核空间的数据直接交互而省去了空间不同数据不通的繁琐过程。因此mmap效率更高</p><p>mmap使用过程中的几个细节点：</p><p>细节点一： mmap映射区域大小必须是物理页大小(page_size)的整倍数（在Linux中内存页通常是4k）。原因是，内存的最小粒度是页，而进程虚拟地址空间和内存的映射也是以页为单位。为了匹配内存的操作，mmap从磁盘到虚拟地址空间的映射也必须是页。</p><p>例如，有一个文件的大小是5K，mmap函数从文件的起始位置映射5K到虚拟内存中，由于内存物理页是4K，虽然映射的文件只有5K，但是实际上映射到内存区域的内存是8K，以便满足物理页大小的整数倍。映射后对5~8K的内存区域用零填充，对这部分的操作不会报错也不会写入到原文件中。</p><p>细节点二 ： 映射建立之后，即使文件关闭，映射依然存在。因为映射的是磁盘的地址，不是文件本身，和文件句柄无关。同时可用于进程间通信的有效地址空间不完全受限于被映射文件的大小，因为是按页映射。</p><p>平时会遇到应用OOM的问题，日志中有时候会有如下内容<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">07</span>-<span class="number">03</span> <span class="number">17</span>:<span class="number">43</span>:<span class="number">55.266</span> <span class="number">10181</span>  <span class="number">4737</span>  <span class="number">6529</span> E filemap : mmap(<span class="number">6078464</span>,<span class="number">299753</span>) failed: Out of memory</span><br></pre></td></tr></table></figure></p><p>对应的Code</p><p>system/core/libutils/FileMap.cpp</p><p>这里谷歌在2020.5.7号有修改，之前是调用的mmap，mmap中继而调用mmap64</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">void</span>* ptr = mmap64(nullptr, adjLength, prot, flags, fd, adjOffset);</span><br><span class="line"><span class="keyword">if</span> (ptr == MAP_FAILED) &#123;</span><br><span class="line">    <span class="keyword">if</span> (errno == EINVAL &amp;&amp; length == <span class="number">0</span>) &#123;</span><br><span class="line">        ptr = nullptr;</span><br><span class="line">        adjust = <span class="number">0</span>;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        ALOGE(<span class="string">"mmap(%lld,%zu) failed: %s\n"</span>, (<span class="keyword">long</span> <span class="keyword">long</span>)adjOffset, adjLength, strerror(errno));</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>bionic/libc/bionic/mmap.cpp</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">void</span>* mmap64(<span class="keyword">void</span>* addr, size_t size, <span class="keyword">int</span> prot, <span class="keyword">int</span> flags, <span class="keyword">int</span> fd, off64_t offset) &#123;</span><br><span class="line">  <span class="keyword">if</span> (offset &lt; <span class="number">0</span> || (offset &amp; ((<span class="number">1</span>UL &lt;&lt; MMAP2_SHIFT)-<span class="number">1</span>)) != <span class="number">0</span>) &#123;</span><br><span class="line">    errno = EINVAL;</span><br><span class="line">    <span class="keyword">return</span> MAP_FAILED;</span><br><span class="line">  &#125;</span><br><span class="line"> </span><br><span class="line">  <span class="comment">// prevent allocations large enough for `end - start` to overflow</span></span><br><span class="line">  size_t rounded = __BIONIC_ALIGN(size, PAGE_SIZE);</span><br><span class="line">  <span class="keyword">if</span> (rounded &lt; size || rounded &gt; PTRDIFF_MAX) &#123;</span><br><span class="line">    errno = ENOMEM;</span><br><span class="line">    <span class="keyword">return</span> MAP_FAILED;</span><br><span class="line">  &#125;</span><br><span class="line"> </span><br><span class="line">  bool is_private_anonymous =</span><br><span class="line">      (flags &amp; (MAP_PRIVATE | MAP_ANONYMOUS)) == (MAP_PRIVATE | MAP_ANONYMOUS);</span><br><span class="line">  bool is_stack_or_grows_down = (flags &amp; (MAP_STACK | MAP_GROWSDOWN)) != <span class="number">0</span>;</span><br><span class="line">  <span class="keyword">void</span>* result = __mmap2(addr, size, prot, flags, fd, offset &gt;&gt; MMAP2_SHIFT);</span><br><span class="line"> </span><br><span class="line">  <span class="keyword">if</span> (result != MAP_FAILED &amp;&amp; kernel_has_MADV_MERGEABLE &amp;&amp;</span><br><span class="line">      is_private_anonymous &amp;&amp; !is_stack_or_grows_down) &#123;</span><br><span class="line">    ErrnoRestorer errno_restorer;</span><br><span class="line">    <span class="keyword">int</span> rc = madvise(result, size, MADV_MERGEABLE);</span><br><span class="line">    <span class="keyword">if</span> (rc == -<span class="number">1</span> &amp;&amp; errno == EINVAL) &#123;</span><br><span class="line">      kernel_has_MADV_MERGEABLE = <span class="keyword">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> result;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>mmap常见的错误类型：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">EACCES：访问出错</span><br><span class="line">EAGAIN：文件已被锁定，或者太多的内存已被锁定</span><br><span class="line">EBADF：fd不是有效的文件描述词</span><br><span class="line">EINVAL：一个或者多个参数无效 这里的参数常指的是start len offset 但是按照unlinx高级环境编程中描述，start一般会被命名为<span class="keyword">null</span>的空指针，这样告诉内核自己去选择起始地址，offset一般情况下设置为；那么出现这个问题通常就是len出错了，那么可以用printf大法来找到具体的错误。</span><br><span class="line">ENFILE：已达到系统对打开文件的限制</span><br><span class="line">ENODEV：指定文件所在的文件系统不支持内存映射</span><br><span class="line">ENOMEM：内存不足，或者进程已超出最大内存映射数量</span><br><span class="line">EPERM：权能不足，操作不允许</span><br><span class="line">ETXTBSY：已写的方式打开文件，同时指定MAP_DENYWRITE标志</span><br><span class="line">SIGSEGV：试着向只读区写入</span><br><span class="line">SIGBUS：试着访问不属于进程的内存区</span><br></pre></td></tr></table></figure><p><strong>mmap优点总结</strong></p><p>由上文讨论可知，mmap优点共有一下几点：</p><p>1、对文件的读取操作跨过了页缓存，减少了数据的拷贝次数，用内存读写取代I/O读写，提高了文件读取效率。</p><p>2、实现了用户空间和内核空间的高效交互方式, 两空间的各自修改操作可以直接反映在映射的区域内，从而被对方空间及时捕捉。</p><p>3、提供进程间共享内存及相互通信的方式。不管是父子进程还是无亲缘关系的进程，都可以将自身用户空间映射到同一个文件或匿名映射到同一片区域。从而通过各自对映射区域的改动，达到进程间通信和进程间共享的目的。</p><pre><code>同时，如果进程A和进程B都映射了区域C，当A第一次读取C时通过缺页从磁盘复制文件页到内存中；但当B再读C的相同页面时，虽然也会产生缺页异常，但是不再需要从磁盘中复制文件过来，而可直接使用已经保存在内存中的文件数据。</code></pre><p>4、可用于实现高效的大规模数据传输。内存空间不足，是制约大数据操作的一个方面，解决方案往往是借助硬盘空间协助操作，补充内存的不足。但是进一步会造成大量的文件I/O操作，极大影响效率。这个问题可以通过mmap映射很好的解决。换句话说，但凡是需要用磁盘空间代替内  存的时候，mmap都可以发挥其功效</p><p><strong>mmap使用细节</strong><br>1、使用mmap需要注意的一个关键点是mmap映射区域大小必须是物理页大小(page_size)的整倍数（32位系统中通常是4k字节）。原因是内存的最小粒度是页，而进程虚拟地址空间和内存的映射也是以页为单位。为了匹配内存的操作，mmap从磁盘到虚拟地址空间的映射也必须是页。</p><p>2、内核可以跟踪被内存映射的底层对象（文件）的大小，进程可以合法的访问在当前文件大小以内又在内存映射区以内的那些字节。也就是说，如果文件的大小一直在扩张，只要在映射区域范围内的数据，进程都可以合法得到，这和映射建立时文件的大小无关。</p><p>3、映射建立之后，即使文件关闭，映射依然存在。因为映射的是磁盘的地址，不是文件本身，和文件句柄无关。同时可用于进程间通信的有效地址空间不完全受限于被映射文件的大小，因为是按页映射。</p><p>在上面的知识前提下，我们下面看看如果大小不是页的整倍数的具体情况：</p><p>情形一：一个文件的大小是5000字节，mmap函数从一个文件的起始位置开始，映射5000字节到虚拟内存中。</p><p>分析：因为单位物理页面的大小是4096字节，虽然被映射的文件只有5000字节，但是对应到进程虚拟地址区域的大小需要满足整页大小，因此mmap函数执行后，实际映射到虚拟内存区域8192个 字节，5000~8191的字节部分用零填充。映射后的对应关系如下图所示：</p><p><img src="https://raw.githubusercontent.com/hellolihaizhou/saveImg/master/mmap-3.png" alt=""></p><p>此时：</p><p>（1）读/写前5000个字节（0~4999），会返回操作文件内容。</p><p>（2）读字节5000~8191时，结果全为0。写5000~8191时，进程不会报错，但是所写的内容不会写入原文件中 。</p><p>（3）读/写8192以外的磁盘部分，会返回一个SIGSECV错误。</p><p>情形二：一个文件的大小是5000字节，mmap函数从一个文件的起始位置开始，映射15000字节到虚拟内存中，即映射大小超过了原始文件的大小。</p><p>分析：由于文件的大小是5000字节，和情形一一样，其对应的两个物理页。那么这两个物理页都是合法可以读写的，只是超出5000的部分不会体现在原文件中。由于程序要求映射15000字节，而文件只占两个物理页，因此8192字节~15000字节都不能读写，操作时会返回异常。如下图所示：</p><p><img src="https://raw.githubusercontent.com/hellolihaizhou/saveImg/master/mmap-4.png" alt=""></p><p>此时：</p><p>（1）进程可以正常读/写被映射的前5000字节(0~4999)，写操作的改动会在一定时间后反映在原文件中。</p><p>（2）对于5000~8191字节，进程可以进行读写过程，不会报错。但是内容在写入前均为0，另外，写入后不会反映在文件中。</p><p>（3）对于8192~14999字节，进程不能对其进行读写，会报SIGBUS错误。</p><p>（4）对于15000以外的字节，进程不能对其读写，会引发SIGSEGV错误。</p><p>情形三：一个文件初始大小为0，使用mmap操作映射了1000*4K的大小，即1000个物理页大约4M字节空间，mmap返回指针ptr。</p><p>分析：如果在映射建立之初，就对文件进行读写操作，由于文件大小为0，并没有合法的物理页对应，如同情形二一样，会返回SIGBUS错误。</p><p>但是如果，每次操作ptr读写前，先增加文件的大小，那么ptr在文件大小内部的操作就是合法的。例如，文件扩充4096字节，ptr就能操作ptr ~ [ (char)ptr + 4095]的空间。只要文件扩充的范围在1000个物理页（映射范围）内，ptr都可以对应操作相同的大小。</p><p>这样，方便随时扩充文件空间，随时写入文件，不造成空间浪费</p><p>Binder进程间通信用到的mmap</p><p>Linux 下的传统 IPC 通信原理<br>传统的 IPC 方式中，进程之间是如何实现通信的。<br>通常的做法是消息发送方将要发送的数据存放在内存缓存区中，通过系统调用进入内核态。然后内核程序在内核空间分配内存，开辟一块内核缓存区，调用 copyfromuser() 函数将数据从用户空间的内存缓存区拷贝到内核空间的内核缓存区中。同样的，接收方进程在接收数据时在自己的用户空间开辟一块内存缓存区，然后内核程序调用 copytouser() 函数将数据从内核缓存区拷贝到接收进程的内存缓存区。这样数据发送方进程和数据接收方进程就完成了一次数据传输，我们称完成了一次进程间通信</p><p><img src="https://raw.githubusercontent.com/hellolihaizhou/saveImg/master/mmap-5.jpeg" alt=""></p><p>这种传统的 IPC 通信方式有两个问题：</p><pre><code>1.性能低下，一次数据传递需要经历：内存缓存区 --&gt; 内核缓存区 --&gt; 内存缓存区，需要 2 次数据拷贝；2.接收数据的缓存区由数据接收进程提供，但是接收进程并不知道需要多大的空间来存放将要传递过来的数据，因此只能开辟尽可能大的内存空间或者先调用 API 接收消息头来获取消息体的大小，这两种做法不是浪费空间就是浪费时间</code></pre><p>Binder采用一种全新策略：由Binder驱动负责管理数据接收缓存。我们注意到Binder驱动实现了mmap()系统调用，这对字符设备是比较特殊的，因为mmap()通常用在有物理存储介质的文件系统上，而象Binder这样没有物理介质，纯粹用来通信的字符设备没必要支持mmap()。Binder驱动当然不是为了在物理介质和用户空间做映射，而是用来创建数据接收的缓存空间。先看mmap()是如何使用的：<br>fd = open(“/dev/binder”, O_RDWR);<br>mmap(NULL, MAP_SIZE, PROT_READ, MAP_PRIVATE, fd, 0);<br>这样Binder的接收方就有了一片大小为MAP_SIZE的接收缓存区。mmap()的返回值是内存映射在用户空间的地址，不过这段空间是由驱动管理，用户不必也不能直接访问（映射类型为PROT_READ，只读映射）</p><p>一次完整的 Binder IPC 通信过程通常是这样：</p><p>1.Server端在启动之后，调用对/dev/binder设备调用mmap<br>2.内核中的binder_mmap函数进行对应的处理：申请一块物理内存，然后在Server端的用户空间和内核空间同时进行映射。内核中的binder_mmap函数进行对应的处理：申请一块物理内存，然后在Server端的用户空间和内核空间同时进行映射<br>3.Client发送请求，这个请求将先到驱动中，同时需要将数据从Client进程的用户空间拷贝（Client发送请求，这个请求将先到驱动中，同时需要将数据从Client进程的用户空间拷贝（copy_from_user）到内核空间<br>4.驱动通过请求通知Server端有人发出请求，Server进行处理。由于内核空间和Server端进程的用户空间存在内存映射，因此Server进程的代码可以直接访问。这样便完成了一次进程间的通信</p><p><img src="https://raw.githubusercontent.com/hellolihaizhou/saveImg/master/mmap-6.png" alt=""></p><p>而使用mmap操作文件中，创建新的虚拟内存区域和建立文件磁盘地址和虚拟内存区域映射这两步，没有任何文件拷贝操作。而之后访问数据时发现内存中并无数据而发起的缺页异常过程，可以通过已经建立好的映射关系，只使用一次数据拷贝，就从磁盘中将数据传入内存的用户空间中，供进程使用。</p><p>总而言之，常规文件操作需要从磁盘到页缓存再到用户主存的两次数据拷贝。而mmap操控文件，只需要从磁盘到用户主存的一次数据拷贝过程。说白了，mmap的关键点是实现了用户空间和内核空间的数据直接交互而省去了空间不同数据不通的繁琐过程。因此mmap效率更高</p><p>通过上面介绍可以看到，驱动为接收方分担了最为繁琐的任务：分配/释放大小不等，难以预测的有效负荷缓存区，而接收方只需要提供缓存来存放大小固定，最大空间可以预测的消息头即可。在效率上，由于mmap()分配的内存是映射在接收方用户空间里的，所有总体效果就相当于对有效负荷数据做了一次从发送方用户空间到接收方用户空间的直接数据拷贝，省去了内核中暂存这个步骤，提升了一倍的性能。顺便再提一点，Linux内核实际上没有从一个用户空间到另一个用户空间直接拷贝的函数，需要先用copy_from_user()拷贝到内核空间，再用copy_to_user()拷贝到另一个用户空间。为了实现用户空间到用户空间的拷贝，mmap()分配的内存除了映射进了接收方进程里，还映射进了内核空间。所以调用copy_from_user()将数据拷贝进内核空间也相当于拷贝进了接收方的用户空间，这就是Binder只需一次拷贝的‘秘密’</p><p>Binder 并不存在物理介质，因此 Binder 驱动使用 mmap() 并不是为了在物理介质和用户空间之间建立映射，而是用来在内核空间创建数据接收的缓存空间。</p><p>一次完整的 Binder IPC 通信过程通常是这样：</p><pre><code>首先 Binder 驱动在内核空间创建一个数据接收缓存区；接着在内核空间开辟一块内核缓存区，建立内核缓存区和内核中数据接收缓存区之间的映射关系，以及内核中数据接收缓存区和接收进程用户空间地址的映射关系；发送方进程通过系统调用 copyfromuser() 将数据 copy 到内核中的内核缓存区，由于内核缓存区和接收进程的用户空间存在内存映射，因此也就相当于把数据发送到了接收进程的用户空间，这样便完成了一次进程间的通信</code></pre><p><img src="https://raw.githubusercontent.com/hellolihaizhou/saveImg/master/mmap-7.jpeg" alt=""></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;在Unix/Linux系统下读写文件，一般有两种方式&lt;/p&gt;
&lt;p&gt;&lt;code&gt;第一种方式：传统的read/write方式&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;常规文件系统操作的调用过程：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;进程发起读文件请求&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;内核通
      
    
    </summary>
    
      <category term="Linux" scheme="http://lihaizhou.top/categories/Linux/"/>
    
    
  </entry>
  
  <entry>
    <title>为何连接wifi后系统会卡顿一下?</title>
    <link href="http://lihaizhou.top/2020/03/05/%E4%B8%BA%E4%BD%95%E8%BF%9E%E6%8E%A5wifi%E5%90%8E%E7%B3%BB%E7%BB%9F%E4%BC%9A%E5%8D%A1%E9%A1%BF%E4%B8%80%E4%B8%8B/"/>
    <id>http://lihaizhou.top/2020/03/05/为何连接wifi后系统会卡顿一下/</id>
    <published>2020-03-05T03:00:05.000Z</published>
    <updated>2020-03-05T07:32:03.153Z</updated>
    
    <content type="html"><![CDATA[<p><strong>问题描述</strong><br>数据流量使用过程中切换到wifi连接，系统全局会卡一下</p><p><strong>初步分析</strong><br>抓取systrace时手指在桌面不停的滑动，可以看到很明确的一段没有帧，但是这个时间段手指一直在滑动<br>我们都知道vsync是APP最终通过框架层请求上来的，Choreographer收到回调后开始渲染帧。<br>自然而然对应到sf中的vsync-sf也没有帧合成，所以界面上表现为卡顿，现象和jank类似，都是屏幕上没有及时更新画面<br><img src="https://raw.githubusercontent.com/hellolihaizhou/saveImg/master/wifi%E5%88%97%E8%A1%A8%E5%8D%A1%E9%A1%BF4.png" alt=""><br>其实这个时间段可以发现deliverInputEvent也没有，其实这一点也可以从Launcher的PendingInputEventQueue区域看出来<br>PS: PendingInputEventQueue 里面记录的是 App 需要处理的 Input 事件，这个阶段对应的是用户进程中了<br>开始卡顿后即红圈后面便没有波峰出现, 说明压根没有input送到应用进程<br><img src="https://raw.githubusercontent.com/hellolihaizhou/saveImg/master/%E5%88%87%E6%8D%A2%E5%88%B0wifi%E5%90%8E%E5%8D%A1%E9%A1%BF-2.png" alt=""></p><p>这个时候，自然而然就有一个疑问:<br>既然应用进程没有收到input事件，那么会不会是input上报的过程中哪个环节出了问题呢？</p><p>再科普下input事件上报的大概流程</p><ol><li>InputReader 读取 Input 事件</li><li>InputReader 将读取的 Input 事件放到 InboundQueue 中</li><li>InputDispatcher 从 InboundQueue 中取出 Input 事件派发到各个 App(连接) 的 OutBoundQueue<br> 同时将事件记录到各个 App(连接) 的 WaitQueue</li><li>App 接收到 Input 事件，同时记录到 PaddingQueue ，然后对事件进行分发处理<br> App 处理完成后，回调 InputManagerService 将负责监听的 WaitQueue 中对应的 Input 移除</li></ol><p>InputReader和InputDispatcher是跑在SystemServer里面的两个Native线程，负责读取和分发Input 事件<br><img src="https://raw.githubusercontent.com/hellolihaizhou/saveImg/master/%E5%88%87%E6%8D%A2%E5%88%B0wifi%E5%90%8E%E5%8D%A1%E9%A1%BF-3.png" alt=""><br>到这里可以明显看出，卡顿时间段内InputReader在不断的读取事件，说明driver没问题，注意这个时候InputDispatcher 没有收到任何input事件并且处于S状态<br>其实InputDispatcher 没有获取到事件的话，不用说oq区域和wq区域肯定也是没有事件的<br><img src="https://raw.githubusercontent.com/hellolihaizhou/saveImg/master/%E5%88%87%E6%8D%A2%E5%88%B0wifi%E5%90%8E%E5%8D%A1%E9%A1%BF-4.png" alt=""><br>意料之中，空空如也，难怪应用进程苦苦等不来事件<br>这里再简要科普下这几个概念<br>说明</p><ul><li>InputReader 负责从 EventHub 里面把 Input 事件读取出来，然后交给 InputDispatcher 进行事件分发</li><li>InputDispatcher 在拿到 InputReader 获取的事件之后，对事件进行包装和分发 (也就是发给对应的)<ul><li>OutboundQueue 里面放的是即将要被派发给对应 AppConnection 的事件</li></ul></li><li>WaitQueue 里面记录的是已经派发给 AppConnection 但是 App 还在处理没有返回处理成功的事件</li><li>PendingInputEventQueue 里面记录的是 App 需要处理的 Input 事件，这里可以看到已经到了应用进程</li><li>deliverInputEvent 标识 App UI Thread 被 Input 事件唤醒</li><li>InputResponse 标识 Input 事件区域</li><li>App 响应 Input 事件 ： 这里是滑动然后松手，也就是我们熟悉的桌面滑动的操作，桌面随着手指的滑动更新画面，松手后触发 Fling 继续滑动，从 Systrace 就可以看到整个事件的流程</li></ul><p>这个时候，事件上报大致问题区域知道了，再回到InputDispatcher ，看下最后是被1726唤醒的<br><img src="https://raw.githubusercontent.com/hellolihaizhou/saveImg/master/%E5%88%87%E6%8D%A2%E5%88%B0wifi%E5%90%8E%E5%8D%A1%E9%A1%BF-5.png" alt=""></p><p>跟到tid 1726区域，居然定位到了systemserver区域，InputDispatcher正常来讲都是由InputReader 唤醒的，这里不免有些困惑</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">https:<span class="comment">//cs.android.com/android/platform/superproject/+/master:frameworks/native/services/inputflinger/dispatcher/InputDispatcher.cpp;l=2719?q=InputDispatcher.cpp</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">void</span> InputDispatcher::notifyMotion(<span class="keyword">const</span> NotifyMotionArgs* args) &#123;</span><br><span class="line"><span class="comment">//....</span></span><br><span class="line">    bool needWake;</span><br><span class="line">    &#123; <span class="comment">// acquire lock</span></span><br><span class="line">        mLock.lock();</span><br><span class="line">        <span class="keyword">if</span> (shouldSendMotionToInputFilterLocked(args)) &#123;</span><br><span class="line">            mLock.unlock();</span><br><span class="line">            MotionEvent event;</span><br><span class="line">            event.initialize(args-&gt;deviceId, args-&gt;source, args-&gt;displayId, args-&gt;action,</span><br><span class="line">                             args-&gt;actionButton, args-&gt;flags, args-&gt;edgeFlags, args-&gt;metaState,</span><br><span class="line">                             args-&gt;buttonState, args-&gt;classification, <span class="number">0</span>, <span class="number">0</span>, args-&gt;xPrecision,</span><br><span class="line">                             args-&gt;yPrecision, args-&gt;downTime, args-&gt;eventTime, args-&gt;pointerCount,</span><br><span class="line">                             args-&gt;pointerProperties, args-&gt;pointerCoords);</span><br><span class="line">            policyFlags |= POLICY_FLAG_FILTERED;</span><br><span class="line">            <span class="keyword">if</span> (!mPolicy-&gt;filterInputEvent(&amp;event, policyFlags)) &#123;</span><br><span class="line">                <span class="keyword">return</span>; <span class="comment">// event was consumed by the filter</span></span><br><span class="line">            &#125;</span><br><span class="line">            mLock.lock();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// Just enqueue a new motion event.</span></span><br><span class="line">        MotionEntry* newEntry =</span><br><span class="line">                <span class="keyword">new</span> MotionEntry(args-&gt;sequenceNum, args-&gt;eventTime, args-&gt;deviceId, args-&gt;source,</span><br><span class="line">                                args-&gt;displayId, policyFlags, args-&gt;action, args-&gt;actionButton,</span><br><span class="line">                                args-&gt;flags, args-&gt;metaState, args-&gt;buttonState,</span><br><span class="line">                                args-&gt;classification, args-&gt;edgeFlags, args-&gt;xPrecision,</span><br><span class="line">                                args-&gt;yPrecision, args-&gt;downTime, args-&gt;pointerCount,</span><br><span class="line">                                args-&gt;pointerProperties, args-&gt;pointerCoords, <span class="number">0</span>, <span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">        needWake = enqueueInboundEventLocked(newEntry);</span><br><span class="line">        mLock.unlock();</span><br><span class="line">    &#125; <span class="comment">// release lock</span></span><br><span class="line">    <span class="keyword">if</span> (needWake) &#123;</span><br><span class="line">        mLooper-&gt;wake();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这个函数里主要做的事是读取线程InputReaderThread在处理事务并将读取的事件放到队列中<br>可以看到最后mLooper-&gt;wake();这里的looper对应的是InputDispatcher的looper，也就是最后会唤醒InputDispatcher线程<br>而我们这笔问题中InputDispatcher在卡顿期间处于S状态，往上看哪里return了导致没有执行，其实在mPolicy-&gt;filterInputEvent处返回了false并且return了，这里的代码层层追踪会跟到InputManagerService的filterInputEvent()</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">https:<span class="comment">//cs.android.com/android/platform/superproject/+/master:frameworks/base/services/core/java/com/android/server/input/InputManagerService.java;l=1828?q=InputManagerService</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">// Native callback.</span></span><br><span class="line">    <span class="function"><span class="keyword">final</span> <span class="keyword">boolean</span> <span class="title">filterInputEvent</span><span class="params">(InputEvent event, <span class="keyword">int</span> policyFlags)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">synchronized</span> (mInputFilterLock) &#123;</span><br><span class="line">            <span class="keyword">if</span> (mInputFilter != <span class="keyword">null</span>) &#123;</span><br><span class="line">                <span class="keyword">try</span> &#123;</span><br><span class="line">                    mInputFilter.filterInputEvent(event, policyFlags);</span><br><span class="line">                &#125; <span class="keyword">catch</span> (RemoteException e) &#123;</span><br><span class="line">                    <span class="comment">/* ignore */</span></span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        event.recycle();</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>这里主要是判断InputFilter是否为空，如果不为空，则会走到mInputFilter.filterInputEvent，可以注意下，这里已经位于IMS也就是systemserver进程<br>我们这个问题始终不为空，原因在于开启了手势识别会设置一个InputFilter导致这里不为空，以便做进一步的事件加工处理，InputManagerService的filterInputEvent()最后调用到injectInputEvent()将这个事件送入mInBoundQueue，并唤醒InputDispatcher，不是本文重点所以代码就不展开叙述<br>至此明白了为何InputReader的唤醒源会跑到systemserver(UI线程)中</p><p>继续看systemserver(UI线程)这段区域，在执行一个广播的onReceive中等锁导致的sleep<br><img src="https://raw.githubusercontent.com/hellolihaizhou/saveImg/master/%E5%88%87%E6%8D%A2%E5%88%B0wifi%E5%90%8E%E5%8D%A1%E9%A1%BF-6.png" alt=""></p><p>这里顺便对Contended on monitor with owner NetworkPolicy进行解读:<br>Monitor指的是当前锁对象的池，在Java中，每个对象都有两个池，锁(monitor)池和等待池：</p><p>锁池（同步队列 SynchronizedQueue ）：假设线程 A 已经拥有了某个对象(注意:不是类 )的锁，而其它的线程想要调用这个对象的某个 synchronized 方法(或者 synchronized 块)，由于这些线程在进入对象的 synchronized 方法之前必须先获得该对象的锁的拥有权，但是该对象的锁目前正被线程 A 拥有，所以这些线程就进入了该对象的锁池中。</p><p>这里用了争夺(contention)这个词，意思是这里由于在和目前对象的锁正被其他对象（Owner）所持有，所以没法得到该对象的锁的拥有权，所以进入该对象的锁池</p><p>Owner : 指的是当前拥有这个对象的锁的对象，这里是NetworkPolicy</p><p>讲的通俗一点<br>systemserver(UI线程)在执行一个广播的onReceive中等一个锁，这个锁此时被NetworkPolicy持有</p><p>自然而然继续看NetworkPolicy区域<br><img src="https://raw.githubusercontent.com/hellolihaizhou/saveImg/master/%E5%88%87%E6%8D%A2%E5%88%B0wifi%E5%90%8E%E5%8D%A1%E9%A1%BF-7.png" alt=""></p><p>可以看到这段时间NetworkPolicy基本处于S状态，此时netd得到调度运行，这点在cpu区域也可以得到证实</p><p>再看下netd区域，卡顿开始的时候也正是netd得到调度的时候，是被2835这个进程唤醒，2835正是NetworkPolicy</p><p><img src="https://raw.githubusercontent.com/hellolihaizhou/saveImg/master/%E5%88%87%E6%8D%A2%E5%88%B0wifi%E5%90%8E%E5%8D%A1%E9%A1%BF-8.png" alt=""></p><p>到这里可以大致梳理一下卡顿时间内做的事:<br>1.SystemServer中的UI线程在等一个锁，这个锁被NetworkPolicy持有，所以没有发送input事件给InputDispatcher<br>2.NetworkPolicy为何一直不释放呢，是因为其调用了netd，netd执行的时间较长耗时了1s左右，等netd执行结束后NetworkPolicy得到调度继续执行并释放锁<br>3.SystemServer中的UI线程获取到锁，继续发送input事件到mInBoundQueue并唤醒InputDispatcher</p><p>现在的疑问就是NetworkPolicy和SystemServer(UI线程)监听了一样的广播，这个广播的服务端应该是加锁了导致了所有注册的客户端顺序执行<br>其实想想也能猜到应该是wifi状态变化或者网络变化的广播，跟到NetworkManagerService中看下很容易发现NetworkManagerService监听了一个网络变化广播CONNECTIVITY_ACTION<br>但是SystemServer(UI线程)中注册并回调执行的代码位置需要借助traceview进一步定位，这里比较简单不展开讨论</p><p>解决思路看看SystemServer(UI线程)中具体代码处是否能够去掉锁或后台执行，只要不堵在UI线程就行</p><p>这个问题只有开启手势识别或有设置了InputFilter的情况才会出现，最新谷歌代码上发现代码变化没有注册监听，故该问题在新版本上不会存在</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;strong&gt;问题描述&lt;/strong&gt;&lt;br&gt;数据流量使用过程中切换到wifi连接，系统全局会卡一下&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;初步分析&lt;/strong&gt;&lt;br&gt;抓取systrace时手指在桌面不停的滑动，可以看到很明确的一段没有帧，但是这个时间段手指一直在滑动&lt;b
      
    
    </summary>
    
      <category term="Android" scheme="http://lihaizhou.top/categories/Android/"/>
    
      <category term="性能" scheme="http://lihaizhou.top/categories/Android/%E6%80%A7%E8%83%BD/"/>
    
    
  </entry>
  
  <entry>
    <title>谁拖慢了列表的滑动速度</title>
    <link href="http://lihaizhou.top/2020/03/04/%E8%B0%81%E6%8B%96%E6%85%A2%E4%BA%86%E5%88%97%E8%A1%A8%E7%9A%84%E6%BB%91%E5%8A%A8%E9%80%9F%E5%BA%A6/"/>
    <id>http://lihaizhou.top/2020/03/04/谁拖慢了列表的滑动速度/</id>
    <published>2020-03-04T13:59:04.000Z</published>
    <updated>2020-06-21T08:25:47.920Z</updated>
    
    <content type="html"><![CDATA[<p><strong>问题描述</strong><br>在开机向导界面滑动wifi列表界面时比较卡顿，概率为必现</p><p>抓一份systrace，红色帧有多处，总体上看有不少处发生掉帧<br><img src="https://raw.githubusercontent.com/hellolihaizhou/saveImg/master/wifi%E5%88%97%E8%A1%A8%E5%8D%A1%E9%A1%BF1.jpg" alt=""></p><p>挑其中一处红色帧放大看下<br><img src="https://raw.githubusercontent.com/hellolihaizhou/saveImg/master/wifi%E5%88%97%E8%A1%A8%E5%8D%A1%E9%A1%BF2.png" alt=""><br>耗时中的measure是大头，其中一次measure有数十次obtainview，对比其他绿色正常帧，发现正常的时候没有measure的过程<br>放大一次obtainview的过程，做的其实是inflate一项item的过程，红圈处对应了wifi一个item的布局<br><img src="https://raw.githubusercontent.com/hellolihaizhou/saveImg/master/wifi%E5%88%97%E8%A1%A8%E5%8D%A1%E9%A1%BF3.png" alt=""><br>我们都知道，ViewRootImpl的performTraversals方法会经过measure、layout和draw三个流程才能将一帧View需要显示的内容绘制到屏幕上</p><ul><li>performMeasure: 从根节点向下遍历View树，完成所有ViewGroup和View的测量工作，计算出所有ViewGroup和View显示出来需要的高度和宽度</li><li>performLayout()：从根节点向下遍历View树，完成所有ViewGroup和View的布局计算工作，根据测量出来的宽高及自身属性，计算出所有ViewGroup和View显示在屏幕上的区域；</li><li>performDraw()：从根节点向下遍历View树，完成所有ViewGroup和View的绘制工作，根据布局过程计算出的显示区域，将所有View的当前需显示的内容画到屏幕上</li></ul><p>对应到我们这个问题，此时大概心里有数了，一帧的耗时并不是计算显示在哪个区域以及本身的内容绘制耗时，而是计算需要显示的高度或宽度耗时，注意这里是计算这个列表的高度或宽度耗时了，因为每次measure都对应了数十次的加载item的过程，很显然需要依据item的高度或宽度来最终确定列表的高度或宽度</p><p>故真相只有一个，就是列表很可能使用了自适应的高度或宽度</p><p>看下代码<br><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">&lt;LinearLayout</span><br><span class="line">     android:id=<span class="string">"@+id/provision_lyt_content"</span></span><br><span class="line">     android:layout_width=<span class="string">"match_parent"</span></span><br><span class="line">     android:layout_height=<span class="string">"0dip"</span></span><br><span class="line">     android:layout_weight=<span class="string">"1"</span></span><br><span class="line">     android:layout_marginTop=<span class="string">"@dimen/provision_content_top_padding"</span></span><br><span class="line">     android:paddingStart=<span class="string">"@dimen/provision_list_left_padding"</span></span><br><span class="line">     android:paddingEnd=<span class="string">"@dimen/provision_list_right_padding"</span></span><br><span class="line">     android:orientation=<span class="string">"vertical"</span>&gt;</span><br><span class="line">     &lt;ListView</span><br><span class="line">         android:id=<span class="string">"@android:id/list"</span></span><br><span class="line">         android:layout_width=<span class="string">"match_parent"</span></span><br><span class="line">         android:layout_height=<span class="string">"wrap_content"</span> /&gt;</span><br><span class="line"> &lt;/LinearLayout&gt;</span><br></pre></td></tr></table></figure></p><p> 果不其然，这里设置了自适应的高度，修改为match_parent后再次测试发现卡顿消失<br>抓取改后的systrace<br><img src="https://raw.githubusercontent.com/hellolihaizhou/saveImg/master/wifi%E5%88%97%E8%A1%A8%E5%8D%A1%E9%A1%BF4.png" alt=""></p><p>基本上没有了红色帧，每一帧的绘制不再有measure的过程<br>其实这个问题不抓systrace，看traceview同样能够定位，只是没有systrace直观</p><p>到这里，还有一个疑问，当view设置了自适应高度后，它的高度由其子view的高度决定，故需要计算它的所有子view高度后才能确定自身的显示高度<br>这一点容易理解，但是具体到onMeasure的代码里是如何实现的呢？<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">frameworks/base/core/java/android/view/ViewRootImpl.java</span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">performMeasure</span><span class="params">(<span class="keyword">int</span> childWidthMeasureSpec, <span class="keyword">int</span> childHeightMeasureSpec)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (mView == <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line">     <span class="comment">//这里对应了systrace中measure tag</span></span><br><span class="line">        Trace.traceBegin(Trace.TRACE_TAG_VIEW, <span class="string">"measure"</span>);</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            mView.measure(childWidthMeasureSpec, childHeightMeasureSpec);</span><br><span class="line">        &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">            Trace.traceEnd(Trace.TRACE_TAG_VIEW);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure></p><p>其中的mView.measure(childWidthMeasureSpec, childHeightMeasureSpec);通过参数可以看到，view的显示宽高用到了其子view的宽高作为约束条件<br>listview必定会重写onMeasure，直接跟到其源码中<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">frameworks/base/core/java/android/widget/ListView.java</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">onMeasure</span><span class="params">(<span class="keyword">int</span> widthMeasureSpec, <span class="keyword">int</span> heightMeasureSpec)</span> </span>&#123;</span><br><span class="line">        <span class="comment">// Sets up mListPadding</span></span><br><span class="line">        <span class="keyword">super</span>.onMeasure(widthMeasureSpec, heightMeasureSpec);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">final</span> <span class="keyword">int</span> widthMode = MeasureSpec.getMode(widthMeasureSpec);</span><br><span class="line">        <span class="keyword">final</span> <span class="keyword">int</span> heightMode = MeasureSpec.getMode(heightMeasureSpec);</span><br><span class="line">        <span class="keyword">int</span> widthSize = MeasureSpec.getSize(widthMeasureSpec);</span><br><span class="line">        <span class="keyword">int</span> heightSize = MeasureSpec.getSize(heightMeasureSpec);</span><br><span class="line">          <span class="comment">//....</span></span><br><span class="line">          </span><br><span class="line">          <span class="keyword">if</span> (heightMode == MeasureSpec.AT_MOST) &#123;</span><br><span class="line">              <span class="comment">// <span class="doctag">TODO:</span> after first layout we should maybe start at the first visible position, not 0</span></span><br><span class="line">              heightSize = measureHeightOfChildren(widthMeasureSpec, <span class="number">0</span>, NO_POSITION, heightSize, -<span class="number">1</span>);</span><br><span class="line">          &#125;</span><br><span class="line">            <span class="comment">//...</span></span><br><span class="line">         &#125;</span><br></pre></td></tr></table></figure></p><p>我们都知道wrap_content对应的mode为<code>MeasureSpec.AT_MOST</code>,这时候调用到measureHeightOfChildren开始计算其子view的宽高</p><p>这里看注释描述，如果指定了高度，则measure会停止<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">     * Measures the height of the given range of children (inclusive) and</span></span><br><span class="line"><span class="comment">     * returns the height with this ListView's padding and divider heights</span></span><br><span class="line"><span class="comment">     * included. If maxHeight is provided, the measuring will stop when the</span></span><br><span class="line"><span class="comment">     * current height reaches maxHeight.</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> widthMeasureSpec The width measure spec to be given to a child's</span></span><br><span class="line"><span class="comment">     *            &#123;<span class="doctag">@link</span> View#measure(int, int)&#125;.</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> startPosition The position of the first child to be shown.</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> endPosition The (inclusive) position of the last child to be</span></span><br><span class="line"><span class="comment">     *            shown. Specify &#123;<span class="doctag">@link</span> #NO_POSITION&#125; if the last child should be</span></span><br><span class="line"><span class="comment">     *            the last available child from the adapter.</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> maxHeight The maximum height that will be returned (if all the</span></span><br><span class="line"><span class="comment">     *            children don't fit in this value, this value will be</span></span><br><span class="line"><span class="comment">     *            returned).</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> disallowPartialChildPosition In general, whether the returned</span></span><br><span class="line"><span class="comment">     *            height should only contain entire children. This is more</span></span><br><span class="line"><span class="comment">     *            powerful--it is the first inclusive position at which partial</span></span><br><span class="line"><span class="comment">     *            children will not be allowed. Example: it looks nice to have</span></span><br><span class="line"><span class="comment">     *            at least 3 completely visible children, and in portrait this</span></span><br><span class="line"><span class="comment">     *            will most likely fit; but in landscape there could be times</span></span><br><span class="line"><span class="comment">     *            when even 2 children can not be completely shown, so a value</span></span><br><span class="line"><span class="comment">     *            of 2 (remember, inclusive) would be good (assuming</span></span><br><span class="line"><span class="comment">     *            startPosition is 0).</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span> The height of this ListView with the given children.</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@UnsupportedAppUsage</span>(maxTargetSdk = Build.VERSION_CODES.P, trackingBug = <span class="number">115609023</span>)</span><br><span class="line">    <span class="function"><span class="keyword">final</span> <span class="keyword">int</span> <span class="title">measureHeightOfChildren</span><span class="params">(<span class="keyword">int</span> widthMeasureSpec, <span class="keyword">int</span> startPosition, <span class="keyword">int</span> endPosition,</span></span></span><br><span class="line"><span class="function"><span class="params">            <span class="keyword">int</span> maxHeight, <span class="keyword">int</span> disallowPartialChildPosition)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">final</span> ListAdapter adapter = mAdapter;</span><br><span class="line">        <span class="keyword">if</span> (adapter == <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span> mListPadding.top + mListPadding.bottom;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// Include the padding of the list</span></span><br><span class="line">        <span class="keyword">int</span> returnedHeight = mListPadding.top + mListPadding.bottom;</span><br><span class="line">        <span class="keyword">final</span> <span class="keyword">int</span> dividerHeight = mDividerHeight;</span><br><span class="line">        <span class="comment">// The previous height value that was less than maxHeight and contained</span></span><br><span class="line">        <span class="comment">// no partial children</span></span><br><span class="line">        <span class="keyword">int</span> prevHeightWithoutPartialChild = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">int</span> i;</span><br><span class="line">        View child;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// mItemCount - 1 since endPosition parameter is inclusive</span></span><br><span class="line">        endPosition = (endPosition == NO_POSITION) ? adapter.getCount() - <span class="number">1</span> : endPosition;</span><br><span class="line">        <span class="keyword">final</span> AbsListView.RecycleBin recycleBin = mRecycler;</span><br><span class="line">        <span class="keyword">final</span> <span class="keyword">boolean</span> recyle = recycleOnMeasure();</span><br><span class="line">        <span class="keyword">final</span> <span class="keyword">boolean</span>[] isScrap = mIsScrap;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (i = startPosition; i &lt;= endPosition; ++i) &#123;</span><br><span class="line">            child = obtainView(i, isScrap);</span><br><span class="line"></span><br><span class="line">            measureScrapChild(child, i, widthMeasureSpec, maxHeight);</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> (i &gt; <span class="number">0</span>) &#123;</span><br><span class="line">                <span class="comment">// Count the divider for all but one child</span></span><br><span class="line">                returnedHeight += dividerHeight;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="comment">// Recycle the view before we possibly return from the method</span></span><br><span class="line">            <span class="keyword">if</span> (recyle &amp;&amp; recycleBin.shouldRecycleViewType(</span><br><span class="line">                    ((LayoutParams) child.getLayoutParams()).viewType)) &#123;</span><br><span class="line">                recycleBin.addScrapView(child, -<span class="number">1</span>);</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            returnedHeight += child.getMeasuredHeight();</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> (returnedHeight &gt;= maxHeight) &#123;</span><br><span class="line">                <span class="comment">// We went over, figure out which height to return.  If returnedHeight &gt; maxHeight,</span></span><br><span class="line">                <span class="comment">// then the i'th position did not fit completely.</span></span><br><span class="line">                <span class="keyword">return</span> (disallowPartialChildPosition &gt;= <span class="number">0</span>) <span class="comment">// Disallowing is enabled (&gt; -1)</span></span><br><span class="line">                            &amp;&amp; (i &gt; disallowPartialChildPosition) <span class="comment">// We've past the min pos</span></span><br><span class="line">                            &amp;&amp; (prevHeightWithoutPartialChild &gt; <span class="number">0</span>) <span class="comment">// We have a prev height</span></span><br><span class="line">                            &amp;&amp; (returnedHeight != maxHeight) <span class="comment">// i'th child did not fit completely</span></span><br><span class="line">                        ? prevHeightWithoutPartialChild</span><br><span class="line">                        : maxHeight;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> ((disallowPartialChildPosition &gt;= <span class="number">0</span>) &amp;&amp; (i &gt;= disallowPartialChildPosition)) &#123;</span><br><span class="line">                prevHeightWithoutPartialChild = returnedHeight;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// At this point, we went through the range of children, and they each</span></span><br><span class="line">        <span class="comment">// completely fit, so return the returnedHeight</span></span><br><span class="line">        <span class="keyword">return</span> returnedHeight;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure></p><p>这里最关键的代码: <code>child = obtainView(i, isScrap);</code></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">    * Gets a view and have it show the data associated with the specified</span></span><br><span class="line"><span class="comment">    * position. This is called when we have already discovered that the view</span></span><br><span class="line"><span class="comment">    * is not available for reuse in the recycle bin. The only choices left are</span></span><br><span class="line"><span class="comment">    * converting an old view or making a new one.</span></span><br><span class="line"><span class="comment">    *</span></span><br><span class="line"><span class="comment">    * <span class="doctag">@param</span> position the position to display</span></span><br><span class="line"><span class="comment">    * <span class="doctag">@param</span> outMetadata an array of at least 1 boolean where the first entry</span></span><br><span class="line"><span class="comment">    *                    will be set &#123;<span class="doctag">@code</span> true&#125; if the view is currently</span></span><br><span class="line"><span class="comment">    *                    attached to the window, &#123;<span class="doctag">@code</span> false&#125; otherwise (e.g.</span></span><br><span class="line"><span class="comment">    *                    newly-inflated or remained scrap for multiple layout</span></span><br><span class="line"><span class="comment">    *                    passes)</span></span><br><span class="line"><span class="comment">    *</span></span><br><span class="line"><span class="comment">    * <span class="doctag">@return</span> A view displaying the data associated with the specified position</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">   <span class="function">View <span class="title">obtainView</span><span class="params">(<span class="keyword">int</span> position, <span class="keyword">boolean</span>[] outMetadata)</span> </span>&#123;</span><br><span class="line">       Trace.traceBegin(Trace.TRACE_TAG_VIEW, <span class="string">"obtainView"</span>);</span><br><span class="line">       <span class="comment">//...</span></span><br><span class="line">       <span class="comment">//obtainView方法里面核心的代码其实就两行，首先从复用缓存中取出一个可以复用的View，然后作为参传入getView中，</span></span><br><span class="line"><span class="comment">//也就是convertView。这里会走到obtainview，子View实例都是由obtainView方法返回的，然后再调用具体measureScrapChild</span></span><br><span class="line"><span class="comment">//来具体测量子View的高度.</span></span><br><span class="line">        <span class="comment">//正常情况下这里for循环的次数就等于所有子项的个数，不过特殊的是已测量的子View高度之和大于maxHeight</span></span><br><span class="line"> <span class="comment">//就直接return出循环了。这种做法其实很好理解，ListView能显示的最大高度就是屏幕的高度，如果有1000个子项</span></span><br><span class="line"> <span class="comment">//前面10项已经占满了一屏幕了，那后面的990项就没必要继续测量高度了，这样可以大大提高性能</span></span><br><span class="line">      <span class="keyword">final</span> View scrapView = mRecycler.getScrapView(position);</span><br><span class="line">       <span class="keyword">final</span> View child = mAdapter.getView(position, scrapView, <span class="keyword">this</span>);</span><br><span class="line">       <span class="keyword">if</span> (scrapView != <span class="keyword">null</span>) &#123;</span><br><span class="line">           <span class="keyword">if</span> (child != scrapView) &#123;</span><br><span class="line">               <span class="comment">// Failed to re-bind the data, return scrap to the heap.</span></span><br><span class="line">               mRecycler.addScrapView(scrapView, position);</span><br><span class="line">           &#125; <span class="keyword">else</span> <span class="keyword">if</span> (child.isTemporarilyDetached()) &#123;</span><br><span class="line">               outMetadata[<span class="number">0</span>] = <span class="keyword">true</span>;</span><br><span class="line"></span><br><span class="line">               <span class="comment">// Finish the temporary detach started in addScrapView().</span></span><br><span class="line">               child.dispatchFinishTemporaryDetach();</span><br><span class="line">           &#125;</span><br><span class="line">       &#125;</span><br><span class="line">       <span class="comment">//....</span></span><br><span class="line">       setItemViewLayoutParams(child, position);</span><br><span class="line">       Trace.traceEnd(Trace.TRACE_TAG_VIEW);</span><br><span class="line">       <span class="keyword">return</span> child;</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure><p>出现问题时正是触发了onMeasure，导致遍历可见范围内的数十个wifi item并计算他们的高度</p><hr><p><strong>一点小结</strong></p><p>一个View最终显示到屏幕上一共分为三个阶段：Measure、Layout、Draw，而使用不当会造成其重复调用，尤其是Measure过程最为敏感。<br>因为当根布局做measure的时候，需要逐级measure子View和子布局，当所有子View或子布局measure完成的时候才能最终确定根部局的大小，<br>所以子布局的measure调用时机是由父布局来决定的。而像ListView这种在其onMeasure中直接调用getView的情况，<br>如果onMeasure被调用次数过多，将严重影响性能。</p><p>这里的listview还好外边没有裹着RelativeLayout，不然会导致子View的onMeasure重复调用，卡顿也会更加明显，假设RelativeLayout嵌套层数为n，子View的onMeasure次数为2^（n+1）</p><p>使用ListView的时候注意尽量使用layout_height=”match_parent”，如果无法避免，外边也不能裹着RelativeLayout</p><p>总而言之: 写代码三思而后行，谨慎再谨慎</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;strong&gt;问题描述&lt;/strong&gt;&lt;br&gt;在开机向导界面滑动wifi列表界面时比较卡顿，概率为必现&lt;/p&gt;
&lt;p&gt;抓一份systrace，红色帧有多处，总体上看有不少处发生掉帧&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.c
      
    
    </summary>
    
      <category term="Android" scheme="http://lihaizhou.top/categories/Android/"/>
    
      <category term="性能" scheme="http://lihaizhou.top/categories/Android/%E6%80%A7%E8%83%BD/"/>
    
    
  </entry>
  
  <entry>
    <title>如何快速定位kernel错误</title>
    <link href="http://lihaizhou.top/2019/12/26/%E5%A6%82%E4%BD%95%E5%BF%AB%E9%80%9F%E5%AE%9A%E4%BD%8Dkernel%E9%94%99%E8%AF%AF/"/>
    <id>http://lihaizhou.top/2019/12/26/如何快速定位kernel错误/</id>
    <published>2019-12-26T12:08:49.000Z</published>
    <updated>2019-12-28T06:57:16.000Z</updated>
    
    <content type="html"><![CDATA[<p>比如在定位systrace卡顿问题时，最后跟到kernel中<br><img src="https://github.com/hellolihaizhou/saveImg/blob/master/950ffc39-d5dc-47d7-a57b-3e774cae457d.png?raw=true" alt="systrace卡顿"></p><p>可以看到阻塞在<br>{kernel callsite when blocked:: “teei_forward_call+0xac/0xfc”}</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">mi@mi-OptiPlex<span class="number">-7060</span>:~<span class="regexp">/Code_mi/</span>F7_code/prebuilts/gdb/linux-x86/bin$ ./gdb</span><br><span class="line">GNU gdb (GDB) <span class="number">7.11</span></span><br><span class="line">Copyright (C) <span class="number">2016</span> Free Software Foundation, Inc.</span><br><span class="line">License GPLv3+: GNU GPL version <span class="number">3</span> or later &lt;http:<span class="comment">//gnu.org/licenses/gpl.html&gt;</span></span><br><span class="line">This is free software: you are free to change and redistribute it.</span><br><span class="line">There is NO WARRANTY, to the extent permitted by law.  Type <span class="string">"show copying"</span></span><br><span class="line">and <span class="string">"show warranty"</span> <span class="keyword">for</span> details.</span><br><span class="line">This GDB was configured <span class="keyword">as</span> <span class="string">"x86_64-linux-gnu"</span>.</span><br><span class="line">Type <span class="string">"show configuration"</span> <span class="keyword">for</span> configuration details.</span><br><span class="line">For bug reporting instructions, please see:</span><br><span class="line">&lt;http:<span class="comment">//www.gnu.org/software/gdb/bugs/&gt;.</span></span><br><span class="line">Find the GDB manual and other documentation resources online at:</span><br><span class="line">&lt;http:<span class="comment">//www.gnu.org/software/gdb/documentation/&gt;.</span></span><br><span class="line">For help, type <span class="string">"help"</span>.</span><br><span class="line">Type <span class="string">"apropos word"</span> to search <span class="keyword">for</span> commands related to <span class="string">"word"</span>.</span><br><span class="line">(gdb) file <span class="string">'/home/mi/日志/vmliux/out/target/product/merlin/obj/KERNEL_OBJ/vmlinux'</span> </span><br><span class="line"><span class="comment">//此时输入file后面跟vmlinux文件，vmlinux在symbols中，具体路径在out/target/product/libra/obj/KERNEL_OBJ/下</span></span><br><span class="line">Reading symbols <span class="keyword">from</span> /home/mi/日志/vmliux/out/target/product/merlin/obj/KERNEL_OBJ/vmlinux...done.</span><br><span class="line"></span><br><span class="line">(gdb) list*teei_forward_call+<span class="number">0xac</span>  <span class="comment">//list*后面跟上偏移位</span></span><br><span class="line"><span class="number">0xffffff80087fe9d8</span> is <span class="keyword">in</span> teei_forward_call (<span class="regexp">/home/</span>work/merlin-q-dev-build/kernel<span class="number">-4.14</span>/drivers/misc/mediatek/teei/<span class="number">300</span>/tz_driver/teei_smc_call.c:<span class="number">128</span>).</span><br></pre></td></tr></table></figure><p>这种情况适用于像NE问题或者一些watchdog问题等</p><p>还有一种情况是像如下图中</p><p><img src="https://github.com/hellolihaizhou/saveImg/blob/master/7d36fef5-b40b-439b-bd69-fd65e393e8be.png?raw=true" alt="systrace卡顿2"></p><p>这种情况稍微有点麻烦<br>知道地址该如何反向定位函数名和偏移呢, 这个时候就需要用到objdump，-d后面跟的是vmlinux的地址，最后会将汇编语言导入到vmlinux.txt中，此时搜索后五位即 fb684</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">aarch64-linux-android-objdump -d vmlinux &gt; vmlinux.txt</span><br></pre></td></tr></table></figure><p>搜索到如下结果</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ffffff80087fb674:    <span class="number">14000004</span>     b    ffffff80087fb684 &lt;teei_forward_call+<span class="number">0xac</span>&gt;</span><br></pre></td></tr></table></figure><p>这个时候在用gdb配合vmlinux定位teei_forward_call+0xac就可以了</p><p>汇总下<br>分析工具</p><ul><li>addr2line：用来分析单个pc地址对应的源码行数，比如示例log中的第13行中的#00 pc 0004097c，0004097c就是crash时pc调用的堆栈地址，用这个地址就可以分析出对应在源码中的行数；</li><li>objdump：用来把相应的so变成汇编语言的asm文件，然后根据地址信息（比如0004097c）就可以找到更加详细的相关函数信息；</li><li>ndk-stack：用来把log信息全部翻译成更加详细的带源码行数信息的log，相当于是在整个crash堆栈信息都执行addr2line命令。</li></ul><p>linux自带addr2line命令。使用Windows的，在sdk中安装了NDK之后，在ndk中就带有这些工具。<br>比如addr2line工具在：sdk\ndk-bundle\toolchains\arm-linux-androideabi-4.9\prebuilt\windows-x86_64\bin下面，同时这个bin下面包含很多其他工具，比如objdump，readelf等；<br>ndk-stack工具则在sdk\ndk-bundle下面；</p><h3 id="使用addr2line查找代码位置"><a href="#使用addr2line查找代码位置" class="headerlink" title="使用addr2line查找代码位置"></a>使用addr2line查找代码位置</h3><p>执行如下的命令，多个指针地址可以在<br><img src="https://github.com/hellolihaizhou/saveImg/blob/master/16111918_pm7h.jpg?raw=true" alt=""></p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">arm-linux-androideabi-addr2line –e obj/local/armeabi/libhello-jni.so <span class="number">00004</span>de8 <span class="number">000056</span>c8 <span class="number">00004</span>fb4 <span class="number">00004</span>f58</span><br></pre></td></tr></table></figure><p>PS：</p><ul><li>crash log与对应的so一定要对应起来。即错误的情况是：你拿了一份旧的log，然后你修改了so相关的源码，然后编译出来了新的so，你拿着这个新的so以及旧log中的地址去让addr2line等分析，那肯定是得不到正确的结果的</li><li>带symbols的so文件<br>对于比如手机公司的开发人员来说，一般来说出问题的so对应的带symbols的so都在out/target/product/&lt;model_name&gt;/symbols/system/lib/下面，而对于常见的使用AndroidStudio开发的单个应用来说，其对应的带symbols的在&lt;PROJECT_ROOT&gt;\app\src\main\obj\local\<abi>\下面的so，而不能是\app\src\main\libs\<abi>的，这里面的是不包含symbols信息的，拿这个去分析，输出的结果就是“??:?”。其实这两个so的体积对比也是很明显的的，在我的应用中，前一个带symbols的so的体积为7M多，而后一个只有2M</abi></abi></li></ul><h3 id="使用objdump获取函数信息"><a href="#使用objdump获取函数信息" class="headerlink" title="使用objdump获取函数信息"></a>使用objdump获取函数信息</h3><p>使用如下命令导出函数表</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">arm-linux-androideabi-objdump –S obj/local/armeabi/libhello-jni.so &gt; hello.asm</span><br></pre></td></tr></table></figure><p>在生成的asm文件中查找刚刚我们定位的两个关键指针00004fb4和00004f58，搜索后四位<br>可以显示对应的函数名，这样再配合addressline的结果堪称完美，可以得到对应文件的某一行并且知道对应的函数名(其实addr2line就够了)</p><p>参考文章:<br><a href="https://www.oschina.net/question/2241352_213433" target="_blank" rel="noopener">如何定位Android NDK开发中遇到的错误</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;比如在定位systrace卡顿问题时，最后跟到kernel中&lt;br&gt;&lt;img src=&quot;https://github.com/hellolihaizhou/saveImg/blob/master/950ffc39-d5dc-47d7-a57b-3e774cae457d.pn
      
    
    </summary>
    
      <category term="性能" scheme="http://lihaizhou.top/categories/%E6%80%A7%E8%83%BD/"/>
    
    
  </entry>
  
  <entry>
    <title>一个返回卡顿2s问题的分析解决之路</title>
    <link href="http://lihaizhou.top/2019/12/21/%E4%B8%80%E4%B8%AA%E8%BF%94%E5%9B%9E%E5%8D%A1%E9%A1%BF2s%E9%97%AE%E9%A2%98%E7%9A%84%E5%88%86%E6%9E%90%E8%A7%A3%E5%86%B3%E4%B9%8B%E8%B7%AF/"/>
    <id>http://lihaizhou.top/2019/12/21/一个返回卡顿2s问题的分析解决之路/</id>
    <published>2019-12-21T09:54:10.000Z</published>
    <updated>2019-12-26T12:10:08.000Z</updated>
    
    <summary type="html">
    
    </summary>
    
      <category term="性能" scheme="http://lihaizhou.top/categories/%E6%80%A7%E8%83%BD/"/>
    
    
  </entry>
  
  <entry>
    <title>Android-Vsync</title>
    <link href="http://lihaizhou.top/2019/12/15/Android-Vsync/"/>
    <id>http://lihaizhou.top/2019/12/15/Android-Vsync/</id>
    <published>2019-12-15T12:42:18.000Z</published>
    <updated>2019-12-28T07:03:06.000Z</updated>
    
    <content type="html"><![CDATA[<p>本文目的在于通过了解Vsync工作原理加深对systrace的理解</p><p>在 Systrace 中我们可以看到，Android 系统在 Vsync 信号的指引下，有条不紊地进行者每一帧的渲染、合成操作，使我们可以享受稳定帧率的画面。</p><p>Vsync作用-Drawing without Sync<br>Step1. Display显示第0帧数据，此时CPU和GPU渲染第1帧画面，而且赶在Display显示下一帧前完成<br>Step2. 因为渲染及时，Display在第0帧显示完成后，也就是第1个VSync后，正常显示第1帧<br>Step3. 由于某些原因，比如CPU资源被占用，系统没有及时地开始处理第2帧，直到第2个VSync快来前才开始处理<br>Step4. 第2个VSync来时，由于第2帧数据还没有准备就绪，显示的还是第1帧。这种情况被Android开发组命名为“Jank”。<br>Step5. 当第2帧数据准备完成后，它并不会马上被显示，而是要等待下一个VSync。</p><p><img src="https://github.com/hellolihaizhou/saveImg/blob/master/vsync-1.png?raw=true" alt=""></p><p>这个图中还有个值得注意的地方就是FramebufferSurface,这个代表最终合成的数据<br>可以看到sf合成后这个数值变为了1，display显示后这个数值又变为了0</p><p>让CPU GPU渲染工作都在一个Vsync周期工作，保证绘制的步调和屏幕刷新的步调一致，为此Android引入另外两个软件VSync信号，VSYNC-sf和VSYNC-app，VSYNC-sf用于触发SurfaceFlinger合成VSYNC-app用于触发app 绘制这几个信号可通过systrace观察到<br><img src="https://github.com/hellolihaizhou/saveImg/blob/master/vsync-9.png?raw=true" alt=""></p><p><img src="https://github.com/hellolihaizhou/saveImg/blob/master/vsync-10.png?raw=true" alt=""></p><p><img src="https://github.com/hellolihaizhou/saveImg/blob/master/vsync-11.png?raw=true" alt=""></p><p><img src="https://github.com/hellolihaizhou/saveImg/blob/master/vsync-12.png?raw=true" alt=""></p><p>因为 VSYNC 是由硬件产生的，一旦产生了就必须开始干活，不灵活。假设有这么一种需求，我希望在 VSYNC 偏移一段时间以后再干活，那么这个是硬件 VSYNC 提供不了，所以这个时候就必须引入软件模型。而 DispSync 就是为了解决这个需求引入的软件模型。<br>DispSync 类似于一个 PLL（phase lock loop，锁相回路），它通过接收硬件 VSYNC，然后给其他关心硬件 VSYNC 的组件（SurfaceFlinger 和需要渲染的 app）在指定的偏移以后发送软件 VSYNC，并且当误差在可接受的范围内，将会关闭硬件 VSYNC<br><img src="https://github.com/hellolihaizhou/saveImg/blob/master/vsync-2-dispsync.png?raw=true" alt="dispsync"><br>SurfaceFlinger将HWComposer收到新的Vsync-timestamp交给DispSync::addResyncSample来决定是否还需要继续输入HW_VSYNC_0</p><p>与此同时,DispSync会根据HWComposer传过来的retire-fence-timestamps来检查SW_VSYNC</p><p>Vsync虚拟化（Vsync App + Vsync SurfaceFlinger）：<br>虽然vsync使得CPU/GPU/Display同步了，但App UI和SurfaceFlinger的工作显然是一个流水线的模型。即对于一帧内容，先等App UI画完了，SurfaceFlinger再出场对其进行合并渲染后放入framebuffer，最后整到屏幕上。<br>而现有的VSync模型是让大家一起开始干活，这样对于同一帧内容，第一个VSync信号时App UI的数据开始准备，第二个VSync信号SurfaceFlinger工作，第三个VSync信号时用户看到Display内容，这样就两个VSync period(每个16ms)过去了，影响用户体验。<br>解决思路：SurfaceFlinger在App UI准备好数据后及时开工做合成。</p><p>Android 4.4(KitKat)引入了VSync的虚拟化，即把硬件的VSync信号先同步到一个本地VSync模型中，再从中一分为二，引出两条VSync时间与之有固定偏移的线程。示意图如下：<br>  <img src="https://github.com/hellolihaizhou/saveImg/blob/master/vsync-3.png?raw=true" alt=""></p><p>第一阶段：<br>App 在收到 Vsync-App 的时候，在主线程进行 measure、layout、draw(构建 DisplayList , 里面包含 OpenGL 渲染需要的命令及数据) 。这里对应的 Systrace 中的主线程 doFrame 操作<br>第二阶段：<br>CPU 将数据上传（共享或者拷贝）给 GPU,　这里 ARM 设备 内存一般是 GPU 和 CPU 共享内存。这里对应的 Systrace 中的渲染线程的 flush drawing commands 操作<br>第三阶段：<br>通知 GPU 渲染，真机一般不会阻塞等待 GPU 渲染结束，CPU 通知结束后就返回继续执行其他任务，使用 Fence 机制辅助 GPU CPU 进行同步操作<br>第四 阶段：<br>swapBuffers，并通知 SurfaceFlinger 图层合成。这里对应的 Systrace 中的渲染线程的 eglSwapBuffersWithDamageKHR 操作<br>第五阶段：<br>SurfaceFlinger开始合成图层，如果之前提交的GPU渲染任务没结束，则等待GPU渲染完成，再合成（Fence机制），合成依然是依赖GPU，不过这就是下一个任务了.这里对应的Systrace中的SurfaceFlinger主线程的 onMessageReceived操作（包括 handleTransaction、handleMessageInvalidate、handleMessageRefresh）SurfaceFlinger 在合成的时候，会将一些合成工作委托给Hardware Composer,从而降低来自 OpenGL和GPU的负载，只有Hardware Composer 无法处理的图层，或者指定用OpenGL处理的图层，其他的 图层偶会使用Hardware Composer进行合成<br>第六阶段 ：最终合成好的数据放到屏幕对应的Frame Buffer中，固定刷新的时候就可以看到了</p><p>通过systrace看数据流向<br><img src="https://github.com/hellolihaizhou/saveImg/blob/master/vsync-5.jpg?raw=true" alt=""></p><p>上图中主要包含 SurfaceFlinger、App 和 hwc 三个进程，下面就来结合图中的标号，来进一步说明数据的流向</p><ul><li>第一个Vsync信号到来, SurfaceFlinger和App同时收到Vsync信号</li><li>SurfaceFlinger收到Vsync-sf信号，开始进行App上一帧的Buffer的合成</li><li>App收到Vsyc-app信号，开始进行这一帧的Buffer的渲染(对应上面的第一、二、三、四阶段)</li><li>第二个Vsync信号到来 ,SurfaceFlinger和App同时收到Vsync信号，SurfaceFlinger获取App在第二步里面渲染的Buffer,开始合成(对应上面的第五阶段),App收到Vsycn-app 信号，开始新一帧的Buffer的渲染(对应上面的第一、二、三、四阶段)</li></ul><h3 id="Vsync-offset"><a href="#Vsync-offset" class="headerlink" title="Vsync offset"></a>Vsync offset</h3><p>文章最开始有提到，Vsync信号可以由硬件产生，也可以用软件模拟，不过现在基本上都是硬件产生，负责产生硬件Vsync的是HWC,HWC 可生成 VSYNC事件并通过回调将事件发送到 SurfaceFlinge , DispSync将Vsync 生成由Choreographer和SurfaceFlinger使用的VSYNC_APP 和 VSYNC_SF 信号.</p><p><img src="https://github.com/hellolihaizhou/saveImg/blob/master/vsync_6_disp_sync_arch.png?raw=true" alt=""></p><p>有一个疑问<br>因此可以看出SW vsync/App vsync 并不是直接由HW vsync产生的，而是由SW vsync产生的，HW vsync作为SW vsync的参考，动态的更新SW vsync里的模型参数，这样让SW vsync能与HW vsync更加的精确吧。</p><p>那么为什么SurfaceFlinger要用SW vsync而不是直接用HW vsync呢？<br>猜想可能是因为HW vsync每隔固定时间由显示屏产生中断，然后传给driver, driver再回调给SurfaceFlinger, 这样经过层层回调，会对performance有影响吧。而SW vsync直接由SurfaceFlinger产生，省略了很多步骤</p><p>这个文章 <a href="https://www.jianshu.com/p/d3e4b1805c92" target="_blank" rel="noopener">https://www.jianshu.com/p/d3e4b1805c92</a> 很棒</p><p>其中 app 和 sf 相对 hw_vsync_0 都有一个偏移,即 phase-app 和 phase-sf，如下图<br><img src="https://github.com/hellolihaizhou/saveImg/blob/master/vsync-7.jpg?raw=true" alt=""></p><p>Vsync Offset我们指的是VSYNC_APP和VSYNC_SF之间有一个Offset，即上图中phase-sf - phase-app的值，这个Offset是厂商可以配置的。如果 Offset 不为 0，那么意味着App和SurfaceFlinger主进程不是同时收到Vsync信号，而是间隔Offset(通常在0 - 16.6ms之间)</p><p>目前大部分厂商都没有配置这个Offset，所以App和SurfaceFlinger是同时收到Vsync信号的.</p><p>可以通过Dumpsys SurfaceFlinger来查看对应的值</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">C:\Users\MI</span><br><span class="line">λ adb shell dumpsys SurfaceFlinger|grep <span class="string">"app phase"</span></span><br><span class="line">   app phase:   <span class="number">8300000</span> ns      SF phase:   <span class="number">8300000</span> ns</span><br></pre></td></tr></table></figure><p>Offset 为 0<br>首先说 Offset 为 0 的情况， 此时 App 和 SurfaceFlinger 是同时收到 Vsync 信号 ， 其对应的 Systrace 图如下</p><p><img src="https://github.com/hellolihaizhou/saveImg/blob/master/vsync-8.jpg?raw=true" alt=""><br>这个图上面也有讲解，这里就不再详细说明，大家只需要看到，App 渲染好的 Buffer，要等到下一个 Vsync-SF 来的时候才会被 SurfaceFlinger 拿去做合成，这个时间大概在 16.6 ms。这时候大家可能会想，如果 App 的 Buffer 渲染结束，Swap 到 BufferQueue 中 ，就触发 SurfaceFlinger 去做合成，那岂不是省了一些时间(0-16.6ms )?</p><p>答案是可行的，这也就引入了 Offset 机制，在这种情况下，App 先收到 Vsync 信号，进行一帧的渲染工作，然后过了 Offset 时间后，SurfaceFlinger 才收到 Vsync 信号开始合成，这时候如果 App 的 Buffer 已经 Ready 了，那么 SurfaceFlinger 这一次合成就可以包含 App 这一帧，用户也会早一点看到。</p><p>Offset 的优缺点</p><ul><li><p>Offset 的一个比较难以确定的点就在与 Offset 的时间该如何设置，这也是众多厂商默认都不进行配置 Offset 的一个原因，其优缺点是动态的，与机型的性能和使用场景有很大的关系</p></li><li><p>如果 Offset 配置过短，那么可能 App 收到 Vsync-App 后还没有渲染完成，SurfaceFlinger 就收到 Vsync-SF 开始合成，那么此时如果 App 的 BufferQueue 中没有之前累积的 Buffer，那么 SurfaceFlinger 这次合成就不会有 App 的东西在里面，需要等到下一个 Vsync-SF 才能合成这次 App 的内容，时间相当于变成了 Vsync 周期+Offset，而不是我们期待的 Offset<br>如果 Offset 配置过长，就起不到作用了</p></li></ul><h3 id="HW-Vsync"><a href="#HW-Vsync" class="headerlink" title="HW_Vsync"></a>HW_Vsync</h3><p>这里需要说明的是，不是每次申请 Vsync 都会由硬件产生 Vsync，只有此次请求 vsync 的时间距离上次合成时间大于 500ms，才会通知 hwc，请求 HW_VSYNC</p><p>以桌面滑动为例，看 SurfaceFlinger 的进程 Trace 可以看到 HW_VSYNC 的状态</p><p>HW_VSYNC 主要是利用最近的硬件 VSYNC 来做预测,最少要 3 个,最多是 32 个,实际上要用几个则不一定, DispSync 拿到 6 个 VSYNC 后就会计算出 SW_VSYNC,只要收到的 Present Fence 没有超过误差,硬件 VSYNC 就会关掉,不然会继续接收硬件 VSYNC 计算 SW_VSYNC 的值,直到误差小于 threshold.</p><p>下面以AndroidQ上代码为例<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">frameworks/<span class="keyword">native</span>/services/surfaceflinger/SurfaceFlinger.cpp</span><br><span class="line"><span class="keyword">void</span> SurfaceFlinger::onVsyncReceived(int32_t sequenceId, hwc2_display_t hwcDisplayId,</span><br><span class="line">                                     int64_t timestamp) &#123;</span><br><span class="line">    ATRACE_NAME(<span class="string">"SF onVsync"</span>);</span><br><span class="line">    <span class="comment">//...</span></span><br><span class="line">    bool periodFlushed = <span class="keyword">false</span>;</span><br><span class="line">    mScheduler-&gt;addResyncSample(timestamp, &amp;periodFlushed);</span><br><span class="line">    <span class="keyword">if</span> (periodFlushed) &#123;</span><br><span class="line">        mVsyncModulator.onRefreshRateChangeCompleted();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">void</span> Scheduler::addResyncSample(<span class="keyword">const</span> nsecs_t timestamp, bool* periodFlushed) &#123;</span><br><span class="line">    bool needsHwVsync = <span class="keyword">false</span>;</span><br><span class="line">    *periodFlushed = <span class="keyword">false</span>;</span><br><span class="line">    &#123; <span class="comment">// Scope for the lock</span></span><br><span class="line">        std::lock_guard&lt;std::mutex&gt; lock(mHWVsyncLock);</span><br><span class="line">        <span class="keyword">if</span> (mPrimaryHWVsyncEnabled) &#123;</span><br><span class="line"><span class="comment">//addResyncSample会根据现有的硬件Vsync样本计算SW Vsync模型，如果误差已经在可接受范围内</span></span><br><span class="line">   <span class="comment">// 即认为不再需要硬件Vsync样本了，就得关闭硬件Vsync</span></span><br><span class="line">   <span class="comment">// 反之，如果误差还比较大，这里还需要继续加入硬件Vsync样本继续计算SW Vsync模型 </span></span><br><span class="line">            needsHwVsync = mPrimaryDispSync-&gt;addResyncSample(timestamp, periodFlushed);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"><span class="comment">// enableHardwareVsync/disableHardwareVsync都是通过EventControlThread去控制硬件Vsync开关</span></span><br><span class="line">    <span class="keyword">if</span> (needsHwVsync) &#123;</span><br><span class="line">        enableHardwareVsync();</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        disableHardwareVsync(<span class="keyword">false</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>下面重点看硬件Vsync样本是如何计算SW Vsync模型，这也是最有趣的地方</p><h3 id="addResyncSample"><a href="#addResyncSample" class="headerlink" title="addResyncSample"></a>addResyncSample</h3><p>frameworks/native/services/surfaceflinger/Scheduler/DispSync.cpp<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br></pre></td><td class="code"><pre><span class="line">    <span class="keyword">enum</span> &#123; MAX_RESYNC_SAMPLES = <span class="number">32</span> &#125;;</span><br><span class="line">    <span class="keyword">enum</span> &#123; MIN_RESYNC_SAMPLES_FOR_UPDATE = <span class="number">6</span> &#125;;</span><br><span class="line">    <span class="keyword">enum</span> &#123; NUM_PRESENT_SAMPLES = <span class="number">8</span> &#125;;</span><br><span class="line">    <span class="keyword">enum</span> &#123; MAX_RESYNC_SAMPLES_WITHOUT_PRESENT = <span class="number">4</span> &#125;;</span><br><span class="line">    <span class="keyword">enum</span> &#123; ACCEPTABLE_ZERO_ERR_SAMPLES_COUNT = <span class="number">64</span> &#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">bool</span> DispSync::addResyncSample(<span class="keyword">nsecs_t</span> timestamp, <span class="keyword">bool</span>* periodFlushed) &#123;</span><br><span class="line">    Mutex::<span class="function">Autolock <span class="title">lock</span><span class="params">(mMutex)</span></span>;</span><br><span class="line"></span><br><span class="line">    ALOGV(<span class="string">"[%s] addResyncSample(%"</span> PRId64 <span class="string">")"</span>, mName, ns2us(timestamp));</span><br><span class="line"></span><br><span class="line">    *periodFlushed = <span class="literal">false</span>;</span><br><span class="line">    <span class="keyword">const</span> <span class="keyword">size_t</span> idx = (mFirstResyncSample + mNumResyncSamples) % MAX_RESYNC_SAMPLES;</span><br><span class="line"><span class="comment">//// mResyncSamples 记录每个硬件vsync样本的时间戳，在计算sw vsync的模型时有用</span></span><br><span class="line">    mResyncSamples[idx] = timestamp;</span><br><span class="line">    <span class="keyword">if</span> (mNumResyncSamples == <span class="number">0</span>) &#123;</span><br><span class="line">        mPhase = <span class="number">0</span>;</span><br><span class="line">        ALOGV(<span class="string">"[%s] First resync sample: mPeriod = %"</span> PRId64 <span class="string">", mPhase = 0, "</span></span><br><span class="line">              <span class="string">"mReferenceTime = %"</span> PRId64,</span><br><span class="line">              mName, ns2us(mPeriod), ns2us(timestamp));</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (mPendingPeriod &gt; <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="comment">// mNumResyncSamples &gt; 0, so priorIdx won't overflow</span></span><br><span class="line">        <span class="keyword">const</span> <span class="keyword">size_t</span> priorIdx = (mFirstResyncSample + mNumResyncSamples - <span class="number">1</span>) % MAX_RESYNC_SAMPLES;</span><br><span class="line">        <span class="keyword">const</span> <span class="keyword">nsecs_t</span> lastTimestamp = mResyncSamples[priorIdx];</span><br><span class="line"></span><br><span class="line">        <span class="keyword">const</span> <span class="keyword">nsecs_t</span> observedVsync = <span class="built_in">std</span>::<span class="built_in">abs</span>(timestamp - lastTimestamp);</span><br><span class="line">        <span class="keyword">if</span> (<span class="built_in">std</span>::<span class="built_in">abs</span>(observedVsync - mPendingPeriod) &lt;= <span class="built_in">std</span>::<span class="built_in">abs</span>(observedVsync - mIntendedPeriod)) &#123;</span><br><span class="line">            <span class="comment">// Either the observed vsync is closer to the pending period, (and</span></span><br><span class="line">            <span class="comment">// thus we detected a period change), or the period change will</span></span><br><span class="line">            <span class="comment">// no-op. In either case, reset the model and flush the pending</span></span><br><span class="line">            <span class="comment">// period.</span></span><br><span class="line">            resetLocked();</span><br><span class="line">            mIntendedPeriod = mPendingPeriod;</span><br><span class="line">            mPeriod = mPendingPeriod;</span><br><span class="line">            mPendingPeriod = <span class="number">0</span>;</span><br><span class="line">            <span class="keyword">if</span> (mTraceDetailedInfo) &#123;</span><br><span class="line">                ATRACE_INT(<span class="string">"DispSync:PendingPeriod"</span>, mPendingPeriod);</span><br><span class="line">                ATRACE_INT(<span class="string">"DispSync:IntendedPeriod"</span>, mIntendedPeriod);</span><br><span class="line">            &#125;</span><br><span class="line">            *periodFlushed = <span class="literal">true</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 始终用最新的硬件时间戳timestamp来更新mReferenceTime.</span></span><br><span class="line">    mReferenceTime = timestamp;</span><br><span class="line">    mThread-&gt;updateModel(mPeriod, mPhase, mReferenceTime);</span><br><span class="line"><span class="comment">//更新 mNumResyncSamples 或 mFirstResyncSample的值</span></span><br><span class="line">    <span class="keyword">if</span> (mNumResyncSamples &lt; MAX_RESYNC_SAMPLES) &#123;</span><br><span class="line">        mNumResyncSamples++;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        mFirstResyncSample = (mFirstResyncSample + <span class="number">1</span>) % MAX_RESYNC_SAMPLES;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//开始计算更新SW vsync 模型</span></span><br><span class="line">    updateModelLocked();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (mNumResyncSamplesSincePresent++ &gt; MAX_RESYNC_SAMPLES_WITHOUT_PRESENT) &#123;</span><br><span class="line">        resetErrorLocked();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (mIgnorePresentFences) &#123;</span><br><span class="line">        <span class="comment">// If we're ignoring the present fences we have no way to know whether</span></span><br><span class="line">        <span class="comment">// or not we're synchronized with the HW vsyncs, so we just request</span></span><br><span class="line">        <span class="comment">// that the HW vsync events be turned on.</span></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Check against kErrorThreshold / 2 to add some hysteresis before having to</span></span><br><span class="line">    <span class="comment">// resync again</span></span><br><span class="line"><span class="comment">// 如果模型更新了，并且产生的错误小于 kErrorThreshold/2 这个值 (这个值是错误容忍度)，那么   modelLocked就被置为true, 即模型被锁定，模型被锁定的含义是</span></span><br><span class="line">    <span class="comment">// 现在SW vsync工作的很好，暂时不需要硬件Vsync来进行校正了，最后会将硬件Vsync给disable掉</span></span><br><span class="line">    <span class="keyword">bool</span> modelLocked = mModelUpdated &amp;&amp; mError &lt; (kErrorThreshold / <span class="number">2</span>) &amp;&amp; mPendingPeriod == <span class="number">0</span>;</span><br><span class="line">    ALOGV(<span class="string">"[%s] addResyncSample returning %s"</span>, mName, modelLocked ? <span class="string">"locked"</span> : <span class="string">"unlocked"</span>);</span><br><span class="line">    <span class="keyword">if</span> (modelLocked) &#123;</span><br><span class="line">        *periodFlushed = <span class="literal">true</span>;</span><br><span class="line">        mThread-&gt;lockModel();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> !modelLocked;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">关于这个值看下定义的地方注释</span><br><span class="line"><span class="comment">// This is the threshold used to determine when hardware vsync events are</span></span><br><span class="line"><span class="comment">// needed to re-synchronize the software vsync model with the hardware.  The</span></span><br><span class="line"><span class="comment">// error metric used is the mean of the squared difference between each</span></span><br><span class="line"><span class="comment">// present time and the nearest software-predicted vsync.</span></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">const</span> <span class="keyword">nsecs_t</span> kErrorThreshold = <span class="number">160000000000</span>; <span class="comment">// 400 usec squared</span></span><br></pre></td></tr></table></figure></p><p>这里核心是updateModelLocked()即如何依据硬件vsync来校准的，目前看的有点云里雾里<br>有待进一步厘清</p><h3 id="enableHardwareVsync"><a href="#enableHardwareVsync" class="headerlink" title="enableHardwareVsync"></a>enableHardwareVsync</h3><p>frameworks/native/services/surfaceflinger/Scheduler/Scheduler.cpp<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">void</span> Scheduler::enableHardwareVsync() &#123;</span><br><span class="line">    <span class="built_in">std</span>::lock_guard&lt;<span class="built_in">std</span>::mutex&gt; lock(mHWVsyncLock);</span><br><span class="line">    <span class="keyword">if</span> (!mPrimaryHWVsyncEnabled &amp;&amp; mHWVsyncAvailable) &#123;</span><br><span class="line">        mPrimaryDispSync-&gt;beginResync();</span><br><span class="line"><span class="comment">//调用EventControlThread去开启硬件vsync</span></span><br><span class="line">        mEventControlThread-&gt;setVsyncEnabled(<span class="literal">true</span>);</span><br><span class="line">        mPrimaryHWVsyncEnabled = <span class="literal">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>参考文章<br><a href="https://source.android.com/devices/graphics/implement-vsync" target="_blank" rel="noopener">谷歌VSYNC介绍</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;本文目的在于通过了解Vsync工作原理加深对systrace的理解&lt;/p&gt;
&lt;p&gt;在 Systrace 中我们可以看到，Android 系统在 Vsync 信号的指引下，有条不紊地进行者每一帧的渲染、合成操作，使我们可以享受稳定帧率的画面。&lt;/p&gt;
&lt;p&gt;Vsync作用-D
      
    
    </summary>
    
      <category term="Android" scheme="http://lihaizhou.top/categories/Android/"/>
    
    
  </entry>
  
  <entry>
    <title>Android-丢帧分析</title>
    <link href="http://lihaizhou.top/2019/12/15/Android-%E4%B8%A2%E5%B8%A7%E5%88%86%E6%9E%90/"/>
    <id>http://lihaizhou.top/2019/12/15/Android-丢帧分析/</id>
    <published>2019-12-15T07:39:19.000Z</published>
    <updated>2019-12-28T07:02:52.000Z</updated>
    
    <content type="html"><![CDATA[<p>用户日常使用手机过程中慢或者卡顿统一归结为丢帧问题，简单总结下：</p><p>1 内存不足<br>2 app使用的绘制方式区别<br>3 app使用的编译方式区别<br>4 app自身问题</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">C:\Users\MI</span><br><span class="line">λ adb shell cat /proc/meminfo</span><br><span class="line">MemTotal:        <span class="number">5871128</span> kB</span><br><span class="line">MemFree:         <span class="number">1215492</span> kB</span><br><span class="line">MemAvailable:    <span class="number">3631296</span> kB</span><br><span class="line">Buffers:           <span class="number">91956</span> kB</span><br><span class="line">Cached:          <span class="number">2432140</span> kB</span><br></pre></td></tr></table></figure><p>比较多的Uninterruptible Sleep，block 在__lock_page_or_retry </p><p>另外proc/meminfo中 可用内存非常少、且swap空间几乎耗尽 、lmk频繁打印等等都能从侧面反映内存偏低</p><p>app使用的绘制方式区别<br>相同app的软件绘制与硬件绘制对比：</p><p>软件绘制：</p><p>硬件加速<br>Android3.0开始支持硬件加速，Android4.0 默认启用硬件加速。但是app还是能主动设置 hardwareAccelerated 来切换两种模式</p><p>硬件绘制就是将CPU不擅长的图形计算转换成GPU专用指令，由GPU完成。</p><p>优点：</p><p>1）显著提升UI绘速度</p><p>2） 更新UI只重绘脏区域，提升刷新速度</p><p>缺点：</p><p>内存和电量消耗会比软件绘制大</p><p>3 app使用的编译方式区别<br>留意是否有编译方式的区别：</p><p>解释模式编译.dex文件肯定比直接执行.oat文件要来的慢</p><p>4 app自身问题<br>视图太复杂层级太深、主线程有耗时方法</p><p>DrawFrame过程很长，且基本是出于running状态时，可能视图过于复杂</p><p>主线程方法耗时的话，那需要通过加trace Label缩小范围，然后利用traceView对具体方法进行耗时分析</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;用户日常使用手机过程中慢或者卡顿统一归结为丢帧问题，简单总结下：&lt;/p&gt;
&lt;p&gt;1 内存不足&lt;br&gt;2 app使用的绘制方式区别&lt;br&gt;3 app使用的编译方式区别&lt;br&gt;4 app自身问题&lt;/p&gt;
&lt;figure class=&quot;highlight javascript&quot;&gt;
      
    
    </summary>
    
      <category term="Android" scheme="http://lihaizhou.top/categories/Android/"/>
    
    
  </entry>
  
  <entry>
    <title>Android input系统</title>
    <link href="http://lihaizhou.top/2019/12/15/Android%20input%E7%B3%BB%E7%BB%9F/"/>
    <id>http://lihaizhou.top/2019/12/15/Android input系统/</id>
    <published>2019-12-15T05:31:51.000Z</published>
    <updated>2019-12-28T07:03:28.000Z</updated>
    
    <content type="html"><![CDATA[<p>一次input的耗时时间分布</p><ul><li>T1 表示 硬件中断的时间</li><li>T2 表示 InputReader 从 /dev/input/xxx 读出事件的时间</li><li>T3 表示 InputDispatcher 向 app 进程发送事件的时间</li><li>T4 表示 app 主线程开始处理输入事件的时间</li><li>T5 表示 app 主线程完成处理输入事件的时间<br>一次用户输入事件的传递过程可以简化为: 硬件 -&gt; kernel -&gt; system_server -&gt; app</li></ul><p>system_server 耗时: T3 - T2<br>frameworks/native/libs/input/InputTransport.cpp<br>应用处理耗时: T5 - T4<br>frameworks/base / core/java/android/view/InputEventReceiver.java</p><h3 id="代码分布"><a href="#代码分布" class="headerlink" title="代码分布"></a>代码分布</h3><p>frameworks/native/services/inputflinger/</p><ul><li>InputDispatcher.cpp</li><li>InputReader.cpp</li><li>InputManager.cpp</li><li>EventHub.cpp</li><li>InputListener.cpp</li></ul><p>frameworks/native/libs/input/</p><ul><li>InputTransport.cpp</li><li>Input.cpp</li><li>InputDevice.cpp</li><li>Keyboard.cpp</li><li>KeyCharacterMap.cpp</li><li>IInputFlinger.cpp</li></ul><p>frameworks/base/services/core/</p><ul><li>java/com/android/server/input/InputManagerService.java</li><li>jni/com_android_server_input_InputManagerService.cpp</li></ul><p>Input模块的主要组成：</p><ul><li>Native层的InputReader负责从EventHub取出事件并处理，再交给InputDispatcher；</li><li>Native层的InputDispatcher接收来自InputReader的输入事件，并记录WMS的窗口信息，用于派发事件到合适的窗口；</li><li>Java层的InputManagerService跟WMS交互，WMS记录所有窗口信息，并同步更新到IMS，为InputDispatcher正确派发事件到ViewRootImpl提供保障</li></ul><p><img src="https://github.com/hellolihaizhou/saveImg/blob/master/input(1" alt="input事件流转路线">-Input%E4%BA%8B%E4%BB%B6%E7%AE%A1%E7%90%86.png?raw=true)</p><p>1、输入硬件<br>说白了就是任何接受外界刺激，然后将刺激转换为电信号（例如机械能，使得电路导通后产生电信号）的设备，然后向CPU发出硬件中断，然后CPU查找操作系统的中断向量表中相对应的中断编号，调用操作系统的相应的代码段，此处如果有对应的驱动程序的话，操作系统会调用驱动程序对输入设备产生的电信号进行解析和转换成标准的linux内核规定的事件信息结构。</p><p>2、输入设备驱动<br>在linux内核层，处理硬件电信号，并转换成linux内核标准事件信息结构。然后linux会将这些事件信息写入/dev/input/下对应的虚拟设备中。</p><p>3、/dev/input<br>linux写入输入事件的位置，被linux虚拟化成虚拟输入设备文件（字符设备）。</p><p>4、EventHub<br>安卓的事件核心、负责从linux虚拟化输入设备中获取到所有事件。</p><p>framework/native/services/inputflinger/EventHub.h</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;一次input的耗时时间分布&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;T1 表示 硬件中断的时间&lt;/li&gt;
&lt;li&gt;T2 表示 InputReader 从 /dev/input/xxx 读出事件的时间&lt;/li&gt;
&lt;li&gt;T3 表示 InputDispatcher 向 app 进程发送事件
      
    
    </summary>
    
      <category term="Android" scheme="http://lihaizhou.top/categories/Android/"/>
    
    
  </entry>
  
  <entry>
    <title>WFD的学习记录笔记</title>
    <link href="http://lihaizhou.top/2019/09/15/WFD%E7%9A%84%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95%E7%AC%94%E8%AE%B0/"/>
    <id>http://lihaizhou.top/2019/09/15/WFD的学习记录笔记/</id>
    <published>2019-09-15T09:18:25.000Z</published>
    <updated>2019-10-15T13:04:40.000Z</updated>
    
    <content type="html"><![CDATA[<p>本文只讨论miracast，对应的即是设置中投屏的方式，其他视频或者相册中走的是另外一套DLNA协议，不是实时的，还有一些三方应用如腾讯视频爱奇艺是自己搞了一套dlna，DLNA不在本文讨论范围内</p><h1 id="WFD扫盲"><a href="#WFD扫盲" class="headerlink" title="WFD扫盲"></a>WFD扫盲</h1><h2 id="miracast简介"><a href="#miracast简介" class="headerlink" title="miracast简介"></a>miracast简介</h2><h2 id="应用层如何操作WFD？"><a href="#应用层如何操作WFD？" class="headerlink" title="应用层如何操作WFD？"></a>应用层如何操作WFD？</h2><p>连接Miracast设备<br>API<br>import android.hardware.display.DisplayManager;</p><p>mDisplayManager = (DisplayManager) getSystemService(Context.DISPLAY_SERVICE);</p><p>mDisplayManager.connectWifiDisplay(String deviceMacAddress);</p><p>备注<br>（1）隐藏接口，可以通过反射调用。<br>权限<br>android.permission.CONFIGURE_WIFI_DISPLAY</p><p>断开Miracast设备<br>API<br>import android.hardware.display.DisplayManager;</p><p>mDisplayManager = (DisplayManager) getSystemService(Context.DISPLAY_SERVICE);</p><p>mDisplayManager.disconnectWifiDisplay();</p><p>备注<br>（1）隐藏接口，可以通过反射调用<br>扫描Miracast设备<br>API<br>import android.hardware.display.DisplayManager;</p><p>mDisplayManager = (DisplayManager) getSystemService(Context.DISPLAY_SERVICE);</p><p>mDisplayManager.startWifiDisplayScan();</p><p>备注<br>（1）隐藏接口，可以通过反射调用。<br>权限<br>android.permission.CONFIGURE_WIFI_DISPLAY<br>举个milink中的使用例子</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * scan wifi display while we can connect</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">startWifiDisplayScan</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (<span class="keyword">null</span> == mDisplayManager) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> ReflectUtil.callObjectMethod(mDisplayManager, <span class="string">"startWifiDisplayScan"</span>) == <span class="keyword">null</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里用的是反射调用</p><h2 id="芯片商在谷歌基础上的定制化"><a href="#芯片商在谷歌基础上的定制化" class="headerlink" title="芯片商在谷歌基础上的定制化"></a>芯片商在谷歌基础上的定制化</h2><h2 id="高通WFD"><a href="#高通WFD" class="headerlink" title="高通WFD"></a>高通WFD</h2><p>With Android JB MR1, Google released a WFD solution called Remote Display.<br> Google WFD supports AVC, LPCM, and AAC codecs along with HDCP encryption, but lacks support for content protection. </p><p> It is available to applications as an external WFD using Presentation, MediaRouter, and DisplayManager APIs. </p><p> When compared to the QTI-based Miracast solution, it lacks content protection support and has low performance and higher power consumption numbers. </p><p> QTI created a wrapper to launch the QTI-based Miracast solution using Android APIs; this provides an enhanced Miracast solution to third-party vendors and OEMs who would like to use the Presentation API for Miracast</p><h2 id="WFD的应用场景"><a href="#WFD的应用场景" class="headerlink" title="WFD的应用场景"></a>WFD的应用场景</h2><h1 id="高通WFD代码结构"><a href="#高通WFD代码结构" class="headerlink" title="高通WFD代码结构"></a>高通WFD代码结构</h1><p>SessionManagerService<br>vendor/qcom/proprietary/commonsys/wfd/wdsm/service/src/com/qualcomm/wfd/service/<br>提供了很多的接口，诸如：</p><h1 id="RTSP协议"><a href="#RTSP协议" class="headerlink" title="RTSP协议"></a>RTSP协议</h1><h1 id="WFD代码连接流程"><a href="#WFD代码连接流程" class="headerlink" title="WFD代码连接流程"></a>WFD代码连接流程</h1><h1 id="M-Message消息"><a href="#M-Message消息" class="headerlink" title="M-Message消息"></a>M-Message消息</h1><h1 id="P2P以及RTSP的的建立"><a href="#P2P以及RTSP的的建立" class="headerlink" title="P2P以及RTSP的的建立"></a>P2P以及RTSP的的建立</h1><h2 id="p2p的建立"><a href="#p2p的建立" class="headerlink" title="p2p的建立"></a>p2p的建立</h2><h2 id="RTSP的建立"><a href="#RTSP的建立" class="headerlink" title="RTSP的建立"></a>RTSP的建立</h2><h1 id="WFD整体架构-source"><a href="#WFD整体架构-source" class="headerlink" title="WFD整体架构(source)"></a>WFD整体架构(source)</h1><h1 id="WFD常见问题的debug策略"><a href="#WFD常见问题的debug策略" class="headerlink" title="WFD常见问题的debug策略"></a>WFD常见问题的debug策略</h1><h2 id="Wifi-Display-Miracast分析一般需要的日志"><a href="#Wifi-Display-Miracast分析一般需要的日志" class="headerlink" title="Wifi-Display/Miracast分析一般需要的日志"></a>Wifi-Display/Miracast分析一般需要的日志</h2><p>前提条件：root版本，因为有些命令如关selinux这些命令需要root权限</p><h3 id="高通平台"><a href="#高通平台" class="headerlink" title="高通平台"></a>高通平台</h3><p>使能所有WFD日志的开关</p><ol><li>Android N 以及更早的版本<br>创建一个文件名为mmosal_logmask.cfg，内容如下<br><start><br>LOGMASK = 6013:63<br>LOGMASK = 6015:63<end></end></start></li></ol><p>这个文件建议保存在本地，后续方便提供给测试或者自己调试</p><p> push mmosal_logmask.cfg这个文件到 /data/ folder 或者 /data/misc/media/ 目录下, 执行如下命令<br> adb root<br> adb remount<br> adb push mmosal_logmask.cfg /data/<br> adb push mmosal_logmask.cfg /data/misc/media/<br> adb shell setenforce 0</p><ol start="2"><li><p>Android O 版本<br>adb shell setprop mmosal.debug.config 6015:63:6013:63</p></li><li><p>Android P 版本<br>adb shell setprop vendor.debug.mmosal.config 6015:63:6013:63</p></li><li><p>Android Q 版本<br>push  mmosal_logmask.cfg这个文件到 /data/ 目录 或者 /data/misc/media/ folder 或者 /data/vendor/，索性都push了<br>adb root<br>adb remount<br>adb push mmosal_logmask.cfg /data/<br>adb push mmosal_logmask.cfg data/misc/media/<br>adb push mmosal_logmask.cfg  /data/vendor/<br>adb shell setenforce 0</p></li></ol><p>打开延迟分析属性来判断延迟值<br>对于 WFD performance 问题, 需要打开延迟分析属性来判断延迟值<br>Android O<br>adb shell setprop persist.debug.wfd.profile 1</p><p>Android P/Q<br>adb shell setprop persist.vendor.debug.wfd.profile 1</p><p>获取 TCP dump，这一步主要用来分析丢包率以及建立RTSP过程中的问题<br>1.adb shell</p><ol start="2"><li>tcpdump -i wlan0 -s 0 -w /data/tcpdump.pcap</li></ol><h3 id="联发科平台"><a href="#联发科平台" class="headerlink" title="联发科平台"></a>联发科平台</h3><p>WFD卡顿延迟问题<br> 1.当发现有延迟或者卡顿，可以看是否有如下LOG：<br>212887 07-05 11:13:53.018936 582 24850 I MtkNetworkSession: [WFD_P][video][dummy=0]ts=7663475,in 7663545,out 7664846,LatencyF 91,send 1300,LatencyT 1392<br>212888 07-05 11:13:53.019069 582 24850 I MtkNetworkSession: [WFD_P][audo][dummy=0]ts=7663476,in 7663546,out 7664846,LatencyF 7,send 1300,LatencyT 1307</p><p>//如下的时间单位都是毫秒<br>LatencyF 91 //编码打包的延迟时间<br>send 1300 //发送的延迟时间<br>LatencyT 1392 //总的延迟</p><p>2.假如send 时间比较长（一般需要平均1000/25FPS = 40毫秒以内才能保证不会卡顿）那么卡顿是正常现象，一般没办法提升，比如网络原因，如下LOG（ link_score小于70），说明是网络信号不好卡顿延迟：<br>39313 07-05 11:13:50.521 <6>[ 7662.347991] (1)[1261:tx_thread][wlan]nicCmdEventQueryStaStatistics:(P2P INFO) link_score=11, rssi=78, rate=81, threshold_cnt=2780,。</6></p><p>3.假如是LatencyF 太长，请帮忙设置如下property并抓LOG复现（需要提供mtklog和netlog）。<br>  adb root<br>  adb shell setenforce 0<br>  //Android O版本以及之前的版本<br>  adb shell setprop mtk.omx.enable.venc.log 1<br>  //Android P版本<br>  adb shell setprop vendor.mtk.omx.enable.venc.log 2</p><h2 id="如何分析丢包率"><a href="#如何分析丢包率" class="headerlink" title="如何分析丢包率"></a>如何分析丢包率</h2><h2 id="miracast连接超时问题分析"><a href="#miracast连接超时问题分析" class="headerlink" title="miracast连接超时问题分析"></a>miracast连接超时问题分析</h2><h2 id="sink端显示问题一般处理策略"><a href="#sink端显示问题一般处理策略" class="headerlink" title="sink端显示问题一般处理策略"></a>sink端显示问题一般处理策略</h2><h3 id="播放卡顿的厘清方向-source"><a href="#播放卡顿的厘清方向-source" class="headerlink" title="播放卡顿的厘清方向(source)"></a>播放卡顿的厘清方向(source)</h3><h3 id="播放卡顿的厘清方向-sink"><a href="#播放卡顿的厘清方向-sink" class="headerlink" title="播放卡顿的厘清方向(sink)"></a>播放卡顿的厘清方向(sink)</h3><p>1 在测试之前，需要先在屏蔽室中测试手机的吞吐量，看看是否正常。</p><p>2  在测试之前也要先确保硬件没有问题，比如接收灵敏度，EVM，天线效能等硬件因素要是ok的。</p><p>3  测试时首先选择一个比较干净的环境进行测试。</p><p>4  使用sniffer 设备在全信道上扫描，看看周围AP在各信道上的分布</p><p>5  在测试时，最好是选择比较空闲的信道进行测试，可以这样设置：先设置AP的信道为空闲信道，然后手机连接AP，手机再连接dongle，断开AP，此时WFD的连接就处于空闲信道了。</p><p>6  如果一定要在比较繁忙的信道上测试，首先要在这个信道上使用iperf打吞吐量，如果数据可以稳定在15Mbps以上，就可以进行测试。</p><p>7  测试时，请同时拿对比机进行测试，如果遇到卡顿现象，请换一只手机进行测试，也可以再测试一次此时的吞吐量，看看是否有变。</p><p>8  测试时，可以在空闲的时段进行测试，比如下班后，或者周末的时间等</p><p>若只是SINK端卡顿，通常的原因有：<br>1.mdp做resize和rotate慢<br>2.encoder做视频编码慢<br>3.ANetworksession调用socket接口将已打好包的rtp a\v data发送有延迟<br>4.network wifi环境问题<br>5.SINK端本身拆包解码慢</p><p>逆向分析比较容易快速厘清问题，贵司可以先通过mainlog和netlog快速厘清是否是网络或者SINK端本身问题。<br>首先请通过mtklogger apk，勾选moblie log和net log，然后开始复现问题，抓取分析资料.<br>再通过netlog导出SOURCE发送给SINK端的rtp数据，并通过wireshark将rtp包生成ts文件,直接在PC上查看播放视频（可以用vlc视频播放器直接打开），查看视频播放是否有卡顿现象。<br>若视频本身在PC上播放卡顿，请提交eservice，并附带mtklog（mobile log&amp; net log）等文件；<br>若视频本身在PC上播放不卡顿，则surface-&gt;mdp-&gt;encoder-&gt;ANetworksession\socket这一路正常，推荐贵司做下面测试：<br>1）用对比机测试看是否也有同样问题；<br>2）可以把附件视频ts文件直接通过usb的方式，在TV上播放，若播放卡顿，则是5.SINK端本身拆包解码慢；<br>3）测试当前wifi网络环境，在纯净wifi网络环境下再进行测试。<br>若还没有找到原因，请提交eservice，说明贵司分析现状以及测试实验结果，并附带mtklog（mobile log&amp; net log）等文件。</p><p>通常网络不稳定导致的sink端卡顿会有下面log<br>1)link_score不稳定等于100<br>05-31 14:01:09.326144 1238 2086 D WifiP2pService: link_score=10<br>05-31 14:01:11.329835 1238 2086 D WifiP2pService: link_score=8<br>05-31 14:01:13.331112 1238 2086 D WifiP2pService: link_score=10<br>05-31 14:01:15.332513 1238 2086 D WifiP2pService: link_score=10<br>~<br>05-31 14:02:31.387187 1238 2086 D WifiP2pService: link_score=71<br>05-31 14:02:33.391052 1238 2086 D WifiP2pService: link_score=58<br>05-31 14:02:35.390564 1238 2086 D WifiP2pService: link_score=73<br>05-31 14:02:37.393885 1238 2086 D WifiP2pService: link_score=54</p><p>2)Netowrksession打印出来send cost时间较长<br>05-31 14:01:35.820162 413 10936 I NetworkSession: [WFD_P][audo][dummy=0]ts=13041028 ms,in 13041053 ms,out 13044779 ms, mLatencyF 24 ms,send cost 3725 ms,LatencyT 3750 ms<br>05-31 14:01:35.820302 413 10936 I NetworkSession: [WFD_P][audo][dummy=0]ts=13041049 ms,in 13041054 ms,out 13044779 ms, mLatencyF 4 ms,send cost 3725 ms,LatencyT 3729 ms</p><h3 id="高通平台的花屏问题一般分析方向"><a href="#高通平台的花屏问题一般分析方向" class="headerlink" title="高通平台的花屏问题一般分析方向"></a>高通平台的花屏问题一般分析方向</h3><h3 id="MTK平台的花屏问题一般分析方向"><a href="#MTK平台的花屏问题一般分析方向" class="headerlink" title="MTK平台的花屏问题一般分析方向"></a>MTK平台的花屏问题一般分析方向</h3><p>参见：[FAQ21608] WFD图像花屏问题</p><p>step1: 用wireshark打开netlog，并过滤出RTP包，分析丢包率</p><p>step2: 发现了丢包，那么说明花屏是正常的，假如仍然要分析问题，可以去搜索kernel_log里面的link_score关键字。如果出现如下LOG（ link_score小于70），说明是网络信号不好导致丢帧：<br>39313 07-05 11:13:50.521 <6>[ 7662.347991] (1)[1261:tx_thread][wlan]nicCmdEventQueryStaStatistics:(P2P INFO) link_score=11, rssi=78, rate=81, threshold_cnt=2780,</6></p><p>step3:如果发现没有丢包，但是出现了花屏。可以在如下界面把ts数据dump出来，然后拿PC端的播放器播放</p><p>step4:如果发现播放器播放是OK的，那么说明是TV或者其他显示设备的问题，跟平台无关，亲自行去找TV厂商沟通</p><p>step5:如果发现播放有问题，请帮忙提供mtklog，且需要打开netlog</p><h1 id="WFD几个典型案例"><a href="#WFD几个典型案例" class="headerlink" title="WFD几个典型案例"></a>WFD几个典型案例</h1><p>参考了：</p><p><a href="https://online.mediatek.com/FAQ#/SW/FAQ21609" target="_blank" rel="noopener">https://online.mediatek.com/FAQ#/SW/FAQ21609</a><br><a href="https://online.mediatek.com/FAQ#/SW/FAQ21608" target="_blank" rel="noopener">https://online.mediatek.com/FAQ#/SW/FAQ21608</a><br><a href="https://online.mediatek.com/FAQ#/SW/FAQ08527" target="_blank" rel="noopener">https://online.mediatek.com/FAQ#/SW/FAQ08527</a><br><a href="https://online.mediatek.com/FAQ#/SW/FAQ21602" target="_blank" rel="noopener">https://online.mediatek.com/FAQ#/SW/FAQ21602</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;本文只讨论miracast，对应的即是设置中投屏的方式，其他视频或者相册中走的是另外一套DLNA协议，不是实时的，还有一些三方应用如腾讯视频爱奇艺是自己搞了一套dlna，DLNA不在本文讨论范围内&lt;/p&gt;
&lt;h1 id=&quot;WFD扫盲&quot;&gt;&lt;a href=&quot;#WFD扫盲&quot; cl
      
    
    </summary>
    
      <category term="WFD" scheme="http://lihaizhou.top/categories/WFD/"/>
    
    
  </entry>
  
</feed>
