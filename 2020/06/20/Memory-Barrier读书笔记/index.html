<!DOCTYPE html>



  


<html class="theme-next gemini use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">



  
  
    
    
  <script src="/lib/pace/pace.min.js?v=1.0.2"></script>
  <link href="/lib/pace/pace-theme-minimal.min.css?v=1.0.2" rel="stylesheet">







<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT" />





  <link rel="alternate" href="/atom.xml" title="李海洲" type="application/atom+xml" />






<meta name="description" content="本篇文章开始之前需要了解一些背景知识 Cache Memory我们都知道程序是运行在 RAM之中，RAM 就是我们常说的DDR（例如 DDR3、DDR4等），我们称之为main memory（主存）当我们需要运行一个进程的时候，首先会从Flash设备（例如，eMMC、UFS等）中将可执行程序load到main memory中，然后开始执行。 在CPU内部存在一堆的通用寄存器（register），如">
<meta property="og:type" content="article">
<meta property="og:title" content="内存屏障">
<meta property="og:url" content="http://lihaizhou.top/2020/06/20/Memory-Barrier读书笔记/index.html">
<meta property="og:site_name" content="李海洲">
<meta property="og:description" content="本篇文章开始之前需要了解一些背景知识 Cache Memory我们都知道程序是运行在 RAM之中，RAM 就是我们常说的DDR（例如 DDR3、DDR4等），我们称之为main memory（主存）当我们需要运行一个进程的时候，首先会从Flash设备（例如，eMMC、UFS等）中将可执行程序load到main memory中，然后开始执行。 在CPU内部存在一堆的通用寄存器（register），如">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="https://raw.githubusercontent.com/hellolihaizhou/saveImg/master/memory-barrier01.png">
<meta property="og:image" content="https://raw.githubusercontent.com/hellolihaizhou/saveImg/master/memory-barrier02.gif">
<meta property="og:image" content="https://raw.githubusercontent.com/hellolihaizhou/saveImg/master/memory-barrier03.png">
<meta property="og:image" content="https://raw.githubusercontent.com/hellolihaizhou/saveImg/master/memory-barrier04.png">
<meta property="og:image" content="https://raw.githubusercontent.com/hellolihaizhou/saveImg/master/memory-barrier05.png">
<meta property="og:image" content="https://raw.githubusercontent.com/hellolihaizhou/saveImg/master/memory-barrier06.png">
<meta property="og:image" content="https://raw.githubusercontent.com/hellolihaizhou/saveImg/master/memory-barrier07.png">
<meta property="og:updated_time" content="2020-06-21T08:22:31.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="内存屏障">
<meta name="twitter:description" content="本篇文章开始之前需要了解一些背景知识 Cache Memory我们都知道程序是运行在 RAM之中，RAM 就是我们常说的DDR（例如 DDR3、DDR4等），我们称之为main memory（主存）当我们需要运行一个进程的时候，首先会从Flash设备（例如，eMMC、UFS等）中将可执行程序load到main memory中，然后开始执行。 在CPU内部存在一堆的通用寄存器（register），如">
<meta name="twitter:image" content="https://raw.githubusercontent.com/hellolihaizhou/saveImg/master/memory-barrier01.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://lihaizhou.top/2020/06/20/Memory-Barrier读书笔记/"/>





  <title>内存屏障 | 李海洲</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>
	
	<!--<a href="https://github.com/hellolihaizhou" class="github-corner" aria-label="View source on Github"><svg width="80" height="80" viewBox="0 0 250 250" style="fill:#151513; color:#fff; position: absolute; top: 0; border: 0; right: 0;" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><style>.github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px){.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}</style>-->
	
    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">李海洲</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于我
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off"
             placeholder="搜索..." spellcheck="false"
             type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://lihaizhou.top/2020/06/20/Memory-Barrier读书笔记/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Steven Lee">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/background.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="李海洲">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">内存屏障</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-06-20T15:56:03+08:00">
                2020-06-20
              </time>
            

            

            
  	    
            <i class="fa fa-thumb-tack" style="color: #EB6D39"></i>
            <font color=EB6D39>置顶</font>
            <span class="post-meta-divider">|</span>
            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Linux/" itemprop="url" rel="index">
                    <span itemprop="name">Linux</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2020/06/20/Memory-Barrier读书笔记/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count valine-comment-count" data-xid="/2020/06/20/Memory-Barrier读书笔记/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  9,149
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  37
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>本篇文章开始之前需要了解一些背景知识</p>
<h1 id="Cache-Memory"><a href="#Cache-Memory" class="headerlink" title="Cache Memory"></a>Cache Memory</h1><p>我们都知道程序是运行在 RAM之中，RAM 就是我们常说的DDR（例如 DDR3、DDR4等），我们称之为main memory（主存）当我们需要运行一个进程的时候，首先会从Flash设备（例如，eMMC、UFS等）中将可执行程序load到main memory中，然后开始执行。</p>
<p>在CPU内部存在一堆的通用寄存器（register），如果CPU需要将一个变量（假设地址是A）加1，一般分为以下3个步骤</p>
<ol>
<li>CPU 从主存中读取地址A的数据到内部通用寄存器 x0（ARM64架构的通用寄存器之一）</li>
<li>通用寄存器 x0 加1</li>
<li>CPU 将通用寄存器 x0 的值写入主存</li>
</ol>
<p>但是存在一个问题，CPU通用寄存器的速度和主存之间存在着太大的差异<br>从这个网址<a href="https://gist.github.com/jboner/2841832" target="_blank" rel="noopener">https://gist.github.com/jboner/2841832</a> 摘了一段数据<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">Latency Comparison <span class="title">Numbers</span> <span class="params">(~<span class="number">2012</span>)</span></span></span><br><span class="line"><span class="function">----------------------------------</span></span><br><span class="line"><span class="function">L1 cache reference                           0.5 ns</span></span><br><span class="line"><span class="function">Branch mispredict                            5   ns</span></span><br><span class="line"><span class="function">L2 cache reference                           7   ns                      14x L1 cache</span></span><br><span class="line"><span class="function">Mutex lock/unlock                           25   ns</span></span><br><span class="line"><span class="function">Main memory reference                      100   ns                      20x L2 cache, 200x L1 cache</span></span><br><span class="line"><span class="function">Compress 1K bytes with Zippy             3,000   ns        3 us</span></span><br><span class="line"><span class="function">Send 1K bytes over 1 Gbps network       10,000   ns       10 us</span></span><br><span class="line"><span class="function">Read 4K randomly from SSD*             150,000   ns      150 us          ~1GB/sec SSD</span></span><br><span class="line"><span class="function">Read 1 MB sequentially from memory     250,000   ns      250 us</span></span><br><span class="line"><span class="function">Round trip within same datacenter      500,000   ns      500 us</span></span><br><span class="line"><span class="function">Read 1 MB sequentially from SSD*     1,000,000   ns    1,000 us    1 ms  ~1GB/sec SSD, 4X memory</span></span><br><span class="line"><span class="function">Disk seek                           10,000,000   ns   10,000 us   10 ms  20x datacenter roundtrip</span></span><br><span class="line"><span class="function">Read 1 MB sequentially from disk    20,000,000   ns   20,000 us   20 ms  80x memory, 20X SSD</span></span><br><span class="line"><span class="function">Send packet CA-&gt;Netherlands-&gt;CA    150,000,000   ns  150,000 us  150 ms</span></span><br></pre></td></tr></table></figure></p>
<p>这里没有列出寄存器速度，看到L1 cache是0.5ns，可以肯定的是寄存器一定是低于1ns，Main memory是100ns，这里的数据仅供参考<br>所以上面的从主存读取数值三个步骤中的第一和第三步实际上速度很慢相对于寄存器而言</p>
<p>当CPU试图从主存中load/store 操作时，由于主存的速度限制，CPU不得不等待这漫长的65ns时间。如果我们可以提升主存的速度，那么系统将会获得很大的性能提升。如今的DDR存储设备，动不动就是几个GB，容量很大。如果我们采用更快材料制作更快速度的主存，并且拥有几乎差不多的容量。其成本将会大幅度上升。<br>我们试图提升主存的速度和容量，又期望其成本很低，这就有点难为人了。因此，我们有一种折中的方法，那就是制作一块速度极快但是容量极小的存储设备。那么其成本也不会太高。这块存储设备我们称之为cache memory。在硬件上，我们将cache放置在CPU和主存之间，作为主存数据的缓存。当CPU试图从主存中load/store数据的时候， CPU会首先从cache中查找对应地址的数据是否缓存在cache 中。如果其数据缓存在cache中，直接从cache中拿到数据并返回给CPU。<br><strong>CPU和主存之间直接数据传输的方式转变成CPU和cache之间直接数据传输。cache负责和主存之间数据传输。</strong></p>
<p>当存在cache的时候，以上程序如何运行的例子的流程将会变成如下：<br><img src="https://raw.githubusercontent.com/hellolihaizhou/saveImg/master/memory-barrier01.png" alt=""></p>
<p>cahe的速度在一定程度上同样影响着系统的性能。一般情况cache的速度可以达到1ns，几乎可以和CPU寄存器速度媲美。但是，这就满足人们对性能的追求了吗？并没有。当cache中没有缓存我们想要的数据的时候，依然需要漫长的等待从主存中load数据。为了进一步提升性能，引入多级cache。前面提到的cache，称之为L1 cache（第一级cache）。<br>我们在L1 cache 后面连接L2 cache，在L2 cache 和主存之间连接L3 cache。等级越高，速度越慢，容量越大。但是速度相比较主存而言，依然很快</p>
<p>多级cache不是本文重点，详细可参考如下两篇文章，写的比较详细<br><a href="http://www.wowotech.net/memory_management/458.html" target="_blank" rel="noopener">浅谈Cache Memory</a><br><a href="https://zhuanlan.zhihu.com/cpu-cache" target="_blank" rel="noopener">高速缓存与一致性</a></p>
<h2 id="Cacheline"><a href="#Cacheline" class="headerlink" title="Cacheline"></a>Cacheline</h2><p>本文后续会涉及到一个名词Cacheline，cache的大小称之为cahe size，代表cache可以缓存最大数据的大小。<br>我们将cache平均分成相等的很多块，每一个块大小称之为cache line，其大小是cache line size。例如一个64 Bytes大小的cache<br>如果我们将64 Bytes平均分成64块，那么cache line就是1字节，总共64行cache line。如果我们将64 Bytes平均分成8块，那么cache line就是8字节，总共8行cache line<br>有一点需要注意，cache line是cache和主存之间数据传输的最小单位。什么意思呢？当CPU试图load一个字节数据的时候，如果cache缺失，那么cache控制器会从主存中一次性的load cache line大小的数据到cache中。</p>
<p>例如，cache line大小是8字节。CPU即使读取一个byte，在cache缺失后，cache会从主存中load 8字节填充整个cache line，至于原因可以参见这篇文章:<br><a href="http://www.wowotech.net/memory_management/458.html" target="_blank" rel="noopener">浅谈Cache Memory</a></p>
<p>有了前面的基础知识的认知，不难理解下面这个极简的抽象CPU架构图<br><img src="https://raw.githubusercontent.com/hellolihaizhou/saveImg/master/memory-barrier02.gif" alt=""></p>
<h1 id="缓存一致性"><a href="#缓存一致性" class="headerlink" title="缓存一致性"></a>缓存一致性</h1><p>考虑到多线程读写环境中，不免会有个疑问，如果一个数据是多个cpu都共享，其中一个修改了是不是要想办法使得其他cpu也能更新<br>一个cpu去读取一个数值时，怎么确定是最新的呢？说到底就是要保证在使用cache后如何确保各 CPU 看到的数据是一致的<br>这个就引出另外一个名词“cache-coherence protocol”即缓存一致性协议<br>其中，MESI protocol 是一个基本版，从 MESI protocol 可以了解 CPU 之间如何维持看到一致的资料，可以参见MESI的维基定义:   <a href="https://zh.wikipedia.org/wiki/MESI%E5%8D%8F%E8%AE%AE" target="_blank" rel="noopener">MESI协议</a></p>
<p>这里摘取英文文档中的对于MESI拆解开来的四种状态的解释<br><code>A line in the “modified” state has been subject to a recent memory store from the corresponding CPU, and the corresponding memory is guaranteed not to appear in any other CPU’s cache. Cache lines in the “modified”state can thus be said to be “owned” by the CPU. Because this cache holds the only up-to-date copy of the data, this
cache is ultimately responsible for either writing it back to memory or handing it off to some other cache, and must do so before reusing this line to hold other data.</code><br>处于modified状态的cacheline说明近期有过来自对应cpu的写操作，同时也说明该该数据不会存在其他cpu对应的cache中。因此，处于modified状态的cacheline也可以说是被该CPU独占。而又因为只有该CPU的cache保存了最新的数据（最终的memory中都没有更新），所以，该cache需要对该数据负责到底。例如根据请求，该cache将数据及其控制权传递到其他cache中，或者cache需要负责将数据写回到memory中，而这些操作都需要在reuse该cache line之前完成。<br><code>The “exclusive” state is very similar to the “modified”state, the single exception being that the cache line has not yet been modified by the corresponding CPU, which in turn means that the copy of the cache line’s data that resides in memory is up-to-date. However, since the CPU can store to this line at any time, without consulting other CPUs, a line in the “exclusive” state can still be said to be owned by the corresponding CPU. That said, because the corresponding value in memory is up to date, this cache can discard this data without writing it back to memory or handing it off to some other CPU.</code><br>exclusive状态和modified状态非常类似，唯一的区别是对应CPU还没有修改cacheline中的数据，也正因为还没有修改数据，因此memory中对应的data也是最新的。在exclusive状态下，cpu也可以不通知其他CPU cache而直接对cacheline进行操作，因此，exclusive状态也可以被认为是被该CPU独占。由于memory中的数据和cacheline中的数据都是最新的，因此，cpu不需对exclusive状态的cacheline执行写回的操作或者将数据以及归属权转交其他cpu cache，而直接reuse该cacheline（将cacheine中的数据丢弃，用作他用）<br><code>A line in the “shared” state might be replicated in at least one other CPU’s cache, so that this CPU is not permitted to store to the line without first consulting with other CPUs. As with the “exclusive” state, because the
corresponding value in memory is up to date, this cache can discard this data without writing it back to memory or handing it off to some other CPU.</code><br>处于share状态的cacheline，其数据可能在一个或者多个CPU cache中，因此，处于这种状态的cache line，CPU不能直接修改cacheline的数据，而是需要首先和其他CPU cache进行沟通。和exclusive状态类似，处于share状态的cacheline对应的memory中的数据也是最新的，因此，cpu也可以直接丢弃cacheline中的数据而不必将其转交给其他CPU cache或者写回到memory中。<br><code>A line in the “invalid” state is empty, in other words, it holds no data. When new data enters the cache, it is placed into a cache line that was in the “invalid” state if possible. This approach is preferred because replacing a line in any other state could result in an expensive cache miss should the replaced line be referenced in the future.</code><br>处于invalid状态的cacheline是空的，没有数据。当新的数据要进入cache的时候，优选状态是invalid的cacheline，之所以如此是因为如果选中其他状态的cacheline，则说明需要替换cacheline数据，而未来如果再次访问这个被替换掉的cacheline数据的时候将遇到开销非常大的cache miss  </p>
<font color="red"> 个人理解:<br>1. 对于modified状态的cacheline，别的cpu如果需要其中的数据，必须要写回到memory或者转移<br>2. exclusive可以理解为是modified的轻量版，exclusive状态的cacheline数据此时还没有被cpu修改，也就是说它的数据和memory中是一致的，当别的cpu需要状态是exclusive的cacheline数据时，可以直接提供数据不需要写回到memory<br>3. share状态的cacheline不能直接被修改，如果一个cpu需要对这个cacheline进行修改了，需要先通知其他cpu让他们将各自对应的cacheline置为invalid，然后再切换cacheline的状态到exclusive，再然后就是M状态<br>4. invalid状态的cacheline之前可能是有数据的，比如之前是shared状态，后来其他cpu要修改这个cacheline了，就发通知过来了要求置为invalid的，不然读取出来的就是错误的<br><br> </font>

<p>有一个MESI动画的网址，可以模拟各个cacheline的状态切换，比起文字描述来讲更好理解，可以不断的模拟测试，对理解MESI很有帮助<br><a href="https://www.scss.tcd.ie/Jeremy.Jones/VivioJS/caches/MESIHelp.htm" target="_blank" rel="noopener">VivioJS - Interactive Reversible E-Learning Animations for the WWW</a></p>
<p>比如当前状态<br><img src="https://raw.githubusercontent.com/hellolihaizhou/saveImg/master/memory-barrier03.png" alt=""></p>
<font color="red"><br>个人理解添加<br>此时CPU0上a1数据对应的cacheline此时的状态是M状态，可以看到此时的数值是11，比memory要新，其他两个cpu1，cpu2上的a1对应的cacheline是invalid状态。如果此时cpu2上对a1进行写值加1，会是什么样子的呢？<br>根据上面的理论知识，此时应该会通过总线通知cpu0让其写入到memory中，然后cpu2才能读取到最新的值此时再进行修改此时数值应该是12并将状态置为E并且写回memory，此时CPU0上的a1对应cacheline状态理论上应该是invalid。<br></font><br>实际的cpu2对a1加1后效果图如下：<br><img src="https://raw.githubusercontent.com/hellolihaizhou/saveImg/master/memory-barrier04.png" alt=""><br><font color="red"> 个人理解添加<br>此时如果对cpu2的cacheline进行写加1，cacheline状态会切换到M状态，如果一直写，数值一直增加一直是M状态，其他cpu无变化。因为此时M是最新的，只有其他cpu比如此时cpu1需要读取a1的值，这个时候cpu2会将这个值写回到memory并且此时cpu1和cpu2上a1对应的cacheline状态都是S。<br>如果这个时候，对cpu2的a1进行写操作呢？其状态会切换到E，其他cpu对应的a1-cacheline都切到invalid<br>介绍完MESI后，我们知道有了MESI protocol，任何一个CPU 要写入资料前，都要先确保其它CPU 已invalid 同一位置的cache 后(希望写入的CPU 广播invalidate，其它CPU 回invalidate ack)， 才能写资料到自己的cache，并在稍后补写回memory。<br></font><br>这个设计确保资料的一致性，不用担心同一时间同一个位置的资料会有不同的值，但是代价是写入 cache 的速度会有点慢，让 CPU 闲置，下图中的stall就是cpu等待的时长<br><img src="https://raw.githubusercontent.com/hellolihaizhou/saveImg/master/memory-barrier05.png" alt=""><br><br><font color="red">  个人理解添加<br>想象一下这个场景：<br><em> CPU 0 打算写入值到位置 X，CPU 1 的 cache 有 X 的值。因为缓存一致性的缘故，这个时候CPU0给CPU1发送一个invalid的广播告知其需要将其对应数值置于无效
</em> 这个时候呢cpu0就开始傻乎乎的等 CPU 1 回 invalidate ack，但是此时CPU 1 的 cache 可能太忙而拖慢了回覆时间 (比方同时从 cache 大量的读写资料，或是短时间收到大量 invalidate ack)。<br>这样就导致了CPU0白白耗费时间在等待上，这对于宝贵的cpu资源是一种很大的浪费，其实没必要等待这么长的时间，毕竟物理CPU 1中的cacheline保存有什么样子的数据，其实都没有意义，这个值都会被CPU 0新写入的值覆盖的，所以能不能不等呢？这也就引出了另外一个名词StoreBuffer，还有另外一个名词对应刷新的Invalidate Queue<br></font> 

<h2 id="Store-Buffer-amp-Invalidate-Queue"><a href="#Store-Buffer-amp-Invalidate-Queue" class="headerlink" title="Store Buffer &amp; Invalidate Queue"></a>Store Buffer &amp; Invalidate Queue</h2><p>在CPU和cache之间增加store buffer这个HW block</p>
<font color="red">  个人理解添加<br>1. CPU 0 不等 invalidate ack：先写入 store buffer，然后继续作事。之后收到 invalidate ack 再更新 cache 的状态。因为最新的资料可能存在 store buffer，CPU 读资料的顺序变成 store buffer → cache → memory。<br>2. CPU 1 立即回 invalidate ack：收到 invalidate 时，记录到 invalidate queue 里，先回 invalidate ack，稍后再处理 invalidate。<br>3. 为啥有了store buffer后还会冒出来一个invalidate queue，因为 store buffer 很小，store buffer 满的时候，CPU 0 还是得等 invalidate ack，所以加上 invalidate queue，双管齐下减少 CPU 0 等待时间<br>这里还有一个细节后面会提到，如果有数据加了写内存屏障的话，加入storebuffer，其后面的写操作不管有没有写屏障都要加到storebuffer中，这就造成了storebuffer更容易满了，一旦满了又要开始等ack了，这就引入了<br>invalidate queue，后面还会继续讲它的作用<br>其实这里出现了一个重排序的“现象”，就是一旦某一条写指令放到storebuffer中了继续后面的指令操作，这就造成了下一条指令跑到这条指令前面执行的”假象”，这种重排序就是为了充分利用cpu的性能避免白白的浪费等待<br>CPU 为了提升效率而出现的这种”改指令”执行的顺序，只要最后結果和 single thread 预期的結果一样即可。这句话可以细品下，所以多线程的情况下需要我们研发人员自己控制<br></font>  

<p>有了StoreBuffer以及Invalidate Queue之后的cpu cache架构如下<br><img src="https://raw.githubusercontent.com/hellolihaizhou/saveImg/master/memory-barrier06.png" alt=""></p>
<p>下面摘自perfbook文档关于StoreBuffer以及Invalidate Queue的解释</p>
<p><code>These store buffers are local to a given CPU or, on systems with hardware multithreading, local to a given core. Either way, a given CPU is permitted to access only the store buffer assigned to it. For example, in Figure C.5, CPU 0 cannot access CPU 1’s store buffer and vice versa. This restriction simplifies the hardware by separating concerns: The store buffer improves performance for consecutive writes, while the responsibility for communicating among CPUs (or cores, as the case may be) is fully shouldered by the cache-coherence protocol. However, even given this restriction, there are complications that must be addressed, which are covered in the next two sections.</code></p>
<p>这些store buffer对于cpu而言是local的，如果系统是硬件多线程， 那么每一个cpu core拥有自己私有的stroe buffer，一个cpu只能访问自己私有的那个store buffer。在上图中，cpu 0不能访问cpu1的store buffer，反之亦然。之所以做这样的限制是为了模块划分（各个cpu core模块关心自己的事情，让cache系统维护自己的操作），让硬件设计变得简单一些。store buffer增加了CPU连续写的性能，同时把各个CPU之间的通信的任务交给维护cache一致性的协议。即便给每个CPU分配私有的store buffer，仍然引入了一些复杂性，我们会在下面两个小节中描述。</p>
<p><code>Unfortunately, each store buffer must be relatively small, which means that a CPU executing a modest sequence of stores can fill its store buffer (for example, if all of them result in cache misses). At that point, the CPU must once again wait for invalidations to complete in order to drain its store buffer before it can continue executing. This same situation can arise immediately after a memory barrier, when all subsequent store instructions must wait for invalidations to complete, regardless of whether or not these stores result in cache misses.</code></p>
<p>不幸的是：每个cpu的store buffer不能实现的太大，其entry的数目不会太多。当cpu以中等的频率执行store操作的时候（假设所有的store操作导致了cache miss），store buffer会很快的被填满。在这种状况下，CPU只能又进入等待状态，直到cache line完成invalidation和ack的交互之后，可以将store buffer的entry写入cacheline，从而为新的store让出空间之后，CPU才可以继续执行。这种状况也可能发生在调用了memory barrier指令之后，因为一旦store buffer中的某个entry被标记了，那么随后的store都必须等待invalidation完成，因此不管是否cache miss，这些store都必须进入store buffer。</p>
<p><code>This situation can be improved by making invalidate acknowledge messages arrive more quickly. One way of accomplishing this is to use per-CPU queues of invalidate messages, or “invalidate queues”.</code></p>
<p>引入invalidate queues可以缓解这个状况。store buffer之所以很容易被填充满，主要是其他CPU回应invalidate acknowledge比较慢，如果能够加快这个过程，让store buffer尽快进入cacheline，那么也就不会那么容易填满了。</p>
<p><code>Invalidate Queues
One reason that invalidate acknowledge messages can take so long is that they must ensure that the corresponding
cache line is actually invalidated, and this invalidation can be delayed if the cache is busy, for example, if the CPU is intensively loading and storing data, all of which resides in the cache. In addition, if a large number of invalidate messages arrive in a short time period, a given CPU might fall behind in processing them, thus possibly stalling all the other CPUs.</code></p>
<p>invalidate acknowledge不能尽快回复的主要原因是invalidate cacheline的操作没有那么快完成，特别是cache比较繁忙的时候，这时，CPU往往进行密集的loading和storing的操作，而来自其他CPU的，对本CPU local cacheline的操作需要和本CPU的密集的cache操作进行竞争，只要完成了invalidate操作之后，本CPU才会发生invalidate acknowledge。此外，如果短时间内收到大量的invalidate消息，CPU有可能跟不上处理，从而导致其他CPU不断的等待。</p>
<p><code>However, the CPU need not actually invalidate the cache line before sending the acknowledgement. It could instead queue the invalidate message with the understanding that the message will be processed before the CPU sends any further messages regarding that cache line.</code></p>
<p>然而，CPU其实不需要完成invalidate操作就可以回送acknowledgement消息，这样，就不会阻止发生invalidate请求的那个CPU进入无聊的等待状态。CPU可以buffer这些invalidate message（放入Invalidate Queues），然后直接回应acknowledgement，表示自己已经收到请求，随后会慢慢处理。当然，再慢也要有一个度，例如对a变量cacheline的invalidate处理必须在该CPU发送任何关于a变量对应cacheline的操作到bus之前完成。</p>
<p>有了Invalidate Queue的CPU，在收到invalidate消息的时候首先把它放入Invalidate Queue，同时立刻回送acknowledge 消息，无需等到该cacheline被真正invalidate之后再回应。当然，如果本CPU想要针对某个cacheline向总线发送invalidate消息的时候，那么CPU必须首先去Invalidate Queue中看看是否有相关的cacheline，如果有，那么不能立刻发送，需要等到Invalidate Queue中的cacheline被处理完之后再发送。</p>
<p><code>Placing an entry into the invalidate queue is essentially a promise by the CPU to process that entry before transmitting any MESI protocol messages regarding that cache line. As long as the corresponding data structures are not highly contended, the CPU will rarely be inconvenienced by such a promise.</code></p>
<p>一旦将一个invalidate（例如针对变量a的cacheline）消息放入CPU的Invalidate Queue，实际上该CPU就等于作出这样的承诺：在处理完该invalidate消息之前，不会发送任何相关（即针对变量a的cacheline）的MESI协议消息。只要是对该cacheline的竞争不是那么剧烈，CPU还是对这样的承诺很有信心的</p>
<p>因为多了 store buffer 和 invalidate queue，cache 之间的资料就没有完全一致了</p>
<h2 id="一个小案例"><a href="#一个小案例" class="headerlink" title="一个小案例"></a>一个小案例</h2><p>有了上面一连串理论知识的铺垫，下面看一个小例子，这个例子是老演员了，其实也是摘自perfbook中的，在查阅资料过程中发现很多博客都是用的这个图</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> a = b = <span class="number">0</span>;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">foo</span><span class="params">(<span class="keyword">void</span>)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  a = <span class="number">1</span>;</span><br><span class="line">  b = <span class="number">1</span>;</span><br><span class="line">&#125;</span><br><span class="line">  </span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">bar</span><span class="params">(<span class="keyword">void</span>)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="keyword">while</span> (b == <span class="number">0</span>) <span class="keyword">continue</span>;</span><br><span class="line">  <span class="keyword">assert</span>(a == <span class="number">1</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>考虑 CPU 0 执行 foo()， CPU 1 执行 bar()，也就是我们常说的多线程环境，假设 cache 的状态如下:<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">        a       b</span><br><span class="line">------------------------</span><br><span class="line">CPU <span class="number">0</span>:  Shared  Modified</span><br><span class="line">CPU <span class="number">1</span>:  Shared  Invalid</span><br></pre></td></tr></table></figure></p>
<p>其实可以理解为假设 a,b 初始值为 0 ，a 被 CPU0 和 CPU1 共同持有，b 被 CPU0 独占</p>
<p>试想，即便在多线程环境下，foo 和 bar 如若严格按照理想的顺序执行，是无论如何都不会出现 assert failed 的情况的。但往往事与愿违，这种看似很诡异的且有一定几率发生的 assert failed ，结合上面所说的 Store Buffer 就一点都不难理解了<br>我们来还原 assert failed 的整个过程</p>
<ol>
<li>CPU0 处理 a=1 之前发送 Invalidate 消息给 CPU1 ，并将其放入 Store Buffer ，尚未及时刷入缓存，所以这时候 cache 里a的值仍是 0；</li>
<li>CPU 0 转而处理 b=1 ，注意这里我们上面假设的是此时b 的状态已是 Modified，所以 b=1 直接被刷入缓存；</li>
<li>CPU 1 发出 Read 消息读取 b 的值，CPU 1 从 CPU 0 的 cache 读到 b = 1 ，跳出 while 语句；</li>
<li>CPU 1 发出 Read 消息读取 a 的值，发现 a 却为旧值 0，assert failed，然后收到 CPU 0 送来 “invalidate a” 的讯息，但已太迟了</li>
</ol>
<p>上面这个还原过程摘自一个台湾人写的博客&lt;從硬體觀點了解 memory barrier 的實作和效果&gt;<br>个人感觉这个描述过程不完全准确，既然已经有了Invalidate Queue，这个时候cpu1理论上是立刻给cpu0发ack的，可能由于当前要回复的ack很多，导致发送给cpu0的ack并没有达到”立刻”的效果<br>所以出现上面描述的过程也是有可能的，但是其实还有一种可能，就是读取a的时候最新值Invalidate Queue中，详细在下面的个人理解环节中  </p>
<font color="red"><br>个人理解如下<br>1. 大致流程是CPU0这个时候想要对a进行写值，发现a对应的cacheline对应的状态是S，也就是这里的cpu1上也有a的值，所以需要通知cpu1，通过总线发个消息告知cpu1进行invalid，因为有storebuffer这玩意所以直接放到storebuffer，又因为有invalidate queue的存在<br>2. 所以CPU1立刻回复了“已更新”的ack回去了，其实并没有实际更新，只是先放在了invalidate queue中待更改标记为invalid，CPU0收到这个ack后将数据回写到内存中<br>3. 此时CPU0开始了执行下一条对b写值，因为b是M状态也是说是cpu0独占的，所以直接写到缓存就完事了<br>4. 再来到cpu1这边看看，此时cpu1读取b的值，因为cpu1上没有对应的cacheline，cpu0上b对应的cacheline是M状态，所以此时cpu0会将b的值写回到memory,并且这个时候cpu1读取到的值是最新的和memory一样，此时cpu1和cpu0上b对于的cacheline状态变为S<br>5. 这个时候再看assert(a == 1);  此时CPU1读取到的数值a仍然是S状态，所以直接读取了，读取出来自然是0，因为此时并没有去invalidate queue看看有没有值，所以看到的值不是最新的，出现assert fail<br><br>如何解决这个问题呢？可以在foo函数a=1下面加一个写内存屏障，这样的话当a=1的值放到storebuffer中后，发现后面有一个写内存屏障指令，这个时候就会把后面的写指令都会顺序放到storebuffer中。另外在bar函数第二行读取a的时候需要看下invalidqueue中有没有值，有的话一定要将对应值得cacheline标记为无效，然后去读取最新值，这就引入了读内存屏障，强制标记队列中所有的值对应cacheline为无效<br></font> 


<p>上面的这个程序在实际开发中也是有可能会遇到的，于是 CPU提供了write memory barrier 以及 read memory barrier，让软件有机会避免这个问题</p>
<h2 id="write-memory-barrier"><a href="#write-memory-barrier" class="headerlink" title="write memory barrier"></a>write memory barrier</h2><p>比如在上面的 foo 方法中，a 的赋值和 b 的赋值之间加上这个write memory barrier<br>会使得 CPU 在后续变量变更写入之前，把 Store Buffer 的变更写入 flush 到缓存；CPU 要么就等待 flush 完成后写入，要么就把后续的写入变更放到 Store Buffer 中，直到 Store Buffer 数据顺序刷到缓存。<br><strong>write memory barrier 确保之前在 store buffer 里的资料会先更新到 cache，然后才能写入 barrier 之后的资料到 cache。</strong></p>
<p>假设我们在 foo() 的 a=1 和 b=1 之间插一个 write memory barrier，过程变为</p>
<ol>
<li>write memory barrier 先设 store buffer 里的资料为 “marked” (即 a=1)</li>
<li>写入 b 的时候，因为发现 store buffer 里有 marked 的栏位，所以即使 b 已处于 Modified，仍需写入 b=1 到 store buffer，不过状态是 “unmarked”</li>
<li>待收到 a 的 invalidate ack 后，cache 中 a 的状态改为 Modified，然后先写入有 marked 栏位的值到 cache，再写入 unmarked 栏位的值到 cache。</li>
</ol>
<p>这样其它 CPU 就会依序看到 a、b 更新的值了</p>
<h2 id="read-memory-barrier"><a href="#read-memory-barrier" class="headerlink" title="read memory barrier"></a>read memory barrier</h2><p>还是以上面的例子说明，假设 CPU 1 的 cache 里 a 处于 Shared。 CPU 0 已更新 a、b 到它的 cache，CPU 1 的 invalidate queue 里有 “invalidate a”，但还没处理。<br>这时 CPU 1 依序读 b、a 的值，会从 CPU 0 的 cache 读到 b=1，然后从自己的 cache 读到 a=0 (因为还没 invalidate a)。和上面的写入情况本质一样的，invalidate queue破坏了缓存一致性<br>invalidate queue是最新的，但是 a 处于 Shared，所以会从cache中直接拿，拿得是0，不是最新的<br>所以即便在foo函数给a,b分别赋值中间加上写栅栏，还是不能完全保证得到的结果是我们想要的，其实这个时候，可以猜到需要在assert之前也就是读取a之前加上一个读栅栏read memory barrier<br>目的很明确确保先清空 invalidate queue 再继续读资料。<br>在 assert(a==1) 之前插入 read memory barrier，执行顺序变成这样:</p>
<ol>
<li>CPU 1 执行 read memory barrier 时会设 invalidate queue 里的资料为 “marked”</li>
<li>CPU 1 读 cache 里 a 的值时，发现 invalidate queue 里有标记 a，于是会先执行 invalidate a 再继续读 a 的值</li>
<li>执行 invalidate a 后，就不会读自己 cache 的值，而改从 CPU 0 的 cache 读到最新的值，达到「依序读 b、a 的值」的效果</li>
</ol>
<h2 id="第二个小案例"><a href="#第二个小案例" class="headerlink" title="第二个小案例"></a>第二个小案例</h2><p>再摘一句perfbook的话，说的有点意思</p>
<p><code>Since the standard synchronization primitives preserve the illusion of ordering, your path of least resistance is to stop reading this section and simply use these primitives.
However, if you need to implement the synchronization primitives themselves, or if you are simply interested in understanding how memory ordering and memory barriers work, read on!</code></p>
<p>你也许面对CPU的这种out of order的行为有本能的抵抗，没有关系，放轻松，你的抵抗之路可以到此结束，只要你愿意使用各种同步原语来保护你程序中的共享资源，因为透过这些标准的同步原语，你看到的是一个顺序执行的世界。当然，这会引入一些小小的遗憾：你不知道底层到底是如何把“乱序”变成“有序”的。不过，实现同步原语的那些软件工程师没有这个豁免权，他们必须要深入理解memory order和memory barrier。此外，那些想要“打破沙锅问到底”以及想要“知其然知其所以然”的工程师也可以跟随我们继续。</p>
<p>再举一个例子，摘自 perfbook memory barrier（14.2章节）<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1</span> thread0(<span class="keyword">void</span>)</span><br><span class="line"><span class="number">2</span> &#123;</span><br><span class="line"><span class="number">3</span> A = <span class="number">1</span>;</span><br><span class="line"><span class="number">4</span> smp_wmb();</span><br><span class="line"><span class="number">5</span> B = <span class="number">1</span>;</span><br><span class="line"><span class="number">6</span> &#125;</span><br><span class="line"><span class="number">7</span></span><br><span class="line"><span class="number">8</span> thread1(<span class="keyword">void</span>)</span><br><span class="line"><span class="number">9</span> &#123;</span><br><span class="line"><span class="number">10</span> <span class="keyword">while</span> (B != <span class="number">1</span>)</span><br><span class="line"><span class="number">11</span> <span class="keyword">continue</span>;</span><br><span class="line"><span class="number">12</span> barrier();</span><br><span class="line"><span class="number">13</span> C = <span class="number">1</span>;</span><br><span class="line"><span class="number">14</span> &#125;</span><br><span class="line"><span class="number">15</span></span><br><span class="line"><span class="number">16</span> thread2(<span class="keyword">void</span>)</span><br><span class="line"><span class="number">17</span> &#123;</span><br><span class="line"><span class="number">18</span> <span class="keyword">while</span> (C != <span class="number">1</span>)</span><br><span class="line"><span class="number">19</span> <span class="keyword">continue</span>;</span><br><span class="line"><span class="number">20</span> barrier();</span><br><span class="line"><span class="number">21</span> <span class="keyword">assert</span>(A != <span class="number">0</span>);</span><br><span class="line"><span class="number">22</span> &#125;</span><br></pre></td></tr></table></figure></p>
<p>开始，变量A，B，C的初始值都是0。根据程序逻辑：thread0中，A先于B赋值，thread1中，程序逻辑是一直等到B变量被赋值为1之后，再给C赋值。这里，人类的直觉告诉我们，如果变量C已经被赋值为1的时候（第13行程序），A一定已经被赋值为1了。同样的，在thread2中，第21行程序的assert一定是不会被触发的。</p>
<p><code>This line of reasoning, intuitively obvious though it may be, is completely and utterly incorrect. Please note that this is not a theoretical assertion: actually running this code on real-world weakly-ordered hardware (a 1.5GHz 16-CPU POWER 5 system) resulted in the assertion firing 16 times out of 10 million runs. Clearly, anyone who produces code with explicit memory barriers should do some extreme testing – although a proof of correctness might be helpful, the strongly counter-intuitive nature of the behavior of memory barriers should in turn strongly limit one’s trust in such proofs. The requirement for extreme testing should not be taken lightly, given that a number of dirty hardware-dependent tricks were used to greatly increase the probability of failure in this run.</code></p>
<p>上一节的推理从直觉上看是对的，但是在实际的CPU上运行的结果确是完全错误的。特别需要指出的是这个结果不是理论推导得出来的，是在真实的1.5GHz 16核的POWER 5系统（该cpu的内存模型属于weakly order）上观测得到的，平均每1千万次执行会有16次在21行代码处出现assert失败。很显然，当我们撰写显式调用memory barrier的代码的时候，必须进行非常大量的实际测试。在理论上进行正确性的推导是否有意义呢？也许有帮助，但是，你知道的，在使用memory barrier的时候会发生很多和你的直觉相悖的东西，这让理论的推导变得不那么确定。别小看那些看起来愚蠢的、非常重复性的大量测试，要知道不同的CPU会使用不同的硬件设计方法，因此在memory order和memory barrier方面表现各不相同，你的程序想要在各种硬件上，每次都运行成功不是一件容易的事情。</p>
<font color="red"><br>个人理解:<br>到底发生了什么让程序在21行的assert上失败？我们一起分析一下。我们假设CPU0、CPU1和CPU2分别执行thread0、thread1和thread2<br>1. 对于thread 0，我们假设A在CPU0的local cache中，但是状态是shared，因此当执行A=1的语句的时候，不能立刻执行，需要和其他CPU cache进行沟通（发送invalidate message去其他CPU），当然，cpu不会停下其脚步，将A的新值1放入store buffer，继续执行。<br>2. smp_wmb可以mark store buffer中A值，并且阻止后续的store操作进入cache，这时候，即便B在CPU0的local cache中，B=1的赋值也不能操作到cache，而是要进入store buffer，当然状态是unmarked。前面说过，后面进cache的话是marked先进然后unmarked进，由于存在Invalidate Queue这中东西，因此，CPU 0很快就可以收到来自其他CPU的响应，这时候，CPU0可以越过write memory barrier，完成对B的赋值。此时A的状态切到M，回写到cache中，B也跟着回写到cache中了。<br>3. 因此，对于thread1，很快可以感知B的新值“1”并执行了对C变量的赋值。来到thread2，同样的，对C变量的load操作也可以感知到thread1中的赋值因此跳出while循环。<br>4. 最关键的来了，第20行的barrier这个优化屏障不能阻止CPU对A变量的访问，但是，可能由于这时CPU cache操作非常繁忙，A变量的invalidate message还在其invalidate queue中，因此load A得到了旧的值0。<br><br>当然，要修正这个问题非常简单，修改20行代码为smp_rmb即可。一旦执行了smp_rmb，就会mark invalidate queue中的entry，这时候，CPU执行后续的load操作都必须要等到Invalidate queue中的所有缓存的invalidate message（当然，状态必须是marked）被处理并体现到cache中。因此，使用smp_rmb即可以在21行的load A操作中总是获取A的新值“1”从而避免了assert fail。<br>这里有个疑问就是例子中的barrier();这玩意到底到底代表啥意思，按照作者想要表达的意思是barrier()起不到读屏障的功能，要改为smp_rmb<br></font> 

<h2 id="简要归纳"><a href="#简要归纳" class="headerlink" title="简要归纳"></a>简要归纳</h2><p>硬件为了减少读写 memory 而有 cache。有 cache 就要确保 cache 之间的资料一致 (同一时间同一位置只有一个值)。但确保 cache 资料完全一致容易让 CPU 闲置，于是有了 store buffer 和 invalidate queue 降少 CPU 闲置。代价是只保证 CPU 自己会读到自己写入的最新数据，但其它 CPU 不一定。<br><strong>为了让其它 CPU 有需要的时候也能读到最新的资料，针对 store buffer 和 invalidate queue 的副作用设计了 write/read memory barrier</strong><br>于是写程序的人在需要的时候可以用 memory barrier 确保关键的数据有依正确的顺序更新 (没保证更新的时间)。 CPU 在多数情况下仍能避免闲置。<br>到此可以了解为什么这两种操作合在一起比较符合 CPU 架构：</p>
<ul>
<li>一个 thread 「先 write X 后执行 write memory barrier」</li>
<li>另一个 thread 「先执行 read memory barrier 后 read X」</li>
</ul>
<h1 id="java内存模型"><a href="#java内存模型" class="headerlink" title="java内存模型"></a>java内存模型</h1><p>这里再谈一下java的内存模型，这个模型是抽象出来的，下面这个图网上找的也是老演员了，最初来自深入理解虚拟机一书<br><img src="https://raw.githubusercontent.com/hellolihaizhou/saveImg/master/memory-barrier07.png" alt=""></p>
<font color="red"><br>个人理解:<br>这里的java线程对应着cpu，工作内存其实是不存在的，可以简单的理解为是cpu的cache，save和load其实对应的是缓存一致性协议<br></font> 

<h2 id="JVM-barrier"><a href="#JVM-barrier" class="headerlink" title="JVM barrier"></a>JVM barrier</h2><ul>
<li>LoadLoad：两个 Load 操作之间内存屏障，smp_rmb 就是典型实现；</li>
<li>StoreStore：两个Store 操作之间的内存屏障，smp_wmb 典型实现；</li>
<li>LoadStore：在 Load 操作和 Store 操作之间的内存屏障；</li>
<li>StoreLoad：在 Store 操作和  Load 操作之间的内存屏障</li>
</ul>
<font color="red"><br>个人理解添加<br>以StoreLoad为例，这个是上面四个中最重的，最耗性能的，storeload其实能涵盖上面三个，因为它既保证了写也保证了读，它和loadstore的侧重点不一样，loadstore对于后面的那个写什么时候能写进去不是非常要求，更侧重的是前面的写。前一个是写后一个是读，后一个读取不能重排到这个写操作之前，也就是load时要看到前面写的值，这也就要保证前一个写的内容如果在storebuffer中就一定要写到cache中.<br>然后load的时候不能直接去读cache的值，要将invalidqueue中的值处理掉，该标记无效的都要进行标记，确保读取出来的是最新的。<br></font>   

<p>对于java中的volatile防止重排网上博客一大堆，有些文章从汇编角度来分析加了volatile前后的对比，本地测试过hsdis可以用来将java转换为对应的汇编，这里就不展开了     </p>
<p><font color="red"> 个人理解<br>volatile最重要的使命是为了可见性，为了达到可见性这个目的不得不设计出防止指令重排，因为如果不限制重排，就达不到可见性这个目的<br>所以可以理解防止重排只是达到可见性的一个不得已手段<br></font><br><br>   </p>
<p><strong>参考文章</strong><br><a href="https://www.infoq.com/articles/memory_barriers_jvm_concurrency/" target="_blank" rel="noopener">Memory Barriers and JVM Concurrency</a><br><a href="http://www.wowotech.net/kernel_synchronization/memory-barrier.html" target="_blank" rel="noopener">Linux内核同步机制之（三）：memory barrier</a><br><a href="https://medium.com/fcamels-notes/%E5%BE%9E%E7%A1%AC%E9%AB%94%E8%A7%80%E9%BB%9E%E4%BA%86%E8%A7%A3-memry-barrier-%E7%9A%84%E5%AF%A6%E4%BD%9C%E5%92%8C%E6%95%88%E6%9E%9C-416ff0a64fc1" target="_blank" rel="noopener">從硬體觀點了解 memory barrier 的實作和效果</a><br><a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2015/p0098r0.pdf" target="_blank" rel="noopener">P0098R0: Towards Implementation and Use ofmemoryorderconsume</a><br><a href="https://createpoint.qti.qualcomm.com/search/contentdocument/stream/35553?refererRoute=search%2FsearchArgs%2Fq%7C%7CMemory%20Barriers%7C%7Crows%7C%7C10%7C%7CsortField%7C%7Cscore%7C%7CsortOrder%7C%7Cdesc&amp;dcn=80-N5603-1&amp;currentPage=1&amp;itemTotalIndex=1" target="_blank" rel="noopener">LINUX MEMORY ORDERING ON SCORPION-MP AND KRAIT APPLICATION PROCESSORS</a><br><a href="https://preshing.com/20120710/memory-barriers-are-like-source-control-operations/" target="_blank" rel="noopener">Memory Barriers Are Like Source Control Operations</a><br><a href="https://mp.weixin.qq.com/s?__biz=MzUzMDk3NjM3Mg==&amp;mid=2247483755&amp;idx=1&amp;sn=50f80e73f46fab04d8a799e8731432c6&amp;chksm=fa48da70cd3f5366d9658277cccd9e36fca540276f580822d41aef7d8af4dda480fc85e3bde4&amp;token=630636109&amp;lang=zh_CN#rd" target="_blank" rel="noopener">从 Java 内存模型看内部细节</a><br><a href="http://www.4e00.com/blog/java/2018/10/21/inside-java-memory-model.html" target="_blank" rel="noopener">深入理解 java 内存模型</a><br><a href="http://www.wowotech.net/memory_management/458.html" target="_blank" rel="noopener">浅谈Cache Memory</a><br><a href="http://www.wowotech.net/kernel_synchronization/Why-Memory-Barriers.html" target="_blank" rel="noopener">Why Memory Barriers</a></p>

      
    </div>
    
    
    
	
	<div>
	  
      <div>
    
        <div style="text-align:center;color: #ccc;font-size:14px;">-------------本文结束<i class="fa fa-paw"></i>请多多指教-------------</div>
    
</div>

      
    </div>
	
    
	
    

    
      <div>
        <ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>本文作者：</strong>
    Steven Lee
  </li>
  <li class="post-copyright-link">
    <strong>本文链接：</strong>
    <a href="http://lihaizhou.top/2020/06/20/Memory-Barrier读书笔记/" title="内存屏障">http://lihaizhou.top/2020/06/20/Memory-Barrier读书笔记/</a>
  </li>
  <li class="post-copyright-license">
    <strong>版权声明： </strong>
    本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/3.0/" rel="external nofollow" target="_blank">CC BY-NC-SA 3.0</a> 许可协议。转载请注明出处！
  </li>
</ul>

      </div>
    

    <footer class="post-footer">
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2020/05/25/mmap机制初探/" rel="next" title="mmap机制初探">
                <i class="fa fa-chevron-left"></i> mmap机制初探
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2020/08/09/网络协议系列之聊聊三次握手/" rel="prev" title="网络系列之三次握手">
                网络系列之三次握手 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  
    <div class="comments" id="comments">
    </div>
  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/images/background.jpg"
                alt="Steven Lee" />
            
              <p class="site-author-name" itemprop="name">Steven Lee</p>
              <p class="site-description motion-element" itemprop="description">恍恍惚惚</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives">
              
                  <span class="site-state-item-count">34</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">5</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            

          </nav>

          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Cache-Memory"><span class="nav-number">1.</span> <span class="nav-text">Cache Memory</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Cacheline"><span class="nav-number">1.1.</span> <span class="nav-text">Cacheline</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#缓存一致性"><span class="nav-number">2.</span> <span class="nav-text">缓存一致性</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Store-Buffer-amp-Invalidate-Queue"><span class="nav-number">2.1.</span> <span class="nav-text">Store Buffer &amp; Invalidate Queue</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#一个小案例"><span class="nav-number">2.2.</span> <span class="nav-text">一个小案例</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#write-memory-barrier"><span class="nav-number">2.3.</span> <span class="nav-text">write memory barrier</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#read-memory-barrier"><span class="nav-number">2.4.</span> <span class="nav-text">read memory barrier</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#第二个小案例"><span class="nav-number">2.5.</span> <span class="nav-text">第二个小案例</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#简要归纳"><span class="nav-number">2.6.</span> <span class="nav-text">简要归纳</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#java内存模型"><span class="nav-number">3.</span> <span class="nav-text">java内存模型</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#JVM-barrier"><span class="nav-number">3.1.</span> <span class="nav-text">JVM barrier</span></a></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>
<div class="copyright">&copy; <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Steven Lee</span>

  
</div>

<div class="powered-by">
<i class="fa fa-user-md"></i><span id="busuanzi_container_site_uv">
  本站访客数:<span id="busuanzi_value_site_uv"></span>
</span>
</div>




  <span class="post-meta-divider">|</span>





<div class="theme-info">
  <div class="powered-by"></div>
  <span class="post-count">Steven的博客共79.8k字</span>
</div>
        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  


  











  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  

  
  
    <script type="text/javascript" src="/lib/canvas-nest/canvas-nest.min.js"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  










  <script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
  <script src="//unpkg.com/valine/dist/Valine.min.js"></script>
  
  <script type="text/javascript">
    var GUEST = ['nick','mail','link'];
    var guest = 'nick';
    guest = guest.split(',').filter(item=>{
      return GUEST.indexOf(item)>-1;
    });
    new Valine({
        el: '#comments' ,
        verify: false,
        notify: false,
        appId: 'Hsz9zOlrvMN9ry0R9Jfi5ykJ-gzGzoHsz',
        appKey: 'MAHOS3RIF7wDFRbEeC7kf3Vr',
        placeholder: '此处输入评论内容',
        avatar:'wavatar',
        guest_info:guest,
        pageSize:'10' || 10,
    });
  </script>



  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  
<script>
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';        
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>


  
  

  

  

  

</body>
</html>
