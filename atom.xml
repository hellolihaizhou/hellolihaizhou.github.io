<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>李海洲</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://lihaizhou.top/"/>
  <updated>2021-11-08T06:45:49.228Z</updated>
  <id>http://lihaizhou.top/</id>
  
  <author>
    <name>Steven Lee</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>案例分析:打开应用后操作界面无响应(Systrace)</title>
    <link href="http://lihaizhou.top/2021/11/08/%E6%A1%88%E4%BE%8B%E5%88%86%E6%9E%90-%E5%88%87%E6%8D%A2%E5%BA%94%E7%94%A8%E5%90%8E%E9%AB%98%E6%A6%82%E7%8E%87%E6%93%8D%E4%BD%9C%E6%97%A0%E5%93%8D%E5%BA%94-Systrace/"/>
    <id>http://lihaizhou.top/2021/11/08/案例分析-切换应用后高概率操作无响应-Systrace/</id>
    <published>2021-11-08T02:34:51.000Z</published>
    <updated>2021-11-08T06:45:49.228Z</updated>
    
    <content type="html"><![CDATA[<h4 id="问题现象"><a href="#问题现象" class="headerlink" title="问题现象"></a>问题现象</h4><p>打开应用(热启动)后，概率性出现手指滑动界面无任何响应(界面控件支持上下滑动)</p><h4 id="Systrace角度分析"><a href="#Systrace角度分析" class="headerlink" title="Systrace角度分析"></a>Systrace角度分析</h4><p>先看下应用区域帧绘制的情况</p><p><img src="http://blog.lihaizhou.top/Systrace_cpmpact/Systrace_compact2.png" alt="图片"></p><p>这个时间段除了开头的几帧，后面几乎是空白的，复现时手指明明是一直滑动的。</p><p>先确认下input事件是否正常，在分析input事件流转是否正常之前</p><p>我们先简单的介绍下input事件大概的流转过程</p><blockquote><p>1.触摸屏每隔几毫秒扫描一次，如果有触摸事件，那么把事件上报到对应的驱动</p><p>2.InputReader 读取触摸事件交给 InputDispatcher 进行事件派发</p><p>3.InputDispatcher 将触摸事件发给注册了 Input 事件的 App</p><p>4.app 拿到事件之后，进行 Input 事件分发，如果此事件分发的过程中，App的</p><p>UI 发生变化，那么会请求 Vsync，则进行一帧的绘制</p></blockquote><p>先看下input down的时间点</p><p><img src="http://blog.lihaizhou.top/Systrace_cpmpact/Systrace_compact3.png" alt="图片"></p><p>后面的事件是连续且密集的，说明我们复现抓取的时候，报点是没有问题的。</p><p>这个时候我们注意到一个奇怪的现象，outBoundQueue和waitQueue是空的。</p><p>关于outBoundQueue和waitQueue简单介绍下</p><blockquote><p>1.当应用窗口准备就绪，将mPendingEvent转移到outBoundQueue队列，对应的是即将要被派发给对应 AppConnection 的事件。</p><p>2.当outBoundQueue不为空，且应用管道对端连接状态正常，则将数据从outboundQueue中取出事件，放入waitQueue队列，记录的是已经派发给 AppConnection 但是 App 还在处理没有返回处理成功的事件。</p></blockquote><p>如果outBoundQueue和waitQueue是空的话，说明此时应用窗口未就绪。我们操作时窗口明明可见的，难道应用D状态了？</p><p>带着这个疑问，我们再次回到应用所在区域</p><p><img src="http://blog.lihaizhou.top/Systrace_cpmpact/Systrace_compact4.png" alt="图片"></p><p>可以看到飞书热启后，多个运行线程处于非IO导致的D状态，另外结合基本没有占据CPU资源这一情况。</p><p>可以认定之所以应用没有响应down事件，正是由于其处于非IO导致的D状态。</p><p>下面就需要调查为何应用D状态了，很快在应用区域注意到一个现象</p><p><img src="http://blog.lihaizhou.top/Systrace_cpmpact/Systrace_compact5.png" alt="图片"></p><p>我们知道匿名页被压缩换到Zram通常出现在kswapd回收内存场景中。</p><p>但是还有一种场景我们可能会忽略，那就是adj变化触发的进程压缩同样会消费Zram。</p><p>为了验证是进程压缩导致，来到压缩线程所在区域。为了看起来更直观，将down事件和压缩线程放在一起</p><p><img src="http://blog.lihaizhou.top/Systrace_cpmpact/Systrace_compact6.png" alt="图片"></p><p>到这里我们可以确定飞书之所以没有响应到input down事件，正是由于其当时正在进行进程压缩从而导致其处于D状态。</p><h4 id="问题完整时间线"><a href="#问题完整时间线" class="headerlink" title="问题完整时间线"></a>问题完整时间线</h4><p>到这里我们将这个案例完整的故事情节还原出来</p><ol><li><p>在一次退出飞书后，此时引起adj变化，进入压缩判断环节，此时满足一系列条件(如匿名页大小, 前后时间差, adj值)后，压缩线程开始对飞书应用进行压缩。</p></li><li><p>很快再次打开飞书(29s793ms)</p></li><li><p>此时手指按下开始滑动(29s988ms)(不松手)，注意这个时候压缩还未完成，飞书仍处于进程压缩导致的D状态中，所以未能响应down事件。</p><p>我们知道一个事件序列是由down+若干move+up组成，由于down事件丢失以至于后面的move事件未能响应。</p></li><li><p>飞书压缩完成(30s598ms)，该主界面进程压缩过程持续约882.6ms，完成后飞书解除D状态。</p></li></ol><p>这个过程简单点说，在飞书可见后，如果上次压缩未完成，这时候手指按下的down事件都会被丢弃。</p><p>这也解释了为何该问题在快速切换场景下更容易出现</p><h4 id="压缩速度"><a href="#压缩速度" class="headerlink" title="压缩速度"></a>压缩速度</h4><p>这个时候，你可能会觉得疑惑，是不是压缩速度慢导致的这个问题?</p><p>下面我们将试着计算问题时的”压缩速度”, 这里对压缩速度之所以加引号后面会解释</p><p><img src="http://blog.lihaizhou.top/Systrace_cpmpact/Systrace_compact7.png" alt="图片"></p><p>从我们这次复现的Systrace来看，飞书压缩完成后，其Swap占据从118.8M增长到232.7M，共计压缩了约114M的匿名页，共计耗时882ms</p><p>用压缩量除以耗时时间得出”压缩速度”约129M/s。</p><p>影响压缩速度的因素可能有哪些呢？</p><p><strong>主要是压缩算法，CPU频率，DDR频率，内存读写性能这几方面因素</strong></p><p>我们从Systrace中再看下压缩期间的CPU运行情况</p><p><img src="http://blog.lihaizhou.top/Systrace_cpmpact/Systrace_compact8.png" alt="图片"></p><p>可以看到有较多的Runnable (Preempted)，说明该时间段内可能负载较重，存在CPU争抢的情况。</p><p>除了等CPU的片段外，还有很多片段跑在了小核上</p><p><img src="http://blog.lihaizhou.top/Systrace_cpmpact/Systrace_compact9.png" alt="图片"></p><p>这也是为何上面提到的”压缩速度”加引号的原因。正好压缩的耗时882ms并不是一直在running状态。</p><p>其实这点比较好理解，好比你开车上班，短短的五公里的车程却有二十个红绿灯，这个时候用路程除以耗时得出的”车速”，严格意义上说并不准确。</p><h4 id="测试实验"><a href="#测试实验" class="headerlink" title="测试实验"></a>测试实验</h4><p>我们前面已经发现压缩期间很多片段跑在了小核上，那么如果给压缩线程更高的CPU资源权重，是否能提升”压缩速度”呢？</p><p>于是，对压缩线程占据CPU的权重进行调整后，再次抓取了一份Systrace</p><p><img src="http://blog.lihaizhou.top/Systrace_cpmpact/Systrace_compact10.png" alt="图片"></p><p>从修改后抓取的Systrace可以看到，这次压缩线程确实大部分时候跑在了大核上。</p><p>从图中可以看到本次压缩了约144M匿名页，耗时约450ms，”压缩速度”约320M/s</p><p>相比修改前，”压缩速度”提升了近三倍，但是其实仍然不够快，还是会有一定概率发生手指按下时，正好落在压缩未完成的时间段内，只是相比之前大幅降低了该问题复现概率。</p><h4 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h4><p>如果压缩算法已经确认是最优的选择(平衡压缩率和解压缩速度)情况下，通过尽量赋予压缩线程更高的CPU优先级确实能够缩短耗时(假设压缩量固定)，但是最大的影响因素在于内存读写性能。</p><hr><p>愿你秃顶归来，内心依旧少年</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;问题现象&quot;&gt;&lt;a href=&quot;#问题现象&quot; class=&quot;headerlink&quot; title=&quot;问题现象&quot;&gt;&lt;/a&gt;问题现象&lt;/h4&gt;&lt;p&gt;打开应用(热启动)后，概率性出现手指滑动界面无任何响应(界面控件支持上下滑动)&lt;/p&gt;
&lt;h4 id=&quot;Systrace角度
      
    
    </summary>
    
      <category term="性能" scheme="http://lihaizhou.top/categories/%E6%80%A7%E8%83%BD/"/>
    
    
  </entry>
  
  <entry>
    <title>第三视角: 一个ART GC的优化故事</title>
    <link href="http://lihaizhou.top/2021/11/01/%E7%AC%AC%E4%B8%89%E8%A7%86%E8%A7%92-%E4%B8%80%E4%B8%AAART-GC%E7%9A%84%E4%BC%98%E5%8C%96%E6%95%85%E4%BA%8B/"/>
    <id>http://lihaizhou.top/2021/11/01/第三视角-一个ART-GC的优化故事/</id>
    <published>2021-11-01T08:54:55.000Z</published>
    <updated>2021-11-01T10:06:11.284Z</updated>
    
    <content type="html"><![CDATA[<h4 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h4><p>从事过整机性能优化的同事，在实际项目上相信都遇到过GC引起的性能问题。有了上一篇文章<android s="" art="" gc基础="">的铺垫，阅读本文将会比较轻松。<br>笔者在梳理GC这块的代码过程中，深感其复杂并非一蹴而就，如果你对其某处代码的设计缘由不甚理解，不妨试着去追踪它的提交记录。<br>通过其一系列的patch更新以及comment，跟着提交owner的思路历程，便可以了解这个”成品”是如何被加工出来的。</android></p><h4 id="故事的缘起"><a href="#故事的缘起" class="headerlink" title="故事的缘起"></a>故事的缘起</h4><p>笔者在梳理GC这块的代码时，偶然看到一处友商的提交，不禁有点好奇。为了探究其修改的缘由，仔细阅读了这笔修改的提交更新以及所有的comment之后，觉得其中一些思路对我们有启发作用，故而决定将这个思路过程尽可能的还原出来。<br>为了提升可读性，将通过故事叙事的方式展开，以第三视角来讲述。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">主角: 卢卡斯(谷歌员工)，大壮(友商员工)    </span><br><span class="line">配角: 汉斯(谷歌员工)   </span><br><span class="line">旁白: 笔者</span><br></pre></td></tr></table></figure></p><h4 id="故事开始"><a href="#故事开始" class="headerlink" title="故事开始"></a>故事开始</h4><p>大壮在国内一家手机厂商搬砖，负责整机性能方面的研究。最近大壮有点闷闷不乐，项目上一些GC相关的性能问题困扰了他许久，具体是什么GC问题呢？<br>大壮通过不限于Systrace等手段，发现在一些场景下比如后台运行较多应用时，GC会消耗较多CPU资源，加剧系统负担，表现出的现象就是更加卡顿了。<br>于是，自信上进的大壮开始着手调研该如何解决这个问题，最终有了一个方案：<br>既然GC会在后台运行较多应用时争抢CPU，那么在CPU负载高的时候降低GC的触发，CPU负载低的时候再恢复，这不就可以了吗？</p><ol><li>怎么降低GC频率呢？Multiplier机制。</li><li>怎么统计CPU负载呢？大壮看了下代码中原本就有GC期间占据的CPU数据。</li></ol><p>看起来小菜一碟嘛，熟悉GC流程代码的大壮很快就做出了第一笔修改。</p><h5 id="修改Multiplier"><a href="#修改Multiplier" class="headerlink" title="修改Multiplier"></a>修改Multiplier</h5><p>考虑到HeapGrowthMultiplier这个接口是谷歌原有的，存在多处会调用，为了不影响其他调用,贴心的大壮加了一个单独的接口HeapGrowthMultiplierExt,  这个接口最终会调用HeapGrowthMultiplier，只是在此之前会有一些判断条件。比如是否处于亮屏，不同的radio下返回不同的Multiplier值。<br>通过前一篇文章的分析，我们知道Multiplier的改变会引起下次GC水位的提升，总的而言，值越高GC的触发频率就会更低。<br>runtime/gc/collector/garbage_collector.cc<br><img src="http://blog.lihaizhou.top/ART_story/GC_story1.png" alt="图片"><br>runtime/gc/heap.cc</p><p><img src="http://blog.lihaizhou.top/ART_story/GC_story2.png" alt="图片"></p><h5 id="降低GC转换的次数"><a href="#降低GC转换的次数" class="headerlink" title="降低GC转换的次数"></a>降低GC转换的次数</h5><p><img src="http://blog.lihaizhou.top/ART_story/GC_story3.png" alt="图片"><br>前后台切换会导致GC转换，大壮心想有一些本身占据堆内存就比较小的进程，他们很多时候的GC转换带来的收益并不明显。<br>特别是内存比较充足的项目这种GC转换似乎有点多余，那么通过判断堆使用大小，去掉一些”不必要”的GC转换，这样就可以降低系统负担。</p><p>旁白:<br>为了可拓展性，尽可能的不要引入硬编码，即便你是通过大量数据实测出来的最优值，除非是一些约定俗成的值。提到硬编码这种情况，在实际项目上经常出现，很多时候这种代码的引入，是由于Reviewer的疏忽没有发现或者说默许了。</p><h4 id="谷歌Review"><a href="#谷歌Review" class="headerlink" title="谷歌Review"></a>谷歌Review</h4><p>很快，大壮的提交修改引起了卢卡斯的注意，看完了大壮的修改后，卢卡斯脑袋上顶着大大的问号。<br>对于如下大壮添加的计算gc期间CPU负载的做法。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">uint64_t gc_cpu_time = thread_cpu_end_time - thread_cpu_start_time;  </span><br><span class="line">float ratio = static_cast&lt;float&gt;(gc_cpu_time) / duration_ns;</span><br></pre></td></tr></table></figure></p><p>卢卡斯认为这只是本次GC周期内的CPU负载情况，且这个值在绝大部分时候都应该是接近1的，并不能说明未来一段时间的CPU情况。<br>另外，GC等待checkpoint或者其他原因都可能会导致GC等待，但是这些等待的时间不会计入gc_cpu_time中，所以这种计算方式只能说一定程度上可能暗示了当前的负载情况，但是远远达不到可靠的地步。</p><p>旁白：<br>注意这里谷歌提到了未来的CPU使用情况，是因为这个比例值是本次GC周期计算的，你可以理解为是一个瞬时值，但是抑制GC的情况是需要等到<br>下次GC触发才会发生的，是一个未来发生的事情，那么等到下次GC的时候，本次GC算出的负载可能就不适用了。</p><p>大壮：<br>大壮看完大G的回复之后，虎躯一震，这修改。。怕是要凉啊！于是大壮赶紧回复到：<br>在一些性能较差设备上，如果后台开启很多应用，很多时候这个比例值会低于0.5甚至触及0.2。<br>另外，我们做过功耗测试，这修改后的效果杠杠的，改善很明显(使用时间增加了18分钟)。</p><p>卢卡斯：<br>看完大壮理直气壮的回复后，卢卡斯回复到：这里亮屏的判断，并根据不同的radio返回不同的Multiplier，这个修改同样会作用到所有系统进程(如system_server、systemui等)，作用于<br>系统进程是一种错误的行为。还有根据不同的radio即你认为的代表负载情况，返回不同的Multiplier值。这些Multiplier值你是怎么得出来的？<br>比如你上面写的当ratio &lt; 0.3时，返回Multiplier 6，这个值6怎么来的？为何不是返回8？为啥不是9？为啥不是一个10000000000？(谷歌没说这句话)。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (screenOn) &#123;</span><br><span class="line">    <span class="keyword">float</span> ratio = current_gc_iteration_.GetRunningRatio();</span><br><span class="line">    <span class="keyword">if</span> (!CareAboutPauseTimes()) &#123;</span><br><span class="line">      <span class="keyword">if</span> (ratio &lt; <span class="number">0.3</span>) <span class="keyword">return</span> <span class="number">6.0</span>;</span><br><span class="line">      <span class="keyword">if</span> (ratio &lt; <span class="number">0.5</span>) <span class="keyword">return</span> <span class="number">4.0</span>;</span><br><span class="line">      <span class="keyword">if</span> (ratio &lt; <span class="number">0.7</span>) <span class="keyword">return</span> <span class="number">2.0</span>;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="keyword">if</span> (ratio &lt; <span class="number">0.3</span>) <span class="keyword">return</span> <span class="number">7.0</span>;</span><br><span class="line">      <span class="keyword">if</span> (ratio &lt; <span class="number">0.6</span>) <span class="keyword">return</span> <span class="number">5.0</span>;</span><br><span class="line">    &#125;</span><br><span class="line"><span class="comment">//....</span></span><br></pre></td></tr></table></figure><p>旁白：给谷歌提代码一定要避免提交这种硬编码</p><p>大壮：<br>此时的大壮，刚从食堂吃完午饭回来的路上，一路上大壮都在和同事吐槽食堂的饭菜又贵又难吃。<br>坐到座位上，看到卢卡斯的连环追问，大壮有点发蒙。这些数据我经过一些性能和功耗测试，是有帮助的，既然你们提出来这样的修改不合理，那么请告诉我,还有没有其它办法可以降低高负载情况下GC的频率。</p><p>卢卡斯:<br>此时的卢卡斯正喝着咖啡，窗外阳光正明媚，卢卡斯回过头和旁边的汉斯说到，这天气不去钓鱼真是浪费生命啊，汉斯点头如蒜捣，没错没错。<br>这个时候，卢卡斯看了下时间快4点了，准备收拾下班，这个时候看到了大壮的comment，回复到:<br>在堆使用较少的情况下不进行GC我觉得有意义，这种情况下我认为是可以直接跳过GC转换的，而不是引入进程状态切换次数这个变量。</p><p>旁白：谷歌的这句话，在一些场景下跳过GC更有意义，正是这句话改变了修改的方向</p><p>卢卡斯旁边的汉斯看到了大壮的这段回复，心里OS: 上一次这么无语还是在上一次, 忍不住回复到：<br>卢卡斯，大壮的这种改法让我感觉也很不舒服，也许我们在一些场景下GC的次数有点多了，但是能不能用更合理的方式来解决这个问题呢？比如依据自上次GC以来分配的字节数作为依据, 对于某些应用程序来说，转换可能会频繁发生，并且每次执行GC并不总是可取的。<br>用比例值或许更合理？例如:“如果我们已经消耗了超过30%的free heap，我们将在转换时GC”。</p><p>旁白：汉斯的这句话奠定了这个修改的基本方向，依据自上次GC以来的分配数值作为依据，采用比例的方式，不用管这个进程的大小。</p><p>大壮：<br>此时的大壮正在工位上，跟旁边的测试妹纸炫耀自己昨天一口气钓了十几斤的鲫鱼，妹纸看大壮的眼神满是崇拜。大壮说的有点渴了，坐下来喝口水时，看到了卢卡斯的回复，思考片刻后，觉得谷歌提出的修改建议确实更加合理。<br>于是讲起了之前遇到的案例:<br>最早是我们遇到的一个Launcher的卡顿例子，同一uid下的5个进程同时在后台执行collectorTransionGc，导致系统负载过高。四个子进程的堆大小都小于5MB，不信我给你们看Systrace。对于这种内存消耗很小的进程，真的大可不必每次都GC，所以我们希望能够限制这种类型的collectortransiongc。因为从实际用户的GC数据中可以发现，这种类型的CollectorTransitionGC的总量非常大。</p><p>卢卡斯:<br>卢卡斯觉得不应该仅限于小内存进程，应该一视同仁，所以卢卡斯觉得基于堆的大小进行限制不是太好。卢卡斯想起了汉斯提出的建议: 根据自上次GC以来分配的大小作为跳过GC转换的条件。<br>汉斯的这个建议确实更加合理一些，这样的话，所有的应用都有机会跳过一些”不必要”的GC。卢卡斯想了下，与其跳过一些转换GC，不如让它更简单，比如: 如果自上次GC以来的分配小于3MB，GC转换时跳过GC。</p><p>旁白:<br>卢卡斯认同汉斯的通过自上次GC以来分配的大小作为依据，但是忽略了汉斯提出另一个意见，那就是通过堆空闲内存的使用率来作为触发条件，这里卢卡斯提出的小于3M就不进行GC，也正是这句话给了大壮一些误导。</p><p>大壮:<br>听完卢卡斯说的堆使用小于3M就不进行GC转换后，大壮进行了一次修改，加了一个阈值<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="keyword">constexpr</span> <span class="keyword">size_t</span> kDefaultTransitionThreshold = <span class="number">5</span> * MB;</span><br></pre></td></tr></table></figure></p><p>并且在GC转换的地方加了一个判断，如果低于这个阈值，就跳过本次的GC转换<br><img src="http://blog.lihaizhou.top/ART_story/GC_story4.png" alt="图片"></p><p>卢卡斯:<br>看完大壮的修改后，卢卡斯后悔了，这里搞个固定的阈值看起来并不合适。因为如果这个进程是一个占用内存比较小的进程，那么5M对于这个进程来说并不容易达到，这会导致GC的触发频率被大幅降低，导致这个进程的堆大小”不合适”的增大。<br>这个时候卢卡斯想起了汉斯的通过比例的建议，没错，通过比例更合理一些，于是卢卡斯提出了: 上次GC后新增大小如果小于<br>UnignedDifference(target_footprint_.load(std::memory_order_relaxed)- num_bytes_alive_after_gc_)/4 话，则跳过本次GC转换，并且对于LowMemoryMode设备避免跳过GC</p><p>旁白：卢卡斯的这番话基本成形了这个修改，即消耗没有达到堆空闲的1/4，此时有GC转换请求的话，则直接丢弃。</p><p>大壮：<br>看完卢卡斯的建议后，大壮开始着手进行了修改，关于如何计算GC后新分配的值。<br>大壮想到了在GC后算出已分配的减去GC前计算出的已分配大小，修改完之后再次更新了patch，很快卢卡斯在大壮的修改下加了comment<br><img src="http://blog.lihaizhou.top/ART_story/GC_story5.png" alt="图片"></p><p>旁白：这是并发GC的特色所在，分配的同时可能伴随着GC，所以需要考虑GC期间释放的空间大小。</p><h4 id="最终修改思想"><a href="#最终修改思想" class="headerlink" title="最终修改思想"></a>最终修改思想</h4><ol><li>进程状态变化触发GC转换</li><li>计算出自上次GC后新分配字节大小，由于并发缘故，需考虑GC期间释放字节数。</li><li>堆可增长上限减去自上次GC后已分配数值，得出的值即可增长空间，取其四分之一作为分界线</li><li>上次GC后新分配字节数值如果小于第三步算出的可增长空间的1/4，则跳过本次GC转换请求。</li></ol><h4 id="写在最后"><a href="#写在最后" class="headerlink" title="写在最后"></a>写在最后</h4><p>谈到设计思想，笔者想起一句话：Talk is cheap. Show me the code!<br>每次看到这句话，都感觉被无端斥责了一番。<br>笔者曾经特地查询了下Linus说这句话的语境背景，最后得出结论Linus说这句话时，其实是在一个讨论回复中，结合当时的上下文语境，Linus说出这句时明显是带有情绪的，但是奇怪的是这句特定语境下的话，在国内却被大肆宣传甚至被一些人奉为经典。<br>笔者在实际项目上见到过太多shit一样的代码，盲目的追求代码数量，粗制滥造毫无设计可言，更不要说代码规范这些基础原则了，阅读起来你都恨不得砸了键盘。<br>如果你很崇尚“show me the code”，给你这样一堆dog shit代码，你能从中看出什么呢？<br>并不是盲目崇拜谷歌，笔者在阅读谷歌代码的提交记录过程中，能够感受到其思维之严谨，考虑之周到，修改之谨慎。所以推荐大家空闲的时候，可以多阅读谷歌的修改记录。<br>最后多说一句，笔者粗浅的认为，相比于最终的成品代码，当然前提是优秀的代码。笔者认为其思路旅程也很重要，因为是人的思想最终孕育出这块美丽的代码。</p><hr><p>只要不给社会添麻烦，做一个废柴并不丢人</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h4&gt;&lt;p&gt;从事过整机性能优化的同事，在实际项目上相信都遇到过GC引起的性能问题。有了上一篇文章&lt;android s=&quot;&quot; art=&quot;&quot; gc基础=&quot;&quot;
      
    
    </summary>
    
      <category term="ART" scheme="http://lihaizhou.top/categories/ART/"/>
    
    
  </entry>
  
  <entry>
    <title>对Android S ART GC的源码梳理</title>
    <link href="http://lihaizhou.top/2021/10/27/%E5%AF%B9Android-S-ART-GC%E7%9A%84%E6%BA%90%E7%A0%81%E6%A2%B3%E7%90%86/"/>
    <id>http://lihaizhou.top/2021/10/27/对Android-S-ART-GC的源码梳理/</id>
    <published>2021-10-27T01:58:43.000Z</published>
    <updated>2021-10-27T02:52:58.210Z</updated>
    
    <content type="html"><![CDATA[<h4 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h4><p>本文是GC系列文章的首篇，主要为下一篇《第三视角: 一个ART GC优化的故事》文章做铺垫。<br>本文将根据下面的大纲，简单的介绍下GC相关的基础知识，GC这块的内容较多，也相对较为复杂。如果想要研究清楚细节，需要花费较多的时间，也需要有读者有足够的耐心和相关知识背景。</p><p>文中涉及代码均摘自Android S。</p><h4 id="大纲"><a href="#大纲" class="headerlink" title="大纲"></a>大纲</h4><ul><li>研究ART GC目的</li><li>ART GC诞生背景</li><li>里程碑(引入CC)</li><li>ART GC重要特性</li><li>ART GC类别划分</li><li>Multiplier的引入</li><li>堆可分配字节数的计算</li><li>GC触发阈值的计算</li><li>从Systrace角度看GC</li><li>参数修改策略</li><li>写在最后</li><li>参考文献</li></ul><h4 id="研究ART-GC目的"><a href="#研究ART-GC目的" class="headerlink" title="研究ART GC目的"></a>研究ART GC目的</h4><p>尽管GC经过多年发展已得到显著改进，但是在实际项目中仍然会遇到很多GC引起的性能问题。<br>特别是小内存项目上(低于6G)尤为明显，遇到的大部分问题来自于应用不规范的行为，小部分是由于GC机制在特定场景下导致的性能问题。</p><p>GC性能问题主要分为两类：</p><ol><li>对于应用而言，如果代码中存在频繁分配对象、存在内存泄漏、存在主动调用GC接口等问题都有可能导致GC性能问题。<br>主要体现在GC运行的线程HeapTaskDaemon占据CPU资源较多或争抢大核，可能会引起绘制得不到及时调度，导致掉帧的情况。</li><li>另外对于GC机制本身而言，虽然Google一直在优化，但是现在仍然存在一些场景下的表现无法令我们足够满意。<br>比如高负载时争抢CPU资源，小内存进程在某些场景下的频繁触发，多进程应用启动时由于GC导致的卡顿黑屏等现象。</li></ol><h4 id="GC诞生背景"><a href="#GC诞生背景" class="headerlink" title="GC诞生背景"></a>GC诞生背景</h4><p>当我们在学习新技术的时候，了解其诞生背景及其演进变化的历程，再结合具体的代码细节，将有助于我们对这个技术形成一个连续的认知。</p><p>举个网络拥塞控制的例子，网上关于拥塞控制算法的文章铺天盖地，几乎都在讨论其中的代码细节。<br>但是其诞生的历史背景及其本质是为了解决什么问题，却很少有文章能真正解释清楚。<br><strong>为什么说历史背景至关重要</strong><br>还是以拥塞控制为例，如果你不了解1986年的网络大崩溃事件发生的原因，也就无法理解1988年Jacobson提出的TCP拥塞控制的论文。<br>进而即便你多么熟悉TCP的代码细节，你也无法理解这一切实现背后的真正的逻辑，甚至会草率错误的认为拥塞控制是为了加快发包的速度，以至于后面关于这方面的工作很可能是扯淡。</p><p>再回到本文的主题GC，聊下GC诞生的背景</p><blockquote><p><em>1960</em> 年前后诞生于 <em>MIT</em> 的 <em>Lisp</em> 语言是第一种高度依赖于动态内存分配技术的语言，<em>Lisp</em> 语言先天就具有的动态内存管理特性要求 <em>Lisp</em> 语言的设计者必须解决堆中每一个内存块的自动释放问题（否则， <em>Lisp</em> 程序员就必然被程序中不计其数的 <em>free</em> 或 <em>delete</em> 语句淹没），这直接导致了垃圾收集技术的诞生和发展。</p><p><em>J. McCarthy 作为 Lisp</em> 之父，他在发明 <em>Lisp</em> 语言的同时也第一次完整地描述了垃圾收集的算法和实现方式。</p><p>有兴趣的话可以网上搜索这篇文章, 讲的比较详细 &lt;GC技术简单而有趣的发展史&gt;</p></blockquote><h4 id="里程碑-引入CC"><a href="#里程碑-引入CC" class="headerlink" title="里程碑(引入CC)"></a>里程碑(引入CC)</h4><p><code>史前时代Dalvik-&gt;ART的诞生(Android 4.4)-&gt;发展的ART(Android 5.0 ~ 7.0)-&gt;重大变革的ART(Android 8.0 引入Concurrent Copying)-&gt;Android 10开始再次引入分代.</code><br>8.0版本上引入的Concurrent Copying是一项重大改革，大幅提升了Android手机的整机性能表现。<br>8.0版本的GC相比之前的版本改进和提升如下:</p><ul><li>GC always compacts the heap: 32% smaller heap sizes on average compared to Android 7.0.</li><li>Compaction enables thread local bump pointer object allocation: Allocations are 70% faster than in Android 7.0.</li><li>Offers 85% smaller pause times for the H2 benchmark compared to the Android 7.0 GC.</li><li>Pause times no longer scale with heap size; apps should be able to use large heaps without worrying about jank.</li><li>GC implementation detail - Read barriers:</li><li>Read barriers are a small amount of work done for each object field read.</li><li>These are optimized in the compiler, but might slow down some use cases.</li></ul><h4 id="重要特性"><a href="#重要特性" class="headerlink" title="重要特性"></a>重要特性</h4><p>下面简单介绍CC上几种主要的特性，如果阅读过程中有些名词不明其意，大可不必感到困惑。<br>知道其大概的角色作用即可，后面的GC系列文章会对每个特性展开来详细梳理。</p><h5 id="RegionTLAB"><a href="#RegionTLAB" class="headerlink" title="RegionTLAB"></a>RegionTLAB</h5><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">CC enables use of a bump-pointer allocator called RegionTLAB. </span><br><span class="line">This allocates a thread-local allocation buffer (TLAB) to each </span><br><span class="line">app thread, which can then allocate objects out of its TLAB by </span><br><span class="line">bumping the "top" pointer, without any synchronization.</span><br></pre></td></tr></table></figure><p>这里提到的TLAB 即 thread-local allocation buffer，AllocObjectWithAllocator中会先检测如果当前线程TLAB区域的剩余空间可以容纳下这次分配的对象，则在TLAB区域中直接分配。<br>分配算法采用Bump Pointer的方式，仅仅更新已分配区域的游标，简单高效。<br>art/runtime/gc/heap-inl.h<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// If we have a thread local allocation we don't need to update bytes allocated.</span></span><br><span class="line"><span class="keyword">if</span> (IsTLABAllocator(allocator) &amp;&amp; byte_count &lt;= self-&gt;TlabSize()) &#123;</span><br><span class="line">  obj = self-&gt;AllocTlab(byte_count);</span><br><span class="line">  DCHECK(obj != <span class="literal">nullptr</span>) &lt;&lt; <span class="string">"AllocTlab can't fail"</span>;</span><br><span class="line">  obj-&gt;SetClass(klass);</span><br><span class="line">  <span class="keyword">if</span> (kUseBakerReadBarrier) &#123;</span><br><span class="line">    obj-&gt;AssertReadBarrierState();</span><br><span class="line">  &#125;</span><br><span class="line">  bytes_allocated = byte_count;</span><br><span class="line">  usable_size = bytes_allocated;</span><br><span class="line">  no_suspend_pre_fence_visitor(obj, usable_size);</span><br><span class="line">  QuasiAtomic::ThreadFenceForConstructor();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>值得注意的一点是，TLAB在创建之初，它的大小已经计入了num_bytes_allocated_，所以这次虽然分配了新的对象，但num_bytes_allocated_没必要增加，这实际上是一种空间换时间的策略，代价就是会导致num_bytes_allocated_略大于真实使用的字节数。</p><p>谷歌对此修改的commit message:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">New TLAB allocator doesn&apos;t increment bytes allocated </span><br><span class="line">until we allocate a new TLAB. This increases allocation </span><br><span class="line">performance by avoiding a CAS.</span><br><span class="line"></span><br><span class="line">MemAllocTest:</span><br><span class="line">Before GSS TLAB: 3400ms.</span><br><span class="line">After GSS TLAB: 2750ms.</span><br></pre></td></tr></table></figure></p><h5 id="Read-barrier"><a href="#Read-barrier" class="headerlink" title="Read barrier"></a>Read barrier</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">CC performs heap defragmentation by concurrently copying </span><br><span class="line">objects without pausing app threads. This is achieved with </span><br><span class="line">the help of a read-barrier which intercepts reference reads </span><br><span class="line">from the heap, without the need of any intervention from </span><br><span class="line">the app developer.</span><br></pre></td></tr></table></figure><p>CC可以通过在不暂停应用线程的情况下并发复制对象来执行堆碎片整理。这是在read-barrier的帮助下实现的，read-barrier会拦截来自堆的引用读取，无需开发者进行任何干预。<br>注意对第一句话的理解，应用GC的时候不会暂停应用，也就是说这个时候可能存在分配对象的行为，说的其实正是并发。<br>后面的实际案例在计算自上次GC后新分配大小时会用到这一点，目前的GC都是支持read-barrier的，read-barrier的诞生是为了更大程度的降低GC暂停时间。</p><h5 id="一次暂停"><a href="#一次暂停" class="headerlink" title="一次暂停"></a>一次暂停</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">GC only has one small pause, which is constant in time </span><br><span class="line">with regards to the heap size.</span><br></pre></td></tr></table></figure><p>对Dalvik有所了解的话，都知道Dalvik在mark阶段需要暂停应用线程两次，sweep阶段需要暂停一次，三次的STW开销会带来明显的卡顿。<br>到了ART时代，启动 GC 后不再是两次暂停，而是一次暂停，因为（packard pre-cleaning）的存在，在暂停前就做了许多事情，减轻了暂停时的工作量。</p><h5 id="支持分代"><a href="#支持分代" class="headerlink" title="支持分代"></a>支持分代</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">CC extends to be a generational GC in Android 10 and higher. </span><br><span class="line">It enables collecting young objects, which often become </span><br><span class="line">unreachable fairly quickly, with little effort. </span><br><span class="line">This helps by increasing GC throughput and considerably </span><br><span class="line">delaying the need to perform a full-heap GC.</span><br></pre></td></tr></table></figure><p>谷歌对分代的支持历经开，关，开，具体的缘由没有细跟，不过最新Android版本支持分代，分代的好处谷歌解释为更加轻松回收存留期较短的对象，有助于提升GC的吞吐量，并且降低full GC的时机。<br>注意这里提到了一个GC吞吐量的概念，笔者之前从事过网络工作，所以自然而然的想到了WIFI的吞吐量，WIFI吞吐量可以简单的理解为单位时间内通过某个信道的数据量。</p><p>那么这里的GC 吞吐量指的又是什么呢？ <strong>可以理解为单位时间内释放的字节数</strong></p><h4 id="GC类别的划分"><a href="#GC类别的划分" class="headerlink" title="GC类别的划分"></a>GC类别的划分</h4><p>对GC的分类有不同的指标，可以从是否并发，回收力度等指标分类。</p><h5 id="回收力度划分"><a href="#回收力度划分" class="headerlink" title="回收力度划分"></a>回收力度划分</h5><p>art/runtime/gc/collector/gc_type.h<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">art/runtime/gc/collector/gc_type.h// The type of collection to be performed. //The ordering of the enum matters, it is used to determine which GCs are run first.enum GcType &#123;// Placeholder for when no GC has been performed.kGcTypeNone,// Sticky mark bits GC that attempts to only free objects allocated since the last GC.kGcTypeSticky,// Partial GC that marks the application heap but not the Zygote.kGcTypePartial,// Full GC that marks and frees in both the application and Zygote heap.kGcTypeFull,// Number of different GC types.kGcTypeMax,&#125;;</span><br></pre></td></tr></table></figure></p><p>如下摘自谷歌的一笔commit message：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">The new behaviour has that we do sticky GC until we have </span><br><span class="line">less space remaining than minimum free after the GC. </span><br><span class="line">When this occurs, we set the next GC to be a partial GC.</span><br><span class="line"></span><br><span class="line">After a partial / full GC we grow the heap and set the </span><br><span class="line">next GC to be a sticky GC. This prevents the heap from </span><br><span class="line">always growing more than the target utilization, </span><br><span class="line">while ensuring that we do sticky GC often.</span><br></pre></td></tr></table></figure></p><p>建议随着后面不断的深入学习再回过来读这段话，相信会理解的更深。<br>大概意思是我们会尽可能的使用sticky的回收方式，这种回收只会回收自上次GC以来新分配的对象，是一种轻量回收方式，但是回收力度有限。</p><p>当剩余的可用空间低于设定的最小值即min_free，此时将下次GC类别设定为partial GC，加大回收的力度，但是当我们使用partial GC或者full GC后，应该将下次GC类型设定为sticky，从而避免堆的使用率经常超过目标值(默认0.75)，所以需要经常进行sticky方式的回收。</p><h5 id="对应用影响程度划分"><a href="#对应用影响程度划分" class="headerlink" title="对应用影响程度划分"></a>对应用影响程度划分</h5><p>如果基于GC对应用状态的影响分类的话，大致可以分为并发类和阻塞类。<br>并发类GC：GC在GC回收线程(HeapTaskDaemon)执行，阻塞类GC在进程的工作线程执行。</p><p><img src="http://blog.lihaizhou.top/ART_GC/ART_GC1.png" alt="图片"><br>需要注意这里的GcCauseBackground，这里的“Background”并不是指应用切到后台才会执行GC，而是GC在运行时基本不会影响其他线程的执行，即并发GC。</p><p>有了上面的知识铺垫，下面将进入本文最重要的部分，将依次介绍Multiplier的引入，target_size计算过程，concurrent_start_bytes_计算过程这三部分。<br>这三部分相互关联，为了能够更直观的理解这三部分的关系，本地画了一个整体的概览图(花了大半小时画完…….)，后面的内容主要也是围绕下面这个图进行讲解。<br><img src="http://blog.lihaizhou.top/ART_GC/ART_GC2.png" alt="图片"><br>现在看不懂没有关系，在阅读完后面的内容之后，再回过头来看这个图，相信会理解的更加深刻。</p><h4 id="Multiplier的引入"><a href="#Multiplier的引入" class="headerlink" title="Multiplier的引入"></a>Multiplier的引入</h4><p>我们在后面计算预留内存的时候，不论是否是sticky回收，都会使用到Multiplier。<br>这个值主要是为了前台应用设定的，引入该值目的是为了提升前台应用的性能，代价是堆的利用率下降，关于对性能的影响，下面会进行说明。</p><p>先看下对于Multiplier的值来源<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">art/runtime/runtime.cc</span><br><span class="line"><span class="comment">//Extra added to the default heap growth multiplier. </span></span><br><span class="line"><span class="comment">//Used to adjust the GC ergonomics for the read barrier config.</span></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">constexpr</span> <span class="keyword">double</span> kExtraDefaultHeapGrowthMultiplier = kUseReadBarrier ? <span class="number">1.0</span> : <span class="number">0.0</span>;</span><br><span class="line"><span class="keyword">float</span> foreground_heap_growth_multiplier;</span><br><span class="line"><span class="keyword">if</span> (is_low_memory_mode_ &amp;&amp; !runtime_options.Exists(Opt::ForegroundHeapGrowthMultiplier)) &#123;</span><br><span class="line">   <span class="comment">// If low memory mode, use 1.0 as the multiplier by default.</span></span><br><span class="line">   foreground_heap_growth_multiplier = <span class="number">1.0f</span>;</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">   foreground_heap_growth_multiplier =</span><br><span class="line">   runtime_options.GetOrDefault(Opt::ForegroundHeapGrowthMultiplier) +</span><br><span class="line">   kExtraDefaultHeapGrowthMultiplier;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>后台时Multiplier为1，我们主要看下前台的值，最新Android版本上都是支持ReadBarrier的，那么kExtraDefaultHeapGrowthMultiplier值也就是1。<br>再看下ForegroundHeapGrowthMultiplier的值来源于如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">static constexpr double kDefaultHeapGrowthMultiplier = 2.0;</span><br></pre></td></tr></table></figure><p>所以对于前台应用，Multiplier默认的值是2+1=3。</p><p>下面讲的堆大小的调整，下次GC触发阈值计算都是在GrowForUtilization中发生的，而GrowForUtilization又是在CollectGarbageInternal触发的，所以有必要先介绍下CollectGarbageInternal主要做的事情:</p><ol><li>调用RequestTrim做实际的堆裁剪，将空闲内存归还给系统，这块的内容细节较多，后面会另起一篇文章进行详细的介绍；</li><li>第二步会执行SelfDeletingTask* clear = reference_processor_-&gt;CollectClearedReferences(self);</li><li>第三步也是我们本文重点介绍的一步，这一步将进行堆大小的调整以及计算下次触发GC的阈值</li></ol><p>那么什么时候会触发CollectGarbageInternal进行垃圾回收呢？<br><strong>在ART分配对象失败或者已使用内存超过某个设定的阈值就会触发</strong></p><h4 id="堆最大可分配字节数的计算"><a href="#堆最大可分配字节数的计算" class="headerlink" title="堆最大可分配字节数的计算"></a>堆最大可分配字节数的计算</h4><p>堆最大可分配字节数指的是代码中的target_size，一个仅具有指导意义的最大可分配字节数，为何说仅有指导意义，后面会解释。</p><p>在此之前，我们先了解下Sticky GC是什么？<br>谷歌对此的定义如下:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Sticky mark bits GC that attempts to only free objects </span><br><span class="line">allocated since the last GC.</span><br></pre></td></tr></table></figure></p><p>Sticky GC只会回收自上次GC以来新分配的对象，是分代GC下的一种GC类型，也可以理解为Young-generation GC，那么非kGcTypeSticky指的是哪些GC类别呢？对应Partial GC以及Full GC。</p><p>那么什么时候会使用Sticky GC，什么时候会触发Partial GC以及Full GC呢？后面GC系列文章会进行讲解，总体而言，执行Sticky GC频率最高，最低是Full GC。</p><p>下面会看下kGcTypeSticky以及非kGcTypeSticky类别GC的target_size计算过程。</p><h5 id="非kGcTypeSticky-GC"><a href="#非kGcTypeSticky-GC" class="headerlink" title="非kGcTypeSticky GC"></a>非kGcTypeSticky GC</h5><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (gc_type != collector::kGcTypeSticky) &#123;  </span><br><span class="line"><span class="comment">// Grow the heap for non sticky GC.  </span></span><br><span class="line"><span class="keyword">uint64_t</span> delta = bytes_allocated * (<span class="number">1.0</span> / GetTargetHeapUtilization() - <span class="number">1.0</span>);  </span><br><span class="line">DCHECK_LE(delta, <span class="built_in">std</span>::numeric_limits&lt;<span class="keyword">size_t</span>&gt;::max()) &lt;&lt; <span class="string">"bytes_allocated="</span> &lt;&lt;bytes_allocated  &lt;&lt; <span class="string">" target_utilization_="</span> &lt;&lt; target_utilization_;</span><br><span class="line">grow_bytes = <span class="built_in">std</span>::min(delta, <span class="keyword">static_cast</span>&lt;<span class="keyword">uint64_t</span>&gt;(max_free_));</span><br><span class="line">grow_bytes = <span class="built_in">std</span>::max(grow_bytes, <span class="keyword">static_cast</span>&lt;<span class="keyword">uint64_t</span>&gt;(min_free_));</span><br><span class="line">target_size = bytes_allocated + <span class="keyword">static_cast</span>&lt;<span class="keyword">uint64_t</span>&gt;(grow_bytes * multiplier);  </span><br><span class="line">next_gc_type_ = collector::kGcTypeSticky;&#125;</span><br></pre></td></tr></table></figure><p>注意这行代码<br><code>bytes_allocated * (1.0 / GetTargetHeapUtilization() - 1.0);</code><br>这里有一个容易陷入的误区，如果单纯的看头文件中的定义注释</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//Target ideal heap utilization ratio, implements //dalvik.system.VMRuntime.getTargetHeapUtilization.double GetTargetHeapUtilization() </span></span><br><span class="line"><span class="keyword">const</span> &#123;</span><br><span class="line">   <span class="keyword">return</span> target_utilization_;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>可能会认为这个值返回的是默认的最优值0.75，其实这个值是一个动态变化的值，当一次GC发生后，堆的大小会resize。<br>此时GetTargetHeapUtilization的值等于存活对象大小除以堆的大小，算出的delta是除去已分配的字节数后空闲的大小。<br>算出delta后，我们接着往下看，可以看到grow_bytes并不单纯由delta决定，还会受到max_free_以及min_free_的影响，最终确保grow_bytes 的值不会超出这两个值范围。<br>这里的max_free_本意是target_size与已分配内存间可允许的最大差异，差异过小会导致GC频繁，差异过大会延迟下一次GC的到来，目前很多设备将这个值设为8M，min_free_为512K。其实针对RAM超过6G的大内存设备，Google建议可以提高min_free_，用空间换时间获取更好的GC性能。</p><p>有了grow_bytes 之后，再根据如下代码<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bytes_allocated + static_cast&lt;uint64_t&gt;(grow_bytes * multiplier);</span><br></pre></td></tr></table></figure></p><p>计算出目标堆大小。<br>大致的过程可以用下图表示<br><img src="http://blog.lihaizhou.top/ART_GC/ART_GC3.png" alt="图片"></p><h5 id="kGcTypeSticky-GC"><a href="#kGcTypeSticky-GC" class="headerlink" title="kGcTypeSticky GC"></a>kGcTypeSticky GC</h5><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// If we have freed enough memory, shrink the heap back down.</span></span><br><span class="line"><span class="keyword">const</span> <span class="keyword">size_t</span> adjusted_max_free = <span class="keyword">static_cast</span>&lt;<span class="keyword">size_t</span>&gt;(max_free_ * multiplier);</span><br><span class="line"><span class="keyword">if</span> (bytes_allocated + adjusted_max_free &lt; target_footprint) &#123;</span><br><span class="line">    target_size = bytes_allocated + adjusted_max_free;  </span><br><span class="line">    grow_bytes = max_free_;</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">target_size = <span class="built_in">std</span>::max(bytes_allocated, target_footprint);  </span><br><span class="line"><span class="comment">// The same whether jank perceptible or not; just avoid the adjustment.  </span></span><br><span class="line">grow_bytes = <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>对于本次是非kGcTypeSticky回收的方式，设定下次GC类型稍微复杂一些，会涉及到吞吐量之类的指标，后面的GC系列文章中会细谈，这里只关注target_size的计算过程。</p><ul><li>如果bytes_allocated + adjusted_max_free &lt; target_footprint说明此次的GC回收效果明显，注意这里grow_bytes 的值被赋予了max_free_，表示倾向于预留max_free_的空间大小，所以对于这个判断条件中的情况，其grow_bytes 会是一个恒定的值即max_free_。</li><li>否则的话即else中的情况，target_size的值是对bytes_allocated和target_footprint两者取最大，到这里你可能会疑惑bytes_allocated较大的情况，其实是有这个可能的，因为并发的缘故，可能存在GC期间分配大小大于回收数值的情况。</li></ul><p>那么此时target_size设定为bytes_allocated，下次分配对象时，bytes_allocated 立马就超出了target_size，会不会导致分配失败的情况？<br>其实不会，唯一限制堆内存分配的只有growth_limit_，这也解释了为何我们前面说target_size只有指导意义，但是这种情况确实会立即触发一次GC。</p><p>下面是谷歌的一段commit message对OOM的解释<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Are we out of memory, and thus should force a GC or fail?</span><br><span class="line">For concurrent collectors,out of memory is defined by growth_limit_</span><br><span class="line">For nonconcurrent collectors it is defined by target_footprint_ </span><br><span class="line">unless grow is set.If grow is set, the limit is growth_limit_ </span><br><span class="line">and we adjust target_footprint_to accomodate the allocation.</span><br></pre></td></tr></table></figure></p><p>这个时候，你可能还有疑问，为啥不将此时的target_size适当的增大，其实是因为此时的GC是Sticky，只回收自上次GC以来新分配的对象，回收力度是比较小的。<br>如果它释放的空间不多，接下来还可以用Full GC来更彻底地回收。<br>换言之，只有等Full GC回收完，才决定将GC的水位提升，因为这时已经尝试了所有回收策略。</p><p><strong>再回到上面提到的问题，multiplier的引入为何能够提升前台应用的性能？</strong><br>关于target_size 的计算过程中，不论是否是kGcTypeSticky方式，都涉及到了multiplier因子，multiplier的引入直接改变了前台应用的target_size值，此时你可能会疑惑这样的话堆使用率不就下降了吗？ <strong>其实这是一种空间换时间的做法</strong></p><p>如果堆大小扩展的不多，那么对于前台应用很快就会用完，下次GC便会早早的到来，虽说现在只有一次暂停，但是仍然可能会带来性能问题。<br>引入multiplier之后，前台应用有了足够的堆空间，会延迟下次GC到来的时间，也可以理解为降低GC的频率。</p><p>画了一个堆大小调整图，针对delta处于min_free和max_free之间的情况<br><img src="http://blog.lihaizhou.top/ART_GC/ART_GC4.png" alt="图片"><br>堆空间调整过程明白了，那么下次GC触发阈值是如何计算出来的呢？</p><h4 id="GC触发阈值的计算"><a href="#GC触发阈值的计算" class="headerlink" title="GC触发阈值的计算"></a>GC触发阈值的计算</h4><p>下面我们将继续往下看，下次GC触发阈值在代码中指的是concurrent_start_bytes_。<br>当我们在Java中通过new分配对象时，VM会调用AllocObjectWithAllocator来执行真实的分配。<br>在每一次成功分配Java对象后，都会去检测是否需要进行下一次GC，这就是GcCauseBackground GC的触发时机。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">AllocObjectWithAllocator-&gt;CheckConcurrentGCForJava-&gt;ShouldConcurrentGCForJava</span><br></pre></td></tr></table></figure><p>关键代码<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">inline</span> <span class="keyword">bool</span> Heap::ShouldConcurrentGCForJava(</span><br><span class="line">    <span class="keyword">size_t</span> new_num_bytes_allocated) &#123;</span><br><span class="line">    <span class="comment">// For a Java allocation, we only check whether the number // of Java allocated bytes excceeds a threshold. </span></span><br><span class="line">    <span class="comment">// By not considering native allocation here, we (a) ensure that Java heap bounds are</span></span><br><span class="line">    <span class="comment">// maintained, and (b) reduce the cost of the check here.</span></span><br><span class="line">    <span class="keyword">return</span> new_num_bytes_allocated &gt;= concurrent_start_bytes_;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>触发的条件需要满足一个判断，就是最后一行代码new_num_bytes_allocated(所有已分配的字节数，包括此次新分配的对象) &gt;= concurrent_start_bytes_(下一次GC触发的阈值)，就请求一次新的GC。<br>new_num_bytes_alloated是当前分配时计算的，concurrent_start_bytes_是上次GC结束时计算的。</p><h5 id="更新target-footprint-值"><a href="#更新target-footprint-值" class="headerlink" title="更新target_footprint_ 值"></a>更新target_footprint_ 值</h5><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (!ignore_target_footprint_) &#123;</span><br><span class="line">    SetIdealFootprint(target_size);</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">void</span> Heap::SetIdealFootprint(<span class="keyword">size_t</span> target_footprint) &#123;</span><br><span class="line">   <span class="keyword">if</span> (target_footprint &gt; GetMaxMemory()) &#123;</span><br><span class="line">       VLOG(gc) &lt;&lt; <span class="string">"Clamp target GC heap from "</span> &lt;&lt; PrettySize(target_footprint) &lt;&lt; <span class="string">" to "</span></span><br><span class="line">       &lt;&lt; PrettySize(GetMaxMemory());</span><br><span class="line">       target_footprint = GetMaxMemory();</span><br><span class="line">   &#125;</span><br><span class="line">   target_footprint_.store(target_footprint, <span class="built_in">std</span>::memory_order_relaxed);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>存储target_size的值，并通过target_size更新target_footprint_ 的值</p><h5 id="concurrent-start-bytes"><a href="#concurrent-start-bytes" class="headerlink" title="concurrent_start_bytes_"></a>concurrent_start_bytes_</h5><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Minimum amount of remaining bytes before a concurrent GC is triggered.</span></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">constexpr</span> <span class="keyword">size_t</span> kMinConcurrentRemainingBytes = <span class="number">128</span> * KB;</span><br><span class="line"><span class="keyword">static</span> <span class="keyword">constexpr</span> <span class="keyword">size_t</span> kMaxConcurrentRemainingBytes = <span class="number">512</span> * KB;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (IsGcConcurrent()) &#123;</span><br><span class="line">    <span class="keyword">const</span> <span class="keyword">uint64_t</span> freed_bytes = current_gc_iteration_.GetFreedBytes() +</span><br><span class="line">    current_gc_iteration_.GetFreedLargeObjectBytes() +</span><br><span class="line">    current_gc_iteration_.GetFreedRevokeBytes();</span><br><span class="line">    <span class="comment">// Records the number of bytes allocated at the time of GC finish,excluding the number of</span></span><br><span class="line">    <span class="comment">// bytes allocated during GC.</span></span><br><span class="line">    num_bytes_alive_after_gc_ = UnsignedDifference(bytes_allocated_before_gc, freed_bytes);</span><br><span class="line">    <span class="comment">// Bytes allocated will shrink by freed_bytes after the GC runs, so if we want to figure out</span></span><br><span class="line">    <span class="comment">// how many bytes were allocated during the GC we need to add freed_bytes back on.</span></span><br><span class="line">    <span class="comment">// Almost always bytes_allocated + freed_bytes &gt;= bytes_allocated_before_gc.</span></span><br><span class="line">    <span class="keyword">const</span> <span class="keyword">size_t</span> bytes_allocated_during_gc =</span><br><span class="line">          UnsignedDifference(bytes_allocated + freed_bytes, bytes_allocated_before_gc);</span><br><span class="line">    <span class="comment">// Calculate when to perform the next ConcurrentGC.</span></span><br><span class="line">    <span class="comment">// Estimate how many remaining bytes we will have when we need to start the next GC.</span></span><br><span class="line">    <span class="keyword">size_t</span> remaining_bytes = bytes_allocated_during_gc;</span><br><span class="line">    remaining_bytes = <span class="built_in">std</span>::min(remaining_bytes, kMaxConcurrentRemainingBytes);</span><br><span class="line">    remaining_bytes = <span class="built_in">std</span>::max(remaining_bytes, kMinConcurrentRemainingBytes);</span><br><span class="line">    <span class="keyword">size_t</span> target_footprint = target_footprint_.load(<span class="built_in">std</span>::memory_order_relaxed);</span><br><span class="line">    <span class="keyword">if</span> (UNLIKELY(remaining_bytes &gt; target_footprint)) &#123;</span><br><span class="line">       <span class="comment">// A never going to happen situation that from the estimated allocation rate we will exceed</span></span><br><span class="line">      <span class="comment">// the applications entire footprint with the given estimated allocation rate. Schedul</span></span><br><span class="line">      <span class="comment">// another GC nearly straight away.</span></span><br><span class="line">      remaining_bytes = <span class="built_in">std</span>::min(kMinConcurrentRemainingBytes, target_footprint);</span><br><span class="line">     &#125;</span><br><span class="line">     DCHECK_LE(target_footprint_.load(<span class="built_in">std</span>::memory_order_relaxed), GetMaxMemory());</span><br><span class="line">     <span class="comment">// Start a concurrent GC when we get close to the estimated remaining bytes. When the</span></span><br><span class="line">     <span class="comment">// allocation rate is very high, remaining_bytes could tell us that we should start a GC</span></span><br><span class="line">     <span class="comment">// right away.</span></span><br><span class="line">     concurrent_start_bytes_ = <span class="built_in">std</span>::max(target_footprint - remaining_bytes, bytes_allocated);</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure><p>整个处理过程大致流程如下：</p><ol><li>num_bytes_alive_after_gc_此次GC结束后已分配的字节数，不包括GC期间新分配的字节数</li><li>bytes_allocated_during_gcGC<br>期间分配的字节数，计算很简单，通过bytes_allocated_before_gc减去freed_bytes就 是新增的，因为由于并发的缘故，分配和回收很可能是同步进行的，这个思想将贯穿整个GC机制。</li><li>remaining_bytes这个值指的是gc期间新分配对象的大小。<br>同样的，对于预留值也有范围限制，限制在128 <em> KB到512 </em> KB范围之间之间。</li></ol><p>最后再来看这个计算公式concurrent_start_bytes_ =<br><code>std::max(target_footprint - remaining_bytes, bytes_allocated);</code></p><p>之所以需要用target_footprint减去remaining_bytes，是因为在理论意义上，target_footprint_代表当前堆的最大可分配字节数。而由于是同步GC，回收的过程中可能会有其他线程依然在分配。<br>所以为了保证下次GC的顺利进行，需要将这段时间分配的内存空间预留出来。<br>总结下concurrent_start_bytes_ 的值计算过程:<br><strong>用heap resize之后计算出的target_size减去remaining_bytes后的数值，得出来的concurrent_start_bytes_ 作为下次是否触发GC的阈值。</strong></p><h5 id="Systrace角度看GC"><a href="#Systrace角度看GC" class="headerlink" title="Systrace角度看GC"></a>Systrace角度看GC</h5><p>我们平时工作中，分析GC性能问题用到最多的便是Systrace<br>下面抓取一次抖音包含启动过程的Systrace，看下GC情况以及堆大小的变化情况。<br>在启动过程中，堆的大小持续增长<br><img src="http://blog.lihaizhou.top/ART_GC/ART_GC5.png" alt="图片"></p><p>启动结束后约1s左右，有一次Background young concurrent copying GC<br><img src="http://blog.lihaizhou.top/ART_GC/ART_GC6.png" alt="图片"></p><p>可以看到heap size从59M下降到约11M<br>此时处于前台很快数值上升，并触发Background concurrent copying GC<br><img src="http://blog.lihaizhou.top/ART_GC/ART_GC7.png" alt="图片"></p><p>这两次GC类型都是并发GC，以界面显示后的第一次Background young concurrent copying GC为例<br>从Systrace大致可以看到其流程是<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">InitializePhase(995us692ns)-&gt;CopyingPhase(84ms258us385ns) -&gt;ReclaimPhase(11ms 166us 769ns)</span><br></pre></td></tr></table></figure></p><p>对应到代码中大致流程如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CollectGarbageInternal---&gt; collector---&gt;Run(开始真正的GC流程)---&gt; RunPhases(GC实际处理)</span><br></pre></td></tr></table></figure></p><h4 id="参数修改策略"><a href="#参数修改策略" class="headerlink" title="参数修改策略"></a>参数修改策略</h4><p>通过上面的梳理，我们知道GC的触发以及堆大小的调整会受到max_free_，min_free_，kDefaultTargetUtilization 这些参数影响，这些参数其实有系统属性暴露在外，厂商可以根据实际的需求进行修改。<br>以max_free为例，看了下手头的4G手机项目上默认值是8M，从前面的梳理我们知道，如果增大max_free会导致应用的预留空闲内存增大，相应的应用占用内存大小也会增大，这是带来的弊端。<br>但是好处显而易见，GC的频率会降低，性能会有所提升，所以这是一个权衡的策略。</p><p>如果项目上实测发现GC频繁触发，可以适当的增大max_free的值再进行测试，谷歌的建议是不要修改，除非有大量可靠的测试数据做支撑说明修改后的参数确实有提升。</p><p>下面是我手头4G内存手机打印的参数<br><img src="http://blog.lihaizhou.top/ART_GC/ART_GC8.png" alt="图片"></p><h4 id="写在最后"><a href="#写在最后" class="headerlink" title="写在最后"></a>写在最后</h4><p>至此，本文结合Android S源码和systrace对ART GC的基础知识介绍完毕。<br>在书写本文期间，阅读了网上一些优秀的资源，如老罗，芦航，oppo内核等人书写的ART技术文章，受益匪浅，在此感谢这些技术大咖的无私分享。<br>最后说两句，GC对Android整机性能表现起到至关重要的影响，关于ART GC的性能一直是Google在主导优化，同时也是SOC厂商，各家手机厂商长期以来一直努力优化的方向。<br>我们希望通过对ART GC领域的持续研究，为后面的实际问题分析乃至GC机制的优化修改提供技术支撑。</p><h4 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h4><ol><li>ART运行时Foreground GC和Background GC切换过程分<br><a href="https://www.kancloud.cn/alex_wsc/androids/472237" target="_blank" rel="noopener">https://www.kancloud.cn/alex_wsc/androids/472237</a></li><li>Android性能优化（31）—虚拟机调优<br><a href="https://blog.csdn.net/zhangbijun1230/article/details/79996702" target="_blank" rel="noopener">https://blog.csdn.net/zhangbijun1230/article/details/79996702</a></li><li>ART虚拟机 | GC的触发时机和条件<br><a href="https://juejin.cn/post/6875678394332217357" target="_blank" rel="noopener">https://juejin.cn/post/6875678394332217357</a></li></ol><hr><p>时间真快，不知不觉今天已经周三了，印象中上次周三的时候还是在上周</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h4&gt;&lt;p&gt;本文是GC系列文章的首篇，主要为下一篇《第三视角: 一个ART GC优化的故事》文章做铺垫。&lt;br&gt;本文将根据下面的大纲，简单的介绍下GC相
      
    
    </summary>
    
      <category term="ART" scheme="http://lihaizhou.top/categories/ART/"/>
    
    
  </entry>
  
  <entry>
    <title>对进程压缩消费Zram速度的优化</title>
    <link href="http://lihaizhou.top/2021/10/16/%E5%AF%B9%E8%BF%9B%E7%A8%8B%E5%8E%8B%E7%BC%A9%E6%B6%88%E8%B4%B9Zram%E9%80%9F%E5%BA%A6%E7%9A%84%E4%BC%98%E5%8C%96/"/>
    <id>http://lihaizhou.top/2021/10/16/对进程压缩消费Zram速度的优化/</id>
    <published>2021-10-16T02:32:08.000Z</published>
    <updated>2021-10-16T04:59:55.924Z</updated>
    
    <content type="html"><![CDATA[<h4 id="从全局看Zram"><a href="#从全局看Zram" class="headerlink" title="从全局看Zram"></a>从全局看Zram</h4><p><img src="http://blog.lihaizhou.top/%E8%BF%9B%E7%A8%8B%E5%8E%8B%E7%BC%A9%E6%B6%88%E8%80%97Zram/gaitubao_Zram.png" alt="Zram的消费"></p><h4 id="修改演变历程"><a href="#修改演变历程" class="headerlink" title="修改演变历程"></a>修改演变历程</h4><p><img src="http://blog.lihaizhou.top/%E8%BF%9B%E7%A8%8B%E5%8E%8B%E7%BC%A9%E6%B6%88%E8%80%97Zram/shuiyin_yanbian.png" alt="进程压缩对Zram的消耗修改时间线"></p><h4 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h4><p>当前的修改方案可能不是最优方案，但是解决了之前遇到的实际问题，后面如果遇到新的问题可能还会进行调整。</p><hr><p>Have a good day~</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;从全局看Zram&quot;&gt;&lt;a href=&quot;#从全局看Zram&quot; class=&quot;headerlink&quot; title=&quot;从全局看Zram&quot;&gt;&lt;/a&gt;从全局看Zram&lt;/h4&gt;&lt;p&gt;&lt;img src=&quot;http://blog.lihaizhou.top/%E8%BF%9B%
      
    
    </summary>
    
      <category term="内存" scheme="http://lihaizhou.top/categories/%E5%86%85%E5%AD%98/"/>
    
    
  </entry>
  
  <entry>
    <title>AMS锁严重竞争导致的整机卡顿</title>
    <link href="http://lihaizhou.top/2021/09/18/AMS%E9%94%81%E4%B8%A5%E9%87%8D%E7%AB%9E%E4%BA%89%E5%AF%BC%E8%87%B4%E7%9A%84%E6%95%B4%E6%9C%BA%E5%8D%A1%E9%A1%BF/"/>
    <id>http://lihaizhou.top/2021/09/18/AMS锁严重竞争导致的整机卡顿/</id>
    <published>2021-09-18T02:37:49.000Z</published>
    <updated>2021-10-16T05:13:46.925Z</updated>
    
    <content type="html"><![CDATA[<h5 id="日志抓取"><a href="#日志抓取" class="headerlink" title="日志抓取"></a>日志抓取</h5><p>在问题机器上抓了一份Systrace<br>1.操作步骤: 进入设置界面滑动再退出<br>2.问题现象: 进入设置出现较长时间白屏，退出时有拖影，下拉状态栏尤为卡顿，解锁亮屏很慢。</p><h5 id="问题分析"><a href="#问题分析" class="headerlink" title="问题分析"></a>问题分析</h5><p>从下图可以看到进入设置时，Resume耗时近400ms，主要耗费在等binder上<br><img src="http://blog.lihaizhou.top/AMS_lock/broadcast1.png" alt=""><br>来到对端1188_19线程所在区域，看下这个时间点1188_19在做什么操作？<br><img src="http://blog.lihaizhou.top/AMS_lock/broadcast2.png" alt=""><br>1188_19是SystemServer中的线程，从上图可以看出，它在等AMS锁<br>到这里大致梳理如下<br>1.进入设置应用走到onResume环节时，调用到AMS的registerReceiverWithFeature注册广播，这是应用启动过程中很常见的操作，但是此时registerReceiverWithFeature执行操作被block了，因为执行registerReceiverWithFeature需要申请到AMS锁才行。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> Intent <span class="title">registerReceiverWithFeature</span><span class="params">(IApplicationThread caller, String callerPackage,</span></span></span><br><span class="line"><span class="function"><span class="params">   String callerFeatureId, IIntentReceiver receiver, IntentFilter filter,</span></span></span><br><span class="line"><span class="function"><span class="params">   String permission, <span class="keyword">int</span> userId, <span class="keyword">int</span> flags)</span> </span>&#123;</span><br><span class="line">   <span class="comment">//省略部分代码</span></span><br><span class="line">   <span class="keyword">boolean</span> instantApp;</span><br><span class="line">   <span class="keyword">synchronized</span>(<span class="keyword">this</span>) &#123;</span><br><span class="line">      <span class="keyword">if</span> (caller != <span class="keyword">null</span>) &#123;</span><br><span class="line">          callerApp = getRecordForAppLocked(caller);</span><br><span class="line">          <span class="keyword">if</span> (callerApp == <span class="keyword">null</span>) &#123;</span><br><span class="line">              <span class="keyword">throw</span> <span class="keyword">new</span> SecurityException(</span><br><span class="line">                  <span class="string">"Unable to find app for caller "</span> + caller</span><br><span class="line">                      + <span class="string">" (pid="</span> + Binder.getCallingPid()</span><br><span class="line">                      + <span class="string">") when registering receiver "</span> + receiver);</span><br><span class="line">          &#125;</span><br><span class="line">          <span class="comment">//省略部分代码</span></span><br><span class="line">      &#125;</span><br><span class="line">    <span class="comment">//省略部分代码</span></span><br></pre></td></tr></table></figure><p>2.此时Settings的registerReceiverWithFeature在等ActivityManagerService#finishReceiver释放锁，但其实ActivityManagerService#finishReceiver本身也是在等锁，锁在1188_6这个线程手中。<br>图中有一处waiters=6说明还有其它六处加上这次调用共计7处在等AMS的锁<br>纵观整个应用操作片段，发现很多地方都在等AMS锁，这也说明了为何系统会全局卡顿。</p><p>看下真正持有锁的1188_6这个线程,这个线程持有锁的这段时间内，大部分时候都是running状态<br><img src="http://blog.lihaizhou.top/AMS_lock/broadcast3.png" alt=""><br>全局搜索了下在一分钟不到的时间内触发了197次，而且单次基本都在200ms之久。<br><img src="http://blog.lihaizhou.top/AMS_lock/broadcast4.png" alt=""><br>为此对比了下正常情况下的Systrace，两分钟的时间内共触发14次，平均一分钟7次，且每次updateOomAdj_finishReceiver执行时间都不超过1ms<br><img src="http://blog.lihaizhou.top/AMS_lock/broadcast5.png" alt=""></p><p>到这里大概整理下<br>1.<strong>为何updateOomAdj_finishReceiver会调用这么频繁?</strong><br>  updateOomAdj_finishReceiver是在广播处理结束后会触发调用，问题机器上一分钟调用197次，正常情况下一分钟调用次数是个位数.<br>2.<strong>为何updateOomAdj_finishReceiver耗时这么久?</strong><br>  单次执行都在200ms左右，这也意味着每次持有AMS锁大概200ms，也就意味着一分钟的时间finishReceiver持有AMS锁时间高达39s，这也解释了从Systrace看很多地方都在等AMS锁。<br>  测试了下正常情况下，updateOomAdj_finishReceiver单次执行时间最长一般不会超过1ms</p><p>下面先从广播来源分析，updateOomAdj_finishReceiver触发频繁的原因</p><h6 id="频繁触发原因"><a href="#频繁触发原因" class="headerlink" title="频繁触发原因"></a>频繁触发原因</h6><p>以导致设置应用resume耗时严重的这次updateOomAdj_finishReceiver为例<br><img src="http://blog.lihaizhou.top/AMS_lock/broadcast6.png" alt=""><br>1416对应的是SystemUI中线程，直接来到SystemServer区域看下广播部分<br><img src="http://blog.lihaizhou.top/AMS_lock/broadcast7.png" alt=""><br>再从全局来看<br><img src="http://blog.lihaizhou.top/AMS_lock/broadcast8.png" alt=""><br>可以看到com.android.providers.media.module以及SystemUI这两个模块在交替不间断的发送android.intent.action.MEDIA_SCANNER_SCAN_FILE这个广播，查看代码得知是com.android.providers.media.module这个模块处理扫描文件事务后会发送MEDIA_SCANNER_SCAN_FILE这个广播给SystemUI，SystemUI收到这个广播进行一系列的业务处理，然后再次发送MEDIA_SCANNER_SCAN_FILE这个广播出来。<br>这种业务设计肯定是不合理的，这里暂不继续讨论这种做法的缘由。</p><h6 id="单次处理耗时"><a href="#单次处理耗时" class="headerlink" title="单次处理耗时"></a>单次处理耗时</h6><p><img src="http://blog.lihaizhou.top/AMS_lock/broadcast9.png" alt=""><br>从上图可以看到，问题发生时，SystemUI模块中单次处理该模块耗时达到1s多，这也和问题机器上SystemUI下拉栏滑动极其卡顿能够对应上。<br>结论: SystemUI主线程中广播处理耗时导致滑动很卡顿</p><h5 id="问题结论"><a href="#问题结论" class="headerlink" title="问题结论"></a>问题结论</h5><p>主要由于如下两点原因导致:<br>1.SystemUI中不合理的高频广播，导致AMS@finishReceiver触发频繁并持有AMS锁，造成了全局AMS锁争抢极其严重。<br>2.SystemUI主线程中单次处理广播耗时较长，加剧了卡顿的现象。</p><p>PS: SystemUI这个模块比较特殊，它不像其他应用模块。对于应用模块而言，即便是一直收发广播，卡顿也只是会局限在这个应用操作环节中，不会影响到其他模块。但是SystemUI就不同了，它是可以一直运行着，并且此时你可以操作其他任何应用。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h5 id=&quot;日志抓取&quot;&gt;&lt;a href=&quot;#日志抓取&quot; class=&quot;headerlink&quot; title=&quot;日志抓取&quot;&gt;&lt;/a&gt;日志抓取&lt;/h5&gt;&lt;p&gt;在问题机器上抓了一份Systrace&lt;br&gt;1.操作步骤: 进入设置界面滑动再退出&lt;br&gt;2.问题现象: 进入设置出现较长时
      
    
    </summary>
    
      <category term="性能" scheme="http://lihaizhou.top/categories/%E6%80%A7%E8%83%BD/"/>
    
    
  </entry>
  
  <entry>
    <title>GC超时导致的后台应用崩溃问题分析</title>
    <link href="http://lihaizhou.top/2021/09/08/GC%E8%B6%85%E6%97%B6%E5%AF%BC%E8%87%B4%E7%9A%84%E5%90%8E%E5%8F%B0%E5%BA%94%E7%94%A8%E5%B4%A9%E6%BA%83%E9%97%AE%E9%A2%98%E5%88%86%E6%9E%90/"/>
    <id>http://lihaizhou.top/2021/09/08/GC超时导致的后台应用崩溃问题分析/</id>
    <published>2021-09-08T11:55:06.000Z</published>
    <updated>2021-10-16T05:21:11.556Z</updated>
    
    <content type="html"><![CDATA[<h3 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h3><p>这个问题之所以会拿出来仔细分析，一方面是因为这个问题不是简单的应用崩溃而是框架层的报错，另一方面是因为希望通过这个问题梳理下后台GC的超时检测机制怎样的，这样我们后面在应用层如果重写<code>finalize</code>方法回收时会考虑的更加全面点。</p><h3 id="问题背景"><a href="#问题背景" class="headerlink" title="问题背景"></a>问题背景</h3><p>复现概率: 偶现<br>问题版本: <code>Android R</code><br>问题现象: 处于微信界面，突然弹出王者荣耀停止运行</p><h3 id="初步分析"><a href="#初步分析" class="headerlink" title="初步分析"></a>初步分析</h3><p>拿到问题日志后，先看下报错的堆栈<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">09</span>-<span class="number">02</span> <span class="number">20</span>:<span class="number">53</span>:<span class="number">26.679</span>  <span class="number">2073</span>  <span class="number">2089</span> E AndroidRuntime: FATAL EXCEPTION: FinalizerWatchdogDaemon</span><br><span class="line"><span class="number">09</span>-<span class="number">02</span> <span class="number">20</span>:<span class="number">53</span>:<span class="number">26.679</span>  <span class="number">2073</span>  <span class="number">2089</span> E AndroidRuntime: Process: com.tencent.tmgp.sgame:xg_vip_service, PID: <span class="number">2073</span></span><br><span class="line"><span class="number">09</span>-<span class="number">02</span> <span class="number">20</span>:<span class="number">53</span>:<span class="number">26.679</span>  <span class="number">2073</span>  <span class="number">2089</span> E AndroidRuntime: java.util.concurrent.TimeoutException: android.database.BulkCursorToCursorAdaptor.finalize() timed out after <span class="number">10</span> seconds</span><br><span class="line"><span class="comment">//省略部分堆栈</span></span><br><span class="line"><span class="number">09</span>-<span class="number">02</span> <span class="number">20</span>:<span class="number">53</span>:<span class="number">26.679</span>  <span class="number">2073</span>  <span class="number">2089</span> E AndroidRuntime:at android.database.AbstractCursor.finalize(AbstractCursor.java:<span class="number">524</span>)</span><br><span class="line"><span class="number">09</span>-<span class="number">02</span> <span class="number">20</span>:<span class="number">53</span>:<span class="number">26.679</span>  <span class="number">2073</span>  <span class="number">2089</span> E AndroidRuntime:at java.lang.Daemons$FinalizerDaemon.doFinalize(Daemons.java:<span class="number">291</span>)</span><br><span class="line"><span class="number">09</span>-<span class="number">02</span> <span class="number">20</span>:<span class="number">53</span>:<span class="number">26.679</span>  <span class="number">2073</span>  <span class="number">2089</span> E AndroidRuntime:at java.lang.Daemons$FinalizerDaemon.runInternal(Daemons.java:<span class="number">278</span>)</span><br></pre></td></tr></table></figure></p><p>单单从这段堆栈看的话，<code>BulkCursorToCursorAdaptor</code>执行<code>finalize</code>超过了10s，导致<code>FinalizerWatchdogDaemon</code>报错，<code>FinalizerWatchdogDaemon</code>字面上看像是监测回收超时的守护线程。<br>看下<code>FinalizerWatchdogDaemon</code>代码中的作用解释<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * The watchdog exits the VM if the finalizer ever gets stuck. We consider</span></span><br><span class="line"><span class="comment"> * the finalizer to be stuck if it spends more than MAX_FINALIZATION_MILLIS</span></span><br><span class="line"><span class="comment"> * on one instance.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">FinalizerWatchdogDaemon</span> <span class="keyword">extends</span> <span class="title">Daemon</span> </span>&#123;</span><br><span class="line">    <span class="meta">@UnsupportedAppUsage</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> FinalizerWatchdogDaemon INSTANCE = <span class="keyword">new</span> FinalizerWatchdogDaemon();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">boolean</span> needToWork = <span class="keyword">true</span>;  <span class="comment">// Only accessed in synchronized methods.</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">long</span> finalizerTimeoutNs = <span class="number">0</span>;  <span class="comment">// Lazily initialized.</span></span><br><span class="line"></span><br><span class="line">    FinalizerWatchdogDaemon() &#123;</span><br><span class="line">        <span class="keyword">super</span>(<span class="string">"FinalizerWatchdogDaemon"</span>);</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure></p><p>简单解释下就是：如果对象的<code>finalize</code>出现阻塞超时了会导致进程退出</p><p>这个问题中对应的是数据库的关闭，当然也可以发生在其它场景下，只要重写了成员函数<code>finalize</code>的对象都有可能会遇到这个问题，所以如果再遇到GC超时的报错，报错堆栈<code>AndroidRuntime:at java.lang.Daemons$</code>上面的内容可能会不一样。<br><strong>那么对于重写了成员函数<code>finalize</code>的对象，当它们被GC决定要被回收时，会立刻回收吗？</strong><br>其实不会马上被回收，而是被放入到一个队列中，等待<code>FinalizerDaemon</code>守护线程去调用它们的成员函数<code>finalize</code>后再被回收。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * This heap management thread moves elements from the garbage collector's</span></span><br><span class="line"><span class="comment"> * pending list to the managed reference queue.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">ReferenceQueueDaemon</span> <span class="keyword">extends</span> <span class="title">Daemon</span> </span>&#123;</span><br><span class="line">    <span class="meta">@UnsupportedAppUsage</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> ReferenceQueueDaemon INSTANCE = <span class="keyword">new</span> ReferenceQueueDaemon();</span><br><span class="line"></span><br><span class="line">    ReferenceQueueDaemon() &#123;</span><br><span class="line">        <span class="keyword">super</span>(<span class="string">"ReferenceQueueDaemon"</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span> <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">runInternal</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">while</span> (isRunning()) &#123;</span><br><span class="line">            Reference&lt;?&gt; list;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                <span class="keyword">synchronized</span> (ReferenceQueue.class) &#123;</span><br><span class="line">                    <span class="keyword">while</span> (ReferenceQueue.unenqueued == <span class="keyword">null</span>) &#123;</span><br><span class="line">                        ReferenceQueue.class.wait();</span><br><span class="line">                    &#125;</span><br><span class="line">                    list = ReferenceQueue.unenqueued;</span><br><span class="line">                    ReferenceQueue.unenqueued = <span class="keyword">null</span>;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">                <span class="keyword">continue</span>;</span><br><span class="line">            &#125; <span class="keyword">catch</span> (OutOfMemoryError e) &#123;</span><br><span class="line">                <span class="keyword">continue</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            ReferenceQueue.enqueuePending(list);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="超时阈值"><a href="#超时阈值" class="headerlink" title="超时阈值"></a>超时阈值</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// This used to be final. IT IS NOW ONLY WRITTEN. We now update it when we look at the command</span></span><br><span class="line"><span class="comment">// line argument, for the benefit of mis-behaved apps that might read it.  SLATED FOR REMOVAL.</span></span><br><span class="line"><span class="comment">// There is no reason to use this: Finalizers should not rely on the value. If a finalizer takes</span></span><br><span class="line"><span class="comment">// appreciable time, the work should be done elsewhere.  Based on disassembly of Daemons.class,</span></span><br><span class="line"><span class="comment">// the value is effectively inlined, so changing the field never did have an effect.</span></span><br><span class="line"><span class="comment">// DO NOT USE. FOR ANYTHING. THIS WILL BE REMOVED SHORTLY.</span></span><br><span class="line"><span class="meta">@UnsupportedAppUsage</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">long</span> MAX_FINALIZE_NANOS = <span class="number">10L</span> * <span class="number">1000</span> * NANOS_PER_MILLI;</span><br></pre></td></tr></table></figure><p>注释中对于该值的说明是它很快将被移除，实际这个值在代码中并没有起到真正的作用了，更新它的值是为了方便在外边读取到。<br>真正的超时阈值是通过<code>VMRuntime.getFinalizerTimeoutMs</code>获取，默认值是10s.<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">finalizer_timeout_ms_ = runtime_options.GetOrDefault(Opt::FinalizerTimeoutMs);</span><br><span class="line">RUNTIME_OPTIONS_KEY (unsigned <span class="keyword">int</span>, FinalizerTimeoutMs, <span class="number">10000</span>u)</span><br></pre></td></tr></table></figure></p><h3 id="超时检测"><a href="#超时检测" class="headerlink" title="超时检测"></a>超时检测</h3><p>通过watchdog机制检测<code>finalizer</code>在超时时间内有没有成功析构回收对象<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"> * The watchdog exits the VM <span class="keyword">if</span> the finalizer ever gets stuck. We consider</span><br><span class="line"> * the finalizer to be stuck <span class="keyword">if</span> it spends more than MAX_FINALIZATION_MILLIS</span><br><span class="line"> * on one instance.</span><br><span class="line"> */</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">FinalizerWatchdogDaemon</span> <span class="keyword">extends</span> <span class="title">Daemon</span> </span>&#123;</span><br><span class="line">    <span class="meta">@UnsupportedAppUsage</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> FinalizerWatchdogDaemon INSTANCE = <span class="keyword">new</span> FinalizerWatchdogDaemon();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">boolean</span> needToWork = <span class="keyword">true</span>;  <span class="comment">// Only accessed in synchronized methods.</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">long</span> finalizerTimeoutNs = <span class="number">0</span>;  <span class="comment">// Lazily initialized.</span></span><br><span class="line"></span><br><span class="line">    FinalizerWatchdogDaemon() &#123;</span><br><span class="line">        <span class="keyword">super</span>(<span class="string">"FinalizerWatchdogDaemon"</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span> <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">runInternal</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">while</span> (isRunning()) &#123;</span><br><span class="line">            <span class="keyword">if</span> (!sleepUntilNeeded()) &#123; (<span class="number">1</span>)</span><br><span class="line">                <span class="comment">// We have been interrupted, need to see if this daemon has been stopped.</span></span><br><span class="line">                <span class="keyword">continue</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">final</span> Object finalizing = waitForFinalization();(<span class="number">2</span>)</span><br><span class="line">            <span class="keyword">if</span> (finalizing != <span class="keyword">null</span> &amp;&amp; !VMDebug.isDebuggerConnected()) &#123;</span><br><span class="line">                finalizerTimedOut(finalizing);(<span class="number">3</span>)</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure></p><h4 id="Step1-GC前的检查"><a href="#Step1-GC前的检查" class="headerlink" title="Step1 GC前的检查"></a>Step1 GC前的检查</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">        * Notify daemon that it's OK to sleep until notified that something is ready to be</span></span><br><span class="line"><span class="comment">        * finalized.</span></span><br><span class="line"><span class="comment">        */</span></span><br><span class="line">       <span class="function"><span class="keyword">private</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">goToSleep</span><span class="params">()</span> </span>&#123;</span><br><span class="line">           needToWork = <span class="keyword">false</span>;</span><br><span class="line">       &#125;</span><br><span class="line"></span><br><span class="line">       <span class="comment">/**</span></span><br><span class="line"><span class="comment">        * Notify daemon that there is something ready to be finalized.</span></span><br><span class="line"><span class="comment">        */</span></span><br><span class="line">       <span class="function"><span class="keyword">private</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">wakeUp</span><span class="params">()</span> </span>&#123;</span><br><span class="line">           needToWork = <span class="keyword">true</span>;</span><br><span class="line">           notify();</span><br><span class="line">       &#125;</span><br></pre></td></tr></table></figure><p>开启回收之前，<code>needToWork</code>会被置为true，此时<code>sleepUntilNeeded</code>返回的是true，所以线程不会<code>wait</code><br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Override</span> <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">runInternal</span><span class="params">()</span> </span>&#123;</span><br><span class="line">           <span class="comment">// This loop may be performance critical, since we need to keep up with mutator</span></span><br><span class="line">           <span class="comment">// generation of finalizable objects.</span></span><br><span class="line">           <span class="comment">// We minimize the amount of work we do per finalizable object. For example, we avoid</span></span><br><span class="line">           <span class="comment">// reading the current time here, since that involves a kernel call per object.  We</span></span><br><span class="line">           <span class="comment">// limit fast path communication with FinalizerWatchDogDaemon to what's unavoidable: A</span></span><br><span class="line">           <span class="comment">// non-volatile store to communicate the current finalizable object, e.g. for</span></span><br><span class="line">           <span class="comment">// reporting, and a release store (lazySet) to a counter.</span></span><br><span class="line">           <span class="comment">// We do stop the  FinalizerWatchDogDaemon if we have nothing to do for a</span></span><br><span class="line">           <span class="comment">// potentially extended period.  This prevents the device from waking up regularly</span></span><br><span class="line">           <span class="comment">// during idle times.</span></span><br><span class="line"></span><br><span class="line">           <span class="comment">// Local copy of progressCounter; saves a fence per increment on ARM and MIPS.</span></span><br><span class="line">           <span class="keyword">int</span> localProgressCounter = progressCounter.get();</span><br><span class="line"></span><br><span class="line">           <span class="keyword">while</span> (isRunning()) &#123;</span><br><span class="line">               <span class="keyword">try</span> &#123;</span><br><span class="line">                   <span class="comment">// Use non-blocking poll to avoid FinalizerWatchdogDaemon communication</span></span><br><span class="line">                   <span class="comment">// when busy.</span></span><br><span class="line">                   FinalizerReference&lt;?&gt; finalizingReference = (FinalizerReference&lt;?&gt;)queue.poll();</span><br><span class="line">                   <span class="keyword">if</span> (finalizingReference != <span class="keyword">null</span>) &#123;</span><br><span class="line">                       finalizingObject = finalizingReference.get();</span><br><span class="line">                       progressCounter.lazySet(++localProgressCounter);</span><br><span class="line">                   &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                       finalizingObject = <span class="keyword">null</span>;</span><br><span class="line">                       progressCounter.lazySet(++localProgressCounter);</span><br><span class="line">                       <span class="comment">// Slow path; block.</span></span><br><span class="line">                       FinalizerWatchdogDaemon.INSTANCE.goToSleep();</span><br><span class="line">                       finalizingReference = (FinalizerReference&lt;?&gt;)queue.remove();</span><br><span class="line">                       finalizingObject = finalizingReference.get();</span><br><span class="line">                       progressCounter.set(++localProgressCounter);</span><br><span class="line">                       <span class="comment">//回收之前先唤醒看门狗线程</span></span><br><span class="line">                       FinalizerWatchdogDaemon.INSTANCE.wakeUp();</span><br><span class="line">                   &#125;</span><br><span class="line">                   <span class="comment">//开始回收的流程</span></span><br><span class="line">                   doFinalize(finalizingReference);</span><br><span class="line">               &#125; <span class="keyword">catch</span> (InterruptedException ignored) &#123;</span><br><span class="line">               &#125; <span class="keyword">catch</span> (OutOfMemoryError ignored) &#123;</span><br><span class="line">               &#125;</span><br><span class="line">           &#125;</span><br><span class="line">       &#125;</span><br></pre></td></tr></table></figure></p><p>如果此时线程处于<code>wait</code>，被中断了或者有<code>OOME</code>发生时，这个时候回到开头判断下<code>isRunning()</code>，也就是看下回收对象这个线程是否为空，如果该线程为空的话，这个循环体就没有必要再继续执行下去了。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">        * Wait until something is ready to be finalized.</span></span><br><span class="line"><span class="comment">        * Return false if we have been interrupted</span></span><br><span class="line"><span class="comment">        * See also http://code.google.com/p/android/issues/detail?id=22778.</span></span><br><span class="line"><span class="comment">        */</span></span><br><span class="line">       <span class="function"><span class="keyword">private</span> <span class="keyword">synchronized</span> <span class="keyword">boolean</span> <span class="title">sleepUntilNeeded</span><span class="params">()</span> </span>&#123;</span><br><span class="line">           <span class="keyword">while</span> (!needToWork) &#123;</span><br><span class="line">               <span class="keyword">try</span> &#123;</span><br><span class="line">                   wait();</span><br><span class="line">               &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">                   <span class="comment">// Daemon.stop may have interrupted us.</span></span><br><span class="line">                   <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">               &#125; <span class="keyword">catch</span> (OutOfMemoryError e) &#123;</span><br><span class="line">                   <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">               &#125;</span><br><span class="line">           &#125;</span><br><span class="line">           <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">       &#125;</span><br></pre></td></tr></table></figure></p><h4 id="Step2-等待GC完成"><a href="#Step2-等待GC完成" class="headerlink" title="Step2 等待GC完成"></a>Step2 等待GC完成</h4><p>这一步是等待回收结束的过程，这个睡眠过程中如果被中断，说明在这个周期内完成了析构，直接返回null<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">        * Return an object that took too long to finalize or return null.</span></span><br><span class="line"><span class="comment">        * Wait VMRuntime.getFinalizerTimeoutMs.  If the FinalizerDaemon took essentially the</span></span><br><span class="line"><span class="comment">        * whole time processing a single reference, return that reference.  Otherwise return</span></span><br><span class="line"><span class="comment">        * null.  Only called from a single thread.</span></span><br><span class="line"><span class="comment">        */</span></span><br><span class="line">       <span class="function"><span class="keyword">private</span> Object <span class="title">waitForFinalization</span><span class="params">()</span> </span>&#123;</span><br><span class="line">           <span class="keyword">if</span> (finalizerTimeoutNs == <span class="number">0</span>) &#123;</span><br><span class="line">               finalizerTimeoutNs =</span><br><span class="line">                       NANOS_PER_MILLI * VMRuntime.getRuntime().getFinalizerTimeoutMs();</span><br><span class="line">               <span class="comment">// Temporary app backward compatibility. Remove eventually.</span></span><br><span class="line">               MAX_FINALIZE_NANOS = finalizerTimeoutNs;</span><br><span class="line">           &#125;</span><br><span class="line">           <span class="keyword">long</span> startCount = FinalizerDaemon.INSTANCE.progressCounter.get();</span><br><span class="line">           <span class="comment">// Avoid remembering object being finalized, so as not to keep it alive.</span></span><br><span class="line">           <span class="comment">//如果回收对象没有超时的话，这里会返回null</span></span><br><span class="line">           <span class="keyword">if</span> (!sleepForNanos(finalizerTimeoutNs)) &#123;</span><br><span class="line">               <span class="comment">// Don't report possibly spurious timeout if we are interrupted.</span></span><br><span class="line">               <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">           &#125;</span><br><span class="line">           <span class="keyword">if</span> (getNeedToWork() &amp;&amp; FinalizerDaemon.INSTANCE.progressCounter.get() == startCount) &#123;</span><br><span class="line">               <span class="comment">// We assume that only remove() and doFinalize() may take time comparable to</span></span><br><span class="line">               <span class="comment">// the finalizer timeout.</span></span><br><span class="line">               <span class="comment">// We observed neither the effect of the gotoSleep() nor the increment preceding a</span></span><br><span class="line">               <span class="comment">// later wakeUp. Any remove() call by the FinalizerDaemon during our sleep</span></span><br><span class="line">               <span class="comment">// interval must have been followed by a wakeUp call before we checked needToWork.</span></span><br><span class="line">               <span class="comment">// But then we would have seen the counter increment.  Thus there cannot have</span></span><br><span class="line">               <span class="comment">// been such a remove() call.</span></span><br><span class="line">               <span class="comment">// The FinalizerDaemon must not have progressed (from either the beginning or the</span></span><br><span class="line">               <span class="comment">// last progressCounter increment) to either the next increment or gotoSleep()</span></span><br><span class="line">               <span class="comment">// call.  Thus we must have taken essentially the whole finalizerTimeoutMs in a</span></span><br><span class="line">               <span class="comment">// single doFinalize() call.  Thus it's OK to time out.  finalizingObject was set</span></span><br><span class="line">               <span class="comment">// just before the counter increment, which preceded the doFinalize call.  Thus we</span></span><br><span class="line">               <span class="comment">// are guaranteed to get the correct finalizing value below, unless doFinalize()</span></span><br><span class="line">               <span class="comment">// just finished as we were timing out, in which case we may get null or a later</span></span><br><span class="line">               <span class="comment">// one.  In this last case, we are very likely to discard it below.</span></span><br><span class="line">               Object finalizing = FinalizerDaemon.INSTANCE.finalizingObject;</span><br><span class="line">               sleepForNanos(<span class="number">500</span> * NANOS_PER_MILLI);</span><br><span class="line">               <span class="comment">// Recheck to make it even less likely we report the wrong finalizing object in</span></span><br><span class="line">               <span class="comment">// the case which a very slow finalization just finished as we were timing out.</span></span><br><span class="line">               <span class="keyword">if</span> (getNeedToWork()</span><br><span class="line">                       &amp;&amp; FinalizerDaemon.INSTANCE.progressCounter.get() == startCount) &#123;</span><br><span class="line">                   <span class="keyword">return</span> finalizing;</span><br><span class="line">               &#125;</span><br><span class="line">           &#125;</span><br><span class="line">           <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">       &#125;</span><br></pre></td></tr></table></figure></p><p><code>sleepForNanos</code>对应的函数很简单，如果在超时时间内完成GC，就会计算传进来的超时阈值减去当前已经睡眠的时间，如果这个差值小于0，说明睡眠的时间超过了阈值<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">        * Sleep for the given number of nanoseconds, or slightly longer.</span></span><br><span class="line"><span class="comment">        * <span class="doctag">@return</span> false if we were interrupted.</span></span><br><span class="line"><span class="comment">        */</span></span><br><span class="line">       <span class="function"><span class="keyword">private</span> <span class="keyword">boolean</span> <span class="title">sleepForNanos</span><span class="params">(<span class="keyword">long</span> durationNanos)</span> </span>&#123;</span><br><span class="line">           <span class="comment">// It's important to base this on nanoTime(), not currentTimeMillis(), since</span></span><br><span class="line">           <span class="comment">// the former stops counting when the processor isn't running.</span></span><br><span class="line">           <span class="keyword">long</span> startNanos = System.nanoTime();</span><br><span class="line">           <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">               <span class="keyword">long</span> elapsedNanos = System.nanoTime() - startNanos;</span><br><span class="line">               <span class="keyword">long</span> sleepNanos = durationNanos - elapsedNanos;</span><br><span class="line">               <span class="keyword">if</span> (sleepNanos &lt;= <span class="number">0</span>) &#123;</span><br><span class="line">                   <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">               &#125;</span><br><span class="line">               <span class="comment">// Ensure the nano time is always rounded up to the next whole millisecond,</span></span><br><span class="line">               <span class="comment">// ensuring the delay is &gt;= the requested delay.</span></span><br><span class="line">               <span class="keyword">long</span> sleepMillis = (sleepNanos + NANOS_PER_MILLI - <span class="number">1</span>) / NANOS_PER_MILLI;</span><br><span class="line">               <span class="keyword">try</span> &#123;</span><br><span class="line">                   Thread.sleep(sleepMillis);</span><br><span class="line">               &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">                   <span class="keyword">if</span> (!isRunning()) &#123;</span><br><span class="line">                       <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">                   &#125;</span><br><span class="line">               &#125; <span class="keyword">catch</span> (OutOfMemoryError ignored) &#123;</span><br><span class="line">                   <span class="keyword">if</span> (!isRunning()) &#123;</span><br><span class="line">                       <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">                   &#125;</span><br><span class="line">               &#125;</span><br><span class="line">           &#125;</span><br><span class="line">       &#125;</span><br></pre></td></tr></table></figure></p><h4 id="Step3-GC处理超时"><a href="#Step3-GC处理超时" class="headerlink" title="Step3 GC处理超时"></a>Step3 GC处理超时</h4><p>如果第二步中的超时时间内析构没有完成，则返回析构的对象，触发<code>finalizerTimedOut</code>。<br>到了这一步是最不希望看到的结局，此时系统会弹出应用停止运行的报错框。</p><p>注意这个时候并没有立刻杀死进程，杀死进程的选择权交给了用户，即通过弹窗展示给用户，但对于用户来说会一头雾水</p><p><img src="http://blog.lihaizhou.top/GC_crash/GC1.png" alt=""></p><h3 id="分析结论"><a href="#分析结论" class="headerlink" title="分析结论"></a>分析结论</h3><p>这种问题其实还是比较常见的，特别是低内存的机器上。<code>RootCasue</code>就是对象回收超时了，一般是由于队列中等待<code>FinalizerDaemon</code>线程回收的对象太多导致，或者此时系统资源异常紧张比如CPU负载过高或者低内存环境下。</p><h3 id="场景实测"><a href="#场景实测" class="headerlink" title="场景实测"></a>场景实测</h3><h4 id="模拟还原现场"><a href="#模拟还原现场" class="headerlink" title="模拟还原现场"></a>模拟还原现场</h4><p>通过模拟<code>GC</code>时耗时操作，应用退到后台后10s会弹出报错框，堆栈如下</p><p><img src="http://blog.lihaizhou.top/GC_crash/GC2.png" alt=""></p><p>验证了超时时间的确是10s，同时也验证了GC时耗时的操作确实会可能触发这个现象</p><h4 id="对比机情况"><a href="#对比机情况" class="headerlink" title="对比机情况"></a>对比机情况</h4><p>在手头的小米<code>note9 pro</code>上进行场景模拟测试，模拟GC耗时100s的情况<br><img src="http://blog.lihaizhou.top/GC_crash/GC3.png" alt=""></p><p>在小米的机器上，到了默认的10s后并不会有弹窗，说明小米肯定修改了超时时间，第一次是等待了全部的100s后竟然正常回收，说明超时时间设置的比较大。紧接着下一次在达到了近80s时，进程收到<code>signal 9</code>直接被kill了，此时再点击应用是冷启动。</p><p><strong>小米修改了超时阈值(超过100s)，通过直接sig 9杀掉了进程，没有报错弹窗，所以用户无感知</strong></p><h4 id="测试机情况"><a href="#测试机情况" class="headerlink" title="测试机情况"></a>测试机情况</h4><p>同样的在我们的CP03上模拟GC耗时100s的情况<br><strong>退出应用到后台，此时系统触发GC回收，达到十秒钟时，界面上直接弹出停止运行的报错框，此时只有点击了关闭应用，才会去kill进程</strong></p><h4 id="修改策略"><a href="#修改策略" class="headerlink" title="修改策略"></a>修改策略</h4><p>在GC规定的超时时间内如果没有完成析构，直接<code>sig 9</code>给对应进程</p><hr><p>每日一问: 如果我一拳把自己打晕了，说明我是很强呢还是很虚呢？</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;写在前面&quot;&gt;&lt;a href=&quot;#写在前面&quot; class=&quot;headerlink&quot; title=&quot;写在前面&quot;&gt;&lt;/a&gt;写在前面&lt;/h3&gt;&lt;p&gt;这个问题之所以会拿出来仔细分析，一方面是因为这个问题不是简单的应用崩溃而是框架层的报错，另一方面是因为希望通过这个问题梳理下
      
    
    </summary>
    
      <category term="稳定性" scheme="http://lihaizhou.top/categories/%E7%A8%B3%E5%AE%9A%E6%80%A7/"/>
    
    
  </entry>
  
  <entry>
    <title>关于网络&amp;wifi一些基础内容</title>
    <link href="http://lihaizhou.top/2021/01/24/%E5%85%B3%E4%BA%8E%E7%BD%91%E7%BB%9C-wifi%E4%B8%80%E4%BA%9B%E5%9F%BA%E7%A1%80%E5%86%85%E5%AE%B9/"/>
    <id>http://lihaizhou.top/2021/01/24/关于网络-wifi一些基础内容/</id>
    <published>2021-01-24T06:57:50.000Z</published>
    <updated>2021-10-16T05:39:05.530Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>记录一些网络以及wifi的基础内容，会持续补充，以便后续有需要的时候查漏补缺  </p><h2 id="网络分层"><a href="#网络分层" class="headerlink" title="网络分层"></a>网络分层</h2><p><img src="http://blog.lihaizhou.top/WIFI%26Network/wifi%26%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%8001.png" alt=""></p><ul><li>分层的原因？如果不分层的话是否可行？</li><li>有了IP地址为何还需要mac地址？仅从地址作用上看用ipv6来取代mac地址是否可以？</li></ul><h3 id="为何分层？"><a href="#为何分层？" class="headerlink" title="为何分层？"></a>为何分层？</h3><p><strong>Q1_个人理解</strong><br>这种问题网上一大堆,其实我们没有必要纠结这种问题，这种成熟的架构时至今日是这个样子的，必定有其道理，搜索了下网上对此的解释，有不少是拿比喻来解释。<br>通过比喻向初学者解释一个知识点其实是不合适的，但是我们往往在深刻理解了一个东西后会想到用一个比喻，试图用它向不懂的人解释。比喻的意义往往是一群懂的人之间心领神会的交流方式罢了，所以就我个人而言，学习一个知识点的时候最好不用试图通过比喻来理解。<br>我们从软件设计模式的角度来看，其实分层是不是有点像Andorid的架构设计模式，不论是MVC,MVP,MVVM等，其本质都是为了解耦, 为了更方便职责明确, 也便于后续的维护调试,后续修改的话只要修改一层即可而不会牵一发而动全身。  </p><p>既然你说是因为职责明确，那么每一层都有什么职责呢？<br>比如传输层解决的是进程定位的问题，网络层解决数据包寻路的问题，数据链路层解决局域网传输的问题等。<br><strong>归纳起来就是一句话：</strong><br>当一个系统足够复杂时，通过聚合分为不同层次或不同模块， 每层或模块都是内聚的，对外屏蔽复杂性。<br>那么宏观上看去，管理和问题定位很容易到具体层次和模块。 然后层层递进，很容易定位问题。  </p><h3 id="为何需要mac层？"><a href="#为何需要mac层？" class="headerlink" title="为何需要mac层？"></a>为何需要mac层？</h3><p><strong>Q2_个人理解</strong><br>这个问题在网上试图查找资料时，很多说的很多都是因为ip地址会变，mac不变的缘故。<br>但是包在到达目的地之前是不知道目标mac地址的，mac层包装ip层的时候，对方的mac层地址还不一定是目标（最终的）mac地址，有可能是相连的一台路由器的mac地址，解码之后看ip，发现ip不在这个局域网内，然后再次包装一层mac地址，发给相连（也有可能不是相连，反正就是根据某种规则规定的下一个路由器）路由器，所以ip地址会变，mac不变的这样的解释是不合理的吗？最起码我觉得这种说法没有解释清楚这个问题。<br>网卡出厂就设置了mac地址是唯一的，我们也知道ip地址是可变的，就算机器没有移动，一直处在一个局域网内，重启网络也可能会导致ip地址改变。<br>数据包上ip 地址的作用是在外网上投递用的，内网就不行了，必须要用mac，使用mac地址的其中一个原因就是为了在局域网内确认到那台正确的计算机。  </p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">在知乎上找到一个比较好的解释为何需要mac层，和上面的解释是一样的  </span><br><span class="line">信息传递时候，需要知道的其实就是两个地址：  </span><br><span class="line">    • 终点地址（Final destination address）  </span><br><span class="line">    • 下一跳的地址（Next hop address）  </span><br><span class="line">IP地址本质上是终点地址，它在跳过路由器（hop）的时候不会改变，而MAC地址则是下一跳的地址，每跳过一次路由器都会改变。</span><br></pre></td></tr></table></figure><p>归纳下来就是一句话：mac地址局域网寻址，ip地网络寻址<br>这就是为什么还要用MAC地址的原因之一，它起到了记录下一跳的信息的作用</p><h3 id="用ipv6来取代mac地址是否可以？"><a href="#用ipv6来取代mac地址是否可以？" class="headerlink" title="用ipv6来取代mac地址是否可以？"></a>用ipv6来取代mac地址是否可以？</h3><p>既然ipv6号称可以给世界上每一个沙子都分配一个ip地址，那为何不直接取消mac地址，给每一个网卡出场时分配一个ip地址。<br>这是一个看起来比较天马行空的问题。<br>前面提到mac地址起到“下一跳IP地址”的作用，那么我们用ipv6反正不用担心ip不够用的问题对吧，假设交换机也支持IP地址转发（现在的二层交换机不支持这样做），mac地址好像看上去也并不是必要的对吧？<br>当然了mac地址不仅仅是标记网卡这一个作用，先假设它只有这么一个作用，想想这样可行吗？<br>很快便想到一个问题就是这个ip地址得广播出去，假设地球上有几百亿的设备，转发匹配这几百亿的记录便不可能实现，需要的存储太大太大。<br>这个问题搜索了网上貌似相关的解答比较少，知乎上有一个回答我觉得比较好，照抄过来:<br>IPv6定义了多种地址，其中一种地址叫Link-local地址，看上去可以取代mac地址，可是二层三层的封装已经通行于全世界，ipv6何德何能可以打破所有网络设备，主机，都在使用的规范？打破规范带来的网络中断，迁移成本这些也是难以实现的<br>tcpip协议栈设计出来那天就没有自己定义二层协议，也没有取代二层协议，而是去兼容二层协议，仅此而已，让自己能跑在各种二层协议之上</p><h2 id="DHCP"><a href="#DHCP" class="headerlink" title="DHCP"></a>DHCP</h2><p><img src="http://blog.lihaizhou.top/WIFI%26Network/wifi%26%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%8002.png" alt=""><br>本地抓取的正常流程的bugreport，分别包含<code>logcat&amp;driver</code>日志片段，后续可以作为参考分析<br><img src="http://blog.lihaizhou.top/WIFI%26Network/wifi%26%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%8003.png" alt=""><br>静态分配和dhcp分配导致的ip冲突报文<br><img src="http://blog.lihaizhou.top/WIFI%26Network/wifi%26%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%8004.png" alt="">  </p><p>Q:  DHCP Offer 和 DHCP ACK是广播包吗？由什么因素决定的？<br>A：这个其实是取决于client端的ip协议栈的能力，可以抓个报文看下就知道了。<br>如果协议栈在初始化过程中，不接收单播IP报文，请在DHCP Discovery / Request报文的Flags里明确告知服务器，通过设置“BROADCAST flag = 1”，服务器就使用广播来和客户端通信。<br>如果协议栈在初始化过程中，可以接收单播IP报文，请在DHCP Discovery / Request报文的Flags里明确告知服务器，通过设置“BROADCAST flag = 0”，服务器就使用单播来和客户端通信。<br>既然广播方式通信适合所有的协议栈，统统使用广播不就ok了，为何要有这个Flags，岂不是多此一举？<br>单播最大的优点：通信是点对点方式，不会影响到广播域的其它主机。<br>广播的特点：通信是点对所有点的方式，会影响到广播域里其它所有主机  </p><p>链路层放置目标机器的mac地址即可将信息送达客户端机，非该mac地址的机器收到后会丢弃这个包，此时的ip层目标网络地址填的就是要分配给该客户端机的ip地址;<br> <a href="https://www.ietf.org/rfc/rfc2131.txt" target="_blank" rel="noopener">官方文档说明</a></p><p>Q: 是否存在静态ip和DHCP Server分配给Client的ip冲突的情况？ 有冲突后会怎么样？会导致网络访问异常？<br>A：网上找到一篇文章，解释的不错，地址：<a href="https://blog.csdn.net/Butingnal/article/details/76067092" target="_blank" rel="noopener">DHCP以及客户端是如何避免IP冲突</a><br>在最后的确认阶段，当Client收到<code>DHCP Server</code>发送的<code>DHCPACK</code>报文之后，并不会马上使用Server分配的这个地址，而是会发送目的地址为Server分配地址的ARP请求报文作最后的确认（即免费ARP）。<br>如果没有检测到冲突，则将此地址与自己绑定。如果检测到冲突，就向<code>DHCP Server</code>发送<code>DHCPDECLINE</code>报文，在<code>Request IP Address（option 50）</code>字段填入Server提供的发生冲突的IP地址.发送完成后，等待一段时间再开始重新申请IP地址，直至申请到一个可用的IP地址。  </p><p>Q：<code>DHCP server</code>的地址池是有限的吧？同时有大量的client发起请求会不会存在不够用的情况？<br>A: 服务器收到了Discover 包之后，就会从地址池中选择一个IP准备分配给请求者，当然正常情况下客户端收到服务器发送的Offer会回复Request进行确认，但是在泛洪攻击的场景下服务器会收到大量的Discover报文当然也会在地址池为这些请求者执行分配IP的操作并等待客户端的应答。<br>在没有得到客户端确认的情况下，服务器将会为客户端保留要分配的IP，当在大量泛洪攻击的场景下服务器的地址池很快就会满掉。从而影响正常客户端的使用。<br>那我们这个时候就有疑问了，能不能尽可能的扩大这个地址池呢？想象一个极端的情况，地址池中的ip数无穷无尽，这不就不存在这个问题了吗？<br>其实只要简单修改掩码，就可以实现更多的客户端接入，别说254，一万个254都装的下。<br>掩码是用来决定网段大小的，也就是说，一个网段能容纳多少个终端（电脑，手机，摄像头），是由掩码来决定的。<br>最常用的掩码是<code>255.255.255.0</code>，和题主说的一样，最大的可用ip数量只有254<br>但如果把掩码换成<code>255.255.0.0</code>，那么最大可用ip数量，就有256乘256减2，好几万了<br><strong>但是为什么不推荐一个网段主机数太多呢？</strong><br>在实际项目上，虽然通过掩码可以让网段变大，让网络的配置和调试变的简单，但往往还是不用大网段。原因就在于“广播域”<br>什么是广播域，顾名思义，就是1个主机发出的广播包，可以到达的范围。  </p><p>如果一个网段大，那么广播域就大，就像我们再嘈杂的环境里，会收到大量和自己无关的数据，这些数据将占用我们的带宽，以及消耗我们各个终端的计算资源。毕竟广播包，目标地址是所有人，所有人收到都不能视而不见，都要处理。<br>所以，当终端数比较多的时候，一般会采用多个网段，多个vlan（虚拟局域网）的方法，而不是一下搞个大网段。 </p><h2 id="网关"><a href="#网关" class="headerlink" title="网关"></a>网关</h2><p>这里穿插下网关的概念，什么是网关呢？<br>如果你去网上搜索，能搜索到的关于网关的解释大多是这样的:<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">网关往往是一个路由器，是一个三层转发的设备。那么啥叫三层设备？就是把 MAC 头和 IP 头都取下来，然后根据里面的内容，看看接下来把包往哪里转发的设备。</span><br></pre></td></tr></table></figure></p><p>个人理解：<br>说来惭愧，之前对于网关的认识以为就是路由器，其实这种认识是不准确的。<br>首先‘网关’一个大概念，不具体特指一类产品，只要连接两个不同的网络的设备都可以叫网关；而‘路由器’一般特指能够实现路由寻找和转发的特定类产品，路由器很显然能够实现网关的功能。<br>当然电信行业说的‘路由器’又和家用的‘路由器’两个概念。网关并不总是被视为路由器，路由器是最常见的网关，用于将家庭或企业网络连接到Internet。<br>PC本身不具备路由寻址能力，所以PC要把所有的IP包发送到一个默认的中转地址上面进行转发，也就是默认网关。这个网关可以在路由器上，可以在三层交换机上，可以在防火墙上，可以在服务器上，所以和物理的设备无关。<br>网关只针对某个局域网，是某个局域网的出口地址，而一个路由器由多个网关组成<br>任何一个想发往其他局域网的包，都会到达其中一只手，被拿进来，拿下 MAC 头和 IP 头，看一下，根据自己的路由算法，选择另一只手，加上 IP 头和 MAC 头，然后扔出去。<br>如果离开本局域网，就需要经过网关，网关是路由器的一个网口；路由器是一个三层设备，里面有如何寻找下一跳的规则；  </p><h2 id="WIFI漫游"><a href="#WIFI漫游" class="headerlink" title="WIFI漫游"></a>WIFI漫游</h2><p>下面这个图摘自高通文档上，主要是漫游的一个流程<br><img src="http://blog.lihaizhou.top/WIFI%26Network/wifi%26%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%8005.png" alt=""><br>代码中关于漫游的原因，更加细致<br><img src="http://blog.lihaizhou.top/WIFI%26Network/wifi%26%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%8006.png" alt="">  </p><p>本地抓取的9434附录屏的漫游日志，类型：Dense roaming<br><img src="http://blog.lihaizhou.top/WIFI%26Network/wifi%26%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%8007.png" alt=""><br>上面fw中打印的roam reason对应的代码地址(qcom)<br>vendor/qcom/opensource/wlan/fw-api/fw/wmi_unified.h<br><img src="http://blog.lihaizhou.top/WIFI%26Network/wifi%26%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%8008.png" alt="">  </p><p>顺便解释下本地抓取的这份漫游reason 7对应的是DENSE roaming的解释，摘自高通文档<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Dense roaming  </span><br><span class="line">Dense-<span class="function">roaming mechanism is a new feature of location retrieval <span class="title">function</span> <span class="params">(LRF)</span> 3.0. This feature retains high throughput when many roamable APs are present nearby and the data traffic is high then.</span></span><br><span class="line"><span class="function">The original Wi-Fi roaming mechanism is designed to enable roaming when the current RSSI value reaches the defined RSSI threshold value, <span class="keyword">for</span> example, -76 dBm.  </span></span><br><span class="line"><span class="function">However, in a high dense environment where there are many roamable APs, it is better to start roaming earlier when the traffic is high because high throughput is maintained   <span class="keyword">for</span> heavy traffic with minimal power consumption impact. Dense roaming functions in such a manner to retain high throughput during periods of heavy traffic.  </span></span><br><span class="line"><span class="function">To provide <span class="keyword">this</span> value-added enhancement, the dense roaming mechanism is designed with the following two principles.  </span></span><br><span class="line"><span class="function">■ Relying on other triggered scans, sniffing is performed on the management packets to determine the number of roamable APs that are present then in the environment.  </span></span><br><span class="line"><span class="function">■ If a dense roaming environment is <span class="title">found</span> <span class="params">(that is, the number of the found roamable APs is bigger than the configured dense roamable AP threshold value)</span>, and <span class="keyword">if</span> there is significant traffic at that moment, then <span class="keyword">switch</span> to use the dense RSSI threshold value so that the roaming is triggered earlier.</span></span><br></pre></td></tr></table></figure></p><p>MTK online上关于MTK的漫游策略如下图，其实和qcom大同小异，大的流程都是一样的<br><img src="http://blog.lihaizhou.top/WIFI%26Network/wifi%26%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%8009.png" alt=""><br>如下是平时分析漫游可能会用到的关键字</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//Logcat:  </span></span><br><span class="line">CTRL-EVENT-DISCONNECTED|CTRL-EVENT-CONNECTED|fetchRssiLinkSpeedAndFrequencyNative|NL80211_CMD_ROAM|(set AP RSN IE)|LOST_PROVISIONING|wpa_supplicant: wlan0: State</span><br><span class="line"></span><br><span class="line"><span class="comment">//fw log</span></span><br><span class="line">VDEV_MGR_MY_BEACON_RECEIVED|ROAM_LOW_RSSI_INTERRUPT|PEER_ASSOC|ROAM_BETTER_CANDIDATE_FOUND|ROAM_SCAN_REQUESTED|VDEV_MGR_FIRST_BMISS_DETECTED|ROAM_FINAL_BMISS_RECVD|roaming attempt to bssid|RSSI_MONITOR_GET_BEACON_RSSI_AVG</span><br></pre></td></tr></table></figure><ul><li>触发漫游的原因有哪些？</li><li>漫游到哪个候选AP(假设存在)? 有哪些评判条件？</li><li>漫游会断线吗？会重新走四次握手吗？</li></ul><h2 id="ARP-amp-NDP"><a href="#ARP-amp-NDP" class="headerlink" title="ARP&amp;NDP"></a>ARP&amp;NDP</h2><p><img src="http://blog.lihaizhou.top/WIFI%26Network/wifi%26%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%8010.png" alt=""><br>上面是ARP的一个简单流程，这里涉及到一个缓存的过程，大体解释如下:<br>为了避免机器每次都使用ARP协议发送ARP请求，在每台机器的本地会进行ARP缓存。<br>–&gt;只要涉及到缓存，那就是空间换时间的设计思想  </p><ol><li>一般机器都是先查本地ARP缓存  </li><li>本地ARP缓存查不到，再去发送ARP请求在局域网中去找目标IP地址对应的MAC地址<br>当然机器会不断地上线下线，IP 也可能会变，所以 ARP 的 MAC 地址缓存过一段时间就会过期  </li></ol><h3 id="ipv6-ND"><a href="#ipv6-ND" class="headerlink" title="ipv6 ND"></a>ipv6 ND</h3><p><img src="http://blog.lihaizhou.top/WIFI%26Network/wifi%26%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%8011.png" alt=""><br>地址解析过程中使用了两种ICMPv6报文：邻居请求报文NS（Neighbor Solicitation）和邻居通告报文NA（Neighbor Advertisement)。<br>    • NS报文：Type字段值为135，Code字段值为0，在地址解析中的作用类似于IPv4中的ARP请求报文。<br>    • NA报文：Type字段值为136，Code字段值为0，在地址解析中的作用类似于IPv4中的ARP应答报文。</p><p><img src="http://blog.lihaizhou.top/WIFI%26Network/wifi%26%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%8012.png" alt="">    </p><h3 id="NS报文"><a href="#NS报文" class="headerlink" title="NS报文"></a>NS报文</h3><p>  <img src="http://blog.lihaizhou.top/WIFI%26Network/wifi%26%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%8013.png" alt="">  </p><h3 id="arp-request"><a href="#arp-request" class="headerlink" title="arp request"></a>arp request</h3><p><img src="http://blog.lihaizhou.top/WIFI%26Network/wifi%26%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%8014.png" alt="">     </p><p>Q：什么是ARP风暴？<br>A：ARP广播时，交换机会将一个端口收到的包转发到其它所有的端口上。<br>比如数据包经过交换机A到达交换机B，交换机B又将包复制为多份广播出去。<br>如果整个局域网存在一个环路，使得数据包又重新回到了最开始的交换机A，这个包又会被A再次复制多份广播出去。<br>如此循环，数据包会不停得转发，而且越来越多，最终占满带宽，或者使解析协议的硬件过载，行成广播风暴。</p><h2 id="DNS"><a href="#DNS" class="headerlink" title="DNS"></a>DNS</h2><p><img src="http://blog.lihaizhou.top/WIFI%26Network/wifi%26%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%8015.png" alt=""><br>如果分析类似网页加载不出来的问题时候，我们首先需要清楚的知道加载一个网页的流程<br>    • DNS 解析:将域名解析成 IP 地址<br>    • TCP 连接：TCP 三次握手<br>    • 发送 HTTP 请求<br>    • 服务器处理请求并返回 HTTP 报文<br>    • 浏览器解析渲染页面<br>    • 断开连接：TCP 四次挥手  </p><p>Q: 对于已连接网络无法上网问题的快速排查思路？  </p><h2 id="断线问题"><a href="#断线问题" class="headerlink" title="断线问题"></a>断线问题</h2><p>如下是本地测试打印，操作步骤是主动删除已连接热点<br><img src="http://blog.lihaizhou.top/WIFI%26Network/wifi%26%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%8016.png" alt=""><br>如下是本地测试打印，操作步骤是超出范围断开<br><img src="https://raw.githubusercontent.com/hellolihaizhou/saveImg/master/wifi%26%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%8017.png" alt="">  </p><p>Q: 断线一般有哪些原因？<br>A:</p><ul><li>用户手动断开</li><li>FWK断开</li><li>Beacon miss断线</li><li>KickOut断线</li><li>Nud failed断线</li><li>Rx disassoc or deauth断线  </li></ul><p>Q: 如何通过日志如何快速定位断线是上层还是底层发起的？<br>A:如果是底层断线，会先收到底层断线发上来的<code>DISCONNECT Event</code>，然后<code>supplicant</code>才把state切到DISCONENCTED.<br>如果是上层断线，<code>disconnection request</code>会先到supplicant，supplicant state会先切到DISCONNECTED, 发送disconnect request给driver去真正端开wifi连接.<br>归纳下来就是迅速定位是底层还是上层有一个好的办法就是：<br>过滤这两个关键字：<code>wpa_supplicant: nl80211</code> , <code>wpa_supplicant: wlan0</code>看看先后关系  </p><p>Q: 有哪些日志关键字可以过滤来分析断线问题？<br>如下是一些关键字，当然前提你得清楚这些关键字的含义  </p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//bugreport：</span></span><br><span class="line">CMD_IP_REACHABILITY_LOST|NETWORK_DISCONNECTION_EVENT|Received Heart Beat Failure|dev wlan0 INCOMPLETE|get addr info failed|arp who-has|ICMPv4 dst|LOST_PROVISIONING|wma_peer_sta_kickout_event_handler|NetConnTag|No address associated with hostname|DnsMain|IcmpReader|NetworkProvider|NetworkDiagnostics|DnsService|PROBE_DNS</span><br><span class="line"><span class="comment">//driver: </span></span><br><span class="line">STA kickout|blm_fill_reject_list|wma_peer_sta_kickout_event_handler|Sending Deauth frame with reason</span><br><span class="line"><span class="comment">//fw</span></span><br><span class="line">ROAM_STA_KICKOUT_RECV|consecutive failure=</span><br></pre></td></tr></table></figure><p>fw的关键字主要是看<code>tx fail</code>的阀值是否达到了上限，很多都是<code>RSSI</code>值太低导致，还有一种常见的问题是AP没有回ack导致手机一直tx fail,最终触发<code>kickout</code>，这种需要提供<code>sniffer log</code>确认。  </p><h2 id="连接不上问题"><a href="#连接不上问题" class="headerlink" title="连接不上问题"></a>连接不上问题</h2><p>本地测试密码错误抓取的bugreport，以便后续分析日志对照<br><img src="http://blog.lihaizhou.top/WIFI%26Network/wifi%26%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%8018.png" alt="">    </p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//Auth fail</span></span><br><span class="line">rx Auth frame from peer with failure code对应的fail code参见 <span class="number">802.11</span> Association Status Codes</span><br><span class="line">https:<span class="comment">//wiki.n.miui.com/display/~lihaizhou/802.11+Association+Status+Codes</span></span><br><span class="line"></span><br><span class="line">eg: code = <span class="number">17</span> Association denied because AP is unable to handle additional associated stations</span><br><span class="line"></span><br><span class="line"><span class="comment">// portal fail</span></span><br><span class="line"><span class="number">2020</span>-<span class="number">12</span>-<span class="number">03</span>T18:<span class="number">08</span>:<span class="number">11.852</span> - PROBE_DNS connect.rom.miui.com <span class="number">12511</span>ms FAIL </span><br><span class="line"><span class="number">2020</span>-<span class="number">12</span>-<span class="number">03</span>T18:<span class="number">08</span>:<span class="number">39.391</span> - PROBE_HTTP http:<span class="comment">//connect.rom.miui.com/generate_204 Probe failed with exception java.net.UnknownHostException: Unable to resolve host "connect.rom.miui.com": No address associated with hostname</span></span><br><span class="line"><span class="number">2020</span>-<span class="number">12</span>-<span class="number">03</span>T18:<span class="number">08</span>:<span class="number">39.394</span> - Probably not a portal: exception java.net.UnknownHostException: Unable to resolve host <span class="string">"m.baidu.com"</span>: No address associated with hostname</span><br><span class="line"><span class="comment">//filter：</span></span><br><span class="line">Cannot add/update network|save network failed|All saved networks are lost|Association Rejection|CTRL-EVENT-ASSOC-REJECT|EVENT_DHCPACTION_TIMEOUT|NETWORK_SELECTION_DISABLED_BY_WRONG_PASSWORD|AUTHENTICATION_FAILURE|pre-shared key may be incorrect|wpa_supplicant: wlan0</span><br><span class="line"></span><br><span class="line"><span class="comment">//driver：</span></span><br><span class="line">Auth frame from peer with failure|Auth Failure occurred</span><br></pre></td></tr></table></figure><p>Q：连接不上通常有哪几种情形？如何快速甄别？  </p><p><strong>Auth失败</strong><br>一般driver日志中会打印出<code>Auth frame from peer with failure</code>后面对应code值，code值查阅<br>802.11 Association Status Codes即可，正常返回的是0，如果问题有sniffer的话，也可以看auth帧的status值<br>像数值17 对应的含义 <code>Association denied because AP is unable to handle additional associated stations</code> 被AP拒绝了，这时候同时连接AP的sta可能太多了超过了AP的负载<br><strong>四次握手异常</strong><br>1,2握手失败是密码错误导致，其它的可能是路由器设置问题<br><strong>DHCP失败</strong><br>DHCP请求没有回复，看看当时rssi判断信号弱不弱，为什么连接成功但是DHCP会失败：因为连接过程一直发送管理帧，数据小，DHCP是数据帧，比较大，在信号弱时无法正常交互。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;记录一些网络以及wifi的基础内容，会持续补充，以便后续有需要的时候查漏补缺  &lt;/p&gt;
&lt;h2 id=&quot;网络分层&quot;&gt;&lt;a href=&quot;#网
      
    
    </summary>
    
      <category term="网络" scheme="http://lihaizhou.top/categories/%E7%BD%91%E7%BB%9C/"/>
    
    
  </entry>
  
  <entry>
    <title>wifi断流问题的一般分析思路</title>
    <link href="http://lihaizhou.top/2021/01/08/wifi%E6%96%AD%E6%B5%81%E7%9A%84%E4%B8%80%E8%88%AC%E5%88%86%E6%9E%90%E6%80%9D%E8%B7%AF/"/>
    <id>http://lihaizhou.top/2021/01/08/wifi断流的一般分析思路/</id>
    <published>2021-01-08T08:01:12.000Z</published>
    <updated>2021-09-08T12:34:39.885Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>仅针对高通平台，旨在梳理出遇到此类问题的一般应对策略，作为工具篇查阅，快速分类出断流的原因  </p><h2 id="定位时间点"><a href="#定位时间点" class="headerlink" title="定位时间点"></a>定位时间点</h2><p>根据测试或用户反馈的时间点，先通过如下关键字过滤一遍，尝试定位到具体的时间点</p><p><strong>断流断连关键字</strong><br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CMD_IP_REACHABILITY_LOST|NETWORK_DISCONNECTION_EVENT|Received Heart Beat Failure|dev wlan0 INCOMPLETE|get addr info failed|arp who-has|ICMPv4 dst|LOST_PROVISIONING|wma_peer_sta_kickout_event_handler|NetConnTag|No address associated with hostname|DnsMain|IcmpReader|NetworkProvider|NetworkDiagnostics|DnsService|PROBE_DNS</span><br></pre></td></tr></table></figure></p><p>断流|AP连接不成功|AP心跳包接收失败||获取地址失败|arp包发送接收出问题|…….  </p><h2 id="是否是网络环境或RSSI太弱导致"><a href="#是否是网络环境或RSSI太弱导致" class="headerlink" title="是否是网络环境或RSSI太弱导致?"></a>是否是网络环境或RSSI太弱导致?</h2><p>搜索关键字<code>processed=L2ConnectedState&quot;</code>查看状态机状态，当时是否是连接上的，RSSI值是否太低了，TX RX的值是否太低了<br>类似如下<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rec[<span class="number">902</span>]: time=<span class="number">01</span>-<span class="number">03</span> <span class="number">15</span>:<span class="number">05</span>:<span class="number">15.447</span> processed=L2ConnectedState org=ConnectedState dest=&lt;<span class="keyword">null</span>&gt; what=CMD_RSSI_POLL screen=on <span class="number">56</span> <span class="number">0</span> <span class="string">"Xiaomi_8111_5G"</span> <span class="number">88</span>:c3:<span class="number">97</span>:<span class="number">32</span>:c6:cc rssi=-<span class="number">53</span> f=<span class="number">5805</span> sc=<span class="number">60</span> link=<span class="number">720</span> tx=<span class="number">0.1</span>, <span class="number">0.0</span>, <span class="number">0.0</span> rx=<span class="number">1.5</span> bcn=<span class="number">48014</span> [on:<span class="number">2941</span> tx:<span class="number">831</span> rx:<span class="number">24</span> period:<span class="number">3009</span>] from screen [on:<span class="number">79247</span> period:<span class="number">154965</span>] score=<span class="number">60</span></span><br></pre></td></tr></table></figure></p><p>正常来讲，rssi处于<code>-40~-60</code>之间还可以，<code>&lt;-65</code>代表当前信号比较差了  </p><h2 id="ARP-or-DNS是否有问题"><a href="#ARP-or-DNS是否有问题" class="headerlink" title="ARP or DNS是否有问题?"></a>ARP or DNS是否有问题?</h2><p>在bugreport中的<code>dump of service wifi</code> 中出现<code>CMD_IP_REACHABILITY_LOST</code>可以说明arp失败，或者搜索<code>NUD_FAILED</code>关键字，类似如下<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"> rec[<span class="number">135</span>]: time=<span class="number">09</span>-<span class="number">12</span> <span class="number">19</span>:<span class="number">51</span>:<span class="number">14.715</span> processed=L2ConnectedState org=ConnectedState dest=&lt;<span class="keyword">null</span>&gt; what=<span class="number">131221</span>(<span class="number">0x20095</span>) !CMD_IP_REACHABILITY_LOST rt=<span class="number">210940</span>/<span class="number">210940</span> FAILURE: LOST_PROVISIONING, NeighborEvent</span><br><span class="line">&#123;elapsedMs=<span class="number">210940</span>, <span class="number">192.168</span>.1.1, [(<span class="keyword">null</span>)], RTM_NEWNEIGH, NUD_FAILED</span><br></pre></td></tr></table></figure></p><p>还有一种方法是搜索arp who-has关键字看看arp有没有reply以及延迟高不高<br>Connectivity网络诊断过程会ping网关，失败则说明发生了断流，可以搜索下关键字NetworkDiagnostics,看下ping的情况以及DNS解析情况，类似下面的片段  </p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">NetworkDiagnostics:ifaces&#123;wlan0&#125; index&#123;<span class="number">24</span>&#125; network&#123;<span class="number">110</span>&#125; nethandle&#123;<span class="number">475852099597</span>&#125;</span><br><span class="line">  .  ICMPv4 dst&#123;<span class="number">8.8</span>.8.8&#125; src&#123;<span class="number">192.168</span>.31.186:<span class="number">94</span>&#125;: SUCCEEDED: <span class="number">1</span>/<span class="number">14</span> (<span class="number">4213</span>ms)</span><br><span class="line">  .  ICMPv4 dst&#123;<span class="number">192.168</span>.31.1&#125; src&#123;<span class="number">192.168</span>.31.186:<span class="number">93</span>&#125;: SUCCEEDED: <span class="number">1</span>/<span class="number">14</span> (<span class="number">4158</span>ms)</span><br><span class="line">  F  DNS UDP dst&#123;<span class="number">8.8</span>.8.8&#125; src&#123;<span class="number">192.168</span>.31.186:<span class="number">38481</span>&#125; qtype&#123;<span class="number">1</span>&#125; qname&#123;<span class="number">848815</span>-android-ds.metric.gstatic.com&#125;: FAILED: <span class="number">0</span>/<span class="number">8</span> (<span class="number">4112</span>ms)</span><br><span class="line">  F  DNS UDP dst&#123;<span class="number">192.168</span>.31.1&#125; src&#123;<span class="number">192.168</span>.31.186:<span class="number">39053</span>&#125; qtype&#123;<span class="number">1</span>&#125; qname&#123;<span class="number">295600</span>-android-ds.metric.gstatic.com&#125;: FAILED: <span class="number">0</span>/<span class="number">8</span> (<span class="number">4113</span>ms)</span><br><span class="line">  F  DNS TLS dst&#123;<span class="number">8.8</span>.8.8&#125; hostname&#123;&#125;: FAILED: java.net.SocketTimeoutException: failed to connect to /<span class="number">8.8</span>.8.8 (port <span class="number">853</span>) from /<span class="number">192.168</span>.31.186 (port <span class="number">45100</span>) after <span class="number">2500</span>ms (<span class="number">2501</span>ms)</span><br><span class="line">  F  DNS TLS dst&#123;<span class="number">192.168</span>.31.1&#125; hostname&#123;&#125;: FAILED: java.net.SocketTimeoutException: failed to connect to /<span class="number">192.168</span>.31.1 (port <span class="number">853</span>) from /<span class="number">192.168</span>.31.186 (port <span class="number">37304</span>) after <span class="number">2500</span>ms (<span class="number">2501</span>ms)</span><br><span class="line">NetworkProviders <span class="keyword">for</span>: Ethernet UntrustedWifiNetworkFactory WifiSlaveNetworkFactory WifiNetworkFactory TelephonyNetworkFactory[<span class="number">0</span>] WIFI_AWARE_FACTORY UntrustedWifiNetworkFactory TelephonyNetworkFactory[<span class="number">1</span>] PhoneSwitcherNetworkRequstListener</span><br></pre></td></tr></table></figure><p>其实就是通过Ping主流服务器IP地址来判断整体数据通路是否正常 ，通过DNS主流网站查询判断运营商DNS server 是否正常<br>查看DNS时长，日志看起来每五分钟就会检测一次<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">15</span>:<span class="number">00</span>:<span class="number">00.000</span>: &#123;netId=<span class="number">110</span>, WIFI, dns avg=<span class="number">1219</span>ms max=<span class="number">20026</span>ms err=<span class="number">2.0</span>% tot=<span class="number">201</span>, connect avg=<span class="number">0</span>ms max=<span class="number">5</span>ms err=<span class="number">0.5</span>% tot=<span class="number">191</span>, tcp avg_loss=<span class="number">0.2</span>% total_sent=<span class="number">8270</span> total_lost=<span class="number">16</span>, tcp rtt=<span class="number">110</span>ms, tcp sent-ack_diff=-<span class="number">1332</span>ms&#125;</span><br><span class="line"><span class="number">15</span>:<span class="number">05</span>:<span class="number">00.000</span>: &#123;netId=<span class="number">110</span>, WIFI, dns avg=<span class="number">313</span>ms max=<span class="number">12457</span>ms err=<span class="number">0.0</span>% tot=<span class="number">172</span>, connect avg=<span class="number">0</span>ms max=<span class="number">1</span>ms err=<span class="number">0.7</span>% tot=<span class="number">138</span>, tcp avg_loss=<span class="number">0.3</span>% total_sent=<span class="number">4798</span> total_lost=<span class="number">12</span>, tcp rtt=<span class="number">43</span>ms, tcp sent-ack_diff=-<span class="number">593</span>ms&#125;</span><br></pre></td></tr></table></figure></p><p>如果测试提供的是9434日志的话，一般其中会包含tcpdump日志，过滤下<code>dns||arp</code>, 这样看上去更直观  </p><h2 id="是否发生datastall？"><a href="#是否发生datastall？" class="headerlink" title="是否发生datastall？"></a>是否发生datastall？</h2><p>检查driver日志是否有fw传上来的<code>datastall</code>事件，这个谷歌机制是在亮屏下周期性比如一分钟检查一次TCP上行和下行数据，如果只有上行数据无下行数据包且达到临界值，就会认为当前网络异常，类似如下片段：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">13</span>:<span class="number">44</span>:<span class="number">35.605317</span> [kworker/u16:<span class="number">10</span>][<span class="number">0x96c51f025d</span>][<span class="number">13</span>:<span class="number">44</span>:<span class="number">35.602210</span>]wlan: [<span class="number">6253</span>:D:WMA] Received reason code <span class="number">6</span> from FW</span><br><span class="line"><span class="number">13</span>:<span class="number">44</span>:<span class="number">35.605322</span> [kworker/u16:<span class="number">10</span>][<span class="number">0x96c51f032a</span>][<span class="number">13</span>:<span class="number">44</span>:<span class="number">35.602220</span>]wlan: [<span class="number">6253</span>:D:WMA] Data Stall event:</span><br><span class="line"><span class="number">13</span>:<span class="number">44</span>:<span class="number">35.605389</span> [kworker/u16:<span class="number">10</span>][<span class="number">0x96c51f038a</span>][<span class="number">13</span>:<span class="number">44</span>:<span class="number">35.602225</span>]wlan: [<span class="number">6253</span>:D:WMA] data_stall_type: <span class="number">3</span> vdev_id_bitmap: <span class="number">1</span> reason_code1: <span class="number">0</span> reason_code2: <span class="number">7</span> recovery_type: <span class="number">0</span></span><br><span class="line"><span class="number">13</span>:<span class="number">44</span>:<span class="number">35.605397</span> [kworker/u16:<span class="number">10</span>][<span class="number">0x96c51f11a3</span>][<span class="number">13</span>:<span class="number">44</span>:<span class="number">35.602413</span>]wlan: [<span class="number">6253</span>:D:QDF] cds_set_log_completion: <span class="number">2136</span>: is_fatal <span class="number">1</span> indicator <span class="number">3</span> reason_code <span class="number">6</span> recovery needed <span class="number">0</span></span><br><span class="line"><span class="number">13</span>:<span class="number">44</span>:<span class="number">35.629190</span> [wlan_logging_th][<span class="number">0x96c51fc43e</span>][<span class="number">13</span>:<span class="number">44</span>:<span class="number">35.604795</span>]wlan: [<span class="number">900</span>:D:HDD] send_flush_completion_to_user: Sending flush done to userspace reason code <span class="number">6</span></span><br></pre></td></tr></table></figure></p><h2 id="检查TX-RX收发包是否正常？"><a href="#检查TX-RX收发包是否正常？" class="headerlink" title="检查TX RX收发包是否正常？"></a>检查TX RX收发包是否正常？</h2><p>通过搜索关键字<code>wlan_hdd_get_sta_status</code>查看driver日志，如果上面看过没有发生<code>data stall</code>的话，看看<code>rx pkt cnt</code>有没有增加，如果经常不增加，就是有问题，如何确定是路由器没有转发还是底下没收上来？需要sniffer<br>类似如下<code>RX pkt cnt</code>变化很小，这点不正常<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">15</span>:<span class="number">04</span>:<span class="number">57.822610</span> [wifico][<span class="number">0x183a3b70779</span>][<span class="number">15</span>:<span class="number">04</span>:<span class="number">57.369087</span>]wlan: [<span class="number">1372</span>:D:HDD] wlan_hdd_get_sta_stats: [TX: Reporting MCS rate <span class="number">8</span>, flags <span class="number">0x14</span> pkt cnt <span class="number">267148</span>, nss <span class="number">2</span>, bw <span class="number">4</span>]-[RX: Reporting MCS rate <span class="number">8</span>, flags <span class="number">0x14</span> pkt cnt <span class="number">450071</span>, nss <span class="number">2</span>, bw <span class="number">4</span>]</span><br><span class="line"></span><br><span class="line"><span class="number">15</span>:<span class="number">05</span>:<span class="number">00.379218</span> [wifico][<span class="number">0x183a728afa9</span>][<span class="number">15</span>:<span class="number">05</span>:<span class="number">00.378476</span>]wlan: [<span class="number">1372</span>:D:HDD] wlan_hdd_get_sta_stats: [TX: Reporting MCS rate <span class="number">8</span>, flags <span class="number">0x14</span> pkt cnt <span class="number">267148</span>, nss <span class="number">2</span>, bw <span class="number">4</span>]-[RX: Reporting MCS rate <span class="number">8</span>, flags <span class="number">0x14</span> pkt cnt <span class="number">450073</span>, nss <span class="number">2</span>, bw <span class="number">4</span>]</span><br><span class="line"></span><br><span class="line"><span class="number">15</span>:<span class="number">05</span>:<span class="number">03.686570</span> [wifico][<span class="number">0x183aa9a651c</span>][<span class="number">15</span>:<span class="number">05</span>:<span class="number">03.388042</span>]wlan: [<span class="number">1372</span>:D:HDD] wlan_hdd_get_sta_stats: [TX: Reporting MCS rate <span class="number">8</span>, flags <span class="number">0x14</span> pkt cnt <span class="number">267148</span>, nss <span class="number">2</span>, bw <span class="number">4</span>]-[RX: Reporting MCS rate <span class="number">8</span>, flags <span class="number">0x14</span> pkt cnt <span class="number">450074</span>, nss <span class="number">2</span>, bw <span class="number">4</span>]</span><br><span class="line"></span><br><span class="line"><span class="number">15</span>:<span class="number">05</span>:<span class="number">07.132915</span> [wifico][<span class="number">0x183ae0eb713</span>][<span class="number">15</span>:<span class="number">05</span>:<span class="number">06.406522</span>]wlan: [<span class="number">1372</span>:D:HDD] wlan_hdd_get_sta_stats: [TX: Reporting MCS rate <span class="number">8</span>, flags <span class="number">0x14</span> pkt cnt <span class="number">267148</span>, nss <span class="number">2</span>, bw <span class="number">4</span>]-[RX: Reporting MCS rate <span class="number">8</span>, flags <span class="number">0x14</span> pkt cnt <span class="number">450075</span>, nss <span class="number">2</span>, bw <span class="number">4</span>]</span><br><span class="line"></span><br><span class="line"><span class="number">15</span>:<span class="number">05</span>:<span class="number">09.422157</span> [wifico][<span class="number">0x183b18213a7</span>][<span class="number">15</span>:<span class="number">05</span>:<span class="number">09.421730</span>]wlan: [<span class="number">1372</span>:D:HDD] wlan_hdd_get_sta_stats: [TX: Reporting MCS rate <span class="number">8</span>, flags <span class="number">0x14</span> pkt cnt <span class="number">267148</span>, nss <span class="number">2</span>, bw <span class="number">4</span>]-[RX: Reporting MCS rate <span class="number">8</span>, flags <span class="number">0x14</span> pkt cnt <span class="number">450105</span>, nss <span class="number">2</span>, bw <span class="number">4</span>]</span><br><span class="line"></span><br><span class="line"><span class="number">15</span>:<span class="number">05</span>:<span class="number">13.535129</span> [wifico][<span class="number">0x183b4f56b07</span>][<span class="number">15</span>:<span class="number">05</span>:<span class="number">12.436868</span>]wlan: [<span class="number">1372</span>:D:HDD] wlan_hdd_get_sta_stats: [TX: Reporting MCS rate <span class="number">8</span>, flags <span class="number">0x14</span> pkt cnt <span class="number">267148</span>, nss <span class="number">2</span>, bw <span class="number">4</span>]-[RX: Reporting MCS rate <span class="number">8</span>, flags <span class="number">0x14</span> pkt cnt <span class="number">450107</span>, nss <span class="number">2</span>, bw <span class="number">4</span>]</span><br></pre></td></tr></table></figure></p><p>网络正常情况下tx/rx 的收发包是会持续增长的</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;仅针对高通平台，旨在梳理出遇到此类问题的一般应对策略，作为工具篇查阅，快速分类出断流的原因  &lt;/p&gt;
&lt;h2 id=&quot;定位时间点&quot;&gt;&lt;a 
      
    
    </summary>
    
      <category term="网络" scheme="http://lihaizhou.top/categories/%E7%BD%91%E7%BB%9C/"/>
    
    
  </entry>
  
  <entry>
    <title>漫游系列之Dense roaming</title>
    <link href="http://lihaizhou.top/2021/01/03/%E6%BC%AB%E6%B8%B8%E7%B3%BB%E5%88%97%E4%B9%8BDense-roaming/"/>
    <id>http://lihaizhou.top/2021/01/03/漫游系列之Dense-roaming/</id>
    <published>2021-01-03T03:44:39.000Z</published>
    <updated>2021-10-16T05:44:53.112Z</updated>
    
    <content type="html"><![CDATA[<p>本地抓了一份dense roaming的日志，环境是办公室环境下走动到信号相对较弱茶水间再走回来，期间发生两次dense roaming，日志如下：<br><img src="http://blog.lihaizhou.top/DenseRoaming/denseroam-1.png" alt=""></p><p>对于其中的reason=7代码中定义如下：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">typedef <span class="keyword">enum</span> &#123;</span><br><span class="line">    WMI_ROAM_TRIGGER_REASON_NONE = <span class="number">0</span>,</span><br><span class="line">    WMI_ROAM_TRIGGER_REASON_PER,</span><br><span class="line">    WMI_ROAM_TRIGGER_REASON_BMISS,</span><br><span class="line">    WMI_ROAM_TRIGGER_REASON_LOW_RSSI,</span><br><span class="line">    WMI_ROAM_TRIGGER_REASON_HIGH_RSSI,</span><br><span class="line">    WMI_ROAM_TRIGGER_REASON_PERIODIC,</span><br><span class="line">    WMI_ROAM_TRIGGER_REASON_MAWC,</span><br><span class="line">    WMI_ROAM_TRIGGER_REASON_DENSE,</span><br><span class="line">    WMI_ROAM_TRIGGER_REASON_BACKGROUND,</span><br><span class="line">    WMI_ROAM_TRIGGER_REASON_FORCED,</span><br><span class="line">    WMI_ROAM_TRIGGER_REASON_BTM,</span><br><span class="line">    WMI_ROAM_TRIGGER_REASON_UNIT_TEST,</span><br><span class="line">    WMI_ROAM_TRIGGER_REASON_BSS_LOAD,</span><br><span class="line">    WMI_ROAM_TRIGGER_REASON_DEAUTH,</span><br><span class="line">    WMI_ROAM_TRIGGER_REASON_IDLE,</span><br><span class="line">    <span class="comment">/*</span></span><br><span class="line"><span class="comment">     * <span class="doctag">NOTE:</span> don't add any more ROAM_TRIGGER_REASON values here.</span></span><br><span class="line"><span class="comment">     * There are checks in the FW that require the value of</span></span><br><span class="line"><span class="comment">     * WMI_ROAM_TRIGGER_REASON_MAX to be &lt; 16.</span></span><br><span class="line"><span class="comment">     * Add new ROAM_TRIGGER_REASON values below, inside the</span></span><br><span class="line"><span class="comment">     * WMI_ROAM_TRIGGER_EXT_REASON_ID enum.</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    WMI_ROAM_TRIGGER_REASON_MAX,</span><br><span class="line">&#125; WMI_ROAM_TRIGGER_REASON_ID;</span><br></pre></td></tr></table></figure></p><p>reason=7对应的原因是WMI_ROAM_TRIGGER_REASON_DENSE即dense roaming</p><p>高通对dense roaming的解释<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Dense roaming</span><br><span class="line">Dense-<span class="function">roaming mechanism is a new feature of location retrieval <span class="title">function</span> <span class="params">(LRF)</span> 3.0. This feature retains high throughput when many roamable APs are present nearby and the data traffic is high then.</span></span><br><span class="line"><span class="function">The original Wi-Fi roaming mechanism is designed to enable roaming when the current RSSI value reaches the defined RSSI threshold value, <span class="keyword">for</span> example, -76 dBm. However, in a high dense environment where there are many roamable APs, it is better to start roaming earlier when the traffic is high because high throughput is maintained <span class="keyword">for</span> heavy traffic with minimal power consumption impact. Dense roaming functions in such a manner to retain high throughput during periods of heavy traffic.</span></span><br><span class="line"><span class="function">To provide <span class="keyword">this</span> value-added enhancement, the dense roaming mechanism is designed with the following two principles.</span></span><br><span class="line"><span class="function">■ Relying on other triggered scans, sniffing is performed on the management packets to determine the number of roamable APs that are present then in the environment.</span></span><br><span class="line"><span class="function">■ If a dense roaming environment is <span class="title">found</span> <span class="params">(that is, the number of the found roamable APs is bigger than the configured dense roamable AP threshold value)</span>, and <span class="keyword">if</span> there is significant traffic at that moment, then <span class="keyword">switch</span> to use the dense RSSI threshold value so that the roaming is triggered earlier.</span></span><br></pre></td></tr></table></figure></p><p>Dense意思是密集，dense roaming从字面上意思是密集漫游，上面高通的一段话翻译下来就是：<br>密集漫游<br>密集漫游机制是位置检索功能（LRF）3.0上新增的新feature，<font color="#dd0000">当附近有许多可漫游AP且数据流量很高时，此功能可保持高吞吐量。</font><br>   </p><p>最初的Wi-Fi漫游机制设计是当RSSI值比较低的时候并达到定义的RSSI阈值（例如-76 dBm）时启用漫游。<br>但是，在具有许多可漫游AP的高密度环境中，在流量较高时更早开始漫游是一个更好的措施，因为对于高流量保持高吞吐量，这样对功耗的影响则最小， 密集漫游在繁忙流量期间保持高吞吐量的方式运行。</p><p>为了提供这种增强功能，dense roaming按照以下两个原理设计：</p><ol><li>依靠其他条件触发的扫描，对管理数据包执行嗅探以确定当时环境中存在的可漫游AP的数量。</li><li>如果找到密集漫游环境（即找到的可漫游AP的数量大于配置的密集可漫游AP阈值），并且如果此时有大量流量，<font color="#dd0000">则切换为使用dense RSSI阈值，这样漫游就提前触发了</font><br> </li></ol><p>Q：怎么判断当前符合密集漫游环境？<br>A：<br>Detection of dense environment<br>The dense-roaming mechanism detects if it is a dense environment using the following procedure:  </p><ol><li>With any scan triggered, for example, a host scan from Wi-Fi driver, the roaming module snoops toget the beacon or probe response management frames.  </li><li>If a roamable AP is found, then the roaming module increments an internal count of the roamableAPs.  </li><li>If the number of the roamable APs is greater than the groam_dense_min_aps INI parametervalue, where three is the default value, then change to use dense roaming threshold value as thenew threshold value.<br>The dense roaming threshold value comes from the original threshold valuewith the shift of INI parameter, groam_dense_rssi_thresh_offset value. For example, if theoriginal threshold value is -76 dBm and groam_dense_rssi_thresh_offset INI parametervalue is 10, then the dense roaming threshold value is -66 dBm.</li></ol><p>检测密集环境<br>密集漫游机制使用以下步骤检测当前是否是密集环境：  </p><ol><li>如果有任何扫描（例如，从Wi-Fi驱动程序进行主机扫描）发送的话，漫游模块都会监听以获取信标或探测响应管理帧。  </li><li>如果找到了一个可漫游AP，则漫游模块将增加该可漫游AP的内部计数。  </li><li>如果可漫游AP的数量大于groam_dense_min_aps INI参数值（默认值为3），<font color="#dd0000">则更改为使用密集漫游阈值作为新阈值。</font><br> 密集漫游阈值来自原始阈值，并带有INI参数的偏移groam_dense_rssi_thresh_offset值。<br> 例如，如果原始阈值是-76 dBm，并且groam_dense_rssi_thresh_offset INI参数值是10，则密集漫游阈值是-66 dBm。</li></ol><p>Q: 即便当前检测到dense roaming环境了，也不一定会触发dense roaming，为什么？<br>参见如下解释：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Dense roaming in dense environment  </span><br><span class="line">During the detection of a dense environment, dense-roaming mechanism is triggered and the followingactions are taken:  </span><br><span class="line"><span class="number">1</span>.  When the current RSSI breaches the dense roaming RSSI threshold value and the data traffic isabove the dense traffic threshold as defined by the INI parameter, gtraffic_threshold, then the active roam scan is triggered.  </span><br><span class="line"><span class="number">2</span>.  When the current RSSI breaches the dense roaming RSSI threshold value and the data traffic isbelow the dense traffic threshold, then update only the threshold value by RSSI different threshold values and <span class="keyword">do</span> not trigger the active roam scan.  </span><br><span class="line"><span class="number">3</span>.  When the RSSI threshold exceeds the original roaming threshold value, <span class="keyword">for</span> example, -<span class="number">76</span> dBm,then <span class="keyword">do</span> not consider the data traffic and trigger the active roam scan.  </span><br><span class="line"><span class="number">4</span>.  If skipping the active roam scan due to insufficient data traffic in the point mentioned previously,then take either of the following steps based on whichever occurs first:a.  If the <span class="keyword">new</span> threshold value is breached first, <span class="keyword">for</span> example, RSSI drops to -<span class="number">71</span> dBm, then check ifthe condition is as the steps <span class="number">1</span> or <span class="number">2</span> mentioned previously and take actions accordingly.b.  If the data traffic is above the dense traffic threshold, then trigger the roaming scan</span><br></pre></td></tr></table></figure></p><p>在密集环境中的密集漫游<br>  在检测密集环境时，将触发密集漫游机制，并采取以下措施：<br>  1.如果当前RSSI值超过了dense roaming的阈值，并且数据流量高于INI参数gtraffic_threshold定义的密集流量阈值时，这时候将触发活动漫游扫描。<br>  2.如果当前的RSSI超过了dense roaming的RSSI阈值并且数据流量低于密集流量阈值时，则仅更新阈值，并不触发漫游扫描。<br>  3.当RSSI阈值超过原始漫游阈值（例如-76 dBm）时，则无需考虑数据流量并触发活动漫游扫描。<br>  4.如果由于前面提到的数据通信量不足而跳过了主动漫游扫描，则采取以下步骤之一(根据哪种情况先发生)：<br>  a)  如果首先突破了新阈值，例如RSSI降至-71 dBm，则请检查条件是否符合前面提到的步骤1或2并采取相应措施<br>  b)  如果数据流量高于密集流量阈值，则触发漫游扫描</p><p>  个人理解：<br>dense roaming有自己的一个阈值，很显然这个值会低于原始的漫游阈值，假设是-66，我们知道原始的一般是-76，比如这个时候RSSI是-67已经超过了-66，并且这个时候数据流量大于规定的阈值，这种情况符合RSSI达到dense roaming阈值且处于大数据流量情况，此时直接触发漫游扫描。<br>但是如果此时虽然RSSI达到了但是数据流量不够大没有达标，那么只是更新dense roaming阈值，并不会触发漫游扫描。这里我们知道了原来dense roaming的阈值是动态变化的，这点后面看日志也能看出来。<br>这个时候假设dense roaming阈值调整了，比如又降低了一点达到了-71，这个时候会采取下面两个步骤之一，就看哪个先发生</p><ol><li>当前RSSI先达到新阈值了，则执行1&amp;2步骤</li><li>如果此时数据流量高于阈值了，直接漫游！</li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;本地抓了一份dense roaming的日志，环境是办公室环境下走动到信号相对较弱茶水间再走回来，期间发生两次dense roaming，日志如下：&lt;br&gt;&lt;img src=&quot;http://blog.lihaizhou.top/DenseRoaming/denseroam-
      
    
    </summary>
    
      <category term="网络" scheme="http://lihaizhou.top/categories/%E7%BD%91%E7%BB%9C/"/>
    
    
  </entry>
  
  <entry>
    <title>一个Beacon miss导致的掉线问题分析</title>
    <link href="http://lihaizhou.top/2021/01/02/%E4%B8%80%E4%B8%AABeacon-miss%E5%AF%BC%E8%87%B4%E7%9A%84%E6%8E%89%E7%BA%BF%E9%97%AE%E9%A2%98%E5%88%86%E6%9E%90/"/>
    <id>http://lihaizhou.top/2021/01/02/一个Beacon-miss导致的掉线问题分析/</id>
    <published>2021-01-02T06:53:50.000Z</published>
    <updated>2021-09-08T12:36:27.629Z</updated>
    
    <content type="html"><![CDATA[<p>复现步骤：测试机开启双WiFi且连接测试路由主5G，辅2.4G<br>问题现象：主wifi漫游后不久，辅WiFi出现断连<br>问题概率：必现  </p><h1 id="辅wifi为什么会断连？"><a href="#辅wifi为什么会断连？" class="headerlink" title="辅wifi为什么会断连？"></a>辅wifi为什么会断连？</h1><p>先看下辅wifi为何会断连，从测试同事提供的视频来看时间点大概是15:50:07左右  </p><h2 id="step1"><a href="#step1" class="headerlink" title="step1:"></a>step1:</h2><p>看下这个时间点的辅wifi状态机<br><code>tip: 过滤的关键字&quot;WifiClientModeImpl:&quot;,打印不同时间点的wifi状态转移变化</code></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rec[<span class="number">22</span>]: time=<span class="number">12</span>-<span class="number">30</span> <span class="number">15</span>:<span class="number">50</span>:<span class="number">07.841</span> processed=ConnectModeState org=ConnectedState dest=DisconnectedState what=SUPPLICANT_STATE_CHANGE_EVENT screen=on <span class="number">0</span> <span class="number">0</span> SSID: <span class="number">2.4</span> BSSID: <span class="number">00</span>:<span class="number">00</span>:<span class="number">00</span>:<span class="number">00</span>:<span class="number">00</span>:<span class="number">00</span> nid: <span class="number">1</span> state: DISCONNECTED</span><br></pre></td></tr></table></figure><h2 id="step2"><a href="#step2" class="headerlink" title="step2:"></a>step2:</h2><p>看下当前的信号强度以及断线reason值<br>//搜索关键字”NETWORK_DISCONNECTION_EVENT”, 代表网络断开的标志性日志，信号值-21说明信号强度很好，reason为0<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">12</span>-<span class="number">30</span> <span class="number">15</span>:<span class="number">50</span>:<span class="number">07.809</span> NETWORK_DISCONNECTION_EVENT local_gen=<span class="keyword">false</span> reason=<span class="number">0</span>:<span class="number">0x0</span> lastRssi=-<span class="number">21</span> lastFreq=<span class="number">2437</span> lastLinkSpeed=<span class="number">96</span> lastScore=<span class="number">60</span> mobileTxBytes=<span class="number">964</span> mobileRxBytes=<span class="number">476</span> totalTxBytes=<span class="number">711415</span> totalRxBytes=<span class="number">1741111</span> screenOn=<span class="keyword">true</span> cellularData=<span class="keyword">false</span>, supplicantStateChangeEvents: &#123; COMPLETED &#125;</span><br></pre></td></tr></table></figure></p><p>这个reason 0其实没有多大的参考意义，对应的802.11 Deauth Reason Codes表格中给出的解释是正常操作，具体的reason需要看fw打印的reason</p><h2 id="step3"><a href="#step3" class="headerlink" title="step3:"></a>step3:</h2><p>确认下辅wifi是底层断线还是上层断线<br>直接看<code>nl80211</code>收到断线的消息早于<code>wpa_supplicant: wlan1</code>可以说明是底层掉线</p><p>//logcat<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">12</span>-<span class="number">30</span> <span class="number">15</span>:<span class="number">50</span>:<span class="number">07.804</span> wifi <span class="number">4855</span> <span class="number">4855</span> D wpa_supplicant: nl80211: Drv Event <span class="number">48</span> (NL80211_CMD_DISCONNECT) received <span class="keyword">for</span> wlan1</span><br><span class="line"><span class="number">12</span>-<span class="number">30</span> <span class="number">15</span>:<span class="number">50</span>:<span class="number">07.804</span> wifi <span class="number">4855</span> <span class="number">4855</span> D wpa_supplicant: nl80211: Disconnect event</span><br><span class="line"><span class="number">12</span>-<span class="number">30</span> <span class="number">15</span>:<span class="number">50</span>:<span class="number">07.804</span> wifi <span class="number">4855</span> <span class="number">4855</span> D wpa_supplicant: wlan1: <span class="function">Event <span class="title">DEAUTH</span> <span class="params">(<span class="number">11</span>)</span> received</span></span><br><span class="line"><span class="function">12-30 15:50:07.804 wifi 4855 4855 D wpa_supplicant: wlan1: Deauthentication notification</span></span><br><span class="line"><span class="function">12-30 15:50:07.804 wifi 4855 4855 D wpa_supplicant: wlan1: * reason 0 <span class="params">(UNKNOWN)</span> locally_generated</span>=<span class="number">1</span></span><br><span class="line"><span class="number">12</span>-<span class="number">30</span> <span class="number">15</span>:<span class="number">50</span>:<span class="number">07.804</span> wifi <span class="number">4855</span> <span class="number">4855</span> D wpa_supplicant: <span class="function">Deauthentication frame <span class="title">IE</span><span class="params">(s)</span> - <span class="title">hexdump</span><span class="params">(len=<span class="number">0</span>)</span>: [NULL]</span></span><br><span class="line"><span class="function">12-30 15:50:07.804 wifi 4855 4855 I wpa_supplicant: wlan1: CTRL-EVENT-DISCONNECTED bssid</span>=<span class="number">3</span>a:<span class="number">72</span>:e4:<span class="number">68</span>:<span class="number">21</span>:e9 reason=<span class="number">0</span> locally_generated=<span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="number">12</span>-<span class="number">30</span> <span class="number">15</span>:<span class="number">50</span>:<span class="number">07.805</span> wifi <span class="number">4855</span> <span class="number">4855</span> D wpa_supplicant: wlan1: State: COMPLETED -&gt; DISCONNECTED</span><br></pre></td></tr></table></figure></p><h2 id="step4："><a href="#step4：" class="headerlink" title="step4："></a>step4：</h2><p>到这里我们只知道是底层断线的，具体原因还没找到，此时需要看下driver log以及fw log</p><p>//driver log<br>关键性日志<code>wma_roam_event_callback</code>，代表<code>driver</code>收到<code>fw roam</code>的<code>callback</code>，后面跟着的<code>reason=2</code> 代表本次打算去漫游的原因是<code>beacon miss</code>，但是其实后面并没有实际去漫游的动作，<br>包括<code>roam scan</code>也没有，是因为辅wifi底层不支持漫游，此时信号-25很好</p><pre><code class="java"><span class="number">15</span>:<span class="number">50</span>:<span class="number">07.679517</span> [schedu][<span class="number">0x2021a49e0</span>][<span class="number">15</span>:<span class="number">50</span>:<span class="number">07.675444</span>]wlan: [<span class="number">4730</span>:D:WMA] wma_roam_event_callback: Reason <span class="number">2</span>, Notif <span class="number">0</span> <span class="keyword">for</span> vdevid <span class="number">1</span>, rssi -<span class="number">25</span><span class="number">15</span>:<span class="number">50</span>:<span class="number">07.679946</span> [schedu][<span class="number">0x2021a508e</span>][<span class="number">15</span>:<span class="number">50</span>:<span class="number">07.675533</span>]wlan: [<span class="number">4730</span>:E:PE] lim_ps_offload_handle_missed_beacon_ind: <span class="number">1855</span>: Received Heart Beat Failure<span class="comment">//收到fw传上来的心跳包失败的消息</span><span class="number">15</span>:<span class="number">50</span>:<span class="number">07.679961</span> [schedu][<span class="number">0x2021a525e</span>][<span class="number">15</span>:<span class="number">50</span>:<span class="number">07.675557</span>]wlan: [<span class="number">4730</span>:E:PE] lim_send_heart_beat_timeout_ind: <span class="number">1830</span>: Heartbeat failure from Fw<span class="number">15</span>:<span class="number">50</span>:<span class="number">07.679977</span> [schedu][<span class="number">0x2021a5527</span>][<span class="number">15</span>:<span class="number">50</span>:<span class="number">07.675594</span>]wlan: [<span class="number">4730</span>:W:PE] lim_handle_heart_beat_failure: <span class="number">494</span>: Heartbeat Failure<span class="comment">//因为sta没有收到AP发的心跳beacon，所以sta在beacon timeout之前主动发了Probe Req报文探测下AP是否还在</span><span class="number">15</span>:<span class="number">50</span>:<span class="number">07.679984</span> [schedu][<span class="number">0x2021a55f7</span>][<span class="number">15</span>:<span class="number">50</span>:<span class="number">07.675605</span>]wlan: [<span class="number">4730</span>:D:PE] lim_handle_heart_beat_failure: <span class="number">515</span>: HB missed from AP. Sending Probe Req<span class="number">15</span>:<span class="number">50</span>:<span class="number">07.680005</span> [schedu][<span class="number">0x2021a5ada</span>][<span class="number">15</span>:<span class="number">50</span>:<span class="number">07.675670</span>]wlan: [<span class="number">4730</span>:D:PE] Probe req TX: vdev <span class="number">1</span> seq num <span class="number">2077</span> to <span class="number">3</span>a:<span class="number">72</span>:e4:<span class="number">68</span>:<span class="number">21</span>:e9 len <span class="number">158</span><span class="number">15</span>:<span class="number">50</span>:<span class="number">07.750957</span> [schedu][<span class="number">0x2021a6b29</span>][<span class="number">15</span>:<span class="number">50</span>:<span class="number">07.675887</span>]wlan: [<span class="number">4730</span>:D:PE] lim_handle_heart_beat_timeout_for_session: <span class="number">4610</span>: Sending Probe <span class="keyword">for</span> Session: <span class="number">1</span><span class="number">15</span>:<span class="number">50</span>:<span class="number">07.750989</span> [schedu][<span class="number">0x2021a6e9e</span>][<span class="number">15</span>:<span class="number">50</span>:<span class="number">07.675934</span>]wlan: [<span class="number">4730</span>:D:HDD] hdd_lost_link_info_cb: <span class="number">1323</span>: rssi on disconnect -<span class="number">25</span><span class="comment">//AP没有ACK</span><span class="number">15</span>:<span class="number">50</span>:<span class="number">07.750995</span> [schedu][<span class="number">0x20222d395</span>][<span class="number">15</span>:<span class="number">50</span>:<span class="number">07.704587</span>]wlan: [<span class="number">4730</span>:D:WMA] wma_process_mgmt_tx_completion: <span class="number">2613</span>: status: WMI_MGMT_TX_COMP_TYPE_COMPLETE_NO_ACK wmi_desc_id: <span class="number">63</span><span class="number">15</span>:<span class="number">50</span>:<span class="number">07.751023</span> [schedu][<span class="number">0x2022f8cef</span>][<span class="number">15</span>:<span class="number">50</span>:<span class="number">07.748018</span>]wlan: [<span class="number">4730</span>:I:PE] Deauth TX: vdev <span class="number">1</span> seq_num <span class="number">2078</span> reason <span class="number">4</span> waitForAck <span class="number">0</span> to <span class="number">3</span>a:<span class="number">72</span>:e4:<span class="number">68</span>:<span class="number">21</span>:e9 from <span class="number">34</span>:<span class="number">1</span>c:f0:<span class="number">6f</span>:b6:<span class="number">22</span><span class="number">15</span>:<span class="number">50</span>:<span class="number">07.751112</span> [schedu][<span class="number">0x2022fa17f</span>][<span class="number">15</span>:<span class="number">50</span>:<span class="number">07.748292</span>]wlan: [<span class="number">4730</span>:D:SME] csr_roam_chk_lnk_deauth_ind: <span class="number">12441</span>: DEAUTH Indication from MAC <span class="keyword">for</span> vdev_id <span class="number">1</span> bssid <span class="number">3</span>a:<span class="number">72</span>:e4:<span class="number">68</span>:<span class="number">21</span>:e9</code></pre><p><code>beacon miss</code>的发生不一定会立刻掉线，达到一定数量才会触发掉线吧?<br>接下来在fw log中证实下这个猜想</p><p>//fw log<br>//15:50:07 左右发生bmiss</p><p>//…省略cons_bmiss_count = 8之前的片段</p><pre><code class="java"><span class="number">15</span>:<span class="number">50</span>:<span class="number">05.820871</span> R0: FWMSG: [<span class="number">1891</span>d6b92] [ wlan_swbmiss_offload.c : <span class="number">865</span> ] SWBMISS_TIMER_FN: vdev_id=<span class="number">1</span>, curr_bmiss_bcnt=<span class="number">8</span>, pre_bmiss_detected=<span class="number">1</span>, first_bmiss_detected=<span class="number">0</span>, final_bmiss_detected=<span class="number">0</span>, b_timeout=<span class="number">1</span>, cons_bmiss_count = <span class="number">8</span><span class="number">15</span>:<span class="number">50</span>:<span class="number">05.822430</span> R0: FWMSG: [<span class="number">1893</span>b1a83] [ wlan_swbmiss_offload.c : <span class="number">865</span> ] SWBMISS_TIMER_FN: vdev_id=<span class="number">1</span>, curr_bmiss_bcnt=<span class="number">9</span>, pre_bmiss_detected=<span class="number">1</span>, first_bmiss_detected=<span class="number">0</span>, final_bmiss_detected=<span class="number">0</span>, b_timeout=<span class="number">1</span>, cons_bmiss_count = <span class="number">9</span><span class="number">15</span>:<span class="number">50</span>:<span class="number">05.862506</span> R0: FWMSG: [<span class="number">18958</span>dc54] [ wlan_swbmiss_offload.c : <span class="number">865</span> ] SWBMISS_TIMER_FN: vdev_id=<span class="number">1</span>, curr_bmiss_bcnt=<span class="number">10</span>, pre_bmiss_detected=<span class="number">1</span>, first_bmiss_detected=<span class="number">1</span>, final_bmiss_detected=<span class="number">0</span>, b_timeout=<span class="number">1</span>, cons_bmiss_count = <span class="number">10</span><span class="number">15</span>:<span class="number">50</span>:<span class="number">05.905835</span> R0: FWMSG: [<span class="number">189770</span>d97] [ wlan_swbmiss_offload.c : <span class="number">865</span> ] SWBMISS_TIMER_FN: vdev_id=<span class="number">1</span>, curr_bmiss_bcnt=<span class="number">11</span>, pre_bmiss_detected=<span class="number">1</span>, first_bmiss_detected=<span class="number">1</span>, final_bmiss_detected=<span class="number">0</span>, b_timeout=<span class="number">1</span>, cons_bmiss_count = <span class="number">11</span><span class="comment">//.....省略cons_bmiss_count = 12到cons_bmiss_count = 28的片段日志</span><span class="number">15</span>:<span class="number">50</span>:<span class="number">07.761702</span> R0: FWMSG: [<span class="number">18</span>b9308fb] [ wlan_swbmiss_offload.c : <span class="number">865</span> ] SWBMISS_TIMER_FN: vdev_id=<span class="number">1</span>, curr_bmiss_bcnt=<span class="number">29</span>, pre_bmiss_detected=<span class="number">1</span>, first_bmiss_detected=<span class="number">1</span>, final_bmiss_detected=<span class="number">0</span>, b_timeout=<span class="number">1</span>, cons_bmiss_count = <span class="number">2915</span>:<span class="number">50</span>:<span class="number">07.761875</span> R0: FWMSG: [<span class="number">18</span>b95f62e] [ wlan_swbmiss_offload.c : <span class="number">563</span> SWBMISS_NULL_SEND_CMPLT: vdev_id=<span class="number">1</span>, isQosNullSuccess=<span class="number">0</span>, isFinalBmiss=<span class="number">1</span>, first_bmiss_detected=<span class="number">1</span>, final_bmiss_detected=<span class="number">1</span>, fbmiss_evnt_posted=<span class="number">0</span>, vbmiss-&gt;connected = <span class="number">1</span>, cons_bmiss_count = <span class="number">30</span></code></pre><p>这里的<code>final_bmiss_detected</code>  ，<code>first_bmiss_detected</code>  解释对应如下</p><pre><code class="java">gRoamBmissFirstBcnt=<span class="number">10</span>After consecutive number of beacons missed as configured by gRoamBmissFirstBcnt, <span class="function">the system stays <span class="title">alive</span> <span class="params">(no power collapse)</span> t</span><span class="function">o receive beacons until <span class="keyword">final</span> <span class="title">BMISS</span> <span class="params">(consecutive number of beacons missed as configured by gRoamBmissFinalBcnt)</span> </span><span class="function"></span><span class="function">gRoamBmissFinalBcnt</span>=<span class="number">20</span>After consecutive number of beacons missed as configured by gRoamBmissFirstBcnt, <span class="function">the system stays <span class="title">alive</span> <span class="params">(no power collapse)</span> to receive beacons until <span class="keyword">final</span> <span class="title">BMISS</span> <span class="params">(consecutive number of beacons missed as configured by gRoamBmissFinalBcnt)</span></span><span class="function"></span><span class="function">If “p”<span class="params">(gRoamBmissFirstBcnt)</span> beacons are missed in a row, roaming <span class="keyword">module</span> will perform roaming scan and create a channel map.</span><span class="function">If “q”<span class="params">(gRoamBmissFinalBcnt)</span> more beacons are missed, it results in “<span class="keyword">final</span> beacon miss”.</span><span class="function"></span><span class="function">That is a trigger <span class="keyword">for</span> roaming. If we don’t find the candidate, <span class="keyword">this</span> will lead to disconnection.</span></code></pre><p>大概意思是有连续的10个<code>beacon missed</code>发生了，这个时候不会断线，会触发漫游并会继续接收beacon。</p><p>如果在前面连续十个<code>beacon missed</code>之后又发生连续20个<code>beacon missed</code>的话，则会进入<code>final beacon miss</code> ，这个时候如果还没有找到候选AP的话，会最终导致断线<br>所以到这里明白了fw确实总计发生了30次<code>beacon miss</code>，并且由于是辅wifi不支持漫游的缘故，最终以断线收场</p><h2 id="step5："><a href="#step5：" class="headerlink" title="step5："></a>step5：</h2><p>可是beacon miss的原因是什么呢？前面已经分析过断开时信号是-25说明不是信号弱导致，同时也看到了在超时掉线前sta有发probe request即空帧探测AP，没有收到AP的ACK，看上去大概率问题出在AP<br>但是测试同事提的这个问题是在主wifi漫游后才会出现辅wifi掉线，这和主wifi漫游有关系？和channel有关系？</p><p>下一步请求测试同事提供sniffer进一步证实, 此文待续</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;复现步骤：测试机开启双WiFi且连接测试路由主5G，辅2.4G&lt;br&gt;问题现象：主wifi漫游后不久，辅WiFi出现断连&lt;br&gt;问题概率：必现  &lt;/p&gt;
&lt;h1 id=&quot;辅wifi为什么会断连？&quot;&gt;&lt;a href=&quot;#辅wifi为什么会断连？&quot; class=&quot;header
      
    
    </summary>
    
      <category term="网络" scheme="http://lihaizhou.top/categories/%E7%BD%91%E7%BB%9C/"/>
    
    
  </entry>
  
  <entry>
    <title>对投屏工作的回顾小结(持续补充)</title>
    <link href="http://lihaizhou.top/2020/12/01/%E5%AF%B9%E6%8A%95%E5%B1%8F%E5%B7%A5%E4%BD%9C%E7%9A%84%E5%9B%9E%E9%A1%BE%E5%B0%8F%E7%BB%93-%E6%8C%81%E7%BB%AD%E8%A1%A5%E5%85%85/"/>
    <id>http://lihaizhou.top/2020/12/01/对投屏工作的回顾小结-持续补充/</id>
    <published>2020-12-01T09:08:00.000Z</published>
    <updated>2021-10-16T05:46:53.087Z</updated>
    
    <content type="html"><![CDATA[<p>前言<br>主要针对高通平台上的miracast投屏遇到的问题，顺便对miracast投屏的一点归纳总结，以便后续如再处理miracast投屏相关的工作，通过本篇文章能够快速重新开始。</p><p>以下主要通过一些QA方式来概述 </p><p>Q：高通上的投屏和谷歌原生的投屏有什么差别吗？</p><p>A：Google WFD 支持AVC, LPCM, and AAC 编码 并支持HDCP加密, 但是缺少对内容保护的支持<br>      通过使用Presentation、MediaRouter和DisplayManager api，它可以作为一个外部WFD提供给应用程序使用。<br>      按照高通文档的解释，谷歌的miracast和高通的相比，缺乏内容保护支持，性能较低，功耗较高，高通提供了一个增强的Miracast解决方案。</p><p>Q：Miracast Source 软件架构是怎样的？</p><p>A：<br><img src="http://blog.lihaizhou.top/Miracast/miracast.png" alt=""><br>个人理解红色标准1和2的代表视频数据的两种来源，分别是USB/摄像头和录制屏幕，4标注代表的是经过V4L2编码后的视频数据从给混合起Mux，5标注代表音频数据送给Mux，合成后压缩成MPEG-2格式的ts流，再通过RTP server即UDP传送，6标注代表的是RTSP的协议栈，RTSP是基于tcp的，主要是客户端和sink端的一系列交互和协商等。</p><p>Q：如果投屏失败了，从tcpdump上如何分析出是哪一步出错了？</p><p>A：正确的流程参见：<br><a href="http://lihaizhou.top/2020/11/30/%E4%BB%8Etcpdump%E7%9C%8Bmiracast%E7%9A%84play%E6%B5%81%E7%A8%8B/#more">从tcpdump看miracast的play流程(工具篇)</a></p><p>Q：怎么看SessionManagerService在miracast投屏环节中扮演的角色？</p><p>A：个人理解这个类承担的角色比较重要，实现是在vendor中，是一个binder的服务端，起到一个承上启下的作用。<br>      承上的是应用层以及fwk，承下的是主要native层的wifisession打交道。<br>      其实不妨看下这个类中的方法，比如startWfdSession，startUibcSession，setSurface，play, pause，tcpPlaybackControl等几乎都是对WFDSession中的接口所做的一层封装。<br>      所以比较核心的方法还得接着看native层的WFDSession，高通的真正实现封装在so中</p><p>Q：如果投屏遇到花屏了或者其他画面异常的情况，该如何判断是sink还是source的问题，如果是source的话，是哪一步的问题呢？</p><p>A：目前遇到的画面显示异常除了小部分是非问题比如输入法状态栏等隐私保护设计导致的，其他大部分都是网络环境导致的。这里先不考虑可能是sink端解码的问题，假如问题就出在source或者网络，可以先获取发送前的视频流dump.ts，这个ts流已经是音视频合成后的准备通过网络发送的数据。<br>如果这个ts流是正常的，就可以排除是source的问题了，如果这个ts流是有问题的话，就要考虑是不是V4L2编码后的数据是否是正常的了,这个时候可以抓取V4l2 dump获取到编码后的视频数据，这个数据是发给mux的，然后和av数据混合成ts流</p><p>Q：如何判断花屏是否因为是丢包率高导致的？</p><p>A：wireshark打开抓取的tcpdump，选择UDP packet，Right click -&gt; Decode as -&gt; RTP  Then from the tool bar, select Telephony -&gt; RTP-&gt;Stream analysis -&gt; Save Payload<br>. This will open a pop-up which shows the packet loss % rate.</p><p>Q: VirtualDisplay在miracast投屏中是何时创建的，扮演的作用？</p><p>A: 我们先说下手机普通录制视频的流程，一般会先用<code>MediaProjection</code>的<code>createVirtualDisplay</code>创建一个VirtualDisplay，createVirtualDisplay的参数有宽高dpi啥的，还有一个最重要的参数就是surface，这玩意其实就是指向一块内存，surface怎么创建呢，可以使用MediaCodec的createInputSurface创建一个输入surface，也可以自己创建，使用MediaCodec的API创建的话缺乏灵活性，没有办法对一帧一帧数据进行处理。录制屏幕的数据从而而来的呢？MediaCodec的createByCodecName创建一个编码器，然后调用其setCallback，在onOutputBufferAvailable中获取到buffer数据，然后这个时候就可以处理这些录屏数据了。<br>对于VirtualDisplay来说，帧数据的生产者是MediaProjection对象，消费者是向它注册的MediaCodec的Surface对象。</p><p>在miracast投屏环节中，VirtualDisplay是何时创建的呢？<br>WFDSession.java中的notify函数中如下方式：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">                            <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">notify</span><span class="params">(Bundle b, <span class="keyword">int</span> SessionId)</span> </span>&#123;</span><br><span class="line">                            <span class="comment">//....</span></span><br><span class="line">                            Surface surface = (Surface) (b</span><br><span class="line">                                    .getParcelable(<span class="string">"surface"</span>));</span><br><span class="line">                            <span class="keyword">if</span> (surface != <span class="keyword">null</span>) &#123;</span><br><span class="line">                                Log.d(mTAG, <span class="string">"Surface supplied by source modules"</span>);</span><br><span class="line">                                <span class="keyword">int</span> flags = <span class="number">0</span>;</span><br><span class="line">                                <span class="comment">// MIUI MOD: START</span></span><br><span class="line">                                <span class="comment">//flags |= DisplayManager.VIRTUAL_DISPLAY_FLAG_PUBLIC</span></span><br><span class="line">                                <span class="comment">//        | DisplayManager.VIRTUAL_DISPLAY_FLAG_PRESENTATION;</span></span><br><span class="line">                                flags |= DisplayManager.VIRTUAL_DISPLAY_FLAG_PUBLIC</span><br><span class="line">                                        | DisplayManager.VIRTUAL_DISPLAY_FLAG_PRESENTATION</span><br><span class="line">                                        | VIRTUAL_DISPLAY_FLAG_THE_THIRD_SCREEN_PROJECTION;</span><br><span class="line">                                <span class="comment">// END</span></span><br><span class="line">                                <span class="keyword">if</span> (secure == <span class="number">1</span>) &#123;</span><br><span class="line">                                    flags |= DisplayManager.VIRTUAL_DISPLAY_FLAG_SECURE;</span><br><span class="line"><span class="comment">//                                            | DisplayManager.VIRTUAL_DISPLAY_FLAG_SUPPORTS_PROTECTED_BUFFERS;</span></span><br><span class="line">                                &#125;</span><br><span class="line">                                mVirtualDisplayDPI = Math.min(width, height)</span><br><span class="line">                                        * DisplayMetrics.DENSITY_XHIGH / <span class="number">1080</span>;</span><br><span class="line">                                <span class="keyword">if</span> (mDisplayManager != <span class="keyword">null</span>) &#123;</span><br><span class="line">                                    mVirtualDisplay = mDisplayManager</span><br><span class="line">                                            .createVirtualDisplay(</span><br><span class="line">                                                    mPeerDevice.deviceName,</span><br><span class="line">                                                    width,</span><br><span class="line">                                                    height,</span><br><span class="line">                                                    mVirtualDisplayDPI,</span><br><span class="line">                                                    surface, flags);</span><br><span class="line">                                &#125;</span><br><span class="line">                            &#125;</span><br></pre></td></tr></table></figure></p><p>当上层调用创建好WFD session后才会创建这个VirtualDisplay</p><p>Q：隐私投屏是如何实现的？如何做到有些界面在sink端不显示？</p><p>A：我们在WFDSession中createVirtualDisplay时需要传入一个flag参数，文章便在这个flag上，这里新加一个针对隐私的flag，其他界面中的window如果配置了隐私flag的话就不会显示在sink端，fwk端在VirtualDisplayAdapter#performTraversalLocked中判断当前创建的virtualdisplay是否有这个flag，有的话就使能隐私投屏功能</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;前言&lt;br&gt;主要针对高通平台上的miracast投屏遇到的问题，顺便对miracast投屏的一点归纳总结，以便后续如再处理miracast投屏相关的工作，通过本篇文章能够快速重新开始。&lt;/p&gt;
&lt;p&gt;以下主要通过一些QA方式来概述 &lt;/p&gt;
&lt;p&gt;Q：高通上的投屏和谷歌原生
      
    
    </summary>
    
      <category term="网络" scheme="http://lihaizhou.top/categories/%E7%BD%91%E7%BB%9C/"/>
    
    
  </entry>
  
  <entry>
    <title>从tcpdump看miracast的play流程(工具篇)</title>
    <link href="http://lihaizhou.top/2020/11/30/%E4%BB%8Etcpdump%E7%9C%8Bmiracast%E7%9A%84play%E6%B5%81%E7%A8%8B/"/>
    <id>http://lihaizhou.top/2020/11/30/从tcpdump看miracast的play流程/</id>
    <published>2020-11-30T03:01:15.000Z</published>
    <updated>2021-10-16T06:00:43.111Z</updated>
    
    <content type="html"><![CDATA[<p>前言：<br>基于高通平台，其他平台都是类似的<br>本文作为工具篇，记录下来的目的是以便后续如再接触投屏工作能够快速对照上手</p><p>当我们开始准备连接sink设备时，开始的时候，source会创建一个socket监听着并等待sink端过来连接，sink端会触发”connect”的socket函数并开始tcp 握手之路，这个时候source接收到之后，它会触发”accept”的socket函数来处理sink发过俩的连接请求</p><p>开始是握手 Key Message #1~#4<br><img src="http://blog.lihaizhou.top/Miracast_play/miracast-play01.png" alt=""></p><p>RTSP connect M1~M8:<br><img src="http://blog.lihaizhou.top/Miracast_play/miracast-play02.png" alt=""></p><p>DHCP ACK<br><img src="http://blog.lihaizhou.top/Miracast_play/miracast-play03.png" alt=""></p><p>如果这里DHCP Discover -&gt; DHCP ACK耗时超过 5s, 对于一些sink设备来说它就不会继续发 SYN 消息了 ，因此连接会阻塞在这里<br>所以如果遇到sink没有发送SYN的话就要看看这里的DHCP是否耗时太久了</p><p>SYN handshake Sink should send SYN message to 7236 port at this step:<br><img src="http://blog.lihaizhou.top/Miracast_play/miracast-play04.png" alt=""></p><p>Get/Set parameter<br><img src="http://blog.lihaizhou.top/Miracast_play/miracast-play05.png" alt=""></p><p>Play<br><img src="http://blog.lihaizhou.top/Miracast_play/miracast-play06.png" alt=""></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;前言：&lt;br&gt;基于高通平台，其他平台都是类似的&lt;br&gt;本文作为工具篇，记录下来的目的是以便后续如再接触投屏工作能够快速对照上手&lt;/p&gt;
&lt;p&gt;当我们开始准备连接sink设备时，开始的时候，source会创建一个socket监听着并等待sink端过来连接，sink端会触发”c
      
    
    </summary>
    
      <category term="网络" scheme="http://lihaizhou.top/categories/%E7%BD%91%E7%BB%9C/"/>
    
    
  </entry>
  
  <entry>
    <title>一次SystemServer OOM导致的系统重启分析之路</title>
    <link href="http://lihaizhou.top/2020/11/25/%E4%B8%80%E6%AC%A1SystemServer-OOM%E5%AF%BC%E8%87%B4%E7%9A%84%E7%B3%BB%E7%BB%9F%E9%87%8D%E5%90%AF%E5%88%86%E6%9E%90%E4%B9%8B%E8%B7%AF/"/>
    <id>http://lihaizhou.top/2020/11/25/一次SystemServer-OOM导致的系统重启分析之路/</id>
    <published>2020-11-25T00:59:48.000Z</published>
    <updated>2021-10-16T06:14:02.373Z</updated>
    
    <content type="html"><![CDATA[<p><strong>测试步骤</strong><br>MTBF测试跑出来的机器重启，先解释下何为MTBF？<br><code>MTBF测试(Mean Time Between Failure)</code><br>主要测试终端在连续工作状态下，出现死机、重启、冻屏、应用强制关闭等严重故障的概率。通过在一个周期内以自动化方式反复执行规定用例，记录测试过程中被测终端出现的故障数</p><p><strong>复现概率</strong><br>1/200</p><p><strong>问题现象</strong><br>机器出现重启，并自动给出源头是OOM导致的结论</p><h1 id="初步分析"><a href="#初步分析" class="headerlink" title="初步分析"></a>初步分析</h1><p>正常步骤先看bugreport确定下是否是OOM导致的重启，搜索关键字”system_server_crash”或”am_crash”<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">2020</span>-<span class="number">12</span>-<span class="number">07</span> <span class="number">10</span>:<span class="number">56</span>:<span class="number">18</span> system_server_crash (text, <span class="number">346</span> bytes)</span><br><span class="line">Process: system_server</span><br><span class="line">java.lang.OutOfMemoryError: Heap of System_Server has allocated <span class="number">666</span>MB , So trigger OutOfMemoryError crash</span><br><span class="line">at com.android.server.WatchdogInjector.checkOOMState(WatchdogInjector.java:<span class="number">98</span>)</span><br><span class="line">at com.android.server.Watchdog.run(Watchdog.java:<span class="number">776</span>)</span><br><span class="line"></span><br><span class="line"><span class="number">12</span>-<span class="number">07</span> <span class="number">10</span>:<span class="number">56</span>:<span class="number">18.313</span>  <span class="number">1000</span>  <span class="number">1614</span>  <span class="number">1703</span> I am_crash: [<span class="number">1614</span>,<span class="number">0</span>,system_server,-<span class="number">1</span>,java.lang.OutOfMemoryError,Heap of System_Server has allocated <span class="number">666</span>MB , So trigger OutOfMemoryError crash,WatchdogInjector.java,<span class="number">98</span>]</span><br><span class="line"></span><br><span class="line"><span class="number">12</span>-<span class="number">07</span> <span class="number">10</span>:<span class="number">56</span>:<span class="number">18.312</span>  <span class="number">1000</span>  <span class="number">1614</span>  <span class="number">1703</span> D OOMEventManagerFK: dumpheap success : /data/anr/system_server_1614.hprof</span><br></pre></td></tr></table></figure></p><p>上面片段中可以看出当时SystemServer确实发生了OOM，日志中没有打出具体堆栈，这个时候去看下system_server_1614.hprof，这个应该是厂商定制化输出的，比如监测到SystemServer占据内存超过一定的阀值，就dump出这个hprof文件以便于分析<br><img src="http://blog.lihaizhou.top/SystemServerOOM/SystemServerOOM1.png" alt=""><br>这个文件打开后，最大的一块是有五百多个android.app.assist.AssistStructure实例</p><p><img src="http://blog.lihaizhou.top/SystemServerOOM/SystemServerOOM2.png" alt=""></p><p>接下来顺理成章的就看下android.app.assist.AssistStructure单个实例中的引用链关系了<br>直接点击Histogram搜索android.app.assist.AssistStructure即可<br><img src="http://blog.lihaizhou.top/SystemServerOOM/SystemServerOOM3.png" alt=""><br>选择outgoing reference后如下，可以看到有529个<br><img src="http://blog.lihaizhou.top/SystemServerOOM/SystemServerOOM4.png" alt=""><br>随便点击一个右键同样的选outgoing<br><img src="http://blog.lihaizhou.top/SystemServerOOM/SystemServerOOM5.png" alt=""></p><p>每个AssistStructure实例中都包含WifiConfigActivity，WifiConfigActivity是一个什么样的界面呢？<br>是一个对话框样式的Activity，包含了可以填充数据的编辑框。<br>其实我们到这里已经大致明白了，罪魁祸首基本可以认定是WifiConfigActivity了</p><p>从bugreport中寻找关于WifiConfigActivity的线索，查找system_server OOM之前的片段<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">12</span>-<span class="number">07</span> <span class="number">10</span>:<span class="number">56</span>:<span class="number">04.383</span>  <span class="number">1000</span>  <span class="number">1614</span>  <span class="number">2419</span> I WindowManager: Input event dispatching timed out sending to com.android.settings/com.android.settings.wifi.WifiConfigActivity.  Reason: e4a42fb com.android.settings/com.android.settings.wifi.WifiConfigActivity (server) is not responding. Waited <span class="number">8001</span><span class="function">ms <span class="keyword">for</span> <span class="title">FocusEvent</span><span class="params">(hasFocus=<span class="keyword">true</span>)</span></span></span><br></pre></td></tr></table></figure></p><p>可以看到当时的WifiConfigActivity界面是卡住了，无法响应事件，可能当时系统在不停的GC，再看下WifiConfigActivity的调起记录<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">12</span>-<span class="number">07</span> <span class="number">10</span>:<span class="number">55</span>:<span class="number">09.375</span>  <span class="number">1000</span>  <span class="number">1614</span> <span class="number">12880</span> I ActivityTaskManager: START u0 &#123;flg=<span class="number">0x10000000</span> cmp=com.android.settings/.wifi.WifiConfigActivity (has extras)&#125; from uid <span class="number">1000</span></span><br><span class="line"><span class="number">12</span>-<span class="number">07</span> <span class="number">10</span>:<span class="number">55</span>:<span class="number">18.151</span>  <span class="number">1000</span>  <span class="number">1614</span>  <span class="number">4490</span> I ActivityTaskManager: START u0 &#123;flg=<span class="number">0x10000000</span> cmp=com.android.settings/.wifi.WifiConfigActivity (has extras)&#125; from uid <span class="number">1000</span></span><br><span class="line"><span class="number">12</span>-<span class="number">07</span> <span class="number">10</span>:<span class="number">55</span>:<span class="number">21.185</span>  <span class="number">1000</span>  <span class="number">1614</span> <span class="number">12880</span> I ActivityTaskManager: START u0 &#123;flg=<span class="number">0x10000000</span> cmp=com.android.settings/.wifi.WifiConfigActivity (has extras)&#125; from uid <span class="number">1000</span></span><br><span class="line"><span class="number">12</span>-<span class="number">07</span> <span class="number">10</span>:<span class="number">55</span>:<span class="number">32.439</span>  <span class="number">1000</span>  <span class="number">1614</span>  <span class="number">5665</span> I ActivityTaskManager: START u0 &#123;flg=<span class="number">0x10000000</span> cmp=com.android.settings/.wifi.WifiConfigActivity (has extras)&#125; from uid <span class="number">1000</span></span><br><span class="line"><span class="number">12</span>-<span class="number">07</span> <span class="number">10</span>:<span class="number">55</span>:<span class="number">42.120</span>  <span class="number">1000</span>  <span class="number">1614</span>  <span class="number">8959</span> I ActivityTaskManager: START u0 &#123;flg=<span class="number">0x10000000</span> cmp=com.android.settings/.wifi.WifiConfigActivity (has extras)&#125; from uid <span class="number">1000</span></span><br><span class="line"><span class="number">12</span>-<span class="number">07</span> <span class="number">10</span>:<span class="number">55</span>:<span class="number">50.421</span>  <span class="number">1000</span>  <span class="number">1614</span>  <span class="number">4063</span> I ActivityTaskManager: START u0 &#123;flg=<span class="number">0x10000000</span> cmp=com.android.settings/.wifi.WifiConfigActivity (has extras)&#125; from uid <span class="number">1000</span></span><br><span class="line"><span class="number">12</span>-<span class="number">07</span> <span class="number">10</span>:<span class="number">56</span>:<span class="number">03.812</span>  <span class="number">1000</span>  <span class="number">1614</span> <span class="number">14712</span> I ActivityTaskManager: START u0 &#123;flg=<span class="number">0x10000000</span> cmp=com.android.settings/.wifi.WifiConfigActivity (has extras)&#125; from uid <span class="number">1000</span></span><br></pre></td></tr></table></figure></p><p>WifiConfigActivity什么时候会被调起呢，是在收到一个广播后，鉴于其启动模式是singleInstance<br>查阅代码发现这个文件有重写onNewIntent，所以再多次调用的情况下，onNewIntent会被多次触发<br>该函数里有一处代码<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">new</span> AccessPoint(<span class="keyword">this</span>, wifiConfiguration);</span><br></pre></td></tr></table></figure></p><p>这里直接传入了this且该类是singleInstance，所以这个对象是无法被GC的，会导致内存持续增加，其实日志中也有Settings OOM的片段打出来  </p><h1 id="修改方案"><a href="#修改方案" class="headerlink" title="修改方案"></a>修改方案</h1><p>修改方案如下：<br>传入this的地方改为弱引用，这样在该界面退出时activity可以正常被回收掉，另外新增一个文件继承自DialogInterface.OnDismissListener<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DetachWifiDialogListener</span> <span class="keyword">implements</span> <span class="title">DialogInterface</span>.<span class="title">OnDismissListener</span></span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">static</span> String TAG = DetachWifiDialogListener.class.getSimpleName();</span><br><span class="line">    <span class="keyword">private</span> Activity mActivity;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">DetachWifiDialogListener</span><span class="params">(Activity activity)</span> </span>&#123;</span><br><span class="line">        mActivity = activity;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onDismiss</span><span class="params">(DialogInterface dialog)</span> </span>&#123;</span><br><span class="line">       Log.d(TAG,<span class="string">"Dialog onDismiss"</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">clearOnDetach</span><span class="params">(Dialog dialog)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (dialog.getWindow() == <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        dialog.getWindow()</span><br><span class="line">                .getDecorView()</span><br><span class="line">                .getViewTreeObserver()</span><br><span class="line">                .addOnWindowAttachListener(<span class="keyword">new</span> ViewTreeObserver.OnWindowAttachListener() &#123;</span><br><span class="line">                    <span class="meta">@Override</span></span><br><span class="line">                    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onWindowAttached</span><span class="params">()</span> </span>&#123;</span><br><span class="line">                       Log.d(TAG, <span class="string">"dialog Attached to Window"</span>);</span><br><span class="line">                    &#125;</span><br><span class="line">                    <span class="meta">@Override</span></span><br><span class="line">                    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onWindowDetached</span><span class="params">()</span> </span>&#123;</span><br><span class="line">                        Log.d(TAG,<span class="string">"dialog Detached to Window"</span>);</span><br><span class="line">                        <span class="keyword">if</span>(mActivity != <span class="keyword">null</span>) &#123;</span><br><span class="line">                           mActivity.finish();</span><br><span class="line">                           mActivity = <span class="keyword">null</span>;</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>在弹出Dialog后执行clearOnDetach，及时的将Activity finish掉，并且在onPause中(这里因为此处场景特殊，一般在onDestory中)将Listener置空<br>目的是剪断这个引用链<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">dismissListener = <span class="keyword">new</span> DetachWifiDialogListener(mWifiConfigActivity.get());</span><br><span class="line"><span class="comment">//....</span></span><br><span class="line">mDialog.show();</span><br><span class="line">dismissListener.clearOnDetach(mDialog);</span><br></pre></td></tr></table></figure></p><p>本地测试下来，<code>dumpsys meminfo</code>出的Activity实例个数在Dialog消失后会减少，说明不存在内存泄露了</p><h1 id="常见示例"><a href="#常见示例" class="headerlink" title="常见示例"></a>常见示例</h1><p>再例举一个最常见的非静态内部类Handler泄漏例子，延迟发送一个消息，此时在消息处理之前退出该界面，就会存在该Activity泄漏的情形</p><p>此时在onDestory内执行<code>removeCallbacksAndMessages</code>，这样的话每次退出界面后就会清空该handler上所有的callback和消息，这样就不会存在<code>MessageQueue-&gt;Handler-&gt;Activity</code>这个引用链</p><p><img src="http://blog.lihaizhou.top/SystemServerOOM/SystemServerOOM6.png" alt=""></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;strong&gt;测试步骤&lt;/strong&gt;&lt;br&gt;MTBF测试跑出来的机器重启，先解释下何为MTBF？&lt;br&gt;&lt;code&gt;MTBF测试(Mean Time Between Failure)&lt;/code&gt;&lt;br&gt;主要测试终端在连续工作状态下，出现死机、重启、冻屏、应用强制关闭
      
    
    </summary>
    
      <category term="稳定性" scheme="http://lihaizhou.top/categories/%E7%A8%B3%E5%AE%9A%E6%80%A7/"/>
    
    
  </entry>
  
  <entry>
    <title>臭名昭著的bufferbloat</title>
    <link href="http://lihaizhou.top/2020/08/27/%E8%87%AD%E5%90%8D%E6%98%AD%E8%91%97%E7%9A%84bufferbloat/"/>
    <id>http://lihaizhou.top/2020/08/27/臭名昭著的bufferbloat/</id>
    <published>2020-08-27T09:47:35.000Z</published>
    <updated>2021-09-08T12:39:26.762Z</updated>
    
    <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>之前看tcp拥塞算法时了解过bufferbloat，明白网络设备的缓冲区是为了让丢包尽量晚点到来，但是大的缓冲区又加重了延时。<br>知乎有一个问题：<br>既然害怕缓冲区膨胀，为啥现在的路由器缓冲区要弄这么大？<br>本文参考很多网络上优秀的文章，希望借此能够比较全面的了解下bufferbloat</p><h1 id="出现背景"><a href="#出现背景" class="headerlink" title="出现背景"></a>出现背景</h1><p>1980s 以来，基于遗失 (Loss-based) 一直作为拥塞控制的算法标准，并沿用至今 (e.g., 慢启动、拥塞避免、快速重送/恢复)。<br>为使拥塞控制正常运作，必须及时回馈封包遗失的信息，使传送端能选择合适的传输速率。<br>随著科技进步，内存价格下跌，处处充满了大型缓冲区的网路设备，这对基于遗失的拥塞控制算法造成巨大的问题。<br>大型的缓存区使数据包不易被丢弃，而是在队列中缓慢地等待，TCP 传送端并不知道拥塞的发生，仍持续成长传输速率，<br>使网路产生高延迟、吞吐量下降的恶性循环，这就是恶名昭彰的 — — 缓冲区膨胀 (bufferbloat)</p><p><strong>摘抄维基百科上关于bufferbloat的定义</strong></p><p>缓冲膨胀是一种因数据包过度缓冲而引起的数据包交换网络高延迟原因。缓冲膨胀还可能导致数据包延迟变化（也称为抖动），并降低整体网络吞吐量。当路由器或交换机配置了过大的缓冲区时，对于许多交互式应用程序，例如IP语音（VoIP），在线游戏，甚至普通的网页浏览，即使是非常高速的网络也几乎无法使用。</p><p>一些通信设备制造商在他们的某些网络产品中不必要地设计了过大的缓冲区。在这种设备中，当网络链路拥塞时，就会发生缓冲膨胀，从而导致数据包在这些超大缓冲区中长时间排队。在先进先出队列系统中，过大的缓冲区会导致更长的队列和更高的延迟，并且不会提高网络吞吐量。</p><p>早在1985年就已经有人发现并描述了这种缓冲膨胀现象。从2009年开始，它受到了越来越广泛的关注</p><p>大多数TCP拥塞控制算法都依靠测量丢包的发生来确定连接两端之间的可用带宽。该算法会加快数据传输速度，直到数据包开始丢失，然后降低传输速率。理想情况下，他们会不断调整传输速率，直到达到链路的平衡速度为止。为了使算法能够选择合适的传输速度，必须及时收到有关丢包的反馈。使用已满的大缓冲区时，数据包虽然最后会到达目的地，但延迟较高。因为数据包没有丢失，所以即使上行链路饱和，TCP也不会减慢速度，从而进一步导致缓冲区饱和。仅在缓冲区完全饱和时才丢弃新到达的数据包。一旦发生这种情况，TCP可能认为连接的路径已更改而决定更激进地搜索寻找新的工作点</p><p>其实我们经常会陷入一个错误的做法：遇到缓存满的问题我们遇到后通常的简单做法就是先调大缓存，殊不知这种不经意的“偷懒”的做法对于整个网络可能是一种“作恶”。不仅仅是网络，我们程序中各种队列也可能面临这个问题，比如线程间的消息队列，当队列满的时候，问题的根本可能不是队列太小，而是生产线程产出的速度大于消费线程消费的速度，这时候应该：</p><p>（1）检查并解决消费线程的瓶颈；</p><p>（2）反馈给生产线程，如果就是性能/资源达到上限，要从源头慢下来；</p><p>bufferbloat现象不仅存在于路由器、交换机中，Linux操作系统对接收和发送队列的处理也同样会导致该现象的出现</p><p>至少到这儿我们明白了路由器携带很大的Buffer，是错误的！路由器Buffer在够用前提下越小越好，没有Buffer，自然就不会bloat, 但是不能没有Buffer，Buffer到底是用来干什么的？到底多少合适？<br>基于存储/转发TCP/IP网络上的路由器其根本任务不是做存储，而是做转发，存储只是在理论上不得已的一个手段，为什么这么说呢？<br>路由器的入口和出口分别接收到达的数据包和转发数据包，一台路由器上往往有多个接口同时全双工地进行接收/转发，数据包的到达频率是统计意义上的，符合泊松分布，然而数据包的发送则是固有的接口速率，这是分组交换网的核心根基！路由器扮演什么角色？它是一个典型的多服务台排队系统！所以路由器必须携带一个Buffer用来平滑泊松分布的包到达和固定速率的包发送之间的关系<br>其实这里和Andorid的渲染中的buffer生产消耗中间有个bufferqueue很像啊！归根结底这玩意就是为了平衡生产者消费者而诞生的</p><p>那么，设计多大的Buffer合适呢？按照排队理论的现成公式计算，够用即可！<br>其实我们可以想象一下极端的情况，把存储队列的Buffer设计成无穷大，从而转发延迟也将是无穷大(因为排队延迟会趋向无穷大)，会发生什么？无疑，这台路由器将会变成一个超级存储器，它将会拥有全世界所有的信息！<br>但是，它只是个转发设备啊，却装模作样当起了存储设备，这就是声名狼藉的Bufferbloat<br>Bufferbloat的恶劣影响并不是会造成丢包，而是会无端增加无辜连接的延迟，危害在于，由于Bufferbloat造成了整个大Buffer被填充，所有的数据包都将等待一个固有的排队延迟，这会严重影响任意经过的实时类应用！</p><p><strong>bufferbloat真的是网络设备商故意为之？</strong></p><p>很多文章只提到了是buffer愈来愈大导致，却没有或者很少提到为何会越来越大，有些文章只是讲述为了减少丢包，却没有讲述这种情况出现的背景缘由。其实这是一种不得已的行为，真正的原因也是最本质的原因在于：</p><p><strong>早期计算机的处理器性能决定了发包的速率，像思科这种厂商，他们的路由器，交换机的处理能力是发包的终端计算机难以企及的，这个阶段中间节点的高端设备只需要不多且固定数量的缓存，就可以暂时存储还没有来得及处理的数据包。<br>所以在那个计算机终端和网络核心交换设备处理性能差异巨大的年代，所有的计算机终端均采用“尽可能快”的方式发包时，这显然是提高效率的最佳做法。<br>但是后来时代变了！计算机终端的处理器，网卡性能和中间转发设备的距离越来越近，而中间转发设备的性能已经快达到极限，增加处理器和线卡的数量性价比远不如将来不及处理的数据暂时存起来，这带来了一种解决方案：增加缓存大小！这并没有解决问题，而是引入了问题，网络不再是一个用完即走的设施，而成了一个巨大的缓存设施，这就是人人唾弃的Bufferbloat！</strong></p><p>摘取Linux中国的一篇文章《从网络代码中移除“尽可能快”这个目标》中的一段内容<br>在演讲中，Van Jacobson 说互联网的这些已经发生了改变：</p><p><strong>在以前的互联网上，交换机可能总是拥有比服务器更快的网卡，所以这些位于互联网中间层的服务器也可能比客户端更快，并且并不能对客户端发送信息包的速率有多大影响。<br>很显然今天已经不是这样的了！众所周知，今天的计算机相比于 5 年前的计算机在速度上并没有多大的提升（我们遇到了某些有关光速的问题）。所以我想路由器上的大型交换机并不会在速度上大幅领先于数据中心里服务器上的网卡</strong></p><p>这篇文章同时提到了解决Bufferbloat的办法，就是：<strong>以更慢的速率发送更多的信息包以达到更好的性能！</strong></p><p>对于拥塞控制推出的背景历史，可以查看Van Jacobson在1988年推出的Congestion Avoidance and Control，文章开头就介绍了这篇论文的写作背景缘由</p><p>In October of ‘86, the Internet had the first of what became a series of ‘congestion collapses’. During this period, the data throughput from LBL to UC Berke- ley (sites separated by 400 yards and three IMP hops) dropped from 32 Kbps to 40 bps. Mike Karels 1 and I were fascinated by this sudden factor-of-thousand drop in bandwidth and embarked on an investigation of why things had gotten so bad. We wondered, in particular, if the 4.3BSD (Berkeley UNIX) TCP was mis-behaving or if it could be tuned to work better under abysmal net- work conditions. The answer to both of these questions was “yes”.</p><p>也正是在这一年拥塞控制被引入TCP，有点感慨，这是1988年推出的论文，中国进入互联网是在94年！</p><p><strong>摘自一篇比较喜欢的文章里的一句话：</strong><br>TCP拥塞控制的终极目标绝对不是加快数据发送的速度，这种理解非常自私且肤浅！它的终结目标是在公平占有带宽的前提下无限度提高带宽的利用率！<br>恰恰相反，所有的拥塞控制算法都是为了TCP可以在贪婪的时候悬崖勒马，大多数时候，拥塞控制是降低了数据发送的速度</p><p>如果不把公平性作为基本原则，那么整个环将不是闭合的，带宽资源早晚会用尽，此时盲目的AI非MD过程将会促使大家都想往前抢，最后谁也过不去，如此一来，互联网将完全不可用！基于这点，所有搞“TCP单边加速”的个人和厂商都是在做钻空子的坏事，其出发点就是错误的。当然，这类厂商的出发点往往不是TCP层面的，而是业务层面的，这倒是无可厚非，毕竟不是一个领域，我也无权过问太多，TCP对于它们而言只是工具，真到哪天互联网崩溃了，他们还是会用卡车运硬盘的方式来进行数据传输的，到时候，高速公路上堵的水泄不通的运硬盘的卡车与TCP一样，也只是个工具，而已</p><p>在BBR之前，Vegas算法则代表了一种正确的做法，它最终没有上位是因为Vegas部署有个前提，那就是同一时间全部部署成Vegas，然而这是不可能的，只要有Reno或者CUBIC在，Vegas的“正确做法”就会吃亏。现实就是这样，劣币驱良币，CUBIC明明是错误的算法，但因为它可以利用率很低但很简单的方法快速收敛到可用带宽，所以就一直是大家认可的算法，所有人都在默默忍受着Bufferbloat，而这个问题带来的额外排队延迟会大大降低交互式TCP连接的交互体验，同时严重影响实时性的协议，比如NTP之类。<br> CUBIC是一定会堵路的，Buffer被堵了之后，交互应用的数据就会被排队，时延增加，交互性自然下降。<br>我一直好奇的问题是，为什么Reno，CUBIC之流在经过慢启动之后的AI增窗过程叫做拥塞避免，相反，这种盲目的一路走到黑的增窗方式一定会导致拥塞的，即拥塞不可避免。这个过程是玷污了“拥塞避免”这个词呢，还是说仅仅是一个定义呢？</p><p>真正的拥塞控制就应该像城市快速路那样，在拥塞时排队缓行而不是造成bufferbloat！</p><p><strong>小结：</strong><br>TCP几乎全部都是以AIMD原则来运作的，UDP则是无限贪婪的。TCP的AI会造成主动丢包，这也是基于丢包的拥塞控制算法的核心，而MD会造成全局同步，这两点无疑造成了带宽利用率的低下，这是TCP的硬伤，不得不靠不断加大的路由器Buffer来弥补，至少是延迟了悲剧的发生，在延迟悲剧的这段时间内，路由器当然希望端系统可以意识到事情正在悄悄起变化并采取一些措施<br>或许TCP/IP的框架不该这么复杂，或许AIMD根本就不需要，事实上，是路由器不断加大的Buffer和AIMD一起纵容了坏事的频繁发生<br>路由器Buffer减小有什么好处呢？好处在于，即使有连接拼命去AI添堵，那么丢包会很快到来，并且很快反馈给发送方，于是发送方会执行MD以表示忏悔，整个过程中，实时流量不会受到丝毫影响</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h1&gt;&lt;p&gt;之前看tcp拥塞算法时了解过bufferbloat，明白网络设备的缓冲区是为了让丢包尽量晚点到来，但是大的缓冲区又加重了延时。&lt;br&gt;知乎有
      
    
    </summary>
    
      <category term="网络" scheme="http://lihaizhou.top/categories/%E7%BD%91%E7%BB%9C/"/>
    
    
  </entry>
  
  <entry>
    <title>BBR论文之读后感(三)</title>
    <link href="http://lihaizhou.top/2020/08/27/BBR%E8%AE%BA%E6%96%87%E4%B9%8B%E8%AF%BB%E5%90%8E%E6%84%9F-%E4%B8%89/"/>
    <id>http://lihaizhou.top/2020/08/27/BBR论文之读后感-三/</id>
    <published>2020-08-27T04:53:38.000Z</published>
    <updated>2021-10-16T06:40:48.773Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Matching-the-Packet-Flow-to-the-Delivery-Path"><a href="#Matching-the-Packet-Flow-to-the-Delivery-Path" class="headerlink" title="Matching the Packet Flow to the Delivery Path"></a>Matching the Packet Flow to the Delivery Path</h1><p>The core BBR algorithm has two parts:<br>When an ack is received</p><p>Each ack provides new RTT and average delivery rate measurements that update the RTprop and BtlBw estimates:</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">onAck</span>(<span class="params">packet</span>)</span></span><br><span class="line"><span class="function">  <span class="title">rtt</span> = <span class="title">now</span> - <span class="title">packet</span>.<span class="title">sendtime</span></span></span><br><span class="line"><span class="function">  <span class="title">update_min_filter</span>(<span class="params">RTpropFilter, rtt</span>)</span></span><br><span class="line"><span class="function">  <span class="title">delivered</span> += <span class="title">packet</span>.<span class="title">size</span></span></span><br><span class="line"><span class="function">  <span class="title">delivered_time</span> = <span class="title">now</span></span></span><br><span class="line"><span class="function">  <span class="title">deliveryRate</span> = (<span class="params">delivered - packet.delivered</span>) / (<span class="params">delivered_time - packet.delivered_time</span>)</span></span><br><span class="line"><span class="function">  <span class="title">if</span> (<span class="params">deliveryRate &gt; BtlBwFilter.currentMax || ! packet.app_limited</span>)</span></span><br><span class="line"><span class="function">     <span class="title">update_max_filter</span>(<span class="params">BtlBwFilter, deliveryRate</span>)</span></span><br><span class="line"><span class="function">  <span class="title">if</span> (<span class="params">app_limited_until &gt; <span class="number">0</span></span>)</span></span><br><span class="line"><span class="function">     <span class="title">app_limited_until</span> = <span class="title">app_limited_until</span> - <span class="title">packet</span>.<span class="title">size</span></span></span><br></pre></td></tr></table></figure><p>The if checks address the uncertainty issue described in the last paragraph: senders can be application limited, meaning the application runs out of data to fill the network. This is quite common because of request/response traffic. When there is a send opportunity but no data to send, BBR marks the corresponding bandwidth sample(s) as application limited (see send() pseudocode to follow). The code here decides which samples to include in the bandwidth model so it reflects network, not application, limits.<br>BtlBw is a hard upper bound on the delivery rate so a measured delivery rate larger than the current BtlBw estimate must mean the estimate is too low, whether or not the sample was app-limited. Otherwise, application-limited samples are discarded. (Figure 1 shows that in the app-limited region deliveryRate underestimates BtlBw. These checks prevent filling the BtlBw filter with underestimates which would cause data to be sent too slowly.)</p><p><strong>翻译：</strong> </p><p>BBR核心算法包含两大部分：<br>当收到一个ACK报文时：<br>每一个ACK提供了一个新的RTT和新的发送速率估计，BBR将以此为根据来更新RTprop和BtlBw<br>这里略去上面的英文中的伪代码部分<br>伪代码中的if语句是对上一段所讲的不确定性进行估计的：发送方可能受限于应用，发送数据太少，而并没有将管道填满。<br>当发送方采取的协议是request/response类时，这种现象是非常常见的。当没有数据可以发送时，BBR会将对应的带宽估计标志为是应用限制的（见下文伪代码中的send()）。这里的算法是为了决定流应该采集哪些数据，而避免采集那些被应用限制的而不是被网络限制的采集数据。<br>BtlBw是发送速率的上界，所以如果计算出的发送速率大于当前所估计的BtlBw值，那么这表示这个估计值太小了（无论该发送速率是否是应用限制的），我们都应该更新它。否则，那些被应用限制的采集数据将会被丢弃。（如图1所示，在app-limited区域中，deliveryRate低估了BtlBw。这些if判断避免BBR低估了BtlBw而导致发送低速率）。</p><p><strong>额外添加:</strong><br>这里计算发送速率的伪代码算法如此的通俗易懂，当然实际的源代码肯定是很复杂的，不过任何复杂算法最初的雏形一定是像这样简单纯朴</p><h1 id="When-data-is-sent"><a href="#When-data-is-sent" class="headerlink" title="When data is sent"></a>When data is sent</h1><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">To match the packet-arrival rate to the bottleneck link<span class="string">'s departure rate, BBR paces every data packet. (BBR must match the bottleneck rate, which means pacing is integral to the design and fundamental to operation—pacing_rate is BBR'</span>s primary control parameter. A secondary parameter, cwnd_gain, bounds inflight to a small multiple <span class="keyword">of</span> the BDP to handle common network and receiver pathologies (see the later section on Delayed and Stretched ACKs). Conceptually, the TCP send routine looks like the following code. (In Linux, sending uses the efficient FQ/pacing queuing discipline,<span class="number">4</span> which gives BBR line-rate single-connection performance on multigigabit links and handles thousands <span class="keyword">of</span> lower-rate paced connections <span class="keyword">with</span> negligible CPU overhead.)</span><br></pre></td></tr></table></figure><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">send</span>(<span class="params">packet</span>)</span></span><br><span class="line"><span class="function">  <span class="title">bdp</span> = <span class="title">BtlBwFilter</span>.<span class="title">currentMax</span> × <span class="title">RTpropFilter</span>.<span class="title">currentMin</span></span></span><br><span class="line"><span class="function">  <span class="title">if</span> (<span class="params">inflight &gt;= cwnd_gain × bdp</span>)</span></span><br><span class="line"><span class="function">     // <span class="title">wait</span> <span class="title">for</span> <span class="title">ack</span> <span class="title">or</span> <span class="title">retransmission</span> <span class="title">timeout</span></span></span><br><span class="line"><span class="function">     <span class="title">return</span></span></span><br><span class="line"><span class="function">  <span class="title">if</span> (<span class="params">now &gt;= nextSendTime</span>)</span></span><br><span class="line"><span class="function">     <span class="title">packet</span> = <span class="title">nextPacketToSend</span>(<span class="params"></span>)</span></span><br><span class="line"><span class="function">     <span class="title">if</span> (<span class="params">! packet</span>)</span></span><br><span class="line"><span class="function">        <span class="title">app_limited_until</span> = <span class="title">inflight</span></span></span><br><span class="line"><span class="function">        <span class="title">return</span></span></span><br><span class="line"><span class="function">     <span class="title">packet</span>.<span class="title">app_limited</span> = (<span class="params">app_limited_until &gt; <span class="number">0</span></span>)</span></span><br><span class="line"><span class="function">     <span class="title">packet</span>.<span class="title">sendtime</span> = <span class="title">now</span></span></span><br><span class="line"><span class="function">     <span class="title">packet</span>.<span class="title">delivered</span> = <span class="title">delivered</span></span></span><br><span class="line"><span class="function">     <span class="title">packet</span>.<span class="title">delivered_time</span> = <span class="title">delivered_time</span></span></span><br><span class="line"><span class="function">     <span class="title">ship</span>(<span class="params">packet</span>)</span></span><br><span class="line"><span class="function">     <span class="title">nextSendTime</span> = <span class="title">now</span> + <span class="title">packet</span>.<span class="title">size</span> / (<span class="params">pacing_gain × BtlBwFilter.currentMax</span>)</span></span><br><span class="line"><span class="function">  <span class="title">timerCallbackAt</span>(<span class="params">send, nextSendTime</span>)</span></span><br></pre></td></tr></table></figure><p><strong>翻译：</strong> </p><p>为了使得bottleneck链路的报文到达速率和报文离开速率相等，BBR必须进行packet paced。<br>BBR的发送速率必须与bottleneck的速率相等，这意味着BBR的实现需要pacing的支持——pacing_rate是BBR的一个主要控制参数！<br>第二个参数，cwnd_gain，将inflight控制为比BDP稍大一些，从而处理常见的网络机制和接收方机制（参见后文Dealyedand Stretched ACKs）。<br>TCP发送的时候做的事大概如上面的伪代码所示（在Linux中，可以使用FQ/pacing qdisc来发送数据，这可以使得BBR在与几千个低速率的paced流在千兆链路上很好地共存，并且使用FQ这种机制也不会额外造成CPU的负担）。</p><p><strong>额外添加：</strong></p><p>上面说的感觉听上去上挺合理，但是很容易产生这样的疑问：<br>端到端的TCP如何知道带宽到底是多少？如果用测量的话结果具有一个RTT的滞后性。因此你测得的结果永远都是以前的结果而不是现在的结果，由于网络情况存在随机性，更无法预测未来的情景，于是乎，完全按照瓶颈带宽来发送数据是不可能的，我们不得不承认这个结果是滞后的，或者说我们采集到的信息仅仅够算一个所谓的均值，不管怎么样，我们依然会选择Pacing的方式来发送数据，至少在没有新的有别于AIMD的全新数学模型出现之前吧。<br>如此一来，只要我们选择了Pacing，那么就必然要在TCP发送端内置一套数据采集和计算引擎，这是AIMD模型所不需要的。</p><h1 id="Steady-state-behavior"><a href="#Steady-state-behavior" class="headerlink" title="Steady-state behavior"></a>Steady-state behavior</h1><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">The rate and amount BBR sends is solely a <span class="function"><span class="keyword">function</span> <span class="title">of</span> <span class="title">the</span> <span class="title">estimated</span> <span class="title">BtlBw</span> <span class="title">and</span> <span class="title">RTprop</span>, <span class="title">so</span> <span class="title">the</span> <span class="title">filters</span> <span class="title">control</span> <span class="title">adaptation</span> <span class="title">in</span> <span class="title">addition</span> <span class="title">to</span> <span class="title">estimating</span> <span class="title">the</span> <span class="title">bottleneck</span> <span class="title">constraints</span>. <span class="title">This</span> <span class="title">creates</span> <span class="title">the</span> <span class="title">novel</span> <span class="title">control</span> <span class="title">loop</span> <span class="title">shown</span> <span class="title">in</span> <span class="title">figure</span> 2, <span class="title">which</span> <span class="title">illustrates</span> <span class="title">the</span> <span class="title">RTT</span> (<span class="params">blue</span>), <span class="title">inflight</span> (<span class="params">green</span>) <span class="title">and</span> <span class="title">delivery</span> <span class="title">rate</span> (<span class="params">red</span>) <span class="title">detail</span> <span class="title">from</span> 700 <span class="title">ms</span> <span class="title">of</span> <span class="title">a</span> 10-<span class="title">Mbps</span>, 40-<span class="title">ms</span> <span class="title">flow</span>. <span class="title">The</span> <span class="title">thick</span> <span class="title">gray</span> <span class="title">line</span> <span class="title">above</span> <span class="title">the</span> <span class="title">delivery</span>-<span class="title">rate</span> <span class="title">data</span> <span class="title">is</span> <span class="title">the</span> <span class="title">state</span> <span class="title">of</span> <span class="title">the</span> <span class="title">BtlBw</span> <span class="title">max</span> <span class="title">filter</span>. <span class="title">The</span> <span class="title">triangular</span> <span class="title">structures</span> <span class="title">result</span> <span class="title">from</span> <span class="title">BBR</span> <span class="title">cycling</span> <span class="title">pacing_gain</span> <span class="title">to</span> <span class="title">determine</span> <span class="title">if</span> <span class="title">BtlBw</span> <span class="title">has</span> <span class="title">increased</span>. <span class="title">The</span> <span class="title">gain</span> <span class="title">used</span> <span class="title">for</span> <span class="title">each</span> <span class="title">part</span> <span class="title">of</span> <span class="title">the</span> <span class="title">cycle</span> <span class="title">is</span> <span class="title">shown</span> <span class="title">time</span>-<span class="title">aligned</span> <span class="title">with</span> <span class="title">the</span> <span class="title">data</span> <span class="title">it</span> <span class="title">influenced</span>. <span class="title">The</span> <span class="title">gain</span> <span class="title">is</span> <span class="title">applied</span> <span class="title">an</span> <span class="title">RTT</span> <span class="title">earlier</span>, <span class="title">when</span> <span class="title">the</span> <span class="title">data</span> <span class="title">is</span> <span class="title">sent</span>. <span class="title">This</span> <span class="title">is</span> <span class="title">indicated</span> <span class="title">by</span> <span class="title">the</span> <span class="title">horizontal</span> <span class="title">jog</span> <span class="title">in</span> <span class="title">the</span> <span class="title">event</span> <span class="title">sequence</span> <span class="title">description</span> <span class="title">running</span> <span class="title">up</span> <span class="title">the</span> <span class="title">left</span> <span class="title">side</span>.</span></span><br></pre></td></tr></table></figure><p><strong>翻译：</strong></p><p>BBR的发送速率和发送数量完全就是一个关于BtlBw和RTprop的函数，所以BBR应该小心地估计这两个值。这创造了一种新型的闭环控制，如图2所示。图2显示了一个10Mbps，40ms的流在700ms中的RTT（蓝线），inflight（绿线）和发送速率（红线）变化过程。</p><p>注意图中在发送速率上方的灰线是BtlBw最大化滤波器的状态。图中产生的三角形形状是因为BBR的pacing_gain周期性的变化产生的，因为BBR必须以此来探测BtlBw是否提高了。图中展示了该增益值在一个周期不同时间的变化和其影响的数据变化</p><p><img src="http://blog.lihaizhou.top/BBR3/BBRpart3-1.png.png" alt=""></p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">BBR minimizes delay by spending most <span class="keyword">of</span> its time <span class="keyword">with</span> one BDP <span class="keyword">in</span> flight, paced at the BtlBw estimate. This moves the bottleneck to the sender so it can<span class="string">'t observe BtlBw increases. Consequently, BBR periodically spends an RTprop interval at a pacing_gain &gt; 1, which increases the sending rate and inflight. If BtlBw hasn'</span>t changed, then a queue is created at the bottleneck, increasing RTT, which keeps deliveryRate constant. (This queue is removed by sending at a compensating pacing_gain &lt; <span class="number">1</span> <span class="keyword">for</span> the next RTprop.) If BtlBw has increased, deliveryRate increases and the <span class="keyword">new</span> max immediately increases the BtlBw filter output, increasing the base pacing rate. Thus, BBR converges to the <span class="keyword">new</span> bottleneck rate exponentially fast. Figure <span class="number">3</span> shows the effect on a <span class="number">10</span>-Mbps, <span class="number">40</span>-ms flow <span class="keyword">of</span> BtlBw abruptly doubling to <span class="number">20</span> Mbps after <span class="number">20</span> seconds <span class="keyword">of</span> steady operation (left graph) then dropping to <span class="number">10</span> Mbps after another <span class="number">20</span> seconds <span class="keyword">of</span> steady operation at <span class="number">20</span> Mbps (right graph).</span><br></pre></td></tr></table></figure><p><strong>翻译：</strong></p><p>BBR将它的大部分时间的在外发送数据都保持为一个BDP大小，并且发送速率保持在估计得BtlBw值，这将会最小化时延。<br>但是这会把网络中的瓶颈链路移动到BBR发送方本身，所以BBR无法察觉BtlBw是否上升了。</p><p>所以，BBR周期性的在一个RTprop时间内将pacing_gain设为一个大于1的值，这将会增加发送速率和在外报文。如果BtlBw没有改变，那么这意味着BBR在网络中制造了队列，增大了RTT，而deliveryRate仍然没有改变。（这个队列将会在下个RTprop周期被BBR使用小于1的pacing_gain来消除）。</p><p>如果BtlBw增大了，那么deliveryRate增大了，并且BBR会立即更新BtlBw的估计值，从而增大了发送速率。通过这种机制，BBR可以以指数速度非常快地收敛到瓶颈链路。如图3显示的，我们在1条10Mbps，40ms的流在20s稳定运行之后将BtlBw提高了1倍（20Mbps），然后在第40s又将BtlBw恢复至20Mbps<br><img src="http://blog.lihaizhou.top/BBR3/BBRpart3-2.png.png" alt=""></p><p><strong>额外添加</strong></p><p><a href="https://blog.csdn.net/dog250/article/details/52972502?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522159850579919725211953968%2522%252C%2522scm%2522%253A%252220140713.130102334.pc%255Fblog.%2522%257D&amp;request_id=159850579919725211953968&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~blog~first_rank_v2~rank_blog_v1-13-52972502.pc_v2_rank_blog_v1&amp;utm_term=BBR&amp;spm=1018.2118.3001.4187" target="_blank" rel="noopener">https://blog.csdn.net/dog250/article/details/52972502?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522159850579919725211953968%2522%252C%2522scm%2522%253A%252220140713.130102334.pc%255Fblog.%2522%257D&amp;request_id=159850579919725211953968&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~blog~first_rank_v2~rank_blog_v1-13-52972502.pc_v2_rank_blog_v1&amp;utm_term=BBR&amp;spm=1018.2118.3001.4187</a></p><p>(BBR is a simple instance of a Max-plus control system, a new approach to control based on nonstandard algebra.12 This approach allows the adaptation rate [controlled by the max gain] to be independent of the queue growth [controlled by the average gain]. Applied to this problem, it results in a simple, implicit control loop where the adaptation to physical constraint changes is automatically handled by the filters representing those constraints. A conventional control system would require multiple loops connected by a complex state machine to accomplish the same result.)</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Matching-the-Packet-Flow-to-the-Delivery-Path&quot;&gt;&lt;a href=&quot;#Matching-the-Packet-Flow-to-the-Delivery-Path&quot; class=&quot;headerlink&quot; title=&quot;Ma
      
    
    </summary>
    
      <category term="网络" scheme="http://lihaizhou.top/categories/%E7%BD%91%E7%BB%9C/"/>
    
    
  </entry>
  
  <entry>
    <title>BBR论文之读后感(二)</title>
    <link href="http://lihaizhou.top/2020/08/27/BBR%E8%AE%BA%E6%96%87%E4%B9%8B%E8%AF%BB%E5%90%8E%E6%84%9F-%E4%BA%8C/"/>
    <id>http://lihaizhou.top/2020/08/27/BBR论文之读后感-二/</id>
    <published>2020-08-27T02:50:37.000Z</published>
    <updated>2021-10-16T06:42:53.147Z</updated>
    
    <content type="html"><![CDATA[<p>Characterizing the Bottleneck</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">A connection runs <span class="keyword">with</span> the highest throughput and lowest delay when (rate balance) the bottleneck packet arrival rate equals BtlBw and (full pipe) the total data <span class="keyword">in</span> flight is equal to the BDP (= BtlBw × RTprop).</span><br><span class="line"></span><br><span class="line">The first condition guarantees that the bottleneck can run at <span class="number">100</span> percent utilization. The second guarantees there is enough data to prevent bottleneck starvation but not overfill the pipe. The rate balance condition alone does not ensure there is no queue, only that it can<span class="string">'t change size (e.g., if a connection starts by sending its 10-packet Initial Window into a five-packet BDP, then runs at exactly the bottleneck rate, five of the 10 initial packets fill the pipe so the excess forms a standing queue at the bottleneck that cannot dissipate).</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Similarly, the full pipe condition does not guarantee there is no queue (e.g., a connection sending a BDP in BDP/2 bursts gets full bottleneck utilization, but with an average queue of BDP/4). The only way to minimize the queue at the bottleneck and all along the path is to meet both conditions simultaneously.</span></span><br></pre></td></tr></table></figure><p><strong>翻译：</strong></p><p>当一个连接满足以下两个条件时，它可以在达到最高的吞吐量的同时保持最低时延：</p><ol><li>速率平衡：瓶颈带宽的数据到达速率与BtlBw相等；</li><li>填满管道：所有的在外数据（inflight data）与BDP（带宽与时延的乘积）相等</li></ol><p>其中第一个约束保证了瓶颈带宽可以得到100%利用。而第二个约束保证了流有足够的数据来填满瓶颈链路而且同时不会溢出（排队）。</p><p>第一个条件本身并无法保证路径中不存在队列，它只能保证流的速率不发生改变（例如，考虑一个连接在一开始就发送了10个报文到一个BDP只有5个网络中，并且接下来一直保持瓶颈速率发送。这样子会导致在一开始就填满了管道，并且制造了5个报文的队列，并且这个队列永远不会被消灭）。</p><p>相似地，第二个条件也不能保证链路中没有队列。比如，一个连接可以以burst方式发送BDP数量的报文，若该连接每次发二分之一BDP来达到瓶颈带宽，并且发两次，此时full pipe条件得到满足了，然而网络中的平均队列长度是BDP/4。为了最小化网络中的队列长度，唯一的方式是同时满足以上两个条件。</p><p><strong>额外添加：</strong></p><p>两个条件缺一不可，如果只满足第一个条件，可能会出现实际发送数据超过BDP的情况，这样就会出现排队，如果只满足第二点的话，可能会存在数据包突发的情况，可以理解为中间网络设备转发处理速度赶不上发送端发送的速度了，这样也会有排队。<br>所以要想达到最优的情况，就是同时满足以上两个条件，多么理想的想法！</p><p>BtlBw and RTprop vary over the life of a connection, so they must be continuously estimated. TCP currently tracks RTT (the time interval from sending a data packet until it is acknowledged) since it’s required for loss detection. At any time t,</p><p><img src="http://blog.lihaizhou.top/BBR3/BBRpart2-1.png.png" alt=""></p><p>where 𝛈 ≥ 0 represents the “noise” introduced by queues along the path, the receiver’s delayed ack strategy, ack aggregation, etc. RTprop is a physical property of the connection’s path and changes only when the path changes. Since path changes happen on time scales » RTprop, an unbiased, efficient estimator at time T is</p><p><img src="http://blog.lihaizhou.top/BBR3/BBRpart2-2.png.png" alt=""></p><p>(i.e., a running min over time window WR (which is typically tens of seconds to minutes)</p><p><strong>翻译：</strong></p><p>然而，BtlBw和RTprop在整个连接的生命周期中可能是动态变化的，所以我们需要实时地对它们进行估计。<br>目前TCP为了检测丢包，必须实时地跟踪RTT的大小（发送数据到收到这个包的ack的时间），在任意的时间t</p><p>其中，最后一项表示“噪声”。造成噪声的因素主要有：链路队列，接收方的时延ACK配置，ACK聚合等因素等待。<br>RTprop是路径的物理特性，并且只有路径变化才会改变。由于一般来说路径变化的时间尺度远远大于RTprop（这说的是啥玩意，待理解）<br>所以RTprop可以由以下公式进行估计：</p><p>（在一个时间窗口中对RTT取最小值。一般将该窗口大小设置为几十秒至几分钟）</p><p>Unlike RTT, nothing in the TCP spec requires implementations to track bottleneck bandwidth, but a good estimate results from tracking delivery rate. When the ack for some packet arrives back at the sender, it conveys that packet’s RTT and announces the delivery of data inflight when that packet departed. Average delivery rate between send and ack is the ratio of data delivered to time elapsed: deliveryRate = Δdelivered/Δt. This rate must be ≤ the bottleneck rate (the arrival amount is known exactly so all the uncertainty is in the Δt, which must be ≥ the true arrival interval; thus, the ratio must be ≤ the true delivery rate, which is, in turn, upper-bounded by the bottleneck capacity). Therefore, a windowed-max of delivery rate is an efficient, unbiased estimator of BtlBw: </p><p><img src="http://blog.lihaizhou.top/BBR3/BBRpart2-3.png.png" alt=""></p><p>where the time window WB is typically six to ten RTTs.</p><p><strong>翻译：</strong></p><p>然而，bottleneck bandwidth的估计不像RTT那样方便，没有一种TCP spec要求实现算法来跟踪估计bottleneck带宽，但是，我们可以通过跟踪发送速率来估计bottleneck带宽。<br>当发送方收到一个ACK报文时，它可以计算出该报文的RTT，并且从发出报文到收到ack报文这段时间的data Inflight。这段时间内的平均发送速率就可以以此计算出来：deliveryRate = delta delivered/ delta t。这个计算出的速率必定小于bottleneck速率（因为delta delivered是确定的，但是delta t会较大）。因此，BtwBw可以根据以下公式进行估计</p><p>其中，时间窗口大小的值一般为6~10个RTT。</p><p><strong>额外增加：</strong><br>这里提到了BBR的deliveryRate的计算方式，这个公式看起来是如此的简单<br>1).应答了多少数据，记为delivered；<br>2).应答1)中的delivered这么多数据所用的时间，记为interval_us。<br>将上述二者相除，就能得到带宽：<code>bw = delivered/interval_us</code><br>这里的delivered只关注数据的大小，不关注数据的含义，比如delivered的采集中，bbr根本不管某一个应答是重传后的ACK确认的，正常ACK确认的，还是说SACK确认的。bbr只关心被应答了多少！<br>至于为什么能够不关注数据的含义，可以参考这篇文章：<br><a href="https://blog.csdn.net/dog250/article/details/52830576" target="_blank" rel="noopener">来自Google的TCP BBR拥塞控制算法解析</a><br>按照这个公式的计算方式其实是完全忽略了系统层面的TCP状态，计算带宽时它仅仅需要两个值就够了</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">TCP must record the departure time <span class="keyword">of</span> each packet to compute RTT. BBR augments that record <span class="keyword">with</span> the total data delivered so each ack arrival yields both an RTT and a delivery rate measurement that the filters convert to RTprop and BtlBw estimates.</span><br><span class="line"></span><br><span class="line">Note that these values are completely independent: RTprop can change (<span class="keyword">for</span> example, on a route change) but still have the same bottleneck, or BtlBw can change (<span class="keyword">for</span> example, when a wireless link changes rate) without the path changing. (This independence is why both constraints have to be known to match sending behavior to delivery path.) Since RTprop is visible only to the left <span class="keyword">of</span> BDP and BtlBw only to the right <span class="keyword">in</span> figure <span class="number">1</span>, they obey an uncertainty principle: whenever one can be measured, the other cannot. Intuitively, <span class="keyword">this</span> is because the pipe has to be overfilled to find its capacity, which creates a queue that obscures the length <span class="keyword">of</span> the pipe. For example, an application running a request/response protocol might never send enough data to fill the pipe and observe BtlBw.</span><br><span class="line"></span><br><span class="line">A multi-hour bulk data transfer might spend its entire lifetime <span class="keyword">in</span> the bandwidth-limited region and have only a single sample <span class="keyword">of</span> RTprop <span class="keyword">from</span> the first packet<span class="string">'s RTT. This intrinsic uncertainty means that in addition to estimators to recover the two path parameters, there must be states that track both what can be learned at the current operating point and, as information becomes stale, how to get to an operating point where it can be relearned.</span></span><br></pre></td></tr></table></figure><p><strong>翻译：</strong></p><p>TCP必须记录每个报文的离开时间从而计算RTT。BBR必须额外记录已经发送的数据大小，使得在收到每一个ACK之后，计算RTT及发送速率的值，最后得到RTprop和BtlBw的估计值。</p><p>值得注意的是，这两个值是完全独立的：RTprop可以发生变化然而保持bottleneck不变（比如发生路由变化），或者BtlBw可以变化而路径不变（比如无线链路速率发生变化）。（This independence is why both constraints have tobe known to match sending behavior to delivery path.）</p><p>如图1所示，只有在BDP的左边，才能观测到RTprop，并且只有在BDP的右边才能观测到BtlBw，他们遵循了一个不确定性原则：当其中一个可以被观测的时候，另外一个并不能。直觉地，这是因为为了观测出管道的容量，必须填满管道，而这会创造出一个队列从而无法观测到管道的长度。</p><p>例如，一个使用request/response协议的应用可能永远不会发送足够的数据来填满管道，并且观测到BtlBw。一个持续几个小时的大文件传输应用可能永远处在bandwidth-limited区域，而仅仅在第一个报文中的RTT采集到RTprop。这种不确定性机制意味着，在信息变得不明确的时候，必须要有机制来从当前的工作状态中学习到这两个值的其中一个，并且进入对应的工作区来重新学习这两个值。</p><p>下一篇讲进入公式的细节部分</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Characterizing the Bottleneck&lt;/p&gt;
&lt;figure class=&quot;highlight javascript&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;
      
    
    </summary>
    
      <category term="网络" scheme="http://lihaizhou.top/categories/%E7%BD%91%E7%BB%9C/"/>
    
    
  </entry>
  
  <entry>
    <title>BBR论文之读后感(一)</title>
    <link href="http://lihaizhou.top/2020/08/27/BBR%E8%AE%BA%E6%96%87%E4%B9%8B%E8%AF%BB%E5%90%8E%E6%84%9F-%E4%B8%80/"/>
    <id>http://lihaizhou.top/2020/08/27/BBR论文之读后感-一/</id>
    <published>2020-08-27T02:19:27.000Z</published>
    <updated>2021-10-16T06:41:19.641Z</updated>
    
    <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>拥塞控制本身是个比较发散的话题，首先需要说明一点我对这方面其实一窍不通，为了找资料在网上也看了不少文章，但是很多文章都是平铺直叙的讲述，所以很多没看完就放弃了。<br>于是打算看下论文《BBR: Congestion-Based Congestion Control》，这篇文章还是比较有意思，看完多少知道了一点BBR的皮毛。</p><p>因整篇论文内容较多，将分为六篇读后感</p><h1 id="BBR论文部分-1-6"><a href="#BBR论文部分-1-6" class="headerlink" title="BBR论文部分(1/6)"></a>BBR论文部分(1/6)</h1><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Measuring bottleneck bandwidth and round-trip propagation time</span><br><span class="line">Neal Cardwell, Yuchung Cheng, C. Stephen Gunn, Soheil Hassas Yeganeh, Van Jacobson</span><br><span class="line"></span><br><span class="line">By all accounts, today<span class="string">'s Internet is not moving data as well as it should. Most of the world'</span>s cellular users experience delays <span class="keyword">of</span> seconds to minutes; public Wi-Fi <span class="keyword">in</span> airports and conference venues is often worse. Physics and climate researchers need to exchange petabytes <span class="keyword">of</span> data <span class="keyword">with</span> global collaborators but find their carefully engineered multi-Gbps infrastructure often delivers at only a few Mbps over intercontinental distances<span class="number">.6</span></span><br><span class="line"></span><br><span class="line">These problems result <span class="keyword">from</span> a design choice made when TCP congestion control was created <span class="keyword">in</span> the <span class="number">1980</span>s—interpreting packet loss <span class="keyword">as</span> <span class="string">"congestion."</span><span class="number">13</span> This equivalence was <span class="literal">true</span> at the time but was because <span class="keyword">of</span> technology limitations, not first principles. As NICs (network interface controllers) evolved <span class="keyword">from</span> Mbps to Gbps and memory chips <span class="keyword">from</span> KB to GB, the relationship between packet loss and congestion became more tenuous.</span><br><span class="line"></span><br><span class="line">Today TCP<span class="string">'s loss-based congestion control—even with the current best of breed, CUBIC11—is the primary cause of these problems. When bottleneck buffers are large, loss-based congestion control keeps them full, causing bufferbloat. When bottleneck buffers are small, loss-based congestion control misinterprets loss as a signal of congestion, leading to low throughput. Fixing these problems requires an alternative to loss-based congestion control. Finding this alternative requires an understanding of where and how network congestion originates.</span></span><br></pre></td></tr></table></figure><p><strong>翻译</strong></p><p>因为各种原因，今天的互联网并不能像我们所期望的那样很好地传输数据。世界上大部分蜂窝网络用户都会经历几秒乃至几分钟的时延；在公共局域如机场和会议厅等，WIFI质量经常是非常差的。物理和气候学者想要与全球范围内的合作者传输千兆字节级别的数据，但可能会发现他们精心准备的Gbps级别的底层网络在洲际传输中只能达到Mbps级别。这些问题之所以会发生，是因为在80年代设计TCP拥塞控制的时候，TCP将丢包作为“拥塞”的信号。在那个年代，这个假设确实是正确的，但这是因为受限于技术原因。而当网卡的速率从Mbps级别进化为Gbps级别，内存从KB级别进化到GB级别之后，丢包与拥塞的关系变得不那么紧密了。</p><p>今天的这些TCP拥塞控制算法，包括至今为止最好的算法CUBIC，都是基于丢包的。他们是造成这些问题的主要元凶。当瓶颈链路的缓存较大时，这些基于丢包的拥塞控制算法流填满了缓存，造成了bufferbloat。当瓶颈链路的缓存较小时，这些算法会又将丢包作为发生拥塞的信号，从而降低速率导致了较低的吞吐量。</p><p>为了解决这些问题，必须提出一种不是基于丢包的拥塞控制算法，这需要设计者对网络拥塞是如何并且在哪里产生的有非常深刻的理解</p><p><strong>额外添加</strong></p><p>终端设备发的越来越快，中间网络设备的缓冲区越来越大，依靠丢包的算法不是那么明智了，所以需要一种新的拥塞控制算法，就是后面会提到的BBR</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">Congestion and Bottlenecks</span><br><span class="line"></span><br><span class="line">At any time, a (full-duplex) TCP connection has exactly one slowest link or bottleneck <span class="keyword">in</span> each direction. The bottleneck is important because:</span><br><span class="line"></span><br><span class="line">• It determines the connection<span class="string">'s maximum data-delivery rate. This is a general property of incompressible flow (e.g., picture a six-lane freeway at rush hour where an accident has reduced one short section to a single lane. The traffic upstream of the accident moves no faster than the traffic through that lane).</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">• It'</span>s where persistent queues form. Queues shrink only when a link<span class="string">'s departure rate exceeds its arrival rate. For a connection running at maximum delivery rate, all links upstream of the bottleneck have a faster departure rate so their queues migrate to the bottleneck.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Regardless of how many links a connection traverses or what their individual speeds are, from TCP'</span>s viewpoint an arbitrarily complex path behaves <span class="keyword">as</span> a single link <span class="keyword">with</span> the same RTT (round-trip time) and bottleneck rate. Two physical constraints, RTprop (round-trip propagation time) and BtlBw (bottleneck bandwidth), bound transport performance. (If the network path were a physical pipe, RTprop would be its length and BtlBw its minimum diameter.)</span><br><span class="line"></span><br><span class="line">Figure <span class="number">1</span> shows RTT and delivery rate variation <span class="keyword">with</span> the amount <span class="keyword">of</span> data <span class="keyword">in</span> flight (data sent but not yet acknowledged). Blue lines show the RTprop constraint, green lines the BtlBw constraint, and red lines the bottleneck buffer. Operation <span class="keyword">in</span> the shaded regions isn<span class="string">'t possible since it would violate at least one constraint. Transitions between constraints result in three different regions (app-limited, bandwidth-limited, and buffer-limited) with qualitatively different behavior.</span></span><br></pre></td></tr></table></figure><p><strong>翻译</strong></p><p>在一个TCP连接中，每个传输方向都存在一个最慢的链路，或者说瓶颈链路（bottleneck）。Bottleneck很重要！这是因为：</p><ol><li><p>它决定了该连接的最大传输速率（举个例子：如果高速公路上的某一段路发生了车祸，将会导致该道上的车速降低至那一段路的车速）。</p></li><li><p>它是造成队列的元凶！因为只有一个链路的离开速率大于它的到达速率，队列才会缩短。对于一个尽力传输最大速率的连接来说，因为其他的链路速率都比bottleneck大，所以最后会造成bottleneck的队列。</p></li></ol><p>无论一个TCP连接需要穿越多少链路，也无论这些链路的速率各自是多少，从TCP的角度来说，一个极其复杂路径的行为跟一条与它拥有相同RTT和bottleneck速率的简单链路一样（这句话不太好翻译，意思就是不管这条链路多么复杂，在tcp眼里和一条与这条复杂链路同样的RTT及bottleneck的简单链路是一样的）</p><p>这两个参数，RTprop（Round-trippropagation time）和BtlBw（bottleneck bandwidth），决定了传输的性能。</p><p>（打个比方，如果将一条网络路径类比为一个管道，RTprop就是管道的长度，BtlBw就是管道中最短的半径。）</p><p>图1展示了RTT和发送速率与发送数据大小的关系。</p><p>图中的蓝线受到了RTprop的约束，绿线受到BtlBw约束，红线受到瓶颈链路的缓存约束。注意阴影区域的部分是不可达的，因为这会至少违反一项约束。这三种约束形成了3不同的区域，分别为app-limited，bandwidth-limited，buffer-limited。在三种区域，流的行为是完全不同的</p><p><img src="http://blog.lihaizhou.top/BBR3/BBRpart1-1.png" alt=""></p><p><strong>额外添加</strong></p><p>这里重点提到了bottleneck，其实我们很容易想到如果这条链路上如果传输速率和瓶颈速度相近，是否会降低bottlebloat的概率呢？其实这只是其中一个条件，后面会提到。这里提到的两个参数后面会贯穿整篇论文：RTprop（Round-trippropagation time）和BtlBw（bottleneck bandwidth）</p><p>RTprop：光信号从A端到B端的最小时延（因为是一个来回其实是2倍时延），这取决于物理距离<br>BtlBw：在A到B的链路中，它的带宽取决于最慢的那段链路的带宽，称为瓶颈带宽，可以想象为光纤的粗细</p><p>上面的图中转折点有个词BDP，后面会频繁提及到：</p><p>BDP Bandwidth and Delay Product (整条物理链路（不含路由器缓存）所能储藏的比特数据之和，BDP = BtlBw * RTprop)，或者可以这样理解：Source 和 Destination 之间允许处在 Flying 状态的最大数据量。Flying 也叫 Inflights，就是发送了但还未收到的 Ack 的数据。</p><p>其实根据这个定义，我们很容易想到：如果当前的实际发送速率乘以延迟得到的值越接近 BDP 说明算法的效率越高。</p><p>再来看下上面的图，下面以上半图和下半图来称呼</p><p>上半图</p><pre><code>当链路上正在传输的比特数据未超过整条链路的物理容量（BDP）之前，传输时延的极限就是RTprop，对应上半图中蓝色的横线当数据塞满了整条链路的物理容量后，路由器开始启用缓存来存储比特数据，这相当于拉长了整个链路，造成传输时延开始变大，偏离了物理极限RTprop，于是有了slope = 1/BtlBw那条绿色斜线当路由器的缓存填满后（BDP+BtlBufSize），整条链路开始丢数据，1/BtlBw斜线消失，对应于上半图中红点虚线</code></pre><p>下半图<br>这里先说明下有一个需要注意的地方，就是下半图的纵坐标delivery rate，这里是BBR中定义的带宽，和我们平时理解的带宽可能还不太一样，我们平时直观上理解是数据在网线中的传输速率，这里指的是：数据量/从发送出去至收到ACK的时长</p><pre><code>当链路上正在传输的比特数据未超过整条链路的物理容量（BDP）之前，在B端观察到的数据带宽是逐渐往上涨的，对应下半图中蓝色斜线当数据塞满了整条链路的物理容量后，路由器开始启用缓存来存储比特数据，但不影响B端观察到的带宽，这个带宽的极限就是BtlBw，对应于图中那条绿色的BtlBw横线当路由器的缓存填满后（BDP+BtlBufSize），整条链路开始丢数据，但B端观察到的带宽极限还是BtlBw，对应于下半图中红点虚线</code></pre><p>上半图和下半图的斜率是怎么来的呢，我是这么理解的：<br>横坐标实际发送数据大小设为S，实际带宽这里设为R必定是小于等于<code>BtlBw</code>，实际时延这里设为T肯定是大于等于RTprop<br><code>S=T*R</code> 所以这里<code>T/S=1/R&gt;=1/BtlBw</code>,所以实际情况下斜率往往是比上半图中的更陡峭<br>同理下半图的斜率 <code>R/S=1/T&lt;=1/RTprop</code>,所以实际情况下下半图的斜率往往会更平缓些<br>上下半图的阴影部分是不可达，这个图画的真的是太棒了，一图胜千句！</p><p>当到达最大带宽的时候，RTT开始增长(所有不以增加速率为目的的缓存都是耍流氓！缓存不直接增加速率，缓存通过降低丢包来提高网络利用率！)，无论从RTT视图还是从带宽视图来看，两个操作点都是一致的，这是基本！那么bbr是怎么测量的呢？<br><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">先稳定住带宽，当带宽不再增加的时候，bbr认为已经达到最大带宽可，然后在此基础上测量RTT，带宽的RTT的操作点是重合的！就是这么简单且直接。</span><br></pre></td></tr></table></figure></p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">When there isn<span class="string">'t enough data in flight to fill the pipe, RTprop determines behavior; otherwise, BtlBw dominates. Constraint lines intersect at inflight = BtlBw × RTprop, a.k.a. the pipe'</span>s BDP (bandwidth-delay product). Since the pipe is full past <span class="keyword">this</span> point, the inflight - BDP excess creates a queue at the bottleneck, which results <span class="keyword">in</span> the linear dependence <span class="keyword">of</span> RTT on inflight data shown <span class="keyword">in</span> the upper graph. Packets are dropped when the excess exceeds the buffer capacity. Congestion is just sustained operation to the right <span class="keyword">of</span> the BDP line, and congestion control is some scheme to bound how far to the right a connection operates on average.</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure><p><strong>翻译</strong></p><p>当没有足够的数据来填满管道时，RTprop决定了流的行为（说的啥玩意没看懂）；<br>当有足够的数据填满时，那就变成了BtlBw来决定。这两条约束交汇在点inflight=BtlBw*RTprop，也就是管道的BDP（带宽与时延的乘积）。</p><p>当管道被填满时，那些超过的部分（inflight-BDP）就会在瓶颈链路中制造了一个队列，从而导致了RTT的增大，如上面那个图所示，当数据继续增加直到填满了缓存时，多余的报文就会被丢弃了。拥塞就是发生在BDP点的右边，而拥塞控制算法就是来控制流的平均工作点离BDP点有多远。</p><p><strong>额外添加</strong><br>带宽与时延的乘积-&gt;这里如果说是瓶颈带宽乘上最小时延会不会更好点？<br>这里的说的多余的报文就会被丢弃了就是我们经常说的缓冲区肿胀到一定程度，超过了缓冲区大小的报文被丢弃</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Loss-based congestion control operates at the right edge <span class="keyword">of</span> the bandwidth-limited region, delivering full bottleneck bandwidth at the cost <span class="keyword">of</span> high delay and frequent packet loss. When memory was expensive buffer sizes were only slightly larger than the BDP, which minimized loss-based congestion control<span class="string">'s excess delay. Subsequent memory price decreases resulted in buffers orders of magnitude larger than ISP link BDPs, and the resulting bufferbloat yielded RTTs of seconds instead of milliseconds.9</span></span><br></pre></td></tr></table></figure><p><strong>翻译</strong></p><p>基于丢包的拥塞控制算法工作在bandwidth-limited区域的右边界区域，尽管这种算法可以达到最大的传输速率，但是它是以高延迟和高丢包率作为代价的。在存储介质较为昂贵的时候，缓存大小只比BDP大一点，此时这种算法的时延并不会很高。然而，当存储介质变得便宜之后，交换机的缓存大小已经是ISP链路BDP的很多很多倍了，这导致了bufferbloat，从而导致了RTT从毫秒级升到了秒级</p><p><strong>额外添加</strong></p><p>bandwidth-limited区域就是开始缓存了排队了，但是还没超过最大缓存也就是还没丢白<br>它的右边区域说的就是填满缓冲区之后的片段，对应着高延迟和高丢包率<br>这里说的：当存储介质变得便宜之后，交换机的缓存大小已经是ISP链路BDP的很多很多倍了，这导致了bufferbloat<br>个人感觉说的不太好，倒不是说有错误，存储便宜所以缓存搞得大点只是一方面原因，还有更重要的一方面原因是</p><p>现在的终端设备比如计算机的性能已经今非昔比，和中间网络设备的差距越来越小，可以这样理解，终端设备发的越来越快，中间网络设备比如路由器转发的速度逐渐快被终端设备赶上来了，这个时候逼不得已就得加大缓存了，不然转发不过来了就得丢包，实则无奈之举</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">The left edge <span class="keyword">of</span> the bandwidth-limited region is a better operating point than the right. In <span class="number">1979</span> Leonard Kleinrock16 showed <span class="keyword">this</span> operating point was optimal, maximizing delivered bandwidth <span class="keyword">while</span> minimizing delay and loss, both <span class="keyword">for</span> individual connections and <span class="keyword">for</span> the network <span class="keyword">as</span> a whole8. Unfortunately, around the same time Jeffrey M. Jaffe14 proved it was impossible to create a distributed algorithm that converged to <span class="keyword">this</span> operating point. This result changed the direction <span class="keyword">of</span> research <span class="keyword">from</span> finding a distributed algorithm that achieved Kleinrock<span class="string">'s optimal operating point to investigating different approaches to congestion control.</span></span><br></pre></td></tr></table></figure><p><strong>翻译</strong></p><p>工作在bandwidth-limited区域的左边界比工作在右边界好。在1979年Leonard Kleinrock就展示了，无论是对流自身而言，或是对整个网络来说，工作在左边界是最优点，这个点在实现最大传输速率的同时，保持了低时延和低丢包。不幸的是，当时Jeffrey M.Jaffe也同时证明了不可能存在一个分布式算法可以收敛到这个边界点，这使得学术研究不再尝试去设计可以工作在该边界点的分布式算法</p><p><strong>额外添加</strong><br>bandwidth-limited区域的左边界临界点是最佳的，这个看图很直观，此时数据量刚好是BDP</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Our group at Google spends hours each day examining TCP packet header captures <span class="keyword">from</span> all over the world, making sense <span class="keyword">of</span> behavior anomalies and pathologies. Our usual first step is finding the essential path characteristics, RTprop and BtlBw. That these can be inferred <span class="keyword">from</span> traces suggests that Jaffe<span class="string">'s result might not be as limiting as it once appeared. His result rests on fundamental measurement ambiguities (e.g., whether a measured RTT increase is caused by a path-length change, bottleneck bandwidth decrease, or queuing delay increase from another connection'</span>s traffic). Although it is impossible to disambiguate any single measurement, a connection<span class="string">'s behavior over time tells a clearer story, suggesting the possibility of measurement strategies designed to resolve ambiguity.</span></span><br><span class="line"><span class="string">&#125;);</span></span><br></pre></td></tr></table></figure><p><strong>翻译</strong></p><p>我们谷歌工作组每天花了大量的时间来查看从世界各地发来的TCP报文头部，从而对流的异常行为有了很深的了解。<br>我们通常首先计算出流最重要的两个参数：RTprop和BtlBw，这两个参数都可以从trace中推断出来。这表明Jaffe的结论可能不再适用。他当时做出这个结论是因为测量具有模糊性（例如，RTT的增加有可能是因为流的路径改变了，也有可能是瓶颈链路的带宽减少了，也有可能是因为别的流竞争而导致队列等等）。尽管不可能在单次测量中得到非常可靠的值，但是一个持续时间较长的连接会告诉你很多信息，从中或许可以设法来估计得到一个可靠的值</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Combining these measurements <span class="keyword">with</span> a robust servo loop using recent control systems advances12 could result <span class="keyword">in</span> a distributed congestion-control protocol that reacts to actual congestion, not packet loss or transient queue delay, and converges <span class="keyword">with</span> high probability to Kleinrock<span class="string">'s optimal operating point. Thus began our three-year quest to create a congestion control based on measuring the two parameters that characterize a path: bottleneck bandwidth and round-trip propagation time, or BBR.</span></span><br></pre></td></tr></table></figure><p><strong>翻译</strong></p><p>使用最近在控制领域中提出的鲁棒伺服环来对这些观测结果进行处理(这句话不知道咋翻译)，可以设计出一种分布式拥塞控制协议。该协议可以针对真实的拥塞进行反应，而不是基于丢包或者短暂的队列时延的，它可以大概率收敛到Kleinrock的最优边界点。</p><p>因此这推动了我们近三年的研究——如何基于这两个观测参数bottleneck带宽及RTT（这就是BBR缩写的来源，bottleneck bandwidth and round-trip propagation time）来设计拥塞控制算法。</p><p><strong>额外添加</strong></p><p>因为基于丢包探测的算法总会使inflight的数据量达到BDP+BtlBufSize这个状态，在现代的路由器中由于缓存很大，相当于把物理链路人为的拉长了，使数据传输的延时变大，即RTT变大。</p><p>下一篇将进入今天讨论的主题BBR</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h1&gt;&lt;p&gt;拥塞控制本身是个比较发散的话题，首先需要说明一点我对这方面其实一窍不通，为了找资料在网上也看了不少文章，但是很多文章都是平铺直叙的讲述，所以
      
    
    </summary>
    
      <category term="网络" scheme="http://lihaizhou.top/categories/%E7%BD%91%E7%BB%9C/"/>
    
    
  </entry>
  
  <entry>
    <title>网络系列之三次握手</title>
    <link href="http://lihaizhou.top/2020/08/09/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE%E7%B3%BB%E5%88%97%E4%B9%8B%E8%81%8A%E8%81%8A%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B/"/>
    <id>http://lihaizhou.top/2020/08/09/网络协议系列之聊聊三次握手/</id>
    <published>2020-08-09T09:31:07.000Z</published>
    <updated>2021-10-16T06:52:33.183Z</updated>
    
    <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>三次握手这个话题恐怕是网络问答中最常见的问题了，基本上都能说个大概，但是再往下深究，有些问题可能回答的就不是那么顺畅了<br>所以想着再梳理下这个”简单”的概念</p><h1 id="为什么要三次握手"><a href="#为什么要三次握手" class="headerlink" title="为什么要三次握手"></a>为什么要三次握手</h1><p>首先先了解下TCP这个概念:<br>TCP 是靠谱的协议，但是这不能说明它面临的网络环境好，从IP层面来讲，如果网络状况的确比较差的话，是没有任何可靠性保证的，而作为IP的上一层TCP也无能为力，<br>唯一能做的就是更加努力，不断重传，通过各种算法保证。也就是说，对于 TCP 来讲，IP 层你丢不丢包，我管不着，但是我在我的层面上，会努力保证可靠性</p><p>接下来我们接着讨论为何需要这三次握手呢？类似如下的描述是网上比较常见的回答<br>三次握手的目的是建立可靠的通信信道，说到通讯，简单来说就是数据的发送与接收，而三次握手最主要的目的就是:双方确认自己与对方的发送与接收是正常的</p><ol><li>第一次握手：Client 什么都不能确认；Server 确认了对方发送正常</li><li>第二次握手：Client 确认了：自己发送、接收正常，对方发送、接收正常；Server 确认了：自己接收正常，对方发送正常</li><li>第三次握手：Client 确认了：自己发送、接收正常，对方发送、接收正常；Server 确认了：自己发送、接收正常，对方发送接收正常</li></ol><p>所以三次握手就能确认双发收发功能都正常，缺一不可。</p><p>这个听起来没有问题，如果我们试着用香农的信息论来理解下或许更好理解：<br><code>信息论中，有个很重要的思想：要想消除信息的不确定性，就得引入信息</code><br>将这个思想应用到TCP中，很容易理解TCP的三次握手和四次挥手的必要性：它们的存在以及复杂度，就是为了消除不确定性，这里我们叫「不可靠性」。<br>拿三次握手举例，这里为了描述方便，将通信的两端用字母A和B替代</p><p>A要往B发数据，A要确定两件事：</p><ol><li>B在“那儿”，并且能接受数据 —— B确实存在，并且是活的，能听得见</li><li>B能回应 —— B能发数据，能说话<br>为了消除这两个不确定性，所以必须有前两次握手，即A发送了数据，B收到了，并且能回应——“ACK”<br>同样的，对于B来说，它也要消除以上两个不确定性，通过前两次握手，B知道了A能说，但是不能确定A能听，这就是第三次握手的必要性。</li></ol><h1 id="关于握手的一点问题"><a href="#关于握手的一点问题" class="headerlink" title="关于握手的一点问题"></a>关于握手的一点问题</h1><p>我们都知道TCP连接就是两端的状态维护，中间过程没有所谓的连接，一旦传输失败，一端收到消息，才知道状态的变化</p><p><strong>客户端什么时候建立连接</strong><br>初学时以为是“三次握手”后，双方同时建立连接。显然是做不到的，客户端不知道“应答的应答”有没有到达，以及什么时候到达。<br>同样的问题客户端什么时候断开连接？自然也不能说是四次挥手之后，事实上，客户端发出最后的应答(第四次“挥手”)后，永远无法知道有没有到达。于<br>是有了2MSL的等待，在不确定的网络中，把问题最大程度地解决。</p><p><strong>关于三次握手中如果最后一次丢失了没有传递到服务端会怎么样？</strong><br>回答这个问题之前，我们先看下正常的操作流程是什么样的</p><p>我们先来解释一下这张图：</p><ol><li>在初始时，双端处于 CLOSE 状态，服务端为了提供服务，会主动监听某个端口，进入 LISTEN 状态</li><li>客户端主动发送连接的「SYN」包，之后进入 SYN-SENT 状态，服务端在收到客户端发来的「SYN」包后，回复「SYN,ACK」包，之后进入 SYN-RCVD 状态</li><li>客户端收到服务端发来的「SYN,ACK」包后，可以确认对方存在，此时回复「ACK」包，并进入 ESTABLISHED 状态</li><li>服务端收到最后一个「ACK」包后，也进入 ESTABLISHED 状态</li></ol><p>这是正常的 TCP 三次握手，握手完成后双端都进入 ESTABLISHED 状态，在此之后，就是正常的数据传输过程。</p><p>再回到三次握手中如果出现异常情况会是什么样的，就以最后一次报文丢失为例<br>这个问题查阅了一些过程中，发现是比较有争议的，所以还是以实践出真知为准<br>具体实践例子，可以参见：<a href="https://blog.csdn.net/zerooffdate/article/details/79359726" target="_blank" rel="noopener">TCP三次握手的第三个ack丢了会怎样</a><br>所以有些资料里写的当服务端处于 SYN-RCVD 状态下，收到客户端的数据包后，会直接回复 RTS 包响应，表示服务端错误，并进入 CLOSE 状态。是不对的<br>试想一下，服务端还在通过三次握手阶段确定对方是否真实存在，此时对方的数据已经发来了，那肯定是存在的。<br>所以当服务端处于 SYN-RCVD 状态下时，接收到客户端真实发送来的数据包时，会认为连接已建立，并进入 ESTABLISHED 状态。</p><p>另外这个问题在stackoverflow同样找到了一个比较不错的回答<br><a href="https://stackoverflow.com/questions/16259774/what-if-a-tcp-handshake-segment-is-lost" target="_blank" rel="noopener">What if a TCP handshake segment is lost?</a></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">TCP has a sequence number in all packets. Hence it<span class="string">'s easy to know if a packet was lost or not. If a host doesn'</span>t get an ACK on a packet he just resends it.</span><br><span class="line"></span><br><span class="line">In most cases though, even <span class="keyword">if</span> that ACK was lost, there will be no resending <span class="keyword">for</span> a very simple reason. Directly after the ACK, the host that opened the TCP protocol is likely to start sending data. That data will, as all TCP packets, have an ACK number, so the recipient would get an ACK that way. Hence, the sender of the SYN-ACK should reasonably not care that it didn<span class="string">'t get the ACK, because it gets an "implicit" ACK in the following package.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">The re-send of the SYN-ACK is only necessary of there no data is received at all.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Update: I found the place in the RFC that specified exactly this:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    If our SYN has been acknowledged (perhaps in this incoming segment) the precedence level of the incoming segment must match the local precedence level exactly, if it does not a reset must be sent.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">In other words, if the ACK is dropped but the next packet is not dropped, then everything is fine. Otherwise, the connection must be reset. Which makes perfect sense</span></span><br></pre></td></tr></table></figure><p>这个其实就是tcp的累计ack，我们后面的系列谈tcp时会细谈</p><p>在查找资料的过程中，发现网上有比较常见的一种说法<br>当Client端收到Server的SYN+ACK应答后，其状态变为ESTABLISHED，并发送ACK包给Server；<br>如果此时ACK在网络中丢失，那么Server端该TCP连接的状态为SYN_RECV，并且依次等待3秒、6秒、12秒后重新发送SYN+ACK包，以便Client重新发送ACK包，<br>以便Client重新发送ACK包。Server重发SYN+ACK包的次数，可以通过设置<code>/proc/sys/net/ipv4/tcp_synack_retries</code>修改，默认值为5。如果重发指定次数后，<br>仍然未收到ACK应答，那么一段时间后，Server自动关闭这个连接。<br>但是Client认为这个连接已经建立，如果Client端向Server写数据，Server端将以RST包响应，方能感知到Server的错误。</p><p>这里的最后一句其实是有可能是有问题的，不同的tcp实现可能不同，不一定会直接回复rst，真实的情况很可能是如下这样的<br>当客户端在 ESTABLISHED 状态下，开始发送数据包时，会携带上一个「ACK」的确认序号，所以哪怕客户端响应的「ACK」包丢了，服务端在收到这个数据包时，<br>能够通过包内 ACK 的确认序号，正常进入 ESTABLISHED 状态。</p><p>还有一种安全范畴的非正常情况<br>前面一直在说正常的异常逻辑，双方都还算友善，按规矩做事，出现异常主要也是因为网络等客观问题，接下来说一个恶意的情况。<br>如果客户端是恶意的，在发送「SYN」包后，并收到「SYN,ACK」后就不回复了，那么服务端此时处于一种半连接的状态，<br>虽然服务端会通过 tcp_synack_retries 配置重试的次数，不会无限等待下去，但是这也是有一个时间周期的。<br>如果短时间内存在大量的这种恶意连接，对服务端来说压力就会很大，这就是所谓的 SYN FLOOD 攻击。</p><p>我们上面讨论的都是三次握手过程，四次挥手过程，有兴趣可以参考这篇文章，写的不错<br><a href="https://www.jianshu.com/p/723365a47c6e" target="_blank" rel="noopener">TCP三次握手、四次挥手出现意外情况时，为保证稳定，是如何处理的？</a> </p><h1 id="wireshark看三次握手"><a href="#wireshark看三次握手" class="headerlink" title="wireshark看三次握手"></a>wireshark看三次握手</h1><p>抓了一个投屏的tcpdump，可以看下三次握手的过程<br><img src="http://blog.lihaizhou.top/HandShake/TCP%E7%B3%BB%E5%88%97%E4%B9%8B%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B1.png" alt=""></p><p><img src="http://blog.lihaizhou.top/HandShake/TCP%E7%B3%BB%E5%88%97%E4%B9%8B%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B2.png" alt=""></p><p><img src="http://blog.lihaizhou.top/HandShake/TCP%E7%B3%BB%E5%88%97%E4%B9%8B%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B3.png" alt=""></p><p>参考文章：<br><a href="https://www.jianshu.com/p/723365a47c6e" target="_blank" rel="noopener">TCP三次握手、四次挥手出现意外情况时，为保证稳定，是如何处理的？</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h1&gt;&lt;p&gt;三次握手这个话题恐怕是网络问答中最常见的问题了，基本上都能说个大概，但是再往下深究，有些问题可能回答的就不是那么顺畅了&lt;br&gt;所以想着再梳理
      
    
    </summary>
    
      <category term="网络" scheme="http://lihaizhou.top/categories/%E7%BD%91%E7%BB%9C/"/>
    
    
  </entry>
  
  <entry>
    <title>内存屏障</title>
    <link href="http://lihaizhou.top/2020/06/20/Memory-Barrier%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    <id>http://lihaizhou.top/2020/06/20/Memory-Barrier读书笔记/</id>
    <published>2020-06-20T07:56:03.000Z</published>
    <updated>2021-10-17T01:20:13.354Z</updated>
    
    <content type="html"><![CDATA[<p>本篇文章开始之前需要了解一些背景知识</p><h1 id="Cache-Memory"><a href="#Cache-Memory" class="headerlink" title="Cache Memory"></a>Cache Memory</h1><p>我们都知道程序是运行在 RAM之中，RAM 就是我们常说的DDR（例如 DDR3、DDR4等），我们称之为main memory（主存）当我们需要运行一个进程的时候，首先会从Flash设备（例如，eMMC、UFS等）中将可执行程序load到main memory中，然后开始执行。</p><p>在CPU内部存在一堆的通用寄存器（register），如果CPU需要将一个变量（假设地址是A）加1，一般分为以下3个步骤</p><ol><li>CPU 从主存中读取地址A的数据到内部通用寄存器 x0（ARM64架构的通用寄存器之一）</li><li>通用寄存器 x0 加1</li><li>CPU 将通用寄存器 x0 的值写入主存</li></ol><p>但是存在一个问题，CPU通用寄存器的速度和主存之间存在着太大的差异<br>从这个网址<a href="https://gist.github.com/jboner/2841832" target="_blank" rel="noopener">https://gist.github.com/jboner/2841832</a> 摘了一段数据<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">Latency Comparison <span class="title">Numbers</span> <span class="params">(~<span class="number">2012</span>)</span></span></span><br><span class="line"><span class="function">----------------------------------</span></span><br><span class="line"><span class="function">L1 cache reference                           0.5 ns</span></span><br><span class="line"><span class="function">Branch mispredict                            5   ns</span></span><br><span class="line"><span class="function">L2 cache reference                           7   ns                      14x L1 cache</span></span><br><span class="line"><span class="function">Mutex lock/unlock                           25   ns</span></span><br><span class="line"><span class="function">Main memory reference                      100   ns                      20x L2 cache, 200x L1 cache</span></span><br><span class="line"><span class="function">Compress 1K bytes with Zippy             3,000   ns        3 us</span></span><br><span class="line"><span class="function">Send 1K bytes over 1 Gbps network       10,000   ns       10 us</span></span><br><span class="line"><span class="function">Read 4K randomly from SSD*             150,000   ns      150 us          ~1GB/sec SSD</span></span><br><span class="line"><span class="function">Read 1 MB sequentially from memory     250,000   ns      250 us</span></span><br><span class="line"><span class="function">Round trip within same datacenter      500,000   ns      500 us</span></span><br><span class="line"><span class="function">Read 1 MB sequentially from SSD*     1,000,000   ns    1,000 us    1 ms  ~1GB/sec SSD, 4X memory</span></span><br><span class="line"><span class="function">Disk seek                           10,000,000   ns   10,000 us   10 ms  20x datacenter roundtrip</span></span><br><span class="line"><span class="function">Read 1 MB sequentially from disk    20,000,000   ns   20,000 us   20 ms  80x memory, 20X SSD</span></span><br><span class="line"><span class="function">Send packet CA-&gt;Netherlands-&gt;CA    150,000,000   ns  150,000 us  150 ms</span></span><br></pre></td></tr></table></figure></p><p>这里没有列出寄存器速度，看到L1 cache是0.5ns，可以肯定的是寄存器一定是低于1ns，Main memory是100ns，这里的数据仅供参考<br>所以上面的从主存读取数值三个步骤中的第一和第三步实际上速度很慢相对于寄存器而言</p><p>当CPU试图从主存中load/store 操作时，由于主存的速度限制，CPU不得不等待这漫长的65ns时间。如果我们可以提升主存的速度，那么系统将会获得很大的性能提升。如今的DDR存储设备，动不动就是几个GB，容量很大。如果我们采用更快材料制作更快速度的主存，并且拥有几乎差不多的容量。其成本将会大幅度上升。<br>我们试图提升主存的速度和容量，又期望其成本很低，这就有点难为人了。因此，我们有一种折中的方法，那就是制作一块速度极快但是容量极小的存储设备。那么其成本也不会太高。这块存储设备我们称之为cache memory。在硬件上，我们将cache放置在CPU和主存之间，作为主存数据的缓存。当CPU试图从主存中load/store数据的时候， CPU会首先从cache中查找对应地址的数据是否缓存在cache 中。如果其数据缓存在cache中，直接从cache中拿到数据并返回给CPU。<br><strong>CPU和主存之间直接数据传输的方式转变成CPU和cache之间直接数据传输。cache负责和主存之间数据传输。</strong></p><p>当存在cache的时候，以上程序如何运行的例子的流程将会变成如下：<br><img src="http://blog.lihaizhou.top/MemBarrier/memory-barrier01.png" alt=""></p><p>cahe的速度在一定程度上同样影响着系统的性能。一般情况cache的速度可以达到1ns，几乎可以和CPU寄存器速度媲美。但是，这就满足人们对性能的追求了吗？并没有。当cache中没有缓存我们想要的数据的时候，依然需要漫长的等待从主存中load数据。为了进一步提升性能，引入多级cache。前面提到的cache，称之为L1 cache（第一级cache）。<br>我们在L1 cache 后面连接L2 cache，在L2 cache 和主存之间连接L3 cache。等级越高，速度越慢，容量越大。但是速度相比较主存而言，依然很快</p><p>多级cache不是本文重点，详细可参考如下两篇文章，写的比较详细<br><a href="http://www.wowotech.net/memory_management/458.html" target="_blank" rel="noopener">浅谈Cache Memory</a><br><a href="https://zhuanlan.zhihu.com/cpu-cache" target="_blank" rel="noopener">高速缓存与一致性</a></p><h2 id="Cacheline"><a href="#Cacheline" class="headerlink" title="Cacheline"></a>Cacheline</h2><p>本文后续会涉及到一个名词Cacheline，cache的大小称之为cahe size，代表cache可以缓存最大数据的大小。<br>我们将cache平均分成相等的很多块，每一个块大小称之为cache line，其大小是cache line size。例如一个64 Bytes大小的cache<br>如果我们将64 Bytes平均分成64块，那么cache line就是1字节，总共64行cache line。如果我们将64 Bytes平均分成8块，那么cache line就是8字节，总共8行cache line<br>有一点需要注意，cache line是cache和主存之间数据传输的最小单位。什么意思呢？当CPU试图load一个字节数据的时候，如果cache缺失，那么cache控制器会从主存中一次性的load cache line大小的数据到cache中。</p><p>例如，cache line大小是8字节。CPU即使读取一个byte，在cache缺失后，cache会从主存中load 8字节填充整个cache line，至于原因可以参见这篇文章:<br><a href="http://www.wowotech.net/memory_management/458.html" target="_blank" rel="noopener">浅谈Cache Memory</a></p><p>有了前面的基础知识的认知，不难理解下面这个极简的抽象CPU架构图<br><img src="http://blog.lihaizhou.top/MemBarrier/memory-barrier02.gif" alt=""></p><h1 id="缓存一致性"><a href="#缓存一致性" class="headerlink" title="缓存一致性"></a>缓存一致性</h1><p>考虑到多线程读写环境中，不免会有个疑问，如果一个数据是多个cpu都共享，其中一个修改了是不是要想办法使得其他cpu也能更新<br>一个cpu去读取一个数值时，怎么确定是最新的呢？说到底就是要保证在使用cache后如何确保各 CPU 看到的数据是一致的<br>这个就引出另外一个名词“cache-coherence protocol”即缓存一致性协议<br>其中，MESI protocol 是一个基本版，从 MESI protocol 可以了解 CPU 之间如何维持看到一致的资料，可以参见MESI的维基定义:   <a href="https://zh.wikipedia.org/wiki/MESI%E5%8D%8F%E8%AE%AE" target="_blank" rel="noopener">MESI协议</a></p><p>这里摘取英文文档中的对于MESI拆解开来的四种状态的解释<br><code>A line in the “modified” state has been subject to a recent memory store from the corresponding CPU, and the corresponding memory is guaranteed not to appear in any other CPU’s cache. Cache lines in the “modified”state can thus be said to be “owned” by the CPU. Because this cache holds the only up-to-date copy of the data, thiscache is ultimately responsible for either writing it back to memory or handing it off to some other cache, and must do so before reusing this line to hold other data.</code><br>处于modified状态的cacheline说明近期有过来自对应cpu的写操作，同时也说明该该数据不会存在其他cpu对应的cache中。因此，处于modified状态的cacheline也可以说是被该CPU独占。而又因为只有该CPU的cache保存了最新的数据（最终的memory中都没有更新），所以，该cache需要对该数据负责到底。例如根据请求，该cache将数据及其控制权传递到其他cache中，或者cache需要负责将数据写回到memory中，而这些操作都需要在reuse该cache line之前完成。<br><code>The “exclusive” state is very similar to the “modified”state, the single exception being that the cache line has not yet been modified by the corresponding CPU, which in turn means that the copy of the cache line’s data that resides in memory is up-to-date. However, since the CPU can store to this line at any time, without consulting other CPUs, a line in the “exclusive” state can still be said to be owned by the corresponding CPU. That said, because the corresponding value in memory is up to date, this cache can discard this data without writing it back to memory or handing it off to some other CPU.</code><br>exclusive状态和modified状态非常类似，唯一的区别是对应CPU还没有修改cacheline中的数据，也正因为还没有修改数据，因此memory中对应的data也是最新的。在exclusive状态下，cpu也可以不通知其他CPU cache而直接对cacheline进行操作，因此，exclusive状态也可以被认为是被该CPU独占。由于memory中的数据和cacheline中的数据都是最新的，因此，cpu不需对exclusive状态的cacheline执行写回的操作或者将数据以及归属权转交其他cpu cache，而直接reuse该cacheline（将cacheine中的数据丢弃，用作他用）<br><code>A line in the “shared” state might be replicated in at least one other CPU’s cache, so that this CPU is not permitted to store to the line without first consulting with other CPUs. As with the “exclusive” state, because thecorresponding value in memory is up to date, this cache can discard this data without writing it back to memory or handing it off to some other CPU.</code><br>处于share状态的cacheline，其数据可能在一个或者多个CPU cache中，因此，处于这种状态的cache line，CPU不能直接修改cacheline的数据，而是需要首先和其他CPU cache进行沟通。和exclusive状态类似，处于share状态的cacheline对应的memory中的数据也是最新的，因此，cpu也可以直接丢弃cacheline中的数据而不必将其转交给其他CPU cache或者写回到memory中。<br><code>A line in the “invalid” state is empty, in other words, it holds no data. When new data enters the cache, it is placed into a cache line that was in the “invalid” state if possible. This approach is preferred because replacing a line in any other state could result in an expensive cache miss should the replaced line be referenced in the future.</code><br>处于invalid状态的cacheline是空的，没有数据。当新的数据要进入cache的时候，优选状态是invalid的cacheline，之所以如此是因为如果选中其他状态的cacheline，则说明需要替换cacheline数据，而未来如果再次访问这个被替换掉的cacheline数据的时候将遇到开销非常大的cache miss  </p><font color="red"> 个人理解:<br>1. 对于modified状态的cacheline，别的cpu如果需要其中的数据，必须要写回到memory或者转移<br>2. exclusive可以理解为是modified的轻量版，exclusive状态的cacheline数据此时还没有被cpu修改，也就是说它的数据和memory中是一致的，当别的cpu需要状态是exclusive的cacheline数据时，可以直接提供数据不需要写回到memory<br>3. share状态的cacheline不能直接被修改，如果一个cpu需要对这个cacheline进行修改了，需要先通知其他cpu让他们将各自对应的cacheline置为invalid，然后再切换cacheline的状态到exclusive，再然后就是M状态<br>4. invalid状态的cacheline之前可能是有数据的，比如之前是shared状态，后来其他cpu要修改这个cacheline了，就发通知过来了要求置为invalid的，不然读取出来的就是错误的<br><br> </font><p>有一个MESI动画的网址，可以模拟各个cacheline的状态切换，比起文字描述来讲更好理解，可以不断的模拟测试，对理解MESI很有帮助<br><a href="https://www.scss.tcd.ie/Jeremy.Jones/VivioJS/caches/MESIHelp.htm" target="_blank" rel="noopener">VivioJS - Interactive Reversible E-Learning Animations for the WWW</a></p><p>比如当前状态<br><img src="http://blog.lihaizhou.top/MemBarrier/memory-barrier03.png" alt=""></p><font color="red"><br>个人理解添加<br>此时CPU0上a1数据对应的cacheline此时的状态是M状态，可以看到此时的数值是11，比memory要新，其他两个cpu1，cpu2上的a1对应的cacheline是invalid状态。如果此时cpu2上对a1进行写值加1，会是什么样子的呢？<br>根据上面的理论知识，此时应该会通过总线通知cpu0让其写入到memory中，然后cpu2才能读取到最新的值此时再进行修改此时数值应该是12并将状态置为E并且写回memory，此时CPU0上的a1对应cacheline状态理论上应该是invalid。<br></font><br>实际的cpu2对a1加1后效果图如下：<br><img src="http://blog.lihaizhou.top/MemBarrier/memory-barrier04.png" alt=""><br><font color="red"> 个人理解添加<br>此时如果对cpu2的cacheline进行写加1，cacheline状态会切换到M状态，如果一直写，数值一直增加一直是M状态，其他cpu无变化。因为此时M是最新的，只有其他cpu比如此时cpu1需要读取a1的值，这个时候cpu2会将这个值写回到memory并且此时cpu1和cpu2上a1对应的cacheline状态都是S。<br>如果这个时候，对cpu2的a1进行写操作呢？其状态会切换到E，其他cpu对应的a1-cacheline都切到invalid<br>介绍完MESI后，我们知道有了MESI protocol，任何一个CPU 要写入资料前，都要先确保其它CPU 已invalid 同一位置的cache 后(希望写入的CPU 广播invalidate，其它CPU 回invalidate ack)， 才能写资料到自己的cache，并在稍后补写回memory。<br></font><br>这个设计确保资料的一致性，不用担心同一时间同一个位置的资料会有不同的值，但是代价是写入 cache 的速度会有点慢，让 CPU 闲置，下图中的stall就是cpu等待的时长<br><img src="http://blog.lihaizhou.top/MemBarrier/memory-barrier05.png" alt=""><br><br><font color="red">  个人理解添加<br>想象一下这个场景：<br><em> CPU 0 打算写入值到位置 X，CPU 1 的 cache 有 X 的值。因为缓存一致性的缘故，这个时候CPU0给CPU1发送一个invalid的广播告知其需要将其对应数值置于无效</em> 这个时候呢cpu0就开始傻乎乎的等 CPU 1 回 invalidate ack，但是此时CPU 1 的 cache 可能太忙而拖慢了回覆时间 (比方同时从 cache 大量的读写资料，或是短时间收到大量 invalidate ack)。<br>这样就导致了CPU0白白耗费时间在等待上，这对于宝贵的cpu资源是一种很大的浪费，其实没必要等待这么长的时间，毕竟物理CPU 1中的cacheline保存有什么样子的数据，其实都没有意义，这个值都会被CPU 0新写入的值覆盖的，所以能不能不等呢？这也就引出了另外一个名词StoreBuffer，还有另外一个名词对应刷新的Invalidate Queue<br></font> <h2 id="Store-Buffer-amp-Invalidate-Queue"><a href="#Store-Buffer-amp-Invalidate-Queue" class="headerlink" title="Store Buffer &amp; Invalidate Queue"></a>Store Buffer &amp; Invalidate Queue</h2><p>在CPU和cache之间增加store buffer这个HW block</p><font color="red">  个人理解添加<br>1. CPU 0 不等 invalidate ack：先写入 store buffer，然后继续作事。之后收到 invalidate ack 再更新 cache 的状态。因为最新的资料可能存在 store buffer，CPU 读资料的顺序变成 store buffer → cache → memory。<br>2. CPU 1 立即回 invalidate ack：收到 invalidate 时，记录到 invalidate queue 里，先回 invalidate ack，稍后再处理 invalidate。<br>3. 为啥有了store buffer后还会冒出来一个invalidate queue，因为 store buffer 很小，store buffer 满的时候，CPU 0 还是得等 invalidate ack，所以加上 invalidate queue，双管齐下减少 CPU 0 等待时间<br>这里还有一个细节后面会提到，如果有数据加了写内存屏障的话，加入storebuffer，其后面的写操作不管有没有写屏障都要加到storebuffer中，这就造成了storebuffer更容易满了，一旦满了又要开始等ack了，这就引入了<br>invalidate queue，后面还会继续讲它的作用<br>其实这里出现了一个重排序的“现象”，就是一旦某一条写指令放到storebuffer中了继续后面的指令操作，这就造成了下一条指令跑到这条指令前面执行的”假象”，这种重排序就是为了充分利用cpu的性能避免白白的浪费等待<br>CPU 为了提升效率而出现的这种”改指令”执行的顺序，只要最后結果和 single thread 预期的結果一样即可。这句话可以细品下，所以多线程的情况下需要我们研发人员自己控制<br></font>  <p>有了StoreBuffer以及Invalidate Queue之后的cpu cache架构如下<br><img src="http://blog.lihaizhou.top/MemBarrier/memory-barrier06.png" alt=""></p><p>下面摘自perfbook文档关于StoreBuffer以及Invalidate Queue的解释</p><p><code>These store buffers are local to a given CPU or, on systems with hardware multithreading, local to a given core. Either way, a given CPU is permitted to access only the store buffer assigned to it. For example, in Figure C.5, CPU 0 cannot access CPU 1’s store buffer and vice versa. This restriction simplifies the hardware by separating concerns: The store buffer improves performance for consecutive writes, while the responsibility for communicating among CPUs (or cores, as the case may be) is fully shouldered by the cache-coherence protocol. However, even given this restriction, there are complications that must be addressed, which are covered in the next two sections.</code></p><p>这些store buffer对于cpu而言是local的，如果系统是硬件多线程， 那么每一个cpu core拥有自己私有的stroe buffer，一个cpu只能访问自己私有的那个store buffer。在上图中，cpu 0不能访问cpu1的store buffer，反之亦然。之所以做这样的限制是为了模块划分（各个cpu core模块关心自己的事情，让cache系统维护自己的操作），让硬件设计变得简单一些。store buffer增加了CPU连续写的性能，同时把各个CPU之间的通信的任务交给维护cache一致性的协议。即便给每个CPU分配私有的store buffer，仍然引入了一些复杂性，我们会在下面两个小节中描述。</p><p><code>Unfortunately, each store buffer must be relatively small, which means that a CPU executing a modest sequence of stores can fill its store buffer (for example, if all of them result in cache misses). At that point, the CPU must once again wait for invalidations to complete in order to drain its store buffer before it can continue executing. This same situation can arise immediately after a memory barrier, when all subsequent store instructions must wait for invalidations to complete, regardless of whether or not these stores result in cache misses.</code></p><p>不幸的是：每个cpu的store buffer不能实现的太大，其entry的数目不会太多。当cpu以中等的频率执行store操作的时候（假设所有的store操作导致了cache miss），store buffer会很快的被填满。在这种状况下，CPU只能又进入等待状态，直到cache line完成invalidation和ack的交互之后，可以将store buffer的entry写入cacheline，从而为新的store让出空间之后，CPU才可以继续执行。这种状况也可能发生在调用了memory barrier指令之后，因为一旦store buffer中的某个entry被标记了，那么随后的store都必须等待invalidation完成，因此不管是否cache miss，这些store都必须进入store buffer。</p><p><code>This situation can be improved by making invalidate acknowledge messages arrive more quickly. One way of accomplishing this is to use per-CPU queues of invalidate messages, or “invalidate queues”.</code></p><p>引入invalidate queues可以缓解这个状况。store buffer之所以很容易被填充满，主要是其他CPU回应invalidate acknowledge比较慢，如果能够加快这个过程，让store buffer尽快进入cacheline，那么也就不会那么容易填满了。</p><p><code>Invalidate QueuesOne reason that invalidate acknowledge messages can take so long is that they must ensure that the correspondingcache line is actually invalidated, and this invalidation can be delayed if the cache is busy, for example, if the CPU is intensively loading and storing data, all of which resides in the cache. In addition, if a large number of invalidate messages arrive in a short time period, a given CPU might fall behind in processing them, thus possibly stalling all the other CPUs.</code></p><p>invalidate acknowledge不能尽快回复的主要原因是invalidate cacheline的操作没有那么快完成，特别是cache比较繁忙的时候，这时，CPU往往进行密集的loading和storing的操作，而来自其他CPU的，对本CPU local cacheline的操作需要和本CPU的密集的cache操作进行竞争，只要完成了invalidate操作之后，本CPU才会发生invalidate acknowledge。此外，如果短时间内收到大量的invalidate消息，CPU有可能跟不上处理，从而导致其他CPU不断的等待。</p><p><code>However, the CPU need not actually invalidate the cache line before sending the acknowledgement. It could instead queue the invalidate message with the understanding that the message will be processed before the CPU sends any further messages regarding that cache line.</code></p><p>然而，CPU其实不需要完成invalidate操作就可以回送acknowledgement消息，这样，就不会阻止发生invalidate请求的那个CPU进入无聊的等待状态。CPU可以buffer这些invalidate message（放入Invalidate Queues），然后直接回应acknowledgement，表示自己已经收到请求，随后会慢慢处理。当然，再慢也要有一个度，例如对a变量cacheline的invalidate处理必须在该CPU发送任何关于a变量对应cacheline的操作到bus之前完成。</p><p>有了Invalidate Queue的CPU，在收到invalidate消息的时候首先把它放入Invalidate Queue，同时立刻回送acknowledge 消息，无需等到该cacheline被真正invalidate之后再回应。当然，如果本CPU想要针对某个cacheline向总线发送invalidate消息的时候，那么CPU必须首先去Invalidate Queue中看看是否有相关的cacheline，如果有，那么不能立刻发送，需要等到Invalidate Queue中的cacheline被处理完之后再发送。</p><p><code>Placing an entry into the invalidate queue is essentially a promise by the CPU to process that entry before transmitting any MESI protocol messages regarding that cache line. As long as the corresponding data structures are not highly contended, the CPU will rarely be inconvenienced by such a promise.</code></p><p>一旦将一个invalidate（例如针对变量a的cacheline）消息放入CPU的Invalidate Queue，实际上该CPU就等于作出这样的承诺：在处理完该invalidate消息之前，不会发送任何相关（即针对变量a的cacheline）的MESI协议消息。只要是对该cacheline的竞争不是那么剧烈，CPU还是对这样的承诺很有信心的</p><p>因为多了 store buffer 和 invalidate queue，cache 之间的资料就没有完全一致了</p><h2 id="一个小案例"><a href="#一个小案例" class="headerlink" title="一个小案例"></a>一个小案例</h2><p>有了上面一连串理论知识的铺垫，下面看一个小例子，这个例子是老演员了，其实也是摘自perfbook中的，在查阅资料过程中发现很多博客都是用的这个图</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> a = b = <span class="number">0</span>;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">foo</span><span class="params">(<span class="keyword">void</span>)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  a = <span class="number">1</span>;</span><br><span class="line">  b = <span class="number">1</span>;</span><br><span class="line">&#125;</span><br><span class="line">  </span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">bar</span><span class="params">(<span class="keyword">void</span>)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="keyword">while</span> (b == <span class="number">0</span>) <span class="keyword">continue</span>;</span><br><span class="line">  <span class="keyword">assert</span>(a == <span class="number">1</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>考虑 CPU 0 执行 foo()， CPU 1 执行 bar()，也就是我们常说的多线程环境，假设 cache 的状态如下:<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">        a       b</span><br><span class="line">------------------------</span><br><span class="line">CPU <span class="number">0</span>:  Shared  Modified</span><br><span class="line">CPU <span class="number">1</span>:  Shared  Invalid</span><br></pre></td></tr></table></figure></p><p>其实可以理解为假设 a,b 初始值为 0 ，a 被 CPU0 和 CPU1 共同持有，b 被 CPU0 独占</p><p>试想，即便在多线程环境下，foo 和 bar 如若严格按照理想的顺序执行，是无论如何都不会出现 assert failed 的情况的。但往往事与愿违，这种看似很诡异的且有一定几率发生的 assert failed ，结合上面所说的 Store Buffer 就一点都不难理解了<br>我们来还原 assert failed 的整个过程</p><ol><li>CPU0 处理 a=1 之前发送 Invalidate 消息给 CPU1 ，并将其放入 Store Buffer ，尚未及时刷入缓存，所以这时候 cache 里a的值仍是 0；</li><li>CPU 0 转而处理 b=1 ，注意这里我们上面假设的是此时b 的状态已是 Modified，所以 b=1 直接被刷入缓存；</li><li>CPU 1 发出 Read 消息读取 b 的值，CPU 1 从 CPU 0 的 cache 读到 b = 1 ，跳出 while 语句；</li><li>CPU 1 发出 Read 消息读取 a 的值，发现 a 却为旧值 0，assert failed，然后收到 CPU 0 送来 “invalidate a” 的讯息，但已太迟了</li></ol><p>上面这个还原过程摘自一个台湾人写的博客&lt;從硬體觀點了解 memory barrier 的實作和效果&gt;<br>个人感觉这个描述过程不完全准确，既然已经有了Invalidate Queue，这个时候cpu1理论上是立刻给cpu0发ack的，可能由于当前要回复的ack很多，导致发送给cpu0的ack并没有达到”立刻”的效果<br>所以出现上面描述的过程也是有可能的，但是其实还有一种可能，就是读取a的时候最新值Invalidate Queue中，详细在下面的个人理解环节中  </p><font color="red"><br>个人理解如下<br>1. 大致流程是CPU0这个时候想要对a进行写值，发现a对应的cacheline对应的状态是S，也就是这里的cpu1上也有a的值，所以需要通知cpu1，通过总线发个消息告知cpu1进行invalid，因为有storebuffer这玩意所以直接放到storebuffer，又因为有invalidate queue的存在<br>2. 所以CPU1立刻回复了“已更新”的ack回去了，其实并没有实际更新，只是先放在了invalidate queue中待更改标记为invalid，CPU0收到这个ack后将数据回写到内存中<br>3. 此时CPU0开始了执行下一条对b写值，因为b是M状态也是说是cpu0独占的，所以直接写到缓存就完事了<br>4. 再来到cpu1这边看看，此时cpu1读取b的值，因为cpu1上没有对应的cacheline，cpu0上b对应的cacheline是M状态，所以此时cpu0会将b的值写回到memory,并且这个时候cpu1读取到的值是最新的和memory一样，此时cpu1和cpu0上b对于的cacheline状态变为S<br>5. 这个时候再看assert(a == 1);  此时CPU1读取到的数值a仍然是S状态，所以直接读取了，读取出来自然是0，因为此时并没有去invalidate queue看看有没有值，所以看到的值不是最新的，出现assert fail<br><br>如何解决这个问题呢？可以在foo函数a=1下面加一个写内存屏障，这样的话当a=1的值放到storebuffer中后，发现后面有一个写内存屏障指令，这个时候就会把后面的写指令都会顺序放到storebuffer中。另外在bar函数第二行读取a的时候需要看下invalidqueue中有没有值，有的话一定要将对应值得cacheline标记为无效，然后去读取最新值，这就引入了读内存屏障，强制标记队列中所有的值对应cacheline为无效<br></font> <p>上面的这个程序在实际开发中也是有可能会遇到的，于是 CPU提供了write memory barrier 以及 read memory barrier，让软件有机会避免这个问题</p><h2 id="write-memory-barrier"><a href="#write-memory-barrier" class="headerlink" title="write memory barrier"></a>write memory barrier</h2><p>比如在上面的 foo 方法中，a 的赋值和 b 的赋值之间加上这个write memory barrier<br>会使得 CPU 在后续变量变更写入之前，把 Store Buffer 的变更写入 flush 到缓存；CPU 要么就等待 flush 完成后写入，要么就把后续的写入变更放到 Store Buffer 中，直到 Store Buffer 数据顺序刷到缓存。<br><strong>write memory barrier 确保之前在 store buffer 里的资料会先更新到 cache，然后才能写入 barrier 之后的资料到 cache。</strong></p><p>假设我们在 foo() 的 a=1 和 b=1 之间插一个 write memory barrier，过程变为</p><ol><li>write memory barrier 先设 store buffer 里的资料为 “marked” (即 a=1)</li><li>写入 b 的时候，因为发现 store buffer 里有 marked 的栏位，所以即使 b 已处于 Modified，仍需写入 b=1 到 store buffer，不过状态是 “unmarked”</li><li>待收到 a 的 invalidate ack 后，cache 中 a 的状态改为 Modified，然后先写入有 marked 栏位的值到 cache，再写入 unmarked 栏位的值到 cache。</li></ol><p>这样其它 CPU 就会依序看到 a、b 更新的值了</p><h2 id="read-memory-barrier"><a href="#read-memory-barrier" class="headerlink" title="read memory barrier"></a>read memory barrier</h2><p>还是以上面的例子说明，假设 CPU 1 的 cache 里 a 处于 Shared。 CPU 0 已更新 a、b 到它的 cache，CPU 1 的 invalidate queue 里有 “invalidate a”，但还没处理。<br>这时 CPU 1 依序读 b、a 的值，会从 CPU 0 的 cache 读到 b=1，然后从自己的 cache 读到 a=0 (因为还没 invalidate a)。和上面的写入情况本质一样的，invalidate queue破坏了缓存一致性<br>invalidate queue是最新的，但是 a 处于 Shared，所以会从cache中直接拿，拿得是0，不是最新的<br>所以即便在foo函数给a,b分别赋值中间加上写栅栏，还是不能完全保证得到的结果是我们想要的，其实这个时候，可以猜到需要在assert之前也就是读取a之前加上一个读栅栏read memory barrier<br>目的很明确确保先清空 invalidate queue 再继续读资料。<br>在 assert(a==1) 之前插入 read memory barrier，执行顺序变成这样:</p><ol><li>CPU 1 执行 read memory barrier 时会设 invalidate queue 里的资料为 “marked”</li><li>CPU 1 读 cache 里 a 的值时，发现 invalidate queue 里有标记 a，于是会先执行 invalidate a 再继续读 a 的值</li><li>执行 invalidate a 后，就不会读自己 cache 的值，而改从 CPU 0 的 cache 读到最新的值，达到「依序读 b、a 的值」的效果</li></ol><h2 id="第二个小案例"><a href="#第二个小案例" class="headerlink" title="第二个小案例"></a>第二个小案例</h2><p>再摘一句perfbook的话，说的有点意思</p><p><code>Since the standard synchronization primitives preserve the illusion of ordering, your path of least resistance is to stop reading this section and simply use these primitives.However, if you need to implement the synchronization primitives themselves, or if you are simply interested in understanding how memory ordering and memory barriers work, read on!</code></p><p>你也许面对CPU的这种out of order的行为有本能的抵抗，没有关系，放轻松，你的抵抗之路可以到此结束，只要你愿意使用各种同步原语来保护你程序中的共享资源，因为透过这些标准的同步原语，你看到的是一个顺序执行的世界。当然，这会引入一些小小的遗憾：你不知道底层到底是如何把“乱序”变成“有序”的。不过，实现同步原语的那些软件工程师没有这个豁免权，他们必须要深入理解memory order和memory barrier。此外，那些想要“打破沙锅问到底”以及想要“知其然知其所以然”的工程师也可以跟随我们继续。</p><p>再举一个例子，摘自 perfbook memory barrier（14.2章节）<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1</span> thread0(<span class="keyword">void</span>)</span><br><span class="line"><span class="number">2</span> &#123;</span><br><span class="line"><span class="number">3</span> A = <span class="number">1</span>;</span><br><span class="line"><span class="number">4</span> smp_wmb();</span><br><span class="line"><span class="number">5</span> B = <span class="number">1</span>;</span><br><span class="line"><span class="number">6</span> &#125;</span><br><span class="line"><span class="number">7</span></span><br><span class="line"><span class="number">8</span> thread1(<span class="keyword">void</span>)</span><br><span class="line"><span class="number">9</span> &#123;</span><br><span class="line"><span class="number">10</span> <span class="keyword">while</span> (B != <span class="number">1</span>)</span><br><span class="line"><span class="number">11</span> <span class="keyword">continue</span>;</span><br><span class="line"><span class="number">12</span> barrier();</span><br><span class="line"><span class="number">13</span> C = <span class="number">1</span>;</span><br><span class="line"><span class="number">14</span> &#125;</span><br><span class="line"><span class="number">15</span></span><br><span class="line"><span class="number">16</span> thread2(<span class="keyword">void</span>)</span><br><span class="line"><span class="number">17</span> &#123;</span><br><span class="line"><span class="number">18</span> <span class="keyword">while</span> (C != <span class="number">1</span>)</span><br><span class="line"><span class="number">19</span> <span class="keyword">continue</span>;</span><br><span class="line"><span class="number">20</span> barrier();</span><br><span class="line"><span class="number">21</span> <span class="keyword">assert</span>(A != <span class="number">0</span>);</span><br><span class="line"><span class="number">22</span> &#125;</span><br></pre></td></tr></table></figure></p><p>开始，变量A，B，C的初始值都是0。根据程序逻辑：thread0中，A先于B赋值，thread1中，程序逻辑是一直等到B变量被赋值为1之后，再给C赋值。这里，人类的直觉告诉我们，如果变量C已经被赋值为1的时候（第13行程序），A一定已经被赋值为1了。同样的，在thread2中，第21行程序的assert一定是不会被触发的。</p><p><code>This line of reasoning, intuitively obvious though it may be, is completely and utterly incorrect. Please note that this is not a theoretical assertion: actually running this code on real-world weakly-ordered hardware (a 1.5GHz 16-CPU POWER 5 system) resulted in the assertion firing 16 times out of 10 million runs. Clearly, anyone who produces code with explicit memory barriers should do some extreme testing – although a proof of correctness might be helpful, the strongly counter-intuitive nature of the behavior of memory barriers should in turn strongly limit one’s trust in such proofs. The requirement for extreme testing should not be taken lightly, given that a number of dirty hardware-dependent tricks were used to greatly increase the probability of failure in this run.</code></p><p>上一节的推理从直觉上看是对的，但是在实际的CPU上运行的结果确是完全错误的。特别需要指出的是这个结果不是理论推导得出来的，是在真实的1.5GHz 16核的POWER 5系统（该cpu的内存模型属于weakly order）上观测得到的，平均每1千万次执行会有16次在21行代码处出现assert失败。很显然，当我们撰写显式调用memory barrier的代码的时候，必须进行非常大量的实际测试。在理论上进行正确性的推导是否有意义呢？也许有帮助，但是，你知道的，在使用memory barrier的时候会发生很多和你的直觉相悖的东西，这让理论的推导变得不那么确定。别小看那些看起来愚蠢的、非常重复性的大量测试，要知道不同的CPU会使用不同的硬件设计方法，因此在memory order和memory barrier方面表现各不相同，你的程序想要在各种硬件上，每次都运行成功不是一件容易的事情。</p><font color="red"><br>个人理解:<br>到底发生了什么让程序在21行的assert上失败？我们一起分析一下。我们假设CPU0、CPU1和CPU2分别执行thread0、thread1和thread2<br>1. 对于thread 0，我们假设A在CPU0的local cache中，但是状态是shared，因此当执行A=1的语句的时候，不能立刻执行，需要和其他CPU cache进行沟通（发送invalidate message去其他CPU），当然，cpu不会停下其脚步，将A的新值1放入store buffer，继续执行。<br>2. smp_wmb可以mark store buffer中A值，并且阻止后续的store操作进入cache，这时候，即便B在CPU0的local cache中，B=1的赋值也不能操作到cache，而是要进入store buffer，当然状态是unmarked。前面说过，后面进cache的话是marked先进然后unmarked进，由于存在Invalidate Queue这中东西，因此，CPU 0很快就可以收到来自其他CPU的响应，这时候，CPU0可以越过write memory barrier，完成对B的赋值。此时A的状态切到M，回写到cache中，B也跟着回写到cache中了。<br>3. 因此，对于thread1，很快可以感知B的新值“1”并执行了对C变量的赋值。来到thread2，同样的，对C变量的load操作也可以感知到thread1中的赋值因此跳出while循环。<br>4. 最关键的来了，第20行的barrier这个优化屏障不能阻止CPU对A变量的访问，但是，可能由于这时CPU cache操作非常繁忙，A变量的invalidate message还在其invalidate queue中，因此load A得到了旧的值0。<br><br>当然，要修正这个问题非常简单，修改20行代码为smp_rmb即可。一旦执行了smp_rmb，就会mark invalidate queue中的entry，这时候，CPU执行后续的load操作都必须要等到Invalidate queue中的所有缓存的invalidate message（当然，状态必须是marked）被处理并体现到cache中。因此，使用smp_rmb即可以在21行的load A操作中总是获取A的新值“1”从而避免了assert fail。<br>这里有个疑问就是例子中的barrier();这玩意到底到底代表啥意思，按照作者想要表达的意思是barrier()起不到读屏障的功能，要改为smp_rmb<br></font> <h2 id="简要归纳"><a href="#简要归纳" class="headerlink" title="简要归纳"></a>简要归纳</h2><p>硬件为了减少读写 memory 而有 cache。有 cache 就要确保 cache 之间的资料一致 (同一时间同一位置只有一个值)。但确保 cache 资料完全一致容易让 CPU 闲置，于是有了 store buffer 和 invalidate queue 降少 CPU 闲置。代价是只保证 CPU 自己会读到自己写入的最新数据，但其它 CPU 不一定。<br><strong>为了让其它 CPU 有需要的时候也能读到最新的资料，针对 store buffer 和 invalidate queue 的副作用设计了 write/read memory barrier</strong><br>于是写程序的人在需要的时候可以用 memory barrier 确保关键的数据有依正确的顺序更新 (没保证更新的时间)。 CPU 在多数情况下仍能避免闲置。<br>到此可以了解为什么这两种操作合在一起比较符合 CPU 架构：</p><ul><li>一个 thread 「先 write X 后执行 write memory barrier」</li><li>另一个 thread 「先执行 read memory barrier 后 read X」</li></ul><h1 id="java内存模型"><a href="#java内存模型" class="headerlink" title="java内存模型"></a>java内存模型</h1><p>这里再谈一下java的内存模型，这个模型是抽象出来的，下面这个图网上找的也是老演员了，最初来自深入理解虚拟机一书<br><img src="http://blog.lihaizhou.top/MemBarrier/memory-barrier07.png" alt=""></p><font color="red"><br>个人理解:<br>这里的java线程对应着cpu，工作内存其实是不存在的，可以简单的理解为是cpu的cache，save和load其实对应的是缓存一致性协议<br></font> <h2 id="JVM-barrier"><a href="#JVM-barrier" class="headerlink" title="JVM barrier"></a>JVM barrier</h2><ul><li>LoadLoad：两个 Load 操作之间内存屏障，smp_rmb 就是典型实现；</li><li>StoreStore：两个Store 操作之间的内存屏障，smp_wmb 典型实现；</li><li>LoadStore：在 Load 操作和 Store 操作之间的内存屏障；</li><li>StoreLoad：在 Store 操作和  Load 操作之间的内存屏障</li></ul><font color="red"><br>个人理解添加<br>以StoreLoad为例，这个是上面四个中最重的，最耗性能的，storeload其实能涵盖上面三个，因为它既保证了写也保证了读，它和loadstore的侧重点不一样，loadstore对于后面的那个写什么时候能写进去不是非常要求，更侧重的是前面的写。前一个是写后一个是读，后一个读取不能重排到这个写操作之前，也就是load时要看到前面写的值，这也就要保证前一个写的内容如果在storebuffer中就一定要写到cache中.<br>然后load的时候不能直接去读cache的值，要将invalidqueue中的值处理掉，该标记无效的都要进行标记，确保读取出来的是最新的。<br></font>   <p>对于java中的volatile防止重排网上博客一大堆，有些文章从汇编角度来分析加了volatile前后的对比，本地测试过hsdis可以用来将java转换为对应的汇编，这里就不展开了     </p><p><font color="red"> 个人理解<br>volatile最重要的使命是为了可见性，为了达到可见性这个目的不得不设计出防止指令重排，因为如果不限制重排，就达不到可见性这个目的<br>所以可以理解防止重排只是达到可见性的一个不得已手段<br></font><br><br>   </p><p><strong>参考文章</strong><br><a href="https://www.infoq.com/articles/memory_barriers_jvm_concurrency/" target="_blank" rel="noopener">Memory Barriers and JVM Concurrency</a><br><a href="http://www.wowotech.net/kernel_synchronization/memory-barrier.html" target="_blank" rel="noopener">Linux内核同步机制之（三）：memory barrier</a><br><a href="https://medium.com/fcamels-notes/%E5%BE%9E%E7%A1%AC%E9%AB%94%E8%A7%80%E9%BB%9E%E4%BA%86%E8%A7%A3-memry-barrier-%E7%9A%84%E5%AF%A6%E4%BD%9C%E5%92%8C%E6%95%88%E6%9E%9C-416ff0a64fc1" target="_blank" rel="noopener">從硬體觀點了解 memory barrier 的實作和效果</a><br><a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2015/p0098r0.pdf" target="_blank" rel="noopener">P0098R0: Towards Implementation and Use ofmemoryorderconsume</a><br><a href="https://createpoint.qti.qualcomm.com/search/contentdocument/stream/35553?refererRoute=search%2FsearchArgs%2Fq%7C%7CMemory%20Barriers%7C%7Crows%7C%7C10%7C%7CsortField%7C%7Cscore%7C%7CsortOrder%7C%7Cdesc&amp;dcn=80-N5603-1&amp;currentPage=1&amp;itemTotalIndex=1" target="_blank" rel="noopener">LINUX MEMORY ORDERING ON SCORPION-MP AND KRAIT APPLICATION PROCESSORS</a><br><a href="https://preshing.com/20120710/memory-barriers-are-like-source-control-operations/" target="_blank" rel="noopener">Memory Barriers Are Like Source Control Operations</a><br><a href="https://mp.weixin.qq.com/s?__biz=MzUzMDk3NjM3Mg==&amp;mid=2247483755&amp;idx=1&amp;sn=50f80e73f46fab04d8a799e8731432c6&amp;chksm=fa48da70cd3f5366d9658277cccd9e36fca540276f580822d41aef7d8af4dda480fc85e3bde4&amp;token=630636109&amp;lang=zh_CN#rd" target="_blank" rel="noopener">从 Java 内存模型看内部细节</a><br><a href="http://www.4e00.com/blog/java/2018/10/21/inside-java-memory-model.html" target="_blank" rel="noopener">深入理解 java 内存模型</a><br><a href="http://www.wowotech.net/memory_management/458.html" target="_blank" rel="noopener">浅谈Cache Memory</a><br><a href="http://www.wowotech.net/kernel_synchronization/Why-Memory-Barriers.html" target="_blank" rel="noopener">Why Memory Barriers</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;本篇文章开始之前需要了解一些背景知识&lt;/p&gt;
&lt;h1 id=&quot;Cache-Memory&quot;&gt;&lt;a href=&quot;#Cache-Memory&quot; class=&quot;headerlink&quot; title=&quot;Cache Memory&quot;&gt;&lt;/a&gt;Cache Memory&lt;/h1&gt;&lt;p&gt;我们都知
      
    
    </summary>
    
      <category term="Linux" scheme="http://lihaizhou.top/categories/Linux/"/>
    
    
  </entry>
  
  <entry>
    <title>mmap机制初探</title>
    <link href="http://lihaizhou.top/2020/05/25/mmap%E6%9C%BA%E5%88%B6%E5%88%9D%E6%8E%A2/"/>
    <id>http://lihaizhou.top/2020/05/25/mmap机制初探/</id>
    <published>2020-05-25T11:18:16.000Z</published>
    <updated>2020-06-02T03:37:05.000Z</updated>
    
    <content type="html"><![CDATA[<p>在Unix/Linux系统下读写文件，一般有两种方式</p><p><code>第一种方式：传统的read/write方式</code></p><p>常规文件系统操作的调用过程：</p><ul><li><p>进程发起读文件请求</p></li><li><p>内核通过查找进程文件符表，定位到内核已打开文件集上的文件信息，从而找到此文件的inode</p></li><li><p>inode在address_space上查找要请求的文件页是否已经缓存在页缓存中。如果存在，则直接返回这片文件页的内容。</p></li><li><p>如果不存在，则通过inode定位到文件磁盘地址，将数据从磁盘复制到页缓存。之后再次发起读页面过程，进而将页缓存中的数据发给用户进程。</p></li></ul><p>总结来说，常规文件操作为了提高读写效率和保护磁盘，使用了页缓存机制。这样造成读文件时需要先将文件页从磁盘拷贝到页缓存中，由于页缓存处在内核空间，不能被用户进程直接寻址，所以还需要将页缓存中数据页再次拷贝到内存对应的用户空间中。这样，通过了两次数据拷贝过程，才能完成进程对文件内容的获取任务。写操作也是一样，待写入的buffer在内核空间不能直接访问，必须要先拷贝至内核空间对应的主存，再写回磁盘中（延迟写回），也是需要两次数据拷贝。</p><p>当存在多个进程同时读取同一个文件时，每一个进程中的地址空间都会保存一份副本，这样肯定不是最优方式的，造成了物理内存的浪费</p><p><code>第二种方式：内存映射</code></p><p>具体操作方式是：<br>open一个文件，然后调用mmap系统调用，将文件的内容的全部或一部分直接映射到进程的地址空间，映射完成后，进程可以像访问普通内存一样做其他的操作，比如memcpy等等。</p><p>mmap并不分配物理地址空间，它只是占有进程的虚拟地址空间。这跟第一种方式不一样的，第一种方式需要预先分配好物理内存，内核才能将页高速缓冲中的文件数据拷贝到用户进程指定的内存空间中。</p><p>而第二种方式，当多个进程需要同时访问同一个文件时，每个进程都将文件所存储的内核高速缓冲映射到自己的进程地址空间。当第一个进程访问内核中的缓冲区时候，前面讲过并没有实际拷贝数据，这时MMU在地址映射表中是无法找到与地址空间相对应的物理地址的，也就是MMU失败，就会触发缺页中断。内核将文件的这一页数据读入到内核高速缓冲区中，并更新进程的页表，使页表指向内核缓冲中的这一页。之后有其他的进程再次访问这一页的时候，该页已经在内存中了，内核只需要将进程的页表登记并且指向内核的页高速缓冲区即可</p><p><img src="https://raw.githubusercontent.com/hellolihaizhou/saveImg/master/mmap-1-1.jpg" alt=""></p><p>异步IO<br><img src="https://raw.githubusercontent.com/hellolihaizhou/saveImg/master/mmap-1-2.jpg" alt=""></p><p>mmap内存映射具体流程如下：</p><p>1、用户进程调用内存映射函数库mmap，当前进程在虚拟地址空间中，寻找一段空闲的满足要求的虚拟地址。</p><p>2、此时内核收到相关请求后会调用内核的mmap函数，注意，不同于用户空间库函数。内核mmap函数通过虚拟文件系统定位到文件磁盘物理地址，既实现了文件地址和虚拟地址区域的映射关系。 此时，这片虚拟地址并没有任何数据关联到主存中。</p><p>注意，前两个阶段仅在于创建虚拟区间并完成地址映射，但是并没有将任何文件数据的拷贝至主存。真正的文件读取是当进程发起读或写操作时。</p><p>3、进程的读或写操作访问虚拟地址空间这一段映射地址，现这一段地址并不在物理页面上。因为目前只建立了地址映射，真正的硬盘数据还没有拷贝到内存中，因此引发缺页中断。</p><p>4、由于引发了缺页中断，内核则调用nopage函数把所缺的页从磁盘装入到主存中。</p><p>5、之后用户进程即可对这片主存进行读或者写的操作，如果写操作改变了其内容，一定时间后系统会自动回写脏页面到对应磁盘地址，也即完成了写入到文件的过程。</p><p>注意：这里拷贝磁盘内容到主存，这里的主存是指处于内核空间的Page Cache，而不是用户空间的内存。用户地址要访问内核空间中的数据，需使用MMU把虚拟地址映射到内核的内存地址中，即可对数据进行操作。整个mmap工作流程大体如下：</p><p><img src="https://raw.githubusercontent.com/hellolihaizhou/saveImg/master/mmap-2.png" alt=""></p><p>这里我们可以看出mmap系统调用与read/write调用的区别在于：</p><p>mmap只需要一次系统调用（一次拷贝），后续操作不需要系统调用。访问的数据不需要在page cache和用户缓冲区之间拷贝。 访问的数据不需要在page cache和用户缓冲区之间拷贝。<br>从上所述，当频繁对一个文件进行读取操作时，mmap会比read/write更高效</p><p>既然建立内存映射没有进行实际的数据拷贝，那么进程又怎么能最终直接通过内存操作访问到硬盘上的文件呢？那就要看内存映射之后的几个相关的过程了。</p><p>mmap()会返回一个指针ptr，它指向进程逻辑地址空间中的一个地址，这样以后，进程无需再调用read或write对文件进行读写，而只需要通过ptr就能够操作文件。但是ptr所指向的是一个逻辑地址，要操作其中的数据，必须通过MMU将逻辑地址转换成物理地址，这个过程与内存映射无关。 </p><p>前面讲过，建立内存映射并没有实际拷贝数据，这时，MMU在地址映射表中是无法找到与ptr相对应的物理地址的，也就是MMU失败，将产生一个缺页中断，缺页中断的中断响应函数会在swap中寻找相对应的页面，如果找不到（也就是该文件从来没有被读入内存的情况），则会通过mmap()建立的映射关系，从硬盘上将文件读取到物理内存中，这个过程与内存映射无关。</p><p>如果在拷贝数据时，发现物理内存不够用，则会通过虚拟内存机制（swap）将暂时不用的物理页面交换到硬盘上，这个过程也与内存映射无关。</p><p>使用mmap操作文件中，创建新的虚拟内存区域和建立文件磁盘地址和虚拟内存区域映射这两步，没有任何文件拷贝操作。而之后访问数据时发现内存中并无数据而发起的缺页异常过程，可以通过已经建立好的映射关系，只使用一次数据拷贝，就从磁盘中将数据传入内存的用户空间中，供进程使用。</p><p>总而言之，常规文件操作需要从磁盘到页缓存再到用户主存的两次数据拷贝。而mmap操控文件，只需要从磁盘到用户主存的一次数据拷贝过程。说白了，mmap的关键点是实现了用户空间和内核空间的数据直接交互而省去了空间不同数据不通的繁琐过程。因此mmap效率更高</p><p>mmap使用过程中的几个细节点：</p><p>细节点一： mmap映射区域大小必须是物理页大小(page_size)的整倍数（在Linux中内存页通常是4k）。原因是，内存的最小粒度是页，而进程虚拟地址空间和内存的映射也是以页为单位。为了匹配内存的操作，mmap从磁盘到虚拟地址空间的映射也必须是页。</p><p>例如，有一个文件的大小是5K，mmap函数从文件的起始位置映射5K到虚拟内存中，由于内存物理页是4K，虽然映射的文件只有5K，但是实际上映射到内存区域的内存是8K，以便满足物理页大小的整数倍。映射后对5~8K的内存区域用零填充，对这部分的操作不会报错也不会写入到原文件中。</p><p>细节点二 ： 映射建立之后，即使文件关闭，映射依然存在。因为映射的是磁盘的地址，不是文件本身，和文件句柄无关。同时可用于进程间通信的有效地址空间不完全受限于被映射文件的大小，因为是按页映射。</p><p>平时会遇到应用OOM的问题，日志中有时候会有如下内容<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">07</span>-<span class="number">03</span> <span class="number">17</span>:<span class="number">43</span>:<span class="number">55.266</span> <span class="number">10181</span>  <span class="number">4737</span>  <span class="number">6529</span> E filemap : mmap(<span class="number">6078464</span>,<span class="number">299753</span>) failed: Out of memory</span><br></pre></td></tr></table></figure></p><p>对应的Code</p><p>system/core/libutils/FileMap.cpp</p><p>这里谷歌在2020.5.7号有修改，之前是调用的mmap，mmap中继而调用mmap64</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">void</span>* ptr = mmap64(nullptr, adjLength, prot, flags, fd, adjOffset);</span><br><span class="line"><span class="keyword">if</span> (ptr == MAP_FAILED) &#123;</span><br><span class="line">    <span class="keyword">if</span> (errno == EINVAL &amp;&amp; length == <span class="number">0</span>) &#123;</span><br><span class="line">        ptr = nullptr;</span><br><span class="line">        adjust = <span class="number">0</span>;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        ALOGE(<span class="string">"mmap(%lld,%zu) failed: %s\n"</span>, (<span class="keyword">long</span> <span class="keyword">long</span>)adjOffset, adjLength, strerror(errno));</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>bionic/libc/bionic/mmap.cpp</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">void</span>* mmap64(<span class="keyword">void</span>* addr, size_t size, <span class="keyword">int</span> prot, <span class="keyword">int</span> flags, <span class="keyword">int</span> fd, off64_t offset) &#123;</span><br><span class="line">  <span class="keyword">if</span> (offset &lt; <span class="number">0</span> || (offset &amp; ((<span class="number">1</span>UL &lt;&lt; MMAP2_SHIFT)-<span class="number">1</span>)) != <span class="number">0</span>) &#123;</span><br><span class="line">    errno = EINVAL;</span><br><span class="line">    <span class="keyword">return</span> MAP_FAILED;</span><br><span class="line">  &#125;</span><br><span class="line"> </span><br><span class="line">  <span class="comment">// prevent allocations large enough for `end - start` to overflow</span></span><br><span class="line">  size_t rounded = __BIONIC_ALIGN(size, PAGE_SIZE);</span><br><span class="line">  <span class="keyword">if</span> (rounded &lt; size || rounded &gt; PTRDIFF_MAX) &#123;</span><br><span class="line">    errno = ENOMEM;</span><br><span class="line">    <span class="keyword">return</span> MAP_FAILED;</span><br><span class="line">  &#125;</span><br><span class="line"> </span><br><span class="line">  bool is_private_anonymous =</span><br><span class="line">      (flags &amp; (MAP_PRIVATE | MAP_ANONYMOUS)) == (MAP_PRIVATE | MAP_ANONYMOUS);</span><br><span class="line">  bool is_stack_or_grows_down = (flags &amp; (MAP_STACK | MAP_GROWSDOWN)) != <span class="number">0</span>;</span><br><span class="line">  <span class="keyword">void</span>* result = __mmap2(addr, size, prot, flags, fd, offset &gt;&gt; MMAP2_SHIFT);</span><br><span class="line"> </span><br><span class="line">  <span class="keyword">if</span> (result != MAP_FAILED &amp;&amp; kernel_has_MADV_MERGEABLE &amp;&amp;</span><br><span class="line">      is_private_anonymous &amp;&amp; !is_stack_or_grows_down) &#123;</span><br><span class="line">    ErrnoRestorer errno_restorer;</span><br><span class="line">    <span class="keyword">int</span> rc = madvise(result, size, MADV_MERGEABLE);</span><br><span class="line">    <span class="keyword">if</span> (rc == -<span class="number">1</span> &amp;&amp; errno == EINVAL) &#123;</span><br><span class="line">      kernel_has_MADV_MERGEABLE = <span class="keyword">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> result;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>mmap常见的错误类型：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">EACCES：访问出错</span><br><span class="line">EAGAIN：文件已被锁定，或者太多的内存已被锁定</span><br><span class="line">EBADF：fd不是有效的文件描述词</span><br><span class="line">EINVAL：一个或者多个参数无效 这里的参数常指的是start len offset 但是按照unlinx高级环境编程中描述，start一般会被命名为<span class="keyword">null</span>的空指针，这样告诉内核自己去选择起始地址，offset一般情况下设置为；那么出现这个问题通常就是len出错了，那么可以用printf大法来找到具体的错误。</span><br><span class="line">ENFILE：已达到系统对打开文件的限制</span><br><span class="line">ENODEV：指定文件所在的文件系统不支持内存映射</span><br><span class="line">ENOMEM：内存不足，或者进程已超出最大内存映射数量</span><br><span class="line">EPERM：权能不足，操作不允许</span><br><span class="line">ETXTBSY：已写的方式打开文件，同时指定MAP_DENYWRITE标志</span><br><span class="line">SIGSEGV：试着向只读区写入</span><br><span class="line">SIGBUS：试着访问不属于进程的内存区</span><br></pre></td></tr></table></figure><p><strong>mmap优点总结</strong></p><p>由上文讨论可知，mmap优点共有一下几点：</p><p>1、对文件的读取操作跨过了页缓存，减少了数据的拷贝次数，用内存读写取代I/O读写，提高了文件读取效率。</p><p>2、实现了用户空间和内核空间的高效交互方式, 两空间的各自修改操作可以直接反映在映射的区域内，从而被对方空间及时捕捉。</p><p>3、提供进程间共享内存及相互通信的方式。不管是父子进程还是无亲缘关系的进程，都可以将自身用户空间映射到同一个文件或匿名映射到同一片区域。从而通过各自对映射区域的改动，达到进程间通信和进程间共享的目的。</p><pre><code>同时，如果进程A和进程B都映射了区域C，当A第一次读取C时通过缺页从磁盘复制文件页到内存中；但当B再读C的相同页面时，虽然也会产生缺页异常，但是不再需要从磁盘中复制文件过来，而可直接使用已经保存在内存中的文件数据。</code></pre><p>4、可用于实现高效的大规模数据传输。内存空间不足，是制约大数据操作的一个方面，解决方案往往是借助硬盘空间协助操作，补充内存的不足。但是进一步会造成大量的文件I/O操作，极大影响效率。这个问题可以通过mmap映射很好的解决。换句话说，但凡是需要用磁盘空间代替内  存的时候，mmap都可以发挥其功效</p><p><strong>mmap使用细节</strong><br>1、使用mmap需要注意的一个关键点是mmap映射区域大小必须是物理页大小(page_size)的整倍数（32位系统中通常是4k字节）。原因是内存的最小粒度是页，而进程虚拟地址空间和内存的映射也是以页为单位。为了匹配内存的操作，mmap从磁盘到虚拟地址空间的映射也必须是页。</p><p>2、内核可以跟踪被内存映射的底层对象（文件）的大小，进程可以合法的访问在当前文件大小以内又在内存映射区以内的那些字节。也就是说，如果文件的大小一直在扩张，只要在映射区域范围内的数据，进程都可以合法得到，这和映射建立时文件的大小无关。</p><p>3、映射建立之后，即使文件关闭，映射依然存在。因为映射的是磁盘的地址，不是文件本身，和文件句柄无关。同时可用于进程间通信的有效地址空间不完全受限于被映射文件的大小，因为是按页映射。</p><p>在上面的知识前提下，我们下面看看如果大小不是页的整倍数的具体情况：</p><p>情形一：一个文件的大小是5000字节，mmap函数从一个文件的起始位置开始，映射5000字节到虚拟内存中。</p><p>分析：因为单位物理页面的大小是4096字节，虽然被映射的文件只有5000字节，但是对应到进程虚拟地址区域的大小需要满足整页大小，因此mmap函数执行后，实际映射到虚拟内存区域8192个 字节，5000~8191的字节部分用零填充。映射后的对应关系如下图所示：</p><p><img src="https://raw.githubusercontent.com/hellolihaizhou/saveImg/master/mmap-3.png" alt=""></p><p>此时：</p><p>（1）读/写前5000个字节（0~4999），会返回操作文件内容。</p><p>（2）读字节5000~8191时，结果全为0。写5000~8191时，进程不会报错，但是所写的内容不会写入原文件中 。</p><p>（3）读/写8192以外的磁盘部分，会返回一个SIGSECV错误。</p><p>情形二：一个文件的大小是5000字节，mmap函数从一个文件的起始位置开始，映射15000字节到虚拟内存中，即映射大小超过了原始文件的大小。</p><p>分析：由于文件的大小是5000字节，和情形一一样，其对应的两个物理页。那么这两个物理页都是合法可以读写的，只是超出5000的部分不会体现在原文件中。由于程序要求映射15000字节，而文件只占两个物理页，因此8192字节~15000字节都不能读写，操作时会返回异常。如下图所示：</p><p><img src="https://raw.githubusercontent.com/hellolihaizhou/saveImg/master/mmap-4.png" alt=""></p><p>此时：</p><p>（1）进程可以正常读/写被映射的前5000字节(0~4999)，写操作的改动会在一定时间后反映在原文件中。</p><p>（2）对于5000~8191字节，进程可以进行读写过程，不会报错。但是内容在写入前均为0，另外，写入后不会反映在文件中。</p><p>（3）对于8192~14999字节，进程不能对其进行读写，会报SIGBUS错误。</p><p>（4）对于15000以外的字节，进程不能对其读写，会引发SIGSEGV错误。</p><p>情形三：一个文件初始大小为0，使用mmap操作映射了1000*4K的大小，即1000个物理页大约4M字节空间，mmap返回指针ptr。</p><p>分析：如果在映射建立之初，就对文件进行读写操作，由于文件大小为0，并没有合法的物理页对应，如同情形二一样，会返回SIGBUS错误。</p><p>但是如果，每次操作ptr读写前，先增加文件的大小，那么ptr在文件大小内部的操作就是合法的。例如，文件扩充4096字节，ptr就能操作ptr ~ [ (char)ptr + 4095]的空间。只要文件扩充的范围在1000个物理页（映射范围）内，ptr都可以对应操作相同的大小。</p><p>这样，方便随时扩充文件空间，随时写入文件，不造成空间浪费</p><p>Binder进程间通信用到的mmap</p><p>Linux 下的传统 IPC 通信原理<br>传统的 IPC 方式中，进程之间是如何实现通信的。<br>通常的做法是消息发送方将要发送的数据存放在内存缓存区中，通过系统调用进入内核态。然后内核程序在内核空间分配内存，开辟一块内核缓存区，调用 copyfromuser() 函数将数据从用户空间的内存缓存区拷贝到内核空间的内核缓存区中。同样的，接收方进程在接收数据时在自己的用户空间开辟一块内存缓存区，然后内核程序调用 copytouser() 函数将数据从内核缓存区拷贝到接收进程的内存缓存区。这样数据发送方进程和数据接收方进程就完成了一次数据传输，我们称完成了一次进程间通信</p><p><img src="https://raw.githubusercontent.com/hellolihaizhou/saveImg/master/mmap-5.jpeg" alt=""></p><p>这种传统的 IPC 通信方式有两个问题：</p><pre><code>1.性能低下，一次数据传递需要经历：内存缓存区 --&gt; 内核缓存区 --&gt; 内存缓存区，需要 2 次数据拷贝；2.接收数据的缓存区由数据接收进程提供，但是接收进程并不知道需要多大的空间来存放将要传递过来的数据，因此只能开辟尽可能大的内存空间或者先调用 API 接收消息头来获取消息体的大小，这两种做法不是浪费空间就是浪费时间</code></pre><p>Binder采用一种全新策略：由Binder驱动负责管理数据接收缓存。我们注意到Binder驱动实现了mmap()系统调用，这对字符设备是比较特殊的，因为mmap()通常用在有物理存储介质的文件系统上，而象Binder这样没有物理介质，纯粹用来通信的字符设备没必要支持mmap()。Binder驱动当然不是为了在物理介质和用户空间做映射，而是用来创建数据接收的缓存空间。先看mmap()是如何使用的：<br>fd = open(“/dev/binder”, O_RDWR);<br>mmap(NULL, MAP_SIZE, PROT_READ, MAP_PRIVATE, fd, 0);<br>这样Binder的接收方就有了一片大小为MAP_SIZE的接收缓存区。mmap()的返回值是内存映射在用户空间的地址，不过这段空间是由驱动管理，用户不必也不能直接访问（映射类型为PROT_READ，只读映射）</p><p>一次完整的 Binder IPC 通信过程通常是这样：</p><p>1.Server端在启动之后，调用对/dev/binder设备调用mmap<br>2.内核中的binder_mmap函数进行对应的处理：申请一块物理内存，然后在Server端的用户空间和内核空间同时进行映射。内核中的binder_mmap函数进行对应的处理：申请一块物理内存，然后在Server端的用户空间和内核空间同时进行映射<br>3.Client发送请求，这个请求将先到驱动中，同时需要将数据从Client进程的用户空间拷贝（Client发送请求，这个请求将先到驱动中，同时需要将数据从Client进程的用户空间拷贝（copy_from_user）到内核空间<br>4.驱动通过请求通知Server端有人发出请求，Server进行处理。由于内核空间和Server端进程的用户空间存在内存映射，因此Server进程的代码可以直接访问。这样便完成了一次进程间的通信</p><p><img src="https://raw.githubusercontent.com/hellolihaizhou/saveImg/master/mmap-6.png" alt=""></p><p>而使用mmap操作文件中，创建新的虚拟内存区域和建立文件磁盘地址和虚拟内存区域映射这两步，没有任何文件拷贝操作。而之后访问数据时发现内存中并无数据而发起的缺页异常过程，可以通过已经建立好的映射关系，只使用一次数据拷贝，就从磁盘中将数据传入内存的用户空间中，供进程使用。</p><p>总而言之，常规文件操作需要从磁盘到页缓存再到用户主存的两次数据拷贝。而mmap操控文件，只需要从磁盘到用户主存的一次数据拷贝过程。说白了，mmap的关键点是实现了用户空间和内核空间的数据直接交互而省去了空间不同数据不通的繁琐过程。因此mmap效率更高</p><p>通过上面介绍可以看到，驱动为接收方分担了最为繁琐的任务：分配/释放大小不等，难以预测的有效负荷缓存区，而接收方只需要提供缓存来存放大小固定，最大空间可以预测的消息头即可。在效率上，由于mmap()分配的内存是映射在接收方用户空间里的，所有总体效果就相当于对有效负荷数据做了一次从发送方用户空间到接收方用户空间的直接数据拷贝，省去了内核中暂存这个步骤，提升了一倍的性能。顺便再提一点，Linux内核实际上没有从一个用户空间到另一个用户空间直接拷贝的函数，需要先用copy_from_user()拷贝到内核空间，再用copy_to_user()拷贝到另一个用户空间。为了实现用户空间到用户空间的拷贝，mmap()分配的内存除了映射进了接收方进程里，还映射进了内核空间。所以调用copy_from_user()将数据拷贝进内核空间也相当于拷贝进了接收方的用户空间，这就是Binder只需一次拷贝的‘秘密’</p><p>Binder 并不存在物理介质，因此 Binder 驱动使用 mmap() 并不是为了在物理介质和用户空间之间建立映射，而是用来在内核空间创建数据接收的缓存空间。</p><p>一次完整的 Binder IPC 通信过程通常是这样：</p><pre><code>首先 Binder 驱动在内核空间创建一个数据接收缓存区；接着在内核空间开辟一块内核缓存区，建立内核缓存区和内核中数据接收缓存区之间的映射关系，以及内核中数据接收缓存区和接收进程用户空间地址的映射关系；发送方进程通过系统调用 copyfromuser() 将数据 copy 到内核中的内核缓存区，由于内核缓存区和接收进程的用户空间存在内存映射，因此也就相当于把数据发送到了接收进程的用户空间，这样便完成了一次进程间的通信</code></pre><p><img src="https://raw.githubusercontent.com/hellolihaizhou/saveImg/master/mmap-7.jpeg" alt=""></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;在Unix/Linux系统下读写文件，一般有两种方式&lt;/p&gt;
&lt;p&gt;&lt;code&gt;第一种方式：传统的read/write方式&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;常规文件系统操作的调用过程：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;进程发起读文件请求&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;内核通
      
    
    </summary>
    
      <category term="Linux" scheme="http://lihaizhou.top/categories/Linux/"/>
    
    
  </entry>
  
</feed>
