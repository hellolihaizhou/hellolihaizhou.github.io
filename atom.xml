<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>李海洲</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://lihaizhou.top/"/>
  <updated>2021-11-27T04:27:12.249Z</updated>
  <id>http://lihaizhou.top/</id>
  
  <author>
    <name>Steven Lee</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>优化实践: 高刷下列表滑动出现卡顿掉帧</title>
    <link href="http://lihaizhou.top/2021/11/27/%E4%BC%98%E5%8C%96%E5%AE%9E%E8%B7%B5-%E9%AB%98%E5%88%B7%E4%B8%8B%E5%88%97%E8%A1%A8%E6%BB%91%E5%8A%A8%E5%87%BA%E7%8E%B0%E5%8D%A1%E9%A1%BF%E6%8E%89%E5%B8%A7/"/>
    <id>http://lihaizhou.top/2021/11/27/优化实践-高刷下列表滑动出现卡顿掉帧/</id>
    <published>2021-11-27T04:08:46.000Z</published>
    <updated>2021-11-27T04:27:12.249Z</updated>
    
    <content type="html"><![CDATA[<h4 id="问题背景"><a href="#问题背景" class="headerlink" title="问题背景"></a>问题背景</h4><p>近期我们的测试同事，上报了一些操作掉帧的问题，对比机选取的是同配置的荣耀x20。</p><p>以微信为例，如下是测试提供的测试报告</p><p><img src="http://blog.lihaizhou.top/%E9%AB%98%E5%88%B7%E4%B8%8B%E6%BB%91%E5%8A%A8%E5%8D%A1%E9%A1%BF/gaoshua_kadun1.png" alt="图片"></p><p>这份perfdog报告的操作步骤对应的是上下滑动微信列表，数据上看，测试机表现似乎比对比机逊色一些。</p><p>抱着怀疑的态度，打算实际对比体验下，于是在两台机器上安装同版本的微信，清理后台任务，并确保两台机器上的微信均已完成dex2oat且dex2oat模式一样。</p><p>实际对比测试下来的主观感受是: </p><p>在我们的测试机上，滑动松开手指后会概率性出现顿挫感，荣耀机器上滑动的fling阶段比较平滑，虽然偶尔也会有顿挫，对比体验上确实优于我们的测试机。</p><p>基于数据报告以及主观测试感受，说明我们的机器在部分场景操作上可能确实存在性能问题，于是笔者开始着手调查这个问题背后的原因。</p><h4 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h4><p>我们的测试机和对比机均支持120hz高刷，实测在滑动场景下，两者屏幕的刷新率均为120hz，意味着都是8.3ms刷新一次屏幕，滑动松开手指后的fling阶段，两者软件上均为120fps。</p><p>需要注意一点的是: </p><blockquote><p>120hz指的是屏幕这个硬件刷新画面的频率，是一个硬件的概念。而软件的120fps则是一个软件的概念，表示1秒内生产120帧。</p><p>一般而言，屏幕刷新率和软件的fps是对应的，比如60hz对应60fps，120hz对应120fps，只有这样用户体验才是最佳的，两者是通过Vsync 机制做到同步，如果屏的刷新率和软件不匹配的话，效果上势必会打折扣，还可能造成无端的功耗开销。</p><p>比如屏幕刷新率是 60 hz，软件是 120 fps，那么软件每秒绘制的120次有一半是没有显示就被抛弃了的。</p></blockquote><p>以我们这个案例来说，滑动微信列表松开手指后，此时屏的刷新率是120hz，系统为了适配这个120hz，会将Vsync的周期设置为8.3ms，意味着每隔 8.3 ms，Vsync-app 信号就会到来唤醒 Choreographer 来做 App 的绘制渲染操作。</p><p>App绘制渲染完成后，会将buffer给SurfaceFlinger对应的App所在的bufferQueue队列中，SurfaceFlinger同样需要等Vsync-sf信号，等到信号后SurfaceFlinger开始合成工作并最终送给屏显示，这个过程中如果有一个步骤耗时长了都有可能导致最终一帧花费时间超出8.3ms。</p><p>有了这些基础知识铺垫后，下面从系统全局来分析</p><p>先看下手指松开fling阶段的应用绘制片段</p><p><img src="http://blog.lihaizhou.top/%E9%AB%98%E5%88%B7%E4%B8%8B%E6%BB%91%E5%8A%A8%E5%8D%A1%E9%A1%BF/gaoshua_kadun2.png" alt="图片"></p><p>可以看到，在fling阶段，我们的测试机有很多黄帧，对比机上只有少数的几帧是黄色的</p><p>这里先解释下黄色帧的含义</p><blockquote><p>黄帧表示这一帧的耗时超过了1个 Vsync 周期，但是小于 2 个 Vsync 周期。</p><p>黄帧的出现表示这一帧可能存在性能问题，可能掉帧了，注意这里用了可能这个词，因为TripleBuffer机制，即便主线程这一帧超过一个Vsync周期，由于多buffer缓冲，这一帧不一定会掉帧，我们后面会单独成文介绍这块。</p><p>绿帧表示这一帧在规定时间内及时完成了，耗时不超过1个 Vsync 周期</p></blockquote><p>再看下Sf区域的情况</p><p><img src="http://blog.lihaizhou.top/%E9%AB%98%E5%88%B7%E4%B8%8B%E6%BB%91%E5%8A%A8%E5%8D%A1%E9%A1%BF/gaoshua_kadun3.png" alt="图片"></p><p>两者Vsync间隔都是8.3ms，对比机的Sf主线程在大部分时候，都能在Vsync-sf到来后的8.3ms内及时完成，画面上看有条不紊。</p><p>再看下我们的测试机情况，很容易发现由于单次处理比较耗时，出现了堆积延后的情况，这也导致了在屏幕上看到的画面不是很流畅的缘故。</p><p>通过对比应用fling阶段主线程区域，绘制区域，Sf区域，很快便发现了我们的测试机输在了CPU频率上</p><p><img src="http://blog.lihaizhou.top/%E9%AB%98%E5%88%B7%E4%B8%8B%E6%BB%91%E5%8A%A8%E5%8D%A1%E9%A1%BF/gaoshua_kadun4.png" alt="图片"></p><p>从上图可以看出，我们的测试机在应用主线程处理过程中，很多时候CPU频率会掉的很低。</p><p>比如图中圈出的红色位置，我们测试机在这一帧的应用主线程处理上耗时12ms，虽然是落在大核CPU6上，但是频率只有650Mkhz。</p><p>再看下竞品机的应用主线程处理阶段CPU情况，在手指触摸后，其频率迅速提升，并且在手指松开后的fling阶段，对比机仍然能够维持一两秒的CPU高频。</p><p>到这里，我们明白了差距在哪里，我们的测试机在手指松开后的fling阶段CPU落下来，而对比机能够在fling阶段维持高频。</p><h4 id="修改方案"><a href="#修改方案" class="headerlink" title="修改方案"></a>修改方案</h4><p>修改方案是当用户触摸屏幕后，即监测到有touch事件后，将大核和小核的CPU频率分别限制为不低于1.75Ghz和2.2Ghz(天花板分别为2G和2.4G)</p><p>并且boost持续时间限定为2s，这样的话可以避免一直处于高频带来的功耗问题</p><p><img src="http://blog.lihaizhou.top/%E9%AB%98%E5%88%B7%E4%B8%8B%E6%BB%91%E5%8A%A8%E5%8D%A1%E9%A1%BF/gaoshua_kadun5.png" alt="图片"></p><p>再次测试微信滑动列表的场景，可以看到修改后，处理堆积延后的现象消失</p><p>再看下应用区域的fling阶段</p><p><img src="http://blog.lihaizhou.top/%E9%AB%98%E5%88%B7%E4%B8%8B%E6%BB%91%E5%8A%A8%E5%8D%A1%E9%A1%BF/gaoshua_kadun6.png" alt="图片"></p><p>从图中可以看到修改后，fling阶段黄色帧大幅减少，基本达到了竞品机的表现</p><h4 id="写在最后"><a href="#写在最后" class="headerlink" title="写在最后"></a>写在最后</h4><p>120fps最大的挑战在于一帧的完成必须在8.3ms内完成，细化一点就是App 和 SurfaceFlinger 及其相关的进程端 (加上 crtc 和 hw service)花费的时间总和必须在 8.3ms 之内, 这就需要App侧和Sf侧都不能出现较长耗时，才可以保证不掉帧. </p><p>高刷下的掉帧原因可能有很多，就笔者遇到的场景有低内存下kswapd跑大核、同步GC、温升限频、IO、Vsync不均、GPU&amp;CPU性能不足等场景，当然最常见的场景还是应用自身绘制超时导致。</p><p>这个案例根因在于高刷场景下没有提供足够的CPU性能。</p><hr><p>2021.11.27 周六  午后  今天真的应该带个野餐垫去公园，而不是呆在公司</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;问题背景&quot;&gt;&lt;a href=&quot;#问题背景&quot; class=&quot;headerlink&quot; title=&quot;问题背景&quot;&gt;&lt;/a&gt;问题背景&lt;/h4&gt;&lt;p&gt;近期我们的测试同事，上报了一些操作掉帧的问题，对比机选取的是同配置的荣耀x20。&lt;/p&gt;
&lt;p&gt;以微信为例，如下是测试提供的
      
    
    </summary>
    
      <category term="性能" scheme="http://lihaizhou.top/categories/%E6%80%A7%E8%83%BD/"/>
    
    
  </entry>
  
  <entry>
    <title>优化实践:从系统层面优化应用启动速度</title>
    <link href="http://lihaizhou.top/2021/11/19/%E4%BC%98%E5%8C%96%E5%AE%9E%E8%B7%B5-%E4%BB%8E%E7%B3%BB%E7%BB%9F%E5%B1%82%E9%9D%A2%E4%BC%98%E5%8C%96%E5%BA%94%E7%94%A8%E5%90%AF%E5%8A%A8%E9%80%9F%E5%BA%A6/"/>
    <id>http://lihaizhou.top/2021/11/19/优化实践-从系统层面优化应用启动速度/</id>
    <published>2021-11-19T02:00:24.000Z</published>
    <updated>2021-11-19T06:26:58.357Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>应用的启动表现特别是冷启动的速度，是用户对App的第一印象。很多时候也会被评测机构用来测试一个手机性能的依据，所以对启动速度的优化一直以来是App和手机厂商发力的重点</p></blockquote><h4 id="故事背景"><a href="#故事背景" class="headerlink" title="故事背景"></a>故事背景</h4><p>最近，测试提了很多应用启动速度落后于竞品荣耀x20的问题单<br>以其中的支付宝为例, 如下是测试提供的支付宝冷启数据<br>(通过高速相机，以手指松开为起点，以首页内容加载出为结束点)<br><img style="margin: left;" src="http://blog.lihaizhou.top/startProcess/startProcess1.png"></p><p>从高速相机均值数据上，我们的机器上冷启支付宝比竞品机慢了29%，另外通过实测同时打开，直观感受上发现绝大部分时候确实慢于竞品机。<br>顺便说一句:<br><code>测试冷启速度最佳方式是通过高速相机，这种方式最贴近用户实际感受，其次便是通过Systrace，但是Systrace的结束帧的确定是个技术活(没有源码情况下)。</code></p><h4 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h4><p>本文将以支付宝为例进行讨论，对于支付宝这种体积的App，在启动过程中会起来上百个业务操作，但是其冷启耗时却能够控制在几百毫秒，我觉得已经是非常之优秀了。<br>其实这种头部App会有专门的性能团队进行优化，相信支付宝已经做了很多的优化工作。</p><p>本文将致力于回答如下两个问题</p><ol><li>同样的App版本，同样的配置，为何我们的机器启动速度会比竞品机慢？</li><li>如何优化提升我们机器上的应用启动速度？</li></ol><h4 id="大纲"><a href="#大纲" class="headerlink" title="大纲"></a>大纲</h4><ol><li>App和系统角度分别看启动速度优化</li><li>CPU提频</li><li>Dex2oat策略优化</li><li>抑制GC次数</li><li>IO优化</li><li>优化后实测数据</li><li>写在最后</li><li>参考文献</li></ol><h4 id="App-amp-系统角度看启动速度优化"><a href="#App-amp-系统角度看启动速度优化" class="headerlink" title="App&amp;系统角度看启动速度优化"></a>App&amp;系统角度看启动速度优化</h4><h5 id="应用角度看启动优化"><a href="#应用角度看启动优化" class="headerlink" title="应用角度看启动优化"></a>应用角度看启动优化</h5><p>对于应用启动优化手段比较常规，主要有如下几种:</p><ol><li>启动页主题之类的替换，达到视觉上的速度加快，并非真的快了。</li><li>初始化的生命周期内一些繁重业务或者库加载尽可能的延迟加载，异步加载，用的时候再加载。</li><li>布局上的优化，尽可能降低布局的复杂度，在需要用的时再加载</li><li>主动dex2oat，需要注意的是在Android10+上谷歌限制了应用进程主动dex2oat，但是其实还是有办法触发，只是实现上会稍微麻烦一点，这里不展开讨论。</li></ol><p>这些常规的优化步骤是最基础的，但是实际优化起来并不一定容易，特别是一些庞大的团队合作App。<br>之前在小米做过启动优化的工作，由于项目业务代码实在太繁杂，初始化代码里充斥了各种回调各种插件，还有很多锁等待，文件读写，反射hook，网络操作等耗时的操作，梳理优化的过程需要有足够的耐心，需要不少的沟通成本。<br>对于应用开发人员而言，分析应用自身的耗时分析手段比较常规，最常见的手段就是Systrace，traceview，simpleperf等，实在不行代码里进行插桩埋点，因为有源代码，一切都好办。<br>而对于一些头部App比如抖音支付宝等，这类App往往有专门的性能团队，可能会涉及到GC优化，dex2oat优化，文件重排列降低IO次数等门槛较高的方向。</p><h5 id="系统全局角度看启动优化"><a href="#系统全局角度看启动优化" class="headerlink" title="系统全局角度看启动优化"></a>系统全局角度看启动优化</h5><p>对于系统工程师而言，需要关注从驱动上报input事件到首页第一帧画面合成的整个过程。<br>主要会涉及input事件传递，一帧的渲染，CPU&amp;GPU的调度频率，Surfaceflinger的合成等等。</p><h4 id="CPU提频"><a href="#CPU提频" class="headerlink" title="CPU提频"></a>CPU提频</h4><p>下图是启动过程中主线程的CPU频率<br><img src="http://blog.lihaizhou.top/startProcess/startProcess2.png" alt=""><br>mtk默认已有实现在进程创建后boost持续10s，从上面Systrace可以看到主线程绘制running的片段是跑在大核上且频率已是最高。<br>但是在对比竞品机Systrace时，笔者发现竞品机surfaceflinger很多时候会跑在大核上，而我们的机器没有跑在大核的时候，其单次onMessageReceived耗时很多时候只有我们的一半。<br>这里先解释下onMessageReceived的作用，主要是处理两个Message</p><ol><li>MessageQueue::INVALIDATE — 主要是执行 handleMessageTransaction&amp;handleMessageInvalidate</li><li>MessageQueue::REFRESH — 主要是执行 handleMessageRefresh 方法<br>可以简单的理解为这块的消息处理越快，合成的速度也会越快，画面能够提早显示出来，降低掉帧的概率。<br>这个时候，你可能会有疑问了，竞品机是做了绑大核处理了吗？</li></ol><p>下面我们看下两者cpuset的差异<br><img src="http://blog.lihaizhou.top/startProcess/startProcess3.png" alt=""><br>可以看到竞品机器对于surfaceflinger设置的是前台进程组，我们的机器遵循的是原生System-background，这也意味着我们机器上surfaceflinger只能跑在0-5核上。<br>那么谷歌设计限制在System-background上基于什么考虑呢？猜测是因为绝大部分时候，这个设计都可以满足需求，占用大核的话可能会导致某些情况下加剧大核队列的负载。</p><h4 id="Dex2oat策略优化"><a href="#Dex2oat策略优化" class="headerlink" title="Dex2oat策略优化"></a>Dex2oat策略优化</h4><p>我们知道dex2oat在优化时，会根据需要优化一定量的method。也就是说并不是优化的method都会被翻译成oat模式。根据优化的method的量的多少，可以分为几种常见的模式：<br><code>verify、quicken、space-profile、space、speed-profile、speed、everything</code><br>字面上比较好理解， 越后面的类型编译时间越长，占用的空间也越大，运行时打开速度也越快，典型空间换时间思路的体现。</p><p>下面是我们的机器和对比机上参数的对比<br><img src="http://blog.lihaizhou.top/startProcess/startProcess4.png" alt=""><br>参数是一致的，其实这也是平台默认的配置, 这些参数中有一项是install时的选择的模式: speed-profile.<br>这里说下speed和speed-profile的区别，speed-profile是对profile中的热点函数进行编译，可以简单理解为是局部编译，而speed是全编。<br>对于dex2oat的调优，其实策略比较常规，根据不同的场景和负载，选择不同的模式。</p><h4 id="降低GC的频率"><a href="#降低GC的频率" class="headerlink" title="降低GC的频率"></a>降低GC的频率</h4><p>之前处理过的性能案例中，有不少是GC引起的性能问题。<br>对GC的优化做了这样的修改：<br>大意是在进程状态变化触发的GC转换中，如果当前堆增长(自上次GC以来)大小未达到可增长的1/4，则跳过本次GC，这样可以降低启动过程中GC的频率。<br>另外，谷歌在Android R上的一笔GC优化修改，也是降低启动过程中的GC频率<br><img src="http://blog.lihaizhou.top/startProcess/startProcess5.png" alt=""><br>大意就是应用启动过程中等进程fork结束之后，将堆上限阈值调整到最大，因为我们知道GC的触发时机主要取决于堆实际增长是否触及上限值，这样一来的话，进程启动过程中GC的概率就会降低，等两秒钟过后，再将堆上限阈值恢复回来。<br>这些修改的目的都是为了降低GC对启动速度的影响，其实GC的影响不光光在启动上，对于整机的流畅度都起到了很重要影响。</p><h4 id="IO优化"><a href="#IO优化" class="headerlink" title="IO优化"></a>IO优化</h4><p>当内核发起一个读请求时（例如进程发起 read() 请求），首先会检查请求的数据是否缓存到了 pagecache 中。如果有，那么直接从内存中读取，不需要访问磁盘，这被称为 cache命中（cache hit）。如果 cache 中没有请求的数据，即 cache 未命中（cache miss），就必须从磁盘中读取数据。<br>然后内核将读取的数据缓存到 cache 中，这样后续的读请求就可以命中 cache 了。Page 可以只缓存一个文件部分的内容，不需要把整个文件都缓存进来。对磁盘的数据进行缓存从而提高性能主要是基于两个因素：</p><ol><li>磁盘访问的速度比内存慢好几个数量级（毫秒和纳秒的差距）。</li><li>被访问过的数据，有很大概率会被再次访问。</li></ol><p>对于一些头部App比如支付宝就对Apk中的文件进行了重排优化，大意就是:<br><code>通过文件重布局，将启动阶段需要用到的文件在 APK 文件中排布在一起，尽可能的利用 pagecache 机制，用最少的磁盘 IO 次数，读取尽可能多的启动阶段需要的文件，减少 IO 开销，从而达到提升启动性能的目的</code></p><p>上面是App中的IO优化策略，从系统角度的优化策略比较复杂，需要对文件系统比较熟悉, 后续会单独成文记录IO这块的内容</p><h4 id="最终优化效果"><a href="#最终优化效果" class="headerlink" title="最终优化效果"></a>最终优化效果</h4><p>当前采用了如下三种方式对启动性能进行了优化</p><ol><li>对SurfaceFlinger占据的CPU资源调整</li><li>针对不同场景下的dex2oat进行了编译模式调优</li><li>启动过程中降低GC次数</li></ol><p>在优化后的版本上，我们再次使用高速相机对支付宝进行测试<br><img src="http://blog.lihaizhou.top/startProcess/startProcess6.png" alt=""></p><h4 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h4><p><a href="https://developer.android.google.cn/topic/performance/vitals/launch-time" target="_blank" rel="noopener">https://developer.android.google.cn/topic/performance/vitals/launch-time</a><br><a href="https://source.android.com/devices/tech/dalvik/configure" target="_blank" rel="noopener">https://source.android.com/devices/tech/dalvik/configure</a></p><hr><p>11.19 南京 新华汇 晴 周五</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;应用的启动表现特别是冷启动的速度，是用户对App的第一印象。很多时候也会被评测机构用来测试一个手机性能的依据，所以对启动速度的优化一直以来是App和手机厂商发力的重点&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id=&quot;故事背景&quot;&gt;&lt;a href=
      
    
    </summary>
    
      <category term="性能" scheme="http://lihaizhou.top/categories/%E6%80%A7%E8%83%BD/"/>
    
    
  </entry>
  
  <entry>
    <title>Systrace角度: 拆解分析应用的启动流程</title>
    <link href="http://lihaizhou.top/2021/11/11/Systrace%E8%A7%92%E5%BA%A6-%E6%8B%86%E8%A7%A3%E5%88%86%E6%9E%90%E5%BA%94%E7%94%A8%E7%9A%84%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B/"/>
    <id>http://lihaizhou.top/2021/11/11/Systrace角度-拆解分析应用的启动流程/</id>
    <published>2021-11-11T11:40:26.000Z</published>
    <updated>2021-11-11T11:49:33.776Z</updated>
    
    <content type="html"><![CDATA[<p>上周看了一个支付宝启动速度逊色于对比机的案例，花了些时间整理了下这个过程。</p><p>应用启动过程中牵扯的知识点较多，基本涵盖了Android几大重要的子系统，非一篇文章能够讲清。</p><p>本文将以支付宝为例，介绍下从input事件触发到首页帧显示完成的整个流程，后面会单独成文介绍与竞品的差异分析。</p><h4 id="测试步骤"><a href="#测试步骤" class="headerlink" title="测试步骤"></a>测试步骤</h4><ol><li><p>使用user版本，开机后连接信号好的WIFI网络，清理后台所有程序。登录支付宝账号后先启动几次，最后再forceStop</p></li><li><p>手机放置五分钟后，确保机器未发热，此时打开Systrace录制，通过高速相机拍摄，点击icon冷启，再forceStop下，再次冷启，循环做五组</p></li></ol><p>取耗时最长一次925ms为例进行分析，时间范围起始点:   以手指落下接触到icon为起点，以支付宝首页内容完全加载出为结束点</p><h4 id="Input事件"><a href="#Input事件" class="headerlink" title="Input事件"></a>Input事件</h4><p><img src="http://blog.lihaizhou.top/Systrace_process_start/processStart1.png" alt="img"></p><p>关键时间点</p><ol><li>AppLaunch_dispatchPtr:Up:  5s 617ms</li><li>Launcher中接收到input事件:   5s 620ms</li></ol><p>从up事件到Launcher接收到最早的input事件耗时约3ms</p><p>这个过程大致就是：</p><ol><li>inputReader从Eventhub中获取到input事件后</li><li>inputReader将事件给inputDispatcher，inputDispatcher会将事件放到 “iq” 队列中(图中没有列出)</li><li>这个时候开始寻找处理这个input事件的目标窗口了，这个案例中对应的就是Launcher，找到后放在oq队列中，等着发送给Launcher</li><li>事件发送出去后，将事件放到图中的wq队列中，等Launcher消费过这个事件后，会通知inputDisp已经消费完成，图中的wq凸起点会消失</li></ol><p>这里顺便说下，我们平时经常会遇到input类型的ANR，对应的正是wq的等待时长。</p><p>简单理解就是事件发给应用窗口了，这个时候开始倒计时，如果5s内(我们项目上客制化为8s)应用窗口没有告知inputDispatcher这个事件消费完成，说明应用窗口无响应了，就会触发ANR。</p><p>如果5s内应用窗口处理完成了并告知inputDispatcher后，inputDispatcher就会从 “wq” 队列中及时移除待处理事件避免ANR。</p><h4 id="创建进程"><a href="#创建进程" class="headerlink" title="创建进程"></a>创建进程</h4><p><img src="http://blog.lihaizhou.top/Systrace_process_start/processStart2.png" alt="img"></p><p>时间关键点: </p><p>\1. fork进程起点 5s 652ms，耗时6ms</p><p>这里顺便介绍下关于fork进程花费时间的优化，Android R上新增了一个usap的机制，大意是会预先fork一些空进程放在池中，这样可以省去应用fork的时间。</p><p>有些厂商会定制化这块内容，将这些预先fork出来的空进程指定包名，比如用户感知较强的微信支付宝等，这样的在支付宝冷启时，这里就不会有fork的片段，其实就是空间换时间的做法。</p><p>但是这种做法不太适合小内存机器，相比内存的额外开销所带来的仅仅几毫秒的提速，似乎并不是特别划算。</p><p>\2. Launcher将自身pause 5s 665ms</p><p>大概过程就是检测到前台此时resume状态的Activity是Launcher界面，就会通知桌面应用的 Activity 进入 Paused 状态，有些厂商会定制化桌面icon按压的效果，我手头的小米手机上按压会有一个置灰缩小的动画。</p><p>Launcher onpause执行完成之后，便会开始启动动画，对应的会是一连串的帧。</p><p><img src="http://blog.lihaizhou.top/Systrace_process_start/processStart3.png" alt="img"></p><p>前面的内容大致对应了</p><p>点击icon-&gt;input事件的分发-&gt; fork进程 -&gt; Launcher onpause</p><p>launcher启动动画的过程中，支付宝开始同步执行生命周期，如果支付宝生命周期执行结束，则启动动画也会结束并切换到应用窗口</p><h4 id="应用初始化环节"><a href="#应用初始化环节" class="headerlink" title="应用初始化环节"></a>应用初始化环节</h4><p>这块大致的过程是:</p><p>ZygoteInit-&gt;ActivityThreadMain-&gt;BindApplication-&gt;StartActivity-&gt;onresume-&gt;doFrame-&gt;display</p><p>对于应用开发人员而言，关注点是从BindApplication开始，这个时间点是应用开发者最早能够控制的时间点。</p><p>ZygoteInit-&gt;ActivityThreadMain</p><ul><li><p>ZygoteInit -&gt; 5s 669ms   标识支付宝进程初始化开始，创建binder线程池之类的事务</p></li><li><p>ActivityThreadMain  -&gt; 5s 670ms  创建并启动主线程的 loop 消息循环；通过 binder 调用 AMS 的 attachApplication 接口将自己 attach 注册到 AMS 中。</p></li></ul><h5 id="bindApplication"><a href="#bindApplication" class="headerlink" title="bindApplication"></a>bindApplication</h5><p><img src="http://blog.lihaizhou.top/Systrace_process_start/processStart4.png" alt="img"></p><p>关键时间点</p><p>bindApplication 起始点5s 676ms，耗时112ms</p><p>bindApplication段CPU运行情况</p><p><img src="http://blog.lihaizhou.top/Systrace_process_start/processStart5.png" alt="img"></p><p>bindApplication耗时拆分</p><p><img src="http://blog.lihaizhou.top/Systrace_process_start/processStart6.png" alt="img"></p><h5 id="activityStart"><a href="#activityStart" class="headerlink" title="activityStart"></a>activityStart</h5><p><img src="http://blog.lihaizhou.top/Systrace_process_start/processStart7.png" alt="img"></p><p>这个过程简单概述下来就是</p><ol><li>创建 Activity 的 Context；</li><li>通过反射创建 Activity 对象；</li><li>执行 Activity 的 attach 动作，其中会创建应用窗口的 PhoneWindow 对象并设置 WindowManage；</li><li>执行应用 Activity 的 onCreate 生命周期函数，并在 setContentView 中创建窗口的 DecorView 对象；</li></ol><p>activityStart时间段CPU执行情况</p><p><img src="http://blog.lihaizhou.top/Systrace_process_start/processStart8.png" alt="img"></p><p>activityStart拆分耗时</p><p><img src="http://blog.lihaizhou.top/Systrace_process_start/processStart9.png" alt="img"></p><h5 id="activityResume"><a href="#activityResume" class="headerlink" title="activityResume"></a>activityResume</h5><p><img src="http://blog.lihaizhou.top/Systrace_process_start/processStart10.png" alt="img"></p><p>这个阶段主要对应的操作</p><ol><li>执行应用 Activity 的 onResume 生命周期函数；</li><li>执行 WindowManager 的 addView 动作开启视图绘制逻辑；</li><li>创建 Activity 的 ViewRootImpl 对象；</li><li>执行 ViewRootImpl 的 setView 函数开启 UI 界面绘制动作；</li></ol><p><img src="http://blog.lihaizhou.top/Systrace_process_start/processStart11.png" alt="img"></p><h4 id="SplashActivity首帧"><a href="#SplashActivity首帧" class="headerlink" title="SplashActivity首帧"></a>SplashActivity首帧</h4><p>市面上有很多应用打开后会有一个启动界面，这个界面叫做SplashActivity，一般会在这个页面可以做一些App数据初始化的工作。</p><p>如果应用没有SplashActivity的话，那这个环节可以直接跳过直接来到应用首页帧即可。</p><p><img src="http://blog.lihaizhou.top/Systrace_process_start/processStart12.png" alt="img"></p><p>关键时间点: 启动页首帧 5s 893ms ,耗时37ms</p><p>首帧绘制结束时间点 5s931ms</p><p><img src="http://blog.lihaizhou.top/Systrace_process_start/processStart13.png" alt="img"></p><p>注意一点的是:</p><p>这里的finish draw只有在mDrawsNeededToReport为0时才会打印</p><p>mDrawsNeededToReport的含义是</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">A count of the number of calls to pendingDrawFinished we require to notify the WM drawing is complete.</span><br></pre></td></tr></table></figure><p>简单的理解这次的绘制序列结束后会打印，所以我们在首页帧后面找不到finish draw是因为首页会加载很多内容，对应的是会有很多帧才能完成，所以首页帧的结束点用finish draw并不适用。</p><p>还有一点值得注意，因为我们这个案例中是以支付宝为例的，支付宝是有SplashActivity的 ，所以Systrace中你所看到的launching: com.eg.android.AlipayGphone耗时不能代表整个启动过程。</p><p>只能粗略的代表启动到SplashActivity首帧的耗时， 但是可以在和竞品数据对比时作为一个参考指标</p><p>可以看到launching: com.eg.android.AlipayGphone共计耗费了286.6ms</p><p><img src="http://blog.lihaizhou.top/Systrace_process_start/processStart14.png" alt="img"></p><p>到这里 , 从dispatchPtr:Up的5s 617ms到SplashActivity首帧绘制结束时间点5s931ms，共耗时314ms</p><h4 id="首页帧"><a href="#首页帧" class="headerlink" title="首页帧"></a>首页帧</h4><p><img src="http://blog.lihaizhou.top/Systrace_process_start/processStart15.png" alt="img"></p><p>这一帧的cpu运行情况</p><p><img src="http://blog.lihaizhou.top/Systrace_process_start/processStart16.png" alt="img"></p><p>cpu运行情况</p><p><img src="http://blog.lihaizhou.top/Systrace_process_start/processStart17.png" alt="img"></p><p>渲染结束后将buffer queue到SF的队列中</p><p><img src="http://blog.lihaizhou.top/Systrace_process_start/processStart18.png" alt="img"></p><h4 id="冷启动结束帧"><a href="#冷启动结束帧" class="headerlink" title="冷启动结束帧"></a>冷启动结束帧</h4><p>对于有源码的应用，定义结束帧会比较简单，加载哪个view或layout能够大致代表界面内容显示完全作为owner你是清楚的。</p><p>但是对于三方应用比如我们这个案例，没有其源代码，可以通过高速相机先大致确认下时间范围，然后在范围区域内的几帧逐一看。</p><p>可以先查看下支付宝首页的布局，比如这里home_advertisement.xml对应主界面上的中间广告页，这个布局的加载完成，其后面紧跟着的一帧我我们就认为是结束帧。</p><p>所以我们在对比竞品的Systrace时也要以home_advertisement.xml加载后的一帧为结束点。</p><p><img src="http://blog.lihaizhou.top/Systrace_process_start/processStart19.png" alt="img"></p><p>SF侧以及渲染线程侧</p><p><img src="http://blog.lihaizhou.top/Systrace_process_start/processStart20.png" alt="img"></p><p><img src="http://blog.lihaizhou.top/Systrace_process_start/processStart21.png" alt="img"></p><p>关键时间点: </p><p>SF中bufferQueue对应的支付宝这一帧的buffer被消费后的时间点是 6s554ms</p><p>这个时间点可以基本认为是冷启动最后的时间点</p><p>到这里我们计算下冷启的大概耗时</p><ul><li><p>inputReader中读取到up事件起始点 : 5s 617ms</p></li><li><p>首页内容完全加载第一帧时间点: 6s554ms</p></li></ul><p>整个冷启动过程共计耗时937ms，和我们高速相机测算的925ms比较接近</p><h4 id="写在最后"><a href="#写在最后" class="headerlink" title="写在最后"></a>写在最后</h4><p>到这里，对于支付宝的整个启动流程拆解结束，希望通过本文能够加深对应用启动流程的理解，后面会另行成文分析和竞品机的差异细节。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;上周看了一个支付宝启动速度逊色于对比机的案例，花了些时间整理了下这个过程。&lt;/p&gt;
&lt;p&gt;应用启动过程中牵扯的知识点较多，基本涵盖了Android几大重要的子系统，非一篇文章能够讲清。&lt;/p&gt;
&lt;p&gt;本文将以支付宝为例，介绍下从input事件触发到首页帧显示完成的整个流程，
      
    
    </summary>
    
      <category term="性能" scheme="http://lihaizhou.top/categories/%E6%80%A7%E8%83%BD/"/>
    
    
  </entry>
  
  <entry>
    <title>案例分析:打开应用后操作界面无响应(Systrace)</title>
    <link href="http://lihaizhou.top/2021/11/08/%E6%A1%88%E4%BE%8B%E5%88%86%E6%9E%90-%E5%88%87%E6%8D%A2%E5%BA%94%E7%94%A8%E5%90%8E%E9%AB%98%E6%A6%82%E7%8E%87%E6%93%8D%E4%BD%9C%E6%97%A0%E5%93%8D%E5%BA%94-Systrace/"/>
    <id>http://lihaizhou.top/2021/11/08/案例分析-切换应用后高概率操作无响应-Systrace/</id>
    <published>2021-11-08T02:34:51.000Z</published>
    <updated>2021-11-08T06:45:49.228Z</updated>
    
    <content type="html"><![CDATA[<h4 id="问题现象"><a href="#问题现象" class="headerlink" title="问题现象"></a>问题现象</h4><p>打开应用(热启动)后，概率性出现手指滑动界面无任何响应(界面控件支持上下滑动)</p><h4 id="Systrace角度分析"><a href="#Systrace角度分析" class="headerlink" title="Systrace角度分析"></a>Systrace角度分析</h4><p>先看下应用区域帧绘制的情况</p><p><img src="http://blog.lihaizhou.top/Systrace_cpmpact/Systrace_compact2.png" alt="图片"></p><p>这个时间段除了开头的几帧，后面几乎是空白的，复现时手指明明是一直滑动的。</p><p>先确认下input事件是否正常，在分析input事件流转是否正常之前</p><p>我们先简单的介绍下input事件大概的流转过程</p><blockquote><p>1.触摸屏每隔几毫秒扫描一次，如果有触摸事件，那么把事件上报到对应的驱动</p><p>2.InputReader 读取触摸事件交给 InputDispatcher 进行事件派发</p><p>3.InputDispatcher 将触摸事件发给注册了 Input 事件的 App</p><p>4.app 拿到事件之后，进行 Input 事件分发，如果此事件分发的过程中，App的</p><p>UI 发生变化，那么会请求 Vsync，则进行一帧的绘制</p></blockquote><p>先看下input down的时间点</p><p><img src="http://blog.lihaizhou.top/Systrace_cpmpact/Systrace_compact3.png" alt="图片"></p><p>后面的事件是连续且密集的，说明我们复现抓取的时候，报点是没有问题的。</p><p>这个时候我们注意到一个奇怪的现象，outBoundQueue和waitQueue是空的。</p><p>关于outBoundQueue和waitQueue简单介绍下</p><blockquote><p>1.当应用窗口准备就绪，将mPendingEvent转移到outBoundQueue队列，对应的是即将要被派发给对应 AppConnection 的事件。</p><p>2.当outBoundQueue不为空，且应用管道对端连接状态正常，则将数据从outboundQueue中取出事件，放入waitQueue队列，记录的是已经派发给 AppConnection 但是 App 还在处理没有返回处理成功的事件。</p></blockquote><p>如果outBoundQueue和waitQueue是空的话，说明此时应用窗口未就绪。我们操作时窗口明明可见的，难道应用D状态了？</p><p>带着这个疑问，我们再次回到应用所在区域</p><p><img src="http://blog.lihaizhou.top/Systrace_cpmpact/Systrace_compact4.png" alt="图片"></p><p>可以看到飞书热启后，多个运行线程处于非IO导致的D状态，另外结合基本没有占据CPU资源这一情况。</p><p>可以认定之所以应用没有响应down事件，正是由于其处于非IO导致的D状态。</p><p>下面就需要调查为何应用D状态了，很快在应用区域注意到一个现象</p><p><img src="http://blog.lihaizhou.top/Systrace_cpmpact/Systrace_compact5.png" alt="图片"></p><p>我们知道匿名页被压缩换到Zram通常出现在kswapd回收内存场景中。</p><p>但是还有一种场景我们可能会忽略，那就是adj变化触发的进程压缩同样会消费Zram。</p><p>为了验证是进程压缩导致，来到压缩线程所在区域。为了看起来更直观，将down事件和压缩线程放在一起</p><p><img src="http://blog.lihaizhou.top/Systrace_cpmpact/Systrace_compact6.png" alt="图片"></p><p>到这里我们可以确定飞书之所以没有响应到input down事件，正是由于其当时正在进行进程压缩从而导致其处于D状态。</p><h4 id="问题完整时间线"><a href="#问题完整时间线" class="headerlink" title="问题完整时间线"></a>问题完整时间线</h4><p>到这里我们将这个案例完整的故事情节还原出来</p><ol><li><p>在一次退出飞书后，此时引起adj变化，进入压缩判断环节，此时满足一系列条件(如匿名页大小, 前后时间差, adj值)后，压缩线程开始对飞书应用进行压缩。</p></li><li><p>很快再次打开飞书(29s793ms)</p></li><li><p>此时手指按下开始滑动(29s988ms)(不松手)，注意这个时候压缩还未完成，飞书仍处于进程压缩导致的D状态中，所以未能响应down事件。</p><p>我们知道一个事件序列是由down+若干move+up组成，由于down事件丢失以至于后面的move事件未能响应。</p></li><li><p>飞书压缩完成(30s598ms)，该主界面进程压缩过程持续约882.6ms，完成后飞书解除D状态。</p></li></ol><p>这个过程简单点说，在飞书可见后，如果上次压缩未完成，这时候手指按下的down事件都会被丢弃。</p><p>这也解释了为何该问题在快速切换场景下更容易出现</p><h4 id="压缩速度"><a href="#压缩速度" class="headerlink" title="压缩速度"></a>压缩速度</h4><p>这个时候，你可能会觉得疑惑，是不是压缩速度慢导致的这个问题?</p><p>下面我们将试着计算问题时的”压缩速度”, 这里对压缩速度之所以加引号后面会解释</p><p><img src="http://blog.lihaizhou.top/Systrace_cpmpact/Systrace_compact7.png" alt="图片"></p><p>从我们这次复现的Systrace来看，飞书压缩完成后，其Swap占据从118.8M增长到232.7M，共计压缩了约114M的匿名页，共计耗时882ms</p><p>用压缩量除以耗时时间得出”压缩速度”约129M/s。</p><p>影响压缩速度的因素可能有哪些呢？</p><p><strong>主要是压缩算法，CPU频率，DDR频率，内存读写性能这几方面因素</strong></p><p>我们从Systrace中再看下压缩期间的CPU运行情况</p><p><img src="http://blog.lihaizhou.top/Systrace_cpmpact/Systrace_compact8.png" alt="图片"></p><p>可以看到有较多的Runnable (Preempted)，说明该时间段内可能负载较重，存在CPU争抢的情况。</p><p>除了等CPU的片段外，还有很多片段跑在了小核上</p><p><img src="http://blog.lihaizhou.top/Systrace_cpmpact/Systrace_compact9.png" alt="图片"></p><p>这也是为何上面提到的”压缩速度”加引号的原因。正好压缩的耗时882ms并不是一直在running状态。</p><p>其实这点比较好理解，好比你开车上班，短短的五公里的车程却有二十个红绿灯，这个时候用路程除以耗时得出的”车速”，严格意义上说并不准确。</p><h4 id="测试实验"><a href="#测试实验" class="headerlink" title="测试实验"></a>测试实验</h4><p>我们前面已经发现压缩期间很多片段跑在了小核上，那么如果给压缩线程更高的CPU资源权重，是否能提升”压缩速度”呢？</p><p>于是，对压缩线程占据CPU的权重进行调整后，再次抓取了一份Systrace</p><p><img src="http://blog.lihaizhou.top/Systrace_cpmpact/Systrace_compact10.png" alt="图片"></p><p>从修改后抓取的Systrace可以看到，这次压缩线程确实大部分时候跑在了大核上。</p><p>从图中可以看到本次压缩了约144M匿名页，耗时约450ms，”压缩速度”约320M/s</p><p>相比修改前，”压缩速度”提升了近三倍，但是其实仍然不够快，还是会有一定概率发生手指按下时，正好落在压缩未完成的时间段内，只是相比之前大幅降低了该问题复现概率。</p><h4 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h4><p>如果压缩算法已经确认是最优的选择(平衡压缩率和解压缩速度)情况下，通过尽量赋予压缩线程更高的CPU优先级确实能够缩短耗时(假设压缩量固定)，但是最大的影响因素在于内存读写性能。</p><hr><p>愿你秃顶归来，内心依旧少年</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;问题现象&quot;&gt;&lt;a href=&quot;#问题现象&quot; class=&quot;headerlink&quot; title=&quot;问题现象&quot;&gt;&lt;/a&gt;问题现象&lt;/h4&gt;&lt;p&gt;打开应用(热启动)后，概率性出现手指滑动界面无任何响应(界面控件支持上下滑动)&lt;/p&gt;
&lt;h4 id=&quot;Systrace角度
      
    
    </summary>
    
      <category term="性能" scheme="http://lihaizhou.top/categories/%E6%80%A7%E8%83%BD/"/>
    
    
  </entry>
  
  <entry>
    <title>第三视角: 一个ART GC的优化故事</title>
    <link href="http://lihaizhou.top/2021/11/01/%E7%AC%AC%E4%B8%89%E8%A7%86%E8%A7%92-%E4%B8%80%E4%B8%AAART-GC%E7%9A%84%E4%BC%98%E5%8C%96%E6%95%85%E4%BA%8B/"/>
    <id>http://lihaizhou.top/2021/11/01/第三视角-一个ART-GC的优化故事/</id>
    <published>2021-11-01T08:54:55.000Z</published>
    <updated>2021-11-01T10:06:11.284Z</updated>
    
    <content type="html"><![CDATA[<h4 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h4><p>从事过整机性能优化的同事，在实际项目上相信都遇到过GC引起的性能问题。有了上一篇文章<android s="" art="" gc基础="">的铺垫，阅读本文将会比较轻松。<br>笔者在梳理GC这块的代码过程中，深感其复杂并非一蹴而就，如果你对其某处代码的设计缘由不甚理解，不妨试着去追踪它的提交记录。<br>通过其一系列的patch更新以及comment，跟着提交owner的思路历程，便可以了解这个”成品”是如何被加工出来的。</android></p><h4 id="故事的缘起"><a href="#故事的缘起" class="headerlink" title="故事的缘起"></a>故事的缘起</h4><p>笔者在梳理GC这块的代码时，偶然看到一处友商的提交，不禁有点好奇。为了探究其修改的缘由，仔细阅读了这笔修改的提交更新以及所有的comment之后，觉得其中一些思路对我们有启发作用，故而决定将这个思路过程尽可能的还原出来。<br>为了提升可读性，将通过故事叙事的方式展开，以第三视角来讲述。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">主角: 卢卡斯(谷歌员工)，大壮(友商员工)    </span><br><span class="line">配角: 汉斯(谷歌员工)   </span><br><span class="line">旁白: 笔者</span><br></pre></td></tr></table></figure></p><h4 id="故事开始"><a href="#故事开始" class="headerlink" title="故事开始"></a>故事开始</h4><p>大壮在国内一家手机厂商搬砖，负责整机性能方面的研究。最近大壮有点闷闷不乐，项目上一些GC相关的性能问题困扰了他许久，具体是什么GC问题呢？<br>大壮通过不限于Systrace等手段，发现在一些场景下比如后台运行较多应用时，GC会消耗较多CPU资源，加剧系统负担，表现出的现象就是更加卡顿了。<br>于是，自信上进的大壮开始着手调研该如何解决这个问题，最终有了一个方案：<br>既然GC会在后台运行较多应用时争抢CPU，那么在CPU负载高的时候降低GC的触发，CPU负载低的时候再恢复，这不就可以了吗？</p><ol><li>怎么降低GC频率呢？Multiplier机制。</li><li>怎么统计CPU负载呢？大壮看了下代码中原本就有GC期间占据的CPU数据。</li></ol><p>看起来小菜一碟嘛，熟悉GC流程代码的大壮很快就做出了第一笔修改。</p><h5 id="修改Multiplier"><a href="#修改Multiplier" class="headerlink" title="修改Multiplier"></a>修改Multiplier</h5><p>考虑到HeapGrowthMultiplier这个接口是谷歌原有的，存在多处会调用，为了不影响其他调用,贴心的大壮加了一个单独的接口HeapGrowthMultiplierExt,  这个接口最终会调用HeapGrowthMultiplier，只是在此之前会有一些判断条件。比如是否处于亮屏，不同的radio下返回不同的Multiplier值。<br>通过前一篇文章的分析，我们知道Multiplier的改变会引起下次GC水位的提升，总的而言，值越高GC的触发频率就会更低。<br>runtime/gc/collector/garbage_collector.cc<br><img src="http://blog.lihaizhou.top/ART_story/GC_story1.png" alt="图片"><br>runtime/gc/heap.cc</p><p><img src="http://blog.lihaizhou.top/ART_story/GC_story2.png" alt="图片"></p><h5 id="降低GC转换的次数"><a href="#降低GC转换的次数" class="headerlink" title="降低GC转换的次数"></a>降低GC转换的次数</h5><p><img src="http://blog.lihaizhou.top/ART_story/GC_story3.png" alt="图片"><br>前后台切换会导致GC转换，大壮心想有一些本身占据堆内存就比较小的进程，他们很多时候的GC转换带来的收益并不明显。<br>特别是内存比较充足的项目这种GC转换似乎有点多余，那么通过判断堆使用大小，去掉一些”不必要”的GC转换，这样就可以降低系统负担。</p><p>旁白:<br>为了可拓展性，尽可能的不要引入硬编码，即便你是通过大量数据实测出来的最优值，除非是一些约定俗成的值。提到硬编码这种情况，在实际项目上经常出现，很多时候这种代码的引入，是由于Reviewer的疏忽没有发现或者说默许了。</p><h4 id="谷歌Review"><a href="#谷歌Review" class="headerlink" title="谷歌Review"></a>谷歌Review</h4><p>很快，大壮的提交修改引起了卢卡斯的注意，看完了大壮的修改后，卢卡斯脑袋上顶着大大的问号。<br>对于如下大壮添加的计算gc期间CPU负载的做法。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">uint64_t gc_cpu_time = thread_cpu_end_time - thread_cpu_start_time;  </span><br><span class="line">float ratio = static_cast&lt;float&gt;(gc_cpu_time) / duration_ns;</span><br></pre></td></tr></table></figure></p><p>卢卡斯认为这只是本次GC周期内的CPU负载情况，且这个值在绝大部分时候都应该是接近1的，并不能说明未来一段时间的CPU情况。<br>另外，GC等待checkpoint或者其他原因都可能会导致GC等待，但是这些等待的时间不会计入gc_cpu_time中，所以这种计算方式只能说一定程度上可能暗示了当前的负载情况，但是远远达不到可靠的地步。</p><p>旁白：<br>注意这里谷歌提到了未来的CPU使用情况，是因为这个比例值是本次GC周期计算的，你可以理解为是一个瞬时值，但是抑制GC的情况是需要等到<br>下次GC触发才会发生的，是一个未来发生的事情，那么等到下次GC的时候，本次GC算出的负载可能就不适用了。</p><p>大壮：<br>大壮看完大G的回复之后，虎躯一震，这修改。。怕是要凉啊！于是大壮赶紧回复到：<br>在一些性能较差设备上，如果后台开启很多应用，很多时候这个比例值会低于0.5甚至触及0.2。<br>另外，我们做过功耗测试，这修改后的效果杠杠的，改善很明显(使用时间增加了18分钟)。</p><p>卢卡斯：<br>看完大壮理直气壮的回复后，卢卡斯回复到：这里亮屏的判断，并根据不同的radio返回不同的Multiplier，这个修改同样会作用到所有系统进程(如system_server、systemui等)，作用于<br>系统进程是一种错误的行为。还有根据不同的radio即你认为的代表负载情况，返回不同的Multiplier值。这些Multiplier值你是怎么得出来的？<br>比如你上面写的当ratio &lt; 0.3时，返回Multiplier 6，这个值6怎么来的？为何不是返回8？为啥不是9？为啥不是一个10000000000？(谷歌没说这句话)。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (screenOn) &#123;</span><br><span class="line">    <span class="keyword">float</span> ratio = current_gc_iteration_.GetRunningRatio();</span><br><span class="line">    <span class="keyword">if</span> (!CareAboutPauseTimes()) &#123;</span><br><span class="line">      <span class="keyword">if</span> (ratio &lt; <span class="number">0.3</span>) <span class="keyword">return</span> <span class="number">6.0</span>;</span><br><span class="line">      <span class="keyword">if</span> (ratio &lt; <span class="number">0.5</span>) <span class="keyword">return</span> <span class="number">4.0</span>;</span><br><span class="line">      <span class="keyword">if</span> (ratio &lt; <span class="number">0.7</span>) <span class="keyword">return</span> <span class="number">2.0</span>;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="keyword">if</span> (ratio &lt; <span class="number">0.3</span>) <span class="keyword">return</span> <span class="number">7.0</span>;</span><br><span class="line">      <span class="keyword">if</span> (ratio &lt; <span class="number">0.6</span>) <span class="keyword">return</span> <span class="number">5.0</span>;</span><br><span class="line">    &#125;</span><br><span class="line"><span class="comment">//....</span></span><br></pre></td></tr></table></figure><p>旁白：给谷歌提代码一定要避免提交这种硬编码</p><p>大壮：<br>此时的大壮，刚从食堂吃完午饭回来的路上，一路上大壮都在和同事吐槽食堂的饭菜又贵又难吃。<br>坐到座位上，看到卢卡斯的连环追问，大壮有点发蒙。这些数据我经过一些性能和功耗测试，是有帮助的，既然你们提出来这样的修改不合理，那么请告诉我,还有没有其它办法可以降低高负载情况下GC的频率。</p><p>卢卡斯:<br>此时的卢卡斯正喝着咖啡，窗外阳光正明媚，卢卡斯回过头和旁边的汉斯说到，这天气不去钓鱼真是浪费生命啊，汉斯点头如蒜捣，没错没错。<br>这个时候，卢卡斯看了下时间快4点了，准备收拾下班，这个时候看到了大壮的comment，回复到:<br>在堆使用较少的情况下不进行GC我觉得有意义，这种情况下我认为是可以直接跳过GC转换的，而不是引入进程状态切换次数这个变量。</p><p>旁白：谷歌的这句话，在一些场景下跳过GC更有意义，正是这句话改变了修改的方向</p><p>卢卡斯旁边的汉斯看到了大壮的这段回复，心里OS: 上一次这么无语还是在上一次, 忍不住回复到：<br>卢卡斯，大壮的这种改法让我感觉也很不舒服，也许我们在一些场景下GC的次数有点多了，但是能不能用更合理的方式来解决这个问题呢？比如依据自上次GC以来分配的字节数作为依据, 对于某些应用程序来说，转换可能会频繁发生，并且每次执行GC并不总是可取的。<br>用比例值或许更合理？例如:“如果我们已经消耗了超过30%的free heap，我们将在转换时GC”。</p><p>旁白：汉斯的这句话奠定了这个修改的基本方向，依据自上次GC以来的分配数值作为依据，采用比例的方式，不用管这个进程的大小。</p><p>大壮：<br>此时的大壮正在工位上，跟旁边的测试妹纸炫耀自己昨天一口气钓了十几斤的鲫鱼，妹纸看大壮的眼神满是崇拜。大壮说的有点渴了，坐下来喝口水时，看到了卢卡斯的回复，思考片刻后，觉得谷歌提出的修改建议确实更加合理。<br>于是讲起了之前遇到的案例:<br>最早是我们遇到的一个Launcher的卡顿例子，同一uid下的5个进程同时在后台执行collectorTransionGc，导致系统负载过高。四个子进程的堆大小都小于5MB，不信我给你们看Systrace。对于这种内存消耗很小的进程，真的大可不必每次都GC，所以我们希望能够限制这种类型的collectortransiongc。因为从实际用户的GC数据中可以发现，这种类型的CollectorTransitionGC的总量非常大。</p><p>卢卡斯:<br>卢卡斯觉得不应该仅限于小内存进程，应该一视同仁，所以卢卡斯觉得基于堆的大小进行限制不是太好。卢卡斯想起了汉斯提出的建议: 根据自上次GC以来分配的大小作为跳过GC转换的条件。<br>汉斯的这个建议确实更加合理一些，这样的话，所有的应用都有机会跳过一些”不必要”的GC。卢卡斯想了下，与其跳过一些转换GC，不如让它更简单，比如: 如果自上次GC以来的分配小于3MB，GC转换时跳过GC。</p><p>旁白:<br>卢卡斯认同汉斯的通过自上次GC以来分配的大小作为依据，但是忽略了汉斯提出另一个意见，那就是通过堆空闲内存的使用率来作为触发条件，这里卢卡斯提出的小于3M就不进行GC，也正是这句话给了大壮一些误导。</p><p>大壮:<br>听完卢卡斯说的堆使用小于3M就不进行GC转换后，大壮进行了一次修改，加了一个阈值<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="keyword">constexpr</span> <span class="keyword">size_t</span> kDefaultTransitionThreshold = <span class="number">5</span> * MB;</span><br></pre></td></tr></table></figure></p><p>并且在GC转换的地方加了一个判断，如果低于这个阈值，就跳过本次的GC转换<br><img src="http://blog.lihaizhou.top/ART_story/GC_story4.png" alt="图片"></p><p>卢卡斯:<br>看完大壮的修改后，卢卡斯后悔了，这里搞个固定的阈值看起来并不合适。因为如果这个进程是一个占用内存比较小的进程，那么5M对于这个进程来说并不容易达到，这会导致GC的触发频率被大幅降低，导致这个进程的堆大小”不合适”的增大。<br>这个时候卢卡斯想起了汉斯的通过比例的建议，没错，通过比例更合理一些，于是卢卡斯提出了: 上次GC后新增大小如果小于<br>UnignedDifference(target_footprint_.load(std::memory_order_relaxed)- num_bytes_alive_after_gc_)/4 话，则跳过本次GC转换，并且对于LowMemoryMode设备避免跳过GC</p><p>旁白：卢卡斯的这番话基本成形了这个修改，即消耗没有达到堆空闲的1/4，此时有GC转换请求的话，则直接丢弃。</p><p>大壮：<br>看完卢卡斯的建议后，大壮开始着手进行了修改，关于如何计算GC后新分配的值。<br>大壮想到了在GC后算出已分配的减去GC前计算出的已分配大小，修改完之后再次更新了patch，很快卢卡斯在大壮的修改下加了comment<br><img src="http://blog.lihaizhou.top/ART_story/GC_story5.png" alt="图片"></p><p>旁白：这是并发GC的特色所在，分配的同时可能伴随着GC，所以需要考虑GC期间释放的空间大小。</p><h4 id="最终修改思想"><a href="#最终修改思想" class="headerlink" title="最终修改思想"></a>最终修改思想</h4><ol><li>进程状态变化触发GC转换</li><li>计算出自上次GC后新分配字节大小，由于并发缘故，需考虑GC期间释放字节数。</li><li>堆可增长上限减去自上次GC后已分配数值，得出的值即可增长空间，取其四分之一作为分界线</li><li>上次GC后新分配字节数值如果小于第三步算出的可增长空间的1/4，则跳过本次GC转换请求。</li></ol><h4 id="写在最后"><a href="#写在最后" class="headerlink" title="写在最后"></a>写在最后</h4><p>谈到设计思想，笔者想起一句话：Talk is cheap. Show me the code!<br>每次看到这句话，都感觉被无端斥责了一番。<br>笔者曾经特地查询了下Linus说这句话的语境背景，最后得出结论Linus说这句话时，其实是在一个讨论回复中，结合当时的上下文语境，Linus说出这句时明显是带有情绪的，但是奇怪的是这句特定语境下的话，在国内却被大肆宣传甚至被一些人奉为经典。<br>笔者在实际项目上见到过太多shit一样的代码，盲目的追求代码数量，粗制滥造毫无设计可言，更不要说代码规范这些基础原则了，阅读起来你都恨不得砸了键盘。<br>如果你很崇尚“show me the code”，给你这样一堆dog shit代码，你能从中看出什么呢？<br>并不是盲目崇拜谷歌，笔者在阅读谷歌代码的提交记录过程中，能够感受到其思维之严谨，考虑之周到，修改之谨慎。所以推荐大家空闲的时候，可以多阅读谷歌的修改记录。<br>最后多说一句，笔者粗浅的认为，相比于最终的成品代码，当然前提是优秀的代码。笔者认为其思路旅程也很重要，因为是人的思想最终孕育出这块美丽的代码。</p><hr><p>只要不给社会添麻烦，做一个废柴并不丢人</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h4&gt;&lt;p&gt;从事过整机性能优化的同事，在实际项目上相信都遇到过GC引起的性能问题。有了上一篇文章&lt;android s=&quot;&quot; art=&quot;&quot; gc基础=&quot;&quot;
      
    
    </summary>
    
      <category term="ART" scheme="http://lihaizhou.top/categories/ART/"/>
    
    
  </entry>
  
  <entry>
    <title>对Android S ART GC的源码梳理</title>
    <link href="http://lihaizhou.top/2021/10/27/%E5%AF%B9Android-S-ART-GC%E7%9A%84%E6%BA%90%E7%A0%81%E6%A2%B3%E7%90%86/"/>
    <id>http://lihaizhou.top/2021/10/27/对Android-S-ART-GC的源码梳理/</id>
    <published>2021-10-27T01:58:43.000Z</published>
    <updated>2021-10-27T02:52:58.210Z</updated>
    
    <content type="html"><![CDATA[<h4 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h4><p>本文是GC系列文章的首篇，主要为下一篇《第三视角: 一个ART GC优化的故事》文章做铺垫。<br>本文将根据下面的大纲，简单的介绍下GC相关的基础知识，GC这块的内容较多，也相对较为复杂。如果想要研究清楚细节，需要花费较多的时间，也需要有读者有足够的耐心和相关知识背景。</p><p>文中涉及代码均摘自Android S。</p><h4 id="大纲"><a href="#大纲" class="headerlink" title="大纲"></a>大纲</h4><ul><li>研究ART GC目的</li><li>ART GC诞生背景</li><li>里程碑(引入CC)</li><li>ART GC重要特性</li><li>ART GC类别划分</li><li>Multiplier的引入</li><li>堆可分配字节数的计算</li><li>GC触发阈值的计算</li><li>从Systrace角度看GC</li><li>参数修改策略</li><li>写在最后</li><li>参考文献</li></ul><h4 id="研究ART-GC目的"><a href="#研究ART-GC目的" class="headerlink" title="研究ART GC目的"></a>研究ART GC目的</h4><p>尽管GC经过多年发展已得到显著改进，但是在实际项目中仍然会遇到很多GC引起的性能问题。<br>特别是小内存项目上(低于6G)尤为明显，遇到的大部分问题来自于应用不规范的行为，小部分是由于GC机制在特定场景下导致的性能问题。</p><p>GC性能问题主要分为两类：</p><ol><li>对于应用而言，如果代码中存在频繁分配对象、存在内存泄漏、存在主动调用GC接口等问题都有可能导致GC性能问题。<br>主要体现在GC运行的线程HeapTaskDaemon占据CPU资源较多或争抢大核，可能会引起绘制得不到及时调度，导致掉帧的情况。</li><li>另外对于GC机制本身而言，虽然Google一直在优化，但是现在仍然存在一些场景下的表现无法令我们足够满意。<br>比如高负载时争抢CPU资源，小内存进程在某些场景下的频繁触发，多进程应用启动时由于GC导致的卡顿黑屏等现象。</li></ol><h4 id="GC诞生背景"><a href="#GC诞生背景" class="headerlink" title="GC诞生背景"></a>GC诞生背景</h4><p>当我们在学习新技术的时候，了解其诞生背景及其演进变化的历程，再结合具体的代码细节，将有助于我们对这个技术形成一个连续的认知。</p><p>举个网络拥塞控制的例子，网上关于拥塞控制算法的文章铺天盖地，几乎都在讨论其中的代码细节。<br>但是其诞生的历史背景及其本质是为了解决什么问题，却很少有文章能真正解释清楚。<br><strong>为什么说历史背景至关重要</strong><br>还是以拥塞控制为例，如果你不了解1986年的网络大崩溃事件发生的原因，也就无法理解1988年Jacobson提出的TCP拥塞控制的论文。<br>进而即便你多么熟悉TCP的代码细节，你也无法理解这一切实现背后的真正的逻辑，甚至会草率错误的认为拥塞控制是为了加快发包的速度，以至于后面关于这方面的工作很可能是扯淡。</p><p>再回到本文的主题GC，聊下GC诞生的背景</p><blockquote><p><em>1960</em> 年前后诞生于 <em>MIT</em> 的 <em>Lisp</em> 语言是第一种高度依赖于动态内存分配技术的语言，<em>Lisp</em> 语言先天就具有的动态内存管理特性要求 <em>Lisp</em> 语言的设计者必须解决堆中每一个内存块的自动释放问题（否则， <em>Lisp</em> 程序员就必然被程序中不计其数的 <em>free</em> 或 <em>delete</em> 语句淹没），这直接导致了垃圾收集技术的诞生和发展。</p><p><em>J. McCarthy 作为 Lisp</em> 之父，他在发明 <em>Lisp</em> 语言的同时也第一次完整地描述了垃圾收集的算法和实现方式。</p><p>有兴趣的话可以网上搜索这篇文章, 讲的比较详细 &lt;GC技术简单而有趣的发展史&gt;</p></blockquote><h4 id="里程碑-引入CC"><a href="#里程碑-引入CC" class="headerlink" title="里程碑(引入CC)"></a>里程碑(引入CC)</h4><p><code>史前时代Dalvik-&gt;ART的诞生(Android 4.4)-&gt;发展的ART(Android 5.0 ~ 7.0)-&gt;重大变革的ART(Android 8.0 引入Concurrent Copying)-&gt;Android 10开始再次引入分代.</code><br>8.0版本上引入的Concurrent Copying是一项重大改革，大幅提升了Android手机的整机性能表现。<br>8.0版本的GC相比之前的版本改进和提升如下:</p><ul><li>GC always compacts the heap: 32% smaller heap sizes on average compared to Android 7.0.</li><li>Compaction enables thread local bump pointer object allocation: Allocations are 70% faster than in Android 7.0.</li><li>Offers 85% smaller pause times for the H2 benchmark compared to the Android 7.0 GC.</li><li>Pause times no longer scale with heap size; apps should be able to use large heaps without worrying about jank.</li><li>GC implementation detail - Read barriers:</li><li>Read barriers are a small amount of work done for each object field read.</li><li>These are optimized in the compiler, but might slow down some use cases.</li></ul><h4 id="重要特性"><a href="#重要特性" class="headerlink" title="重要特性"></a>重要特性</h4><p>下面简单介绍CC上几种主要的特性，如果阅读过程中有些名词不明其意，大可不必感到困惑。<br>知道其大概的角色作用即可，后面的GC系列文章会对每个特性展开来详细梳理。</p><h5 id="RegionTLAB"><a href="#RegionTLAB" class="headerlink" title="RegionTLAB"></a>RegionTLAB</h5><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">CC enables use of a bump-pointer allocator called RegionTLAB. </span><br><span class="line">This allocates a thread-local allocation buffer (TLAB) to each </span><br><span class="line">app thread, which can then allocate objects out of its TLAB by </span><br><span class="line">bumping the "top" pointer, without any synchronization.</span><br></pre></td></tr></table></figure><p>这里提到的TLAB 即 thread-local allocation buffer，AllocObjectWithAllocator中会先检测如果当前线程TLAB区域的剩余空间可以容纳下这次分配的对象，则在TLAB区域中直接分配。<br>分配算法采用Bump Pointer的方式，仅仅更新已分配区域的游标，简单高效。<br>art/runtime/gc/heap-inl.h<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// If we have a thread local allocation we don't need to update bytes allocated.</span></span><br><span class="line"><span class="keyword">if</span> (IsTLABAllocator(allocator) &amp;&amp; byte_count &lt;= self-&gt;TlabSize()) &#123;</span><br><span class="line">  obj = self-&gt;AllocTlab(byte_count);</span><br><span class="line">  DCHECK(obj != <span class="literal">nullptr</span>) &lt;&lt; <span class="string">"AllocTlab can't fail"</span>;</span><br><span class="line">  obj-&gt;SetClass(klass);</span><br><span class="line">  <span class="keyword">if</span> (kUseBakerReadBarrier) &#123;</span><br><span class="line">    obj-&gt;AssertReadBarrierState();</span><br><span class="line">  &#125;</span><br><span class="line">  bytes_allocated = byte_count;</span><br><span class="line">  usable_size = bytes_allocated;</span><br><span class="line">  no_suspend_pre_fence_visitor(obj, usable_size);</span><br><span class="line">  QuasiAtomic::ThreadFenceForConstructor();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>值得注意的一点是，TLAB在创建之初，它的大小已经计入了num_bytes_allocated_，所以这次虽然分配了新的对象，但num_bytes_allocated_没必要增加，这实际上是一种空间换时间的策略，代价就是会导致num_bytes_allocated_略大于真实使用的字节数。</p><p>谷歌对此修改的commit message:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">New TLAB allocator doesn&apos;t increment bytes allocated </span><br><span class="line">until we allocate a new TLAB. This increases allocation </span><br><span class="line">performance by avoiding a CAS.</span><br><span class="line"></span><br><span class="line">MemAllocTest:</span><br><span class="line">Before GSS TLAB: 3400ms.</span><br><span class="line">After GSS TLAB: 2750ms.</span><br></pre></td></tr></table></figure></p><h5 id="Read-barrier"><a href="#Read-barrier" class="headerlink" title="Read barrier"></a>Read barrier</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">CC performs heap defragmentation by concurrently copying </span><br><span class="line">objects without pausing app threads. This is achieved with </span><br><span class="line">the help of a read-barrier which intercepts reference reads </span><br><span class="line">from the heap, without the need of any intervention from </span><br><span class="line">the app developer.</span><br></pre></td></tr></table></figure><p>CC可以通过在不暂停应用线程的情况下并发复制对象来执行堆碎片整理。这是在read-barrier的帮助下实现的，read-barrier会拦截来自堆的引用读取，无需开发者进行任何干预。<br>注意对第一句话的理解，应用GC的时候不会暂停应用，也就是说这个时候可能存在分配对象的行为，说的其实正是并发。<br>后面的实际案例在计算自上次GC后新分配大小时会用到这一点，目前的GC都是支持read-barrier的，read-barrier的诞生是为了更大程度的降低GC暂停时间。</p><h5 id="一次暂停"><a href="#一次暂停" class="headerlink" title="一次暂停"></a>一次暂停</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">GC only has one small pause, which is constant in time </span><br><span class="line">with regards to the heap size.</span><br></pre></td></tr></table></figure><p>对Dalvik有所了解的话，都知道Dalvik在mark阶段需要暂停应用线程两次，sweep阶段需要暂停一次，三次的STW开销会带来明显的卡顿。<br>到了ART时代，启动 GC 后不再是两次暂停，而是一次暂停，因为（packard pre-cleaning）的存在，在暂停前就做了许多事情，减轻了暂停时的工作量。</p><h5 id="支持分代"><a href="#支持分代" class="headerlink" title="支持分代"></a>支持分代</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">CC extends to be a generational GC in Android 10 and higher. </span><br><span class="line">It enables collecting young objects, which often become </span><br><span class="line">unreachable fairly quickly, with little effort. </span><br><span class="line">This helps by increasing GC throughput and considerably </span><br><span class="line">delaying the need to perform a full-heap GC.</span><br></pre></td></tr></table></figure><p>谷歌对分代的支持历经开，关，开，具体的缘由没有细跟，不过最新Android版本支持分代，分代的好处谷歌解释为更加轻松回收存留期较短的对象，有助于提升GC的吞吐量，并且降低full GC的时机。<br>注意这里提到了一个GC吞吐量的概念，笔者之前从事过网络工作，所以自然而然的想到了WIFI的吞吐量，WIFI吞吐量可以简单的理解为单位时间内通过某个信道的数据量。</p><p>那么这里的GC 吞吐量指的又是什么呢？ <strong>可以理解为单位时间内释放的字节数</strong></p><h4 id="GC类别的划分"><a href="#GC类别的划分" class="headerlink" title="GC类别的划分"></a>GC类别的划分</h4><p>对GC的分类有不同的指标，可以从是否并发，回收力度等指标分类。</p><h5 id="回收力度划分"><a href="#回收力度划分" class="headerlink" title="回收力度划分"></a>回收力度划分</h5><p>art/runtime/gc/collector/gc_type.h<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">art/runtime/gc/collector/gc_type.h// The type of collection to be performed. //The ordering of the enum matters, it is used to determine which GCs are run first.enum GcType &#123;// Placeholder for when no GC has been performed.kGcTypeNone,// Sticky mark bits GC that attempts to only free objects allocated since the last GC.kGcTypeSticky,// Partial GC that marks the application heap but not the Zygote.kGcTypePartial,// Full GC that marks and frees in both the application and Zygote heap.kGcTypeFull,// Number of different GC types.kGcTypeMax,&#125;;</span><br></pre></td></tr></table></figure></p><p>如下摘自谷歌的一笔commit message：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">The new behaviour has that we do sticky GC until we have </span><br><span class="line">less space remaining than minimum free after the GC. </span><br><span class="line">When this occurs, we set the next GC to be a partial GC.</span><br><span class="line"></span><br><span class="line">After a partial / full GC we grow the heap and set the </span><br><span class="line">next GC to be a sticky GC. This prevents the heap from </span><br><span class="line">always growing more than the target utilization, </span><br><span class="line">while ensuring that we do sticky GC often.</span><br></pre></td></tr></table></figure></p><p>建议随着后面不断的深入学习再回过来读这段话，相信会理解的更深。<br>大概意思是我们会尽可能的使用sticky的回收方式，这种回收只会回收自上次GC以来新分配的对象，是一种轻量回收方式，但是回收力度有限。</p><p>当剩余的可用空间低于设定的最小值即min_free，此时将下次GC类别设定为partial GC，加大回收的力度，但是当我们使用partial GC或者full GC后，应该将下次GC类型设定为sticky，从而避免堆的使用率经常超过目标值(默认0.75)，所以需要经常进行sticky方式的回收。</p><h5 id="对应用影响程度划分"><a href="#对应用影响程度划分" class="headerlink" title="对应用影响程度划分"></a>对应用影响程度划分</h5><p>如果基于GC对应用状态的影响分类的话，大致可以分为并发类和阻塞类。<br>并发类GC：GC在GC回收线程(HeapTaskDaemon)执行，阻塞类GC在进程的工作线程执行。</p><p><img src="http://blog.lihaizhou.top/ART_GC/ART_GC1.png" alt="图片"><br>需要注意这里的GcCauseBackground，这里的“Background”并不是指应用切到后台才会执行GC，而是GC在运行时基本不会影响其他线程的执行，即并发GC。</p><p>有了上面的知识铺垫，下面将进入本文最重要的部分，将依次介绍Multiplier的引入，target_size计算过程，concurrent_start_bytes_计算过程这三部分。<br>这三部分相互关联，为了能够更直观的理解这三部分的关系，本地画了一个整体的概览图(花了大半小时画完…….)，后面的内容主要也是围绕下面这个图进行讲解。<br><img src="http://blog.lihaizhou.top/ART_GC/ART_GC2.png" alt="图片"><br>现在看不懂没有关系，在阅读完后面的内容之后，再回过头来看这个图，相信会理解的更加深刻。</p><h4 id="Multiplier的引入"><a href="#Multiplier的引入" class="headerlink" title="Multiplier的引入"></a>Multiplier的引入</h4><p>我们在后面计算预留内存的时候，不论是否是sticky回收，都会使用到Multiplier。<br>这个值主要是为了前台应用设定的，引入该值目的是为了提升前台应用的性能，代价是堆的利用率下降，关于对性能的影响，下面会进行说明。</p><p>先看下对于Multiplier的值来源<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">art/runtime/runtime.cc</span><br><span class="line"><span class="comment">//Extra added to the default heap growth multiplier. </span></span><br><span class="line"><span class="comment">//Used to adjust the GC ergonomics for the read barrier config.</span></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">constexpr</span> <span class="keyword">double</span> kExtraDefaultHeapGrowthMultiplier = kUseReadBarrier ? <span class="number">1.0</span> : <span class="number">0.0</span>;</span><br><span class="line"><span class="keyword">float</span> foreground_heap_growth_multiplier;</span><br><span class="line"><span class="keyword">if</span> (is_low_memory_mode_ &amp;&amp; !runtime_options.Exists(Opt::ForegroundHeapGrowthMultiplier)) &#123;</span><br><span class="line">   <span class="comment">// If low memory mode, use 1.0 as the multiplier by default.</span></span><br><span class="line">   foreground_heap_growth_multiplier = <span class="number">1.0f</span>;</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">   foreground_heap_growth_multiplier =</span><br><span class="line">   runtime_options.GetOrDefault(Opt::ForegroundHeapGrowthMultiplier) +</span><br><span class="line">   kExtraDefaultHeapGrowthMultiplier;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>后台时Multiplier为1，我们主要看下前台的值，最新Android版本上都是支持ReadBarrier的，那么kExtraDefaultHeapGrowthMultiplier值也就是1。<br>再看下ForegroundHeapGrowthMultiplier的值来源于如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">static constexpr double kDefaultHeapGrowthMultiplier = 2.0;</span><br></pre></td></tr></table></figure><p>所以对于前台应用，Multiplier默认的值是2+1=3。</p><p>下面讲的堆大小的调整，下次GC触发阈值计算都是在GrowForUtilization中发生的，而GrowForUtilization又是在CollectGarbageInternal触发的，所以有必要先介绍下CollectGarbageInternal主要做的事情:</p><ol><li>调用RequestTrim做实际的堆裁剪，将空闲内存归还给系统，这块的内容细节较多，后面会另起一篇文章进行详细的介绍；</li><li>第二步会执行SelfDeletingTask* clear = reference_processor_-&gt;CollectClearedReferences(self);</li><li>第三步也是我们本文重点介绍的一步，这一步将进行堆大小的调整以及计算下次触发GC的阈值</li></ol><p>那么什么时候会触发CollectGarbageInternal进行垃圾回收呢？<br><strong>在ART分配对象失败或者已使用内存超过某个设定的阈值就会触发</strong></p><h4 id="堆最大可分配字节数的计算"><a href="#堆最大可分配字节数的计算" class="headerlink" title="堆最大可分配字节数的计算"></a>堆最大可分配字节数的计算</h4><p>堆最大可分配字节数指的是代码中的target_size，一个仅具有指导意义的最大可分配字节数，为何说仅有指导意义，后面会解释。</p><p>在此之前，我们先了解下Sticky GC是什么？<br>谷歌对此的定义如下:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Sticky mark bits GC that attempts to only free objects </span><br><span class="line">allocated since the last GC.</span><br></pre></td></tr></table></figure></p><p>Sticky GC只会回收自上次GC以来新分配的对象，是分代GC下的一种GC类型，也可以理解为Young-generation GC，那么非kGcTypeSticky指的是哪些GC类别呢？对应Partial GC以及Full GC。</p><p>那么什么时候会使用Sticky GC，什么时候会触发Partial GC以及Full GC呢？后面GC系列文章会进行讲解，总体而言，执行Sticky GC频率最高，最低是Full GC。</p><p>下面会看下kGcTypeSticky以及非kGcTypeSticky类别GC的target_size计算过程。</p><h5 id="非kGcTypeSticky-GC"><a href="#非kGcTypeSticky-GC" class="headerlink" title="非kGcTypeSticky GC"></a>非kGcTypeSticky GC</h5><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (gc_type != collector::kGcTypeSticky) &#123;  </span><br><span class="line"><span class="comment">// Grow the heap for non sticky GC.  </span></span><br><span class="line"><span class="keyword">uint64_t</span> delta = bytes_allocated * (<span class="number">1.0</span> / GetTargetHeapUtilization() - <span class="number">1.0</span>);  </span><br><span class="line">DCHECK_LE(delta, <span class="built_in">std</span>::numeric_limits&lt;<span class="keyword">size_t</span>&gt;::max()) &lt;&lt; <span class="string">"bytes_allocated="</span> &lt;&lt;bytes_allocated  &lt;&lt; <span class="string">" target_utilization_="</span> &lt;&lt; target_utilization_;</span><br><span class="line">grow_bytes = <span class="built_in">std</span>::min(delta, <span class="keyword">static_cast</span>&lt;<span class="keyword">uint64_t</span>&gt;(max_free_));</span><br><span class="line">grow_bytes = <span class="built_in">std</span>::max(grow_bytes, <span class="keyword">static_cast</span>&lt;<span class="keyword">uint64_t</span>&gt;(min_free_));</span><br><span class="line">target_size = bytes_allocated + <span class="keyword">static_cast</span>&lt;<span class="keyword">uint64_t</span>&gt;(grow_bytes * multiplier);  </span><br><span class="line">next_gc_type_ = collector::kGcTypeSticky;&#125;</span><br></pre></td></tr></table></figure><p>注意这行代码<br><code>bytes_allocated * (1.0 / GetTargetHeapUtilization() - 1.0);</code><br>这里有一个容易陷入的误区，如果单纯的看头文件中的定义注释</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//Target ideal heap utilization ratio, implements //dalvik.system.VMRuntime.getTargetHeapUtilization.double GetTargetHeapUtilization() </span></span><br><span class="line"><span class="keyword">const</span> &#123;</span><br><span class="line">   <span class="keyword">return</span> target_utilization_;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>可能会认为这个值返回的是默认的最优值0.75，其实这个值是一个动态变化的值，当一次GC发生后，堆的大小会resize。<br>此时GetTargetHeapUtilization的值等于存活对象大小除以堆的大小，算出的delta是除去已分配的字节数后空闲的大小。<br>算出delta后，我们接着往下看，可以看到grow_bytes并不单纯由delta决定，还会受到max_free_以及min_free_的影响，最终确保grow_bytes 的值不会超出这两个值范围。<br>这里的max_free_本意是target_size与已分配内存间可允许的最大差异，差异过小会导致GC频繁，差异过大会延迟下一次GC的到来，目前很多设备将这个值设为8M，min_free_为512K。其实针对RAM超过6G的大内存设备，Google建议可以提高min_free_，用空间换时间获取更好的GC性能。</p><p>有了grow_bytes 之后，再根据如下代码<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bytes_allocated + static_cast&lt;uint64_t&gt;(grow_bytes * multiplier);</span><br></pre></td></tr></table></figure></p><p>计算出目标堆大小。<br>大致的过程可以用下图表示<br><img src="http://blog.lihaizhou.top/ART_GC/ART_GC3.png" alt="图片"></p><h5 id="kGcTypeSticky-GC"><a href="#kGcTypeSticky-GC" class="headerlink" title="kGcTypeSticky GC"></a>kGcTypeSticky GC</h5><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// If we have freed enough memory, shrink the heap back down.</span></span><br><span class="line"><span class="keyword">const</span> <span class="keyword">size_t</span> adjusted_max_free = <span class="keyword">static_cast</span>&lt;<span class="keyword">size_t</span>&gt;(max_free_ * multiplier);</span><br><span class="line"><span class="keyword">if</span> (bytes_allocated + adjusted_max_free &lt; target_footprint) &#123;</span><br><span class="line">    target_size = bytes_allocated + adjusted_max_free;  </span><br><span class="line">    grow_bytes = max_free_;</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">target_size = <span class="built_in">std</span>::max(bytes_allocated, target_footprint);  </span><br><span class="line"><span class="comment">// The same whether jank perceptible or not; just avoid the adjustment.  </span></span><br><span class="line">grow_bytes = <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>对于本次是非kGcTypeSticky回收的方式，设定下次GC类型稍微复杂一些，会涉及到吞吐量之类的指标，后面的GC系列文章中会细谈，这里只关注target_size的计算过程。</p><ul><li>如果bytes_allocated + adjusted_max_free &lt; target_footprint说明此次的GC回收效果明显，注意这里grow_bytes 的值被赋予了max_free_，表示倾向于预留max_free_的空间大小，所以对于这个判断条件中的情况，其grow_bytes 会是一个恒定的值即max_free_。</li><li>否则的话即else中的情况，target_size的值是对bytes_allocated和target_footprint两者取最大，到这里你可能会疑惑bytes_allocated较大的情况，其实是有这个可能的，因为并发的缘故，可能存在GC期间分配大小大于回收数值的情况。</li></ul><p>那么此时target_size设定为bytes_allocated，下次分配对象时，bytes_allocated 立马就超出了target_size，会不会导致分配失败的情况？<br>其实不会，唯一限制堆内存分配的只有growth_limit_，这也解释了为何我们前面说target_size只有指导意义，但是这种情况确实会立即触发一次GC。</p><p>下面是谷歌的一段commit message对OOM的解释<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Are we out of memory, and thus should force a GC or fail?</span><br><span class="line">For concurrent collectors,out of memory is defined by growth_limit_</span><br><span class="line">For nonconcurrent collectors it is defined by target_footprint_ </span><br><span class="line">unless grow is set.If grow is set, the limit is growth_limit_ </span><br><span class="line">and we adjust target_footprint_to accomodate the allocation.</span><br></pre></td></tr></table></figure></p><p>这个时候，你可能还有疑问，为啥不将此时的target_size适当的增大，其实是因为此时的GC是Sticky，只回收自上次GC以来新分配的对象，回收力度是比较小的。<br>如果它释放的空间不多，接下来还可以用Full GC来更彻底地回收。<br>换言之，只有等Full GC回收完，才决定将GC的水位提升，因为这时已经尝试了所有回收策略。</p><p><strong>再回到上面提到的问题，multiplier的引入为何能够提升前台应用的性能？</strong><br>关于target_size 的计算过程中，不论是否是kGcTypeSticky方式，都涉及到了multiplier因子，multiplier的引入直接改变了前台应用的target_size值，此时你可能会疑惑这样的话堆使用率不就下降了吗？ <strong>其实这是一种空间换时间的做法</strong></p><p>如果堆大小扩展的不多，那么对于前台应用很快就会用完，下次GC便会早早的到来，虽说现在只有一次暂停，但是仍然可能会带来性能问题。<br>引入multiplier之后，前台应用有了足够的堆空间，会延迟下次GC到来的时间，也可以理解为降低GC的频率。</p><p>画了一个堆大小调整图，针对delta处于min_free和max_free之间的情况<br><img src="http://blog.lihaizhou.top/ART_GC/ART_GC4.png" alt="图片"><br>堆空间调整过程明白了，那么下次GC触发阈值是如何计算出来的呢？</p><h4 id="GC触发阈值的计算"><a href="#GC触发阈值的计算" class="headerlink" title="GC触发阈值的计算"></a>GC触发阈值的计算</h4><p>下面我们将继续往下看，下次GC触发阈值在代码中指的是concurrent_start_bytes_。<br>当我们在Java中通过new分配对象时，VM会调用AllocObjectWithAllocator来执行真实的分配。<br>在每一次成功分配Java对象后，都会去检测是否需要进行下一次GC，这就是GcCauseBackground GC的触发时机。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">AllocObjectWithAllocator-&gt;CheckConcurrentGCForJava-&gt;ShouldConcurrentGCForJava</span><br></pre></td></tr></table></figure><p>关键代码<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">inline</span> <span class="keyword">bool</span> Heap::ShouldConcurrentGCForJava(</span><br><span class="line">    <span class="keyword">size_t</span> new_num_bytes_allocated) &#123;</span><br><span class="line">    <span class="comment">// For a Java allocation, we only check whether the number // of Java allocated bytes excceeds a threshold. </span></span><br><span class="line">    <span class="comment">// By not considering native allocation here, we (a) ensure that Java heap bounds are</span></span><br><span class="line">    <span class="comment">// maintained, and (b) reduce the cost of the check here.</span></span><br><span class="line">    <span class="keyword">return</span> new_num_bytes_allocated &gt;= concurrent_start_bytes_;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>触发的条件需要满足一个判断，就是最后一行代码new_num_bytes_allocated(所有已分配的字节数，包括此次新分配的对象) &gt;= concurrent_start_bytes_(下一次GC触发的阈值)，就请求一次新的GC。<br>new_num_bytes_alloated是当前分配时计算的，concurrent_start_bytes_是上次GC结束时计算的。</p><h5 id="更新target-footprint-值"><a href="#更新target-footprint-值" class="headerlink" title="更新target_footprint_ 值"></a>更新target_footprint_ 值</h5><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (!ignore_target_footprint_) &#123;</span><br><span class="line">    SetIdealFootprint(target_size);</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">void</span> Heap::SetIdealFootprint(<span class="keyword">size_t</span> target_footprint) &#123;</span><br><span class="line">   <span class="keyword">if</span> (target_footprint &gt; GetMaxMemory()) &#123;</span><br><span class="line">       VLOG(gc) &lt;&lt; <span class="string">"Clamp target GC heap from "</span> &lt;&lt; PrettySize(target_footprint) &lt;&lt; <span class="string">" to "</span></span><br><span class="line">       &lt;&lt; PrettySize(GetMaxMemory());</span><br><span class="line">       target_footprint = GetMaxMemory();</span><br><span class="line">   &#125;</span><br><span class="line">   target_footprint_.store(target_footprint, <span class="built_in">std</span>::memory_order_relaxed);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>存储target_size的值，并通过target_size更新target_footprint_ 的值</p><h5 id="concurrent-start-bytes"><a href="#concurrent-start-bytes" class="headerlink" title="concurrent_start_bytes_"></a>concurrent_start_bytes_</h5><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Minimum amount of remaining bytes before a concurrent GC is triggered.</span></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">constexpr</span> <span class="keyword">size_t</span> kMinConcurrentRemainingBytes = <span class="number">128</span> * KB;</span><br><span class="line"><span class="keyword">static</span> <span class="keyword">constexpr</span> <span class="keyword">size_t</span> kMaxConcurrentRemainingBytes = <span class="number">512</span> * KB;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (IsGcConcurrent()) &#123;</span><br><span class="line">    <span class="keyword">const</span> <span class="keyword">uint64_t</span> freed_bytes = current_gc_iteration_.GetFreedBytes() +</span><br><span class="line">    current_gc_iteration_.GetFreedLargeObjectBytes() +</span><br><span class="line">    current_gc_iteration_.GetFreedRevokeBytes();</span><br><span class="line">    <span class="comment">// Records the number of bytes allocated at the time of GC finish,excluding the number of</span></span><br><span class="line">    <span class="comment">// bytes allocated during GC.</span></span><br><span class="line">    num_bytes_alive_after_gc_ = UnsignedDifference(bytes_allocated_before_gc, freed_bytes);</span><br><span class="line">    <span class="comment">// Bytes allocated will shrink by freed_bytes after the GC runs, so if we want to figure out</span></span><br><span class="line">    <span class="comment">// how many bytes were allocated during the GC we need to add freed_bytes back on.</span></span><br><span class="line">    <span class="comment">// Almost always bytes_allocated + freed_bytes &gt;= bytes_allocated_before_gc.</span></span><br><span class="line">    <span class="keyword">const</span> <span class="keyword">size_t</span> bytes_allocated_during_gc =</span><br><span class="line">          UnsignedDifference(bytes_allocated + freed_bytes, bytes_allocated_before_gc);</span><br><span class="line">    <span class="comment">// Calculate when to perform the next ConcurrentGC.</span></span><br><span class="line">    <span class="comment">// Estimate how many remaining bytes we will have when we need to start the next GC.</span></span><br><span class="line">    <span class="keyword">size_t</span> remaining_bytes = bytes_allocated_during_gc;</span><br><span class="line">    remaining_bytes = <span class="built_in">std</span>::min(remaining_bytes, kMaxConcurrentRemainingBytes);</span><br><span class="line">    remaining_bytes = <span class="built_in">std</span>::max(remaining_bytes, kMinConcurrentRemainingBytes);</span><br><span class="line">    <span class="keyword">size_t</span> target_footprint = target_footprint_.load(<span class="built_in">std</span>::memory_order_relaxed);</span><br><span class="line">    <span class="keyword">if</span> (UNLIKELY(remaining_bytes &gt; target_footprint)) &#123;</span><br><span class="line">       <span class="comment">// A never going to happen situation that from the estimated allocation rate we will exceed</span></span><br><span class="line">      <span class="comment">// the applications entire footprint with the given estimated allocation rate. Schedul</span></span><br><span class="line">      <span class="comment">// another GC nearly straight away.</span></span><br><span class="line">      remaining_bytes = <span class="built_in">std</span>::min(kMinConcurrentRemainingBytes, target_footprint);</span><br><span class="line">     &#125;</span><br><span class="line">     DCHECK_LE(target_footprint_.load(<span class="built_in">std</span>::memory_order_relaxed), GetMaxMemory());</span><br><span class="line">     <span class="comment">// Start a concurrent GC when we get close to the estimated remaining bytes. When the</span></span><br><span class="line">     <span class="comment">// allocation rate is very high, remaining_bytes could tell us that we should start a GC</span></span><br><span class="line">     <span class="comment">// right away.</span></span><br><span class="line">     concurrent_start_bytes_ = <span class="built_in">std</span>::max(target_footprint - remaining_bytes, bytes_allocated);</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure><p>整个处理过程大致流程如下：</p><ol><li>num_bytes_alive_after_gc_此次GC结束后已分配的字节数，不包括GC期间新分配的字节数</li><li>bytes_allocated_during_gcGC<br>期间分配的字节数，计算很简单，通过bytes_allocated_before_gc减去freed_bytes就 是新增的，因为由于并发的缘故，分配和回收很可能是同步进行的，这个思想将贯穿整个GC机制。</li><li>remaining_bytes这个值指的是gc期间新分配对象的大小。<br>同样的，对于预留值也有范围限制，限制在128 <em> KB到512 </em> KB范围之间之间。</li></ol><p>最后再来看这个计算公式concurrent_start_bytes_ =<br><code>std::max(target_footprint - remaining_bytes, bytes_allocated);</code></p><p>之所以需要用target_footprint减去remaining_bytes，是因为在理论意义上，target_footprint_代表当前堆的最大可分配字节数。而由于是同步GC，回收的过程中可能会有其他线程依然在分配。<br>所以为了保证下次GC的顺利进行，需要将这段时间分配的内存空间预留出来。<br>总结下concurrent_start_bytes_ 的值计算过程:<br><strong>用heap resize之后计算出的target_size减去remaining_bytes后的数值，得出来的concurrent_start_bytes_ 作为下次是否触发GC的阈值。</strong></p><h5 id="Systrace角度看GC"><a href="#Systrace角度看GC" class="headerlink" title="Systrace角度看GC"></a>Systrace角度看GC</h5><p>我们平时工作中，分析GC性能问题用到最多的便是Systrace<br>下面抓取一次抖音包含启动过程的Systrace，看下GC情况以及堆大小的变化情况。<br>在启动过程中，堆的大小持续增长<br><img src="http://blog.lihaizhou.top/ART_GC/ART_GC5.png" alt="图片"></p><p>启动结束后约1s左右，有一次Background young concurrent copying GC<br><img src="http://blog.lihaizhou.top/ART_GC/ART_GC6.png" alt="图片"></p><p>可以看到heap size从59M下降到约11M<br>此时处于前台很快数值上升，并触发Background concurrent copying GC<br><img src="http://blog.lihaizhou.top/ART_GC/ART_GC7.png" alt="图片"></p><p>这两次GC类型都是并发GC，以界面显示后的第一次Background young concurrent copying GC为例<br>从Systrace大致可以看到其流程是<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">InitializePhase(995us692ns)-&gt;CopyingPhase(84ms258us385ns) -&gt;ReclaimPhase(11ms 166us 769ns)</span><br></pre></td></tr></table></figure></p><p>对应到代码中大致流程如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CollectGarbageInternal---&gt; collector---&gt;Run(开始真正的GC流程)---&gt; RunPhases(GC实际处理)</span><br></pre></td></tr></table></figure></p><h4 id="参数修改策略"><a href="#参数修改策略" class="headerlink" title="参数修改策略"></a>参数修改策略</h4><p>通过上面的梳理，我们知道GC的触发以及堆大小的调整会受到max_free_，min_free_，kDefaultTargetUtilization 这些参数影响，这些参数其实有系统属性暴露在外，厂商可以根据实际的需求进行修改。<br>以max_free为例，看了下手头的4G手机项目上默认值是8M，从前面的梳理我们知道，如果增大max_free会导致应用的预留空闲内存增大，相应的应用占用内存大小也会增大，这是带来的弊端。<br>但是好处显而易见，GC的频率会降低，性能会有所提升，所以这是一个权衡的策略。</p><p>如果项目上实测发现GC频繁触发，可以适当的增大max_free的值再进行测试，谷歌的建议是不要修改，除非有大量可靠的测试数据做支撑说明修改后的参数确实有提升。</p><p>下面是我手头4G内存手机打印的参数<br><img src="http://blog.lihaizhou.top/ART_GC/ART_GC8.png" alt="图片"></p><h4 id="写在最后"><a href="#写在最后" class="headerlink" title="写在最后"></a>写在最后</h4><p>至此，本文结合Android S源码和systrace对ART GC的基础知识介绍完毕。<br>在书写本文期间，阅读了网上一些优秀的资源，如老罗，芦航，oppo内核等人书写的ART技术文章，受益匪浅，在此感谢这些技术大咖的无私分享。<br>最后说两句，GC对Android整机性能表现起到至关重要的影响，关于ART GC的性能一直是Google在主导优化，同时也是SOC厂商，各家手机厂商长期以来一直努力优化的方向。<br>我们希望通过对ART GC领域的持续研究，为后面的实际问题分析乃至GC机制的优化修改提供技术支撑。</p><h4 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h4><ol><li>ART运行时Foreground GC和Background GC切换过程分<br><a href="https://www.kancloud.cn/alex_wsc/androids/472237" target="_blank" rel="noopener">https://www.kancloud.cn/alex_wsc/androids/472237</a></li><li>Android性能优化（31）—虚拟机调优<br><a href="https://blog.csdn.net/zhangbijun1230/article/details/79996702" target="_blank" rel="noopener">https://blog.csdn.net/zhangbijun1230/article/details/79996702</a></li><li>ART虚拟机 | GC的触发时机和条件<br><a href="https://juejin.cn/post/6875678394332217357" target="_blank" rel="noopener">https://juejin.cn/post/6875678394332217357</a></li></ol><hr><p>时间真快，不知不觉今天已经周三了，印象中上次周三的时候还是在上周</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h4&gt;&lt;p&gt;本文是GC系列文章的首篇，主要为下一篇《第三视角: 一个ART GC优化的故事》文章做铺垫。&lt;br&gt;本文将根据下面的大纲，简单的介绍下GC相
      
    
    </summary>
    
      <category term="ART" scheme="http://lihaizhou.top/categories/ART/"/>
    
    
  </entry>
  
  <entry>
    <title>对进程压缩消费Zram速度的优化</title>
    <link href="http://lihaizhou.top/2021/10/16/%E5%AF%B9%E8%BF%9B%E7%A8%8B%E5%8E%8B%E7%BC%A9%E6%B6%88%E8%B4%B9Zram%E9%80%9F%E5%BA%A6%E7%9A%84%E4%BC%98%E5%8C%96/"/>
    <id>http://lihaizhou.top/2021/10/16/对进程压缩消费Zram速度的优化/</id>
    <published>2021-10-16T02:32:08.000Z</published>
    <updated>2021-10-16T04:59:55.924Z</updated>
    
    <content type="html"><![CDATA[<h4 id="从全局看Zram"><a href="#从全局看Zram" class="headerlink" title="从全局看Zram"></a>从全局看Zram</h4><p><img src="http://blog.lihaizhou.top/%E8%BF%9B%E7%A8%8B%E5%8E%8B%E7%BC%A9%E6%B6%88%E8%80%97Zram/gaitubao_Zram.png" alt="Zram的消费"></p><h4 id="修改演变历程"><a href="#修改演变历程" class="headerlink" title="修改演变历程"></a>修改演变历程</h4><p><img src="http://blog.lihaizhou.top/%E8%BF%9B%E7%A8%8B%E5%8E%8B%E7%BC%A9%E6%B6%88%E8%80%97Zram/shuiyin_yanbian.png" alt="进程压缩对Zram的消耗修改时间线"></p><h4 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h4><p>当前的修改方案可能不是最优方案，但是解决了之前遇到的实际问题，后面如果遇到新的问题可能还会进行调整。</p><hr><p>Have a good day~</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;从全局看Zram&quot;&gt;&lt;a href=&quot;#从全局看Zram&quot; class=&quot;headerlink&quot; title=&quot;从全局看Zram&quot;&gt;&lt;/a&gt;从全局看Zram&lt;/h4&gt;&lt;p&gt;&lt;img src=&quot;http://blog.lihaizhou.top/%E8%BF%9B%
      
    
    </summary>
    
      <category term="内存" scheme="http://lihaizhou.top/categories/%E5%86%85%E5%AD%98/"/>
    
    
  </entry>
  
  <entry>
    <title>AMS锁严重竞争导致的整机卡顿</title>
    <link href="http://lihaizhou.top/2021/09/18/AMS%E9%94%81%E4%B8%A5%E9%87%8D%E7%AB%9E%E4%BA%89%E5%AF%BC%E8%87%B4%E7%9A%84%E6%95%B4%E6%9C%BA%E5%8D%A1%E9%A1%BF/"/>
    <id>http://lihaizhou.top/2021/09/18/AMS锁严重竞争导致的整机卡顿/</id>
    <published>2021-09-18T02:37:49.000Z</published>
    <updated>2021-10-16T05:13:46.925Z</updated>
    
    <content type="html"><![CDATA[<h5 id="日志抓取"><a href="#日志抓取" class="headerlink" title="日志抓取"></a>日志抓取</h5><p>在问题机器上抓了一份Systrace<br>1.操作步骤: 进入设置界面滑动再退出<br>2.问题现象: 进入设置出现较长时间白屏，退出时有拖影，下拉状态栏尤为卡顿，解锁亮屏很慢。</p><h5 id="问题分析"><a href="#问题分析" class="headerlink" title="问题分析"></a>问题分析</h5><p>从下图可以看到进入设置时，Resume耗时近400ms，主要耗费在等binder上<br><img src="http://blog.lihaizhou.top/AMS_lock/broadcast1.png" alt=""><br>来到对端1188_19线程所在区域，看下这个时间点1188_19在做什么操作？<br><img src="http://blog.lihaizhou.top/AMS_lock/broadcast2.png" alt=""><br>1188_19是SystemServer中的线程，从上图可以看出，它在等AMS锁<br>到这里大致梳理如下<br>1.进入设置应用走到onResume环节时，调用到AMS的registerReceiverWithFeature注册广播，这是应用启动过程中很常见的操作，但是此时registerReceiverWithFeature执行操作被block了，因为执行registerReceiverWithFeature需要申请到AMS锁才行。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> Intent <span class="title">registerReceiverWithFeature</span><span class="params">(IApplicationThread caller, String callerPackage,</span></span></span><br><span class="line"><span class="function"><span class="params">   String callerFeatureId, IIntentReceiver receiver, IntentFilter filter,</span></span></span><br><span class="line"><span class="function"><span class="params">   String permission, <span class="keyword">int</span> userId, <span class="keyword">int</span> flags)</span> </span>&#123;</span><br><span class="line">   <span class="comment">//省略部分代码</span></span><br><span class="line">   <span class="keyword">boolean</span> instantApp;</span><br><span class="line">   <span class="keyword">synchronized</span>(<span class="keyword">this</span>) &#123;</span><br><span class="line">      <span class="keyword">if</span> (caller != <span class="keyword">null</span>) &#123;</span><br><span class="line">          callerApp = getRecordForAppLocked(caller);</span><br><span class="line">          <span class="keyword">if</span> (callerApp == <span class="keyword">null</span>) &#123;</span><br><span class="line">              <span class="keyword">throw</span> <span class="keyword">new</span> SecurityException(</span><br><span class="line">                  <span class="string">"Unable to find app for caller "</span> + caller</span><br><span class="line">                      + <span class="string">" (pid="</span> + Binder.getCallingPid()</span><br><span class="line">                      + <span class="string">") when registering receiver "</span> + receiver);</span><br><span class="line">          &#125;</span><br><span class="line">          <span class="comment">//省略部分代码</span></span><br><span class="line">      &#125;</span><br><span class="line">    <span class="comment">//省略部分代码</span></span><br></pre></td></tr></table></figure><p>2.此时Settings的registerReceiverWithFeature在等ActivityManagerService#finishReceiver释放锁，但其实ActivityManagerService#finishReceiver本身也是在等锁，锁在1188_6这个线程手中。<br>图中有一处waiters=6说明还有其它六处加上这次调用共计7处在等AMS的锁<br>纵观整个应用操作片段，发现很多地方都在等AMS锁，这也说明了为何系统会全局卡顿。</p><p>看下真正持有锁的1188_6这个线程,这个线程持有锁的这段时间内，大部分时候都是running状态<br><img src="http://blog.lihaizhou.top/AMS_lock/broadcast3.png" alt=""><br>全局搜索了下在一分钟不到的时间内触发了197次，而且单次基本都在200ms之久。<br><img src="http://blog.lihaizhou.top/AMS_lock/broadcast4.png" alt=""><br>为此对比了下正常情况下的Systrace，两分钟的时间内共触发14次，平均一分钟7次，且每次updateOomAdj_finishReceiver执行时间都不超过1ms<br><img src="http://blog.lihaizhou.top/AMS_lock/broadcast5.png" alt=""></p><p>到这里大概整理下<br>1.<strong>为何updateOomAdj_finishReceiver会调用这么频繁?</strong><br>  updateOomAdj_finishReceiver是在广播处理结束后会触发调用，问题机器上一分钟调用197次，正常情况下一分钟调用次数是个位数.<br>2.<strong>为何updateOomAdj_finishReceiver耗时这么久?</strong><br>  单次执行都在200ms左右，这也意味着每次持有AMS锁大概200ms，也就意味着一分钟的时间finishReceiver持有AMS锁时间高达39s，这也解释了从Systrace看很多地方都在等AMS锁。<br>  测试了下正常情况下，updateOomAdj_finishReceiver单次执行时间最长一般不会超过1ms</p><p>下面先从广播来源分析，updateOomAdj_finishReceiver触发频繁的原因</p><h6 id="频繁触发原因"><a href="#频繁触发原因" class="headerlink" title="频繁触发原因"></a>频繁触发原因</h6><p>以导致设置应用resume耗时严重的这次updateOomAdj_finishReceiver为例<br><img src="http://blog.lihaizhou.top/AMS_lock/broadcast6.png" alt=""><br>1416对应的是SystemUI中线程，直接来到SystemServer区域看下广播部分<br><img src="http://blog.lihaizhou.top/AMS_lock/broadcast7.png" alt=""><br>再从全局来看<br><img src="http://blog.lihaizhou.top/AMS_lock/broadcast8.png" alt=""><br>可以看到com.android.providers.media.module以及SystemUI这两个模块在交替不间断的发送android.intent.action.MEDIA_SCANNER_SCAN_FILE这个广播，查看代码得知是com.android.providers.media.module这个模块处理扫描文件事务后会发送MEDIA_SCANNER_SCAN_FILE这个广播给SystemUI，SystemUI收到这个广播进行一系列的业务处理，然后再次发送MEDIA_SCANNER_SCAN_FILE这个广播出来。<br>这种业务设计肯定是不合理的，这里暂不继续讨论这种做法的缘由。</p><h6 id="单次处理耗时"><a href="#单次处理耗时" class="headerlink" title="单次处理耗时"></a>单次处理耗时</h6><p><img src="http://blog.lihaizhou.top/AMS_lock/broadcast9.png" alt=""><br>从上图可以看到，问题发生时，SystemUI模块中单次处理该模块耗时达到1s多，这也和问题机器上SystemUI下拉栏滑动极其卡顿能够对应上。<br>结论: SystemUI主线程中广播处理耗时导致滑动很卡顿</p><h5 id="问题结论"><a href="#问题结论" class="headerlink" title="问题结论"></a>问题结论</h5><p>主要由于如下两点原因导致:<br>1.SystemUI中不合理的高频广播，导致AMS@finishReceiver触发频繁并持有AMS锁，造成了全局AMS锁争抢极其严重。<br>2.SystemUI主线程中单次处理广播耗时较长，加剧了卡顿的现象。</p><p>PS: SystemUI这个模块比较特殊，它不像其他应用模块。对于应用模块而言，即便是一直收发广播，卡顿也只是会局限在这个应用操作环节中，不会影响到其他模块。但是SystemUI就不同了，它是可以一直运行着，并且此时你可以操作其他任何应用。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h5 id=&quot;日志抓取&quot;&gt;&lt;a href=&quot;#日志抓取&quot; class=&quot;headerlink&quot; title=&quot;日志抓取&quot;&gt;&lt;/a&gt;日志抓取&lt;/h5&gt;&lt;p&gt;在问题机器上抓了一份Systrace&lt;br&gt;1.操作步骤: 进入设置界面滑动再退出&lt;br&gt;2.问题现象: 进入设置出现较长时
      
    
    </summary>
    
      <category term="性能" scheme="http://lihaizhou.top/categories/%E6%80%A7%E8%83%BD/"/>
    
    
  </entry>
  
  <entry>
    <title>GC超时导致的后台应用崩溃问题分析</title>
    <link href="http://lihaizhou.top/2021/09/08/GC%E8%B6%85%E6%97%B6%E5%AF%BC%E8%87%B4%E7%9A%84%E5%90%8E%E5%8F%B0%E5%BA%94%E7%94%A8%E5%B4%A9%E6%BA%83%E9%97%AE%E9%A2%98%E5%88%86%E6%9E%90/"/>
    <id>http://lihaizhou.top/2021/09/08/GC超时导致的后台应用崩溃问题分析/</id>
    <published>2021-09-08T11:55:06.000Z</published>
    <updated>2021-10-16T05:21:11.556Z</updated>
    
    <content type="html"><![CDATA[<h3 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h3><p>这个问题之所以会拿出来仔细分析，一方面是因为这个问题不是简单的应用崩溃而是框架层的报错，另一方面是因为希望通过这个问题梳理下后台GC的超时检测机制怎样的，这样我们后面在应用层如果重写<code>finalize</code>方法回收时会考虑的更加全面点。</p><h3 id="问题背景"><a href="#问题背景" class="headerlink" title="问题背景"></a>问题背景</h3><p>复现概率: 偶现<br>问题版本: <code>Android R</code><br>问题现象: 处于微信界面，突然弹出王者荣耀停止运行</p><h3 id="初步分析"><a href="#初步分析" class="headerlink" title="初步分析"></a>初步分析</h3><p>拿到问题日志后，先看下报错的堆栈<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">09</span>-<span class="number">02</span> <span class="number">20</span>:<span class="number">53</span>:<span class="number">26.679</span>  <span class="number">2073</span>  <span class="number">2089</span> E AndroidRuntime: FATAL EXCEPTION: FinalizerWatchdogDaemon</span><br><span class="line"><span class="number">09</span>-<span class="number">02</span> <span class="number">20</span>:<span class="number">53</span>:<span class="number">26.679</span>  <span class="number">2073</span>  <span class="number">2089</span> E AndroidRuntime: Process: com.tencent.tmgp.sgame:xg_vip_service, PID: <span class="number">2073</span></span><br><span class="line"><span class="number">09</span>-<span class="number">02</span> <span class="number">20</span>:<span class="number">53</span>:<span class="number">26.679</span>  <span class="number">2073</span>  <span class="number">2089</span> E AndroidRuntime: java.util.concurrent.TimeoutException: android.database.BulkCursorToCursorAdaptor.finalize() timed out after <span class="number">10</span> seconds</span><br><span class="line"><span class="comment">//省略部分堆栈</span></span><br><span class="line"><span class="number">09</span>-<span class="number">02</span> <span class="number">20</span>:<span class="number">53</span>:<span class="number">26.679</span>  <span class="number">2073</span>  <span class="number">2089</span> E AndroidRuntime:at android.database.AbstractCursor.finalize(AbstractCursor.java:<span class="number">524</span>)</span><br><span class="line"><span class="number">09</span>-<span class="number">02</span> <span class="number">20</span>:<span class="number">53</span>:<span class="number">26.679</span>  <span class="number">2073</span>  <span class="number">2089</span> E AndroidRuntime:at java.lang.Daemons$FinalizerDaemon.doFinalize(Daemons.java:<span class="number">291</span>)</span><br><span class="line"><span class="number">09</span>-<span class="number">02</span> <span class="number">20</span>:<span class="number">53</span>:<span class="number">26.679</span>  <span class="number">2073</span>  <span class="number">2089</span> E AndroidRuntime:at java.lang.Daemons$FinalizerDaemon.runInternal(Daemons.java:<span class="number">278</span>)</span><br></pre></td></tr></table></figure></p><p>单单从这段堆栈看的话，<code>BulkCursorToCursorAdaptor</code>执行<code>finalize</code>超过了10s，导致<code>FinalizerWatchdogDaemon</code>报错，<code>FinalizerWatchdogDaemon</code>字面上看像是监测回收超时的守护线程。<br>看下<code>FinalizerWatchdogDaemon</code>代码中的作用解释<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * The watchdog exits the VM if the finalizer ever gets stuck. We consider</span></span><br><span class="line"><span class="comment"> * the finalizer to be stuck if it spends more than MAX_FINALIZATION_MILLIS</span></span><br><span class="line"><span class="comment"> * on one instance.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">FinalizerWatchdogDaemon</span> <span class="keyword">extends</span> <span class="title">Daemon</span> </span>&#123;</span><br><span class="line">    <span class="meta">@UnsupportedAppUsage</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> FinalizerWatchdogDaemon INSTANCE = <span class="keyword">new</span> FinalizerWatchdogDaemon();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">boolean</span> needToWork = <span class="keyword">true</span>;  <span class="comment">// Only accessed in synchronized methods.</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">long</span> finalizerTimeoutNs = <span class="number">0</span>;  <span class="comment">// Lazily initialized.</span></span><br><span class="line"></span><br><span class="line">    FinalizerWatchdogDaemon() &#123;</span><br><span class="line">        <span class="keyword">super</span>(<span class="string">"FinalizerWatchdogDaemon"</span>);</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure></p><p>简单解释下就是：如果对象的<code>finalize</code>出现阻塞超时了会导致进程退出</p><p>这个问题中对应的是数据库的关闭，当然也可以发生在其它场景下，只要重写了成员函数<code>finalize</code>的对象都有可能会遇到这个问题，所以如果再遇到GC超时的报错，报错堆栈<code>AndroidRuntime:at java.lang.Daemons$</code>上面的内容可能会不一样。<br><strong>那么对于重写了成员函数<code>finalize</code>的对象，当它们被GC决定要被回收时，会立刻回收吗？</strong><br>其实不会马上被回收，而是被放入到一个队列中，等待<code>FinalizerDaemon</code>守护线程去调用它们的成员函数<code>finalize</code>后再被回收。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * This heap management thread moves elements from the garbage collector's</span></span><br><span class="line"><span class="comment"> * pending list to the managed reference queue.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">ReferenceQueueDaemon</span> <span class="keyword">extends</span> <span class="title">Daemon</span> </span>&#123;</span><br><span class="line">    <span class="meta">@UnsupportedAppUsage</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> ReferenceQueueDaemon INSTANCE = <span class="keyword">new</span> ReferenceQueueDaemon();</span><br><span class="line"></span><br><span class="line">    ReferenceQueueDaemon() &#123;</span><br><span class="line">        <span class="keyword">super</span>(<span class="string">"ReferenceQueueDaemon"</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span> <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">runInternal</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">while</span> (isRunning()) &#123;</span><br><span class="line">            Reference&lt;?&gt; list;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                <span class="keyword">synchronized</span> (ReferenceQueue.class) &#123;</span><br><span class="line">                    <span class="keyword">while</span> (ReferenceQueue.unenqueued == <span class="keyword">null</span>) &#123;</span><br><span class="line">                        ReferenceQueue.class.wait();</span><br><span class="line">                    &#125;</span><br><span class="line">                    list = ReferenceQueue.unenqueued;</span><br><span class="line">                    ReferenceQueue.unenqueued = <span class="keyword">null</span>;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">                <span class="keyword">continue</span>;</span><br><span class="line">            &#125; <span class="keyword">catch</span> (OutOfMemoryError e) &#123;</span><br><span class="line">                <span class="keyword">continue</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            ReferenceQueue.enqueuePending(list);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="超时阈值"><a href="#超时阈值" class="headerlink" title="超时阈值"></a>超时阈值</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// This used to be final. IT IS NOW ONLY WRITTEN. We now update it when we look at the command</span></span><br><span class="line"><span class="comment">// line argument, for the benefit of mis-behaved apps that might read it.  SLATED FOR REMOVAL.</span></span><br><span class="line"><span class="comment">// There is no reason to use this: Finalizers should not rely on the value. If a finalizer takes</span></span><br><span class="line"><span class="comment">// appreciable time, the work should be done elsewhere.  Based on disassembly of Daemons.class,</span></span><br><span class="line"><span class="comment">// the value is effectively inlined, so changing the field never did have an effect.</span></span><br><span class="line"><span class="comment">// DO NOT USE. FOR ANYTHING. THIS WILL BE REMOVED SHORTLY.</span></span><br><span class="line"><span class="meta">@UnsupportedAppUsage</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">long</span> MAX_FINALIZE_NANOS = <span class="number">10L</span> * <span class="number">1000</span> * NANOS_PER_MILLI;</span><br></pre></td></tr></table></figure><p>注释中对于该值的说明是它很快将被移除，实际这个值在代码中并没有起到真正的作用了，更新它的值是为了方便在外边读取到。<br>真正的超时阈值是通过<code>VMRuntime.getFinalizerTimeoutMs</code>获取，默认值是10s.<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">finalizer_timeout_ms_ = runtime_options.GetOrDefault(Opt::FinalizerTimeoutMs);</span><br><span class="line">RUNTIME_OPTIONS_KEY (unsigned <span class="keyword">int</span>, FinalizerTimeoutMs, <span class="number">10000</span>u)</span><br></pre></td></tr></table></figure></p><h3 id="超时检测"><a href="#超时检测" class="headerlink" title="超时检测"></a>超时检测</h3><p>通过watchdog机制检测<code>finalizer</code>在超时时间内有没有成功析构回收对象<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"> * The watchdog exits the VM <span class="keyword">if</span> the finalizer ever gets stuck. We consider</span><br><span class="line"> * the finalizer to be stuck <span class="keyword">if</span> it spends more than MAX_FINALIZATION_MILLIS</span><br><span class="line"> * on one instance.</span><br><span class="line"> */</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">FinalizerWatchdogDaemon</span> <span class="keyword">extends</span> <span class="title">Daemon</span> </span>&#123;</span><br><span class="line">    <span class="meta">@UnsupportedAppUsage</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> FinalizerWatchdogDaemon INSTANCE = <span class="keyword">new</span> FinalizerWatchdogDaemon();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">boolean</span> needToWork = <span class="keyword">true</span>;  <span class="comment">// Only accessed in synchronized methods.</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">long</span> finalizerTimeoutNs = <span class="number">0</span>;  <span class="comment">// Lazily initialized.</span></span><br><span class="line"></span><br><span class="line">    FinalizerWatchdogDaemon() &#123;</span><br><span class="line">        <span class="keyword">super</span>(<span class="string">"FinalizerWatchdogDaemon"</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span> <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">runInternal</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">while</span> (isRunning()) &#123;</span><br><span class="line">            <span class="keyword">if</span> (!sleepUntilNeeded()) &#123; (<span class="number">1</span>)</span><br><span class="line">                <span class="comment">// We have been interrupted, need to see if this daemon has been stopped.</span></span><br><span class="line">                <span class="keyword">continue</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">final</span> Object finalizing = waitForFinalization();(<span class="number">2</span>)</span><br><span class="line">            <span class="keyword">if</span> (finalizing != <span class="keyword">null</span> &amp;&amp; !VMDebug.isDebuggerConnected()) &#123;</span><br><span class="line">                finalizerTimedOut(finalizing);(<span class="number">3</span>)</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure></p><h4 id="Step1-GC前的检查"><a href="#Step1-GC前的检查" class="headerlink" title="Step1 GC前的检查"></a>Step1 GC前的检查</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">        * Notify daemon that it's OK to sleep until notified that something is ready to be</span></span><br><span class="line"><span class="comment">        * finalized.</span></span><br><span class="line"><span class="comment">        */</span></span><br><span class="line">       <span class="function"><span class="keyword">private</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">goToSleep</span><span class="params">()</span> </span>&#123;</span><br><span class="line">           needToWork = <span class="keyword">false</span>;</span><br><span class="line">       &#125;</span><br><span class="line"></span><br><span class="line">       <span class="comment">/**</span></span><br><span class="line"><span class="comment">        * Notify daemon that there is something ready to be finalized.</span></span><br><span class="line"><span class="comment">        */</span></span><br><span class="line">       <span class="function"><span class="keyword">private</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">wakeUp</span><span class="params">()</span> </span>&#123;</span><br><span class="line">           needToWork = <span class="keyword">true</span>;</span><br><span class="line">           notify();</span><br><span class="line">       &#125;</span><br></pre></td></tr></table></figure><p>开启回收之前，<code>needToWork</code>会被置为true，此时<code>sleepUntilNeeded</code>返回的是true，所以线程不会<code>wait</code><br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Override</span> <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">runInternal</span><span class="params">()</span> </span>&#123;</span><br><span class="line">           <span class="comment">// This loop may be performance critical, since we need to keep up with mutator</span></span><br><span class="line">           <span class="comment">// generation of finalizable objects.</span></span><br><span class="line">           <span class="comment">// We minimize the amount of work we do per finalizable object. For example, we avoid</span></span><br><span class="line">           <span class="comment">// reading the current time here, since that involves a kernel call per object.  We</span></span><br><span class="line">           <span class="comment">// limit fast path communication with FinalizerWatchDogDaemon to what's unavoidable: A</span></span><br><span class="line">           <span class="comment">// non-volatile store to communicate the current finalizable object, e.g. for</span></span><br><span class="line">           <span class="comment">// reporting, and a release store (lazySet) to a counter.</span></span><br><span class="line">           <span class="comment">// We do stop the  FinalizerWatchDogDaemon if we have nothing to do for a</span></span><br><span class="line">           <span class="comment">// potentially extended period.  This prevents the device from waking up regularly</span></span><br><span class="line">           <span class="comment">// during idle times.</span></span><br><span class="line"></span><br><span class="line">           <span class="comment">// Local copy of progressCounter; saves a fence per increment on ARM and MIPS.</span></span><br><span class="line">           <span class="keyword">int</span> localProgressCounter = progressCounter.get();</span><br><span class="line"></span><br><span class="line">           <span class="keyword">while</span> (isRunning()) &#123;</span><br><span class="line">               <span class="keyword">try</span> &#123;</span><br><span class="line">                   <span class="comment">// Use non-blocking poll to avoid FinalizerWatchdogDaemon communication</span></span><br><span class="line">                   <span class="comment">// when busy.</span></span><br><span class="line">                   FinalizerReference&lt;?&gt; finalizingReference = (FinalizerReference&lt;?&gt;)queue.poll();</span><br><span class="line">                   <span class="keyword">if</span> (finalizingReference != <span class="keyword">null</span>) &#123;</span><br><span class="line">                       finalizingObject = finalizingReference.get();</span><br><span class="line">                       progressCounter.lazySet(++localProgressCounter);</span><br><span class="line">                   &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                       finalizingObject = <span class="keyword">null</span>;</span><br><span class="line">                       progressCounter.lazySet(++localProgressCounter);</span><br><span class="line">                       <span class="comment">// Slow path; block.</span></span><br><span class="line">                       FinalizerWatchdogDaemon.INSTANCE.goToSleep();</span><br><span class="line">                       finalizingReference = (FinalizerReference&lt;?&gt;)queue.remove();</span><br><span class="line">                       finalizingObject = finalizingReference.get();</span><br><span class="line">                       progressCounter.set(++localProgressCounter);</span><br><span class="line">                       <span class="comment">//回收之前先唤醒看门狗线程</span></span><br><span class="line">                       FinalizerWatchdogDaemon.INSTANCE.wakeUp();</span><br><span class="line">                   &#125;</span><br><span class="line">                   <span class="comment">//开始回收的流程</span></span><br><span class="line">                   doFinalize(finalizingReference);</span><br><span class="line">               &#125; <span class="keyword">catch</span> (InterruptedException ignored) &#123;</span><br><span class="line">               &#125; <span class="keyword">catch</span> (OutOfMemoryError ignored) &#123;</span><br><span class="line">               &#125;</span><br><span class="line">           &#125;</span><br><span class="line">       &#125;</span><br></pre></td></tr></table></figure></p><p>如果此时线程处于<code>wait</code>，被中断了或者有<code>OOME</code>发生时，这个时候回到开头判断下<code>isRunning()</code>，也就是看下回收对象这个线程是否为空，如果该线程为空的话，这个循环体就没有必要再继续执行下去了。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">        * Wait until something is ready to be finalized.</span></span><br><span class="line"><span class="comment">        * Return false if we have been interrupted</span></span><br><span class="line"><span class="comment">        * See also http://code.google.com/p/android/issues/detail?id=22778.</span></span><br><span class="line"><span class="comment">        */</span></span><br><span class="line">       <span class="function"><span class="keyword">private</span> <span class="keyword">synchronized</span> <span class="keyword">boolean</span> <span class="title">sleepUntilNeeded</span><span class="params">()</span> </span>&#123;</span><br><span class="line">           <span class="keyword">while</span> (!needToWork) &#123;</span><br><span class="line">               <span class="keyword">try</span> &#123;</span><br><span class="line">                   wait();</span><br><span class="line">               &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">                   <span class="comment">// Daemon.stop may have interrupted us.</span></span><br><span class="line">                   <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">               &#125; <span class="keyword">catch</span> (OutOfMemoryError e) &#123;</span><br><span class="line">                   <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">               &#125;</span><br><span class="line">           &#125;</span><br><span class="line">           <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">       &#125;</span><br></pre></td></tr></table></figure></p><h4 id="Step2-等待GC完成"><a href="#Step2-等待GC完成" class="headerlink" title="Step2 等待GC完成"></a>Step2 等待GC完成</h4><p>这一步是等待回收结束的过程，这个睡眠过程中如果被中断，说明在这个周期内完成了析构，直接返回null<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">        * Return an object that took too long to finalize or return null.</span></span><br><span class="line"><span class="comment">        * Wait VMRuntime.getFinalizerTimeoutMs.  If the FinalizerDaemon took essentially the</span></span><br><span class="line"><span class="comment">        * whole time processing a single reference, return that reference.  Otherwise return</span></span><br><span class="line"><span class="comment">        * null.  Only called from a single thread.</span></span><br><span class="line"><span class="comment">        */</span></span><br><span class="line">       <span class="function"><span class="keyword">private</span> Object <span class="title">waitForFinalization</span><span class="params">()</span> </span>&#123;</span><br><span class="line">           <span class="keyword">if</span> (finalizerTimeoutNs == <span class="number">0</span>) &#123;</span><br><span class="line">               finalizerTimeoutNs =</span><br><span class="line">                       NANOS_PER_MILLI * VMRuntime.getRuntime().getFinalizerTimeoutMs();</span><br><span class="line">               <span class="comment">// Temporary app backward compatibility. Remove eventually.</span></span><br><span class="line">               MAX_FINALIZE_NANOS = finalizerTimeoutNs;</span><br><span class="line">           &#125;</span><br><span class="line">           <span class="keyword">long</span> startCount = FinalizerDaemon.INSTANCE.progressCounter.get();</span><br><span class="line">           <span class="comment">// Avoid remembering object being finalized, so as not to keep it alive.</span></span><br><span class="line">           <span class="comment">//如果回收对象没有超时的话，这里会返回null</span></span><br><span class="line">           <span class="keyword">if</span> (!sleepForNanos(finalizerTimeoutNs)) &#123;</span><br><span class="line">               <span class="comment">// Don't report possibly spurious timeout if we are interrupted.</span></span><br><span class="line">               <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">           &#125;</span><br><span class="line">           <span class="keyword">if</span> (getNeedToWork() &amp;&amp; FinalizerDaemon.INSTANCE.progressCounter.get() == startCount) &#123;</span><br><span class="line">               <span class="comment">// We assume that only remove() and doFinalize() may take time comparable to</span></span><br><span class="line">               <span class="comment">// the finalizer timeout.</span></span><br><span class="line">               <span class="comment">// We observed neither the effect of the gotoSleep() nor the increment preceding a</span></span><br><span class="line">               <span class="comment">// later wakeUp. Any remove() call by the FinalizerDaemon during our sleep</span></span><br><span class="line">               <span class="comment">// interval must have been followed by a wakeUp call before we checked needToWork.</span></span><br><span class="line">               <span class="comment">// But then we would have seen the counter increment.  Thus there cannot have</span></span><br><span class="line">               <span class="comment">// been such a remove() call.</span></span><br><span class="line">               <span class="comment">// The FinalizerDaemon must not have progressed (from either the beginning or the</span></span><br><span class="line">               <span class="comment">// last progressCounter increment) to either the next increment or gotoSleep()</span></span><br><span class="line">               <span class="comment">// call.  Thus we must have taken essentially the whole finalizerTimeoutMs in a</span></span><br><span class="line">               <span class="comment">// single doFinalize() call.  Thus it's OK to time out.  finalizingObject was set</span></span><br><span class="line">               <span class="comment">// just before the counter increment, which preceded the doFinalize call.  Thus we</span></span><br><span class="line">               <span class="comment">// are guaranteed to get the correct finalizing value below, unless doFinalize()</span></span><br><span class="line">               <span class="comment">// just finished as we were timing out, in which case we may get null or a later</span></span><br><span class="line">               <span class="comment">// one.  In this last case, we are very likely to discard it below.</span></span><br><span class="line">               Object finalizing = FinalizerDaemon.INSTANCE.finalizingObject;</span><br><span class="line">               sleepForNanos(<span class="number">500</span> * NANOS_PER_MILLI);</span><br><span class="line">               <span class="comment">// Recheck to make it even less likely we report the wrong finalizing object in</span></span><br><span class="line">               <span class="comment">// the case which a very slow finalization just finished as we were timing out.</span></span><br><span class="line">               <span class="keyword">if</span> (getNeedToWork()</span><br><span class="line">                       &amp;&amp; FinalizerDaemon.INSTANCE.progressCounter.get() == startCount) &#123;</span><br><span class="line">                   <span class="keyword">return</span> finalizing;</span><br><span class="line">               &#125;</span><br><span class="line">           &#125;</span><br><span class="line">           <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">       &#125;</span><br></pre></td></tr></table></figure></p><p><code>sleepForNanos</code>对应的函数很简单，如果在超时时间内完成GC，就会计算传进来的超时阈值减去当前已经睡眠的时间，如果这个差值小于0，说明睡眠的时间超过了阈值<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">        * Sleep for the given number of nanoseconds, or slightly longer.</span></span><br><span class="line"><span class="comment">        * <span class="doctag">@return</span> false if we were interrupted.</span></span><br><span class="line"><span class="comment">        */</span></span><br><span class="line">       <span class="function"><span class="keyword">private</span> <span class="keyword">boolean</span> <span class="title">sleepForNanos</span><span class="params">(<span class="keyword">long</span> durationNanos)</span> </span>&#123;</span><br><span class="line">           <span class="comment">// It's important to base this on nanoTime(), not currentTimeMillis(), since</span></span><br><span class="line">           <span class="comment">// the former stops counting when the processor isn't running.</span></span><br><span class="line">           <span class="keyword">long</span> startNanos = System.nanoTime();</span><br><span class="line">           <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">               <span class="keyword">long</span> elapsedNanos = System.nanoTime() - startNanos;</span><br><span class="line">               <span class="keyword">long</span> sleepNanos = durationNanos - elapsedNanos;</span><br><span class="line">               <span class="keyword">if</span> (sleepNanos &lt;= <span class="number">0</span>) &#123;</span><br><span class="line">                   <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">               &#125;</span><br><span class="line">               <span class="comment">// Ensure the nano time is always rounded up to the next whole millisecond,</span></span><br><span class="line">               <span class="comment">// ensuring the delay is &gt;= the requested delay.</span></span><br><span class="line">               <span class="keyword">long</span> sleepMillis = (sleepNanos + NANOS_PER_MILLI - <span class="number">1</span>) / NANOS_PER_MILLI;</span><br><span class="line">               <span class="keyword">try</span> &#123;</span><br><span class="line">                   Thread.sleep(sleepMillis);</span><br><span class="line">               &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">                   <span class="keyword">if</span> (!isRunning()) &#123;</span><br><span class="line">                       <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">                   &#125;</span><br><span class="line">               &#125; <span class="keyword">catch</span> (OutOfMemoryError ignored) &#123;</span><br><span class="line">                   <span class="keyword">if</span> (!isRunning()) &#123;</span><br><span class="line">                       <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">                   &#125;</span><br><span class="line">               &#125;</span><br><span class="line">           &#125;</span><br><span class="line">       &#125;</span><br></pre></td></tr></table></figure></p><h4 id="Step3-GC处理超时"><a href="#Step3-GC处理超时" class="headerlink" title="Step3 GC处理超时"></a>Step3 GC处理超时</h4><p>如果第二步中的超时时间内析构没有完成，则返回析构的对象，触发<code>finalizerTimedOut</code>。<br>到了这一步是最不希望看到的结局，此时系统会弹出应用停止运行的报错框。</p><p>注意这个时候并没有立刻杀死进程，杀死进程的选择权交给了用户，即通过弹窗展示给用户，但对于用户来说会一头雾水</p><p><img src="http://blog.lihaizhou.top/GC_crash/GC1.png" alt=""></p><h3 id="分析结论"><a href="#分析结论" class="headerlink" title="分析结论"></a>分析结论</h3><p>这种问题其实还是比较常见的，特别是低内存的机器上。<code>RootCasue</code>就是对象回收超时了，一般是由于队列中等待<code>FinalizerDaemon</code>线程回收的对象太多导致，或者此时系统资源异常紧张比如CPU负载过高或者低内存环境下。</p><h3 id="场景实测"><a href="#场景实测" class="headerlink" title="场景实测"></a>场景实测</h3><h4 id="模拟还原现场"><a href="#模拟还原现场" class="headerlink" title="模拟还原现场"></a>模拟还原现场</h4><p>通过模拟<code>GC</code>时耗时操作，应用退到后台后10s会弹出报错框，堆栈如下</p><p><img src="http://blog.lihaizhou.top/GC_crash/GC2.png" alt=""></p><p>验证了超时时间的确是10s，同时也验证了GC时耗时的操作确实会可能触发这个现象</p><h4 id="对比机情况"><a href="#对比机情况" class="headerlink" title="对比机情况"></a>对比机情况</h4><p>在手头的小米<code>note9 pro</code>上进行场景模拟测试，模拟GC耗时100s的情况<br><img src="http://blog.lihaizhou.top/GC_crash/GC3.png" alt=""></p><p>在小米的机器上，到了默认的10s后并不会有弹窗，说明小米肯定修改了超时时间，第一次是等待了全部的100s后竟然正常回收，说明超时时间设置的比较大。紧接着下一次在达到了近80s时，进程收到<code>signal 9</code>直接被kill了，此时再点击应用是冷启动。</p><p><strong>小米修改了超时阈值(超过100s)，通过直接sig 9杀掉了进程，没有报错弹窗，所以用户无感知</strong></p><h4 id="测试机情况"><a href="#测试机情况" class="headerlink" title="测试机情况"></a>测试机情况</h4><p>同样的在我们的CP03上模拟GC耗时100s的情况<br><strong>退出应用到后台，此时系统触发GC回收，达到十秒钟时，界面上直接弹出停止运行的报错框，此时只有点击了关闭应用，才会去kill进程</strong></p><h4 id="修改策略"><a href="#修改策略" class="headerlink" title="修改策略"></a>修改策略</h4><p>在GC规定的超时时间内如果没有完成析构，直接<code>sig 9</code>给对应进程</p><hr><p>每日一问: 如果我一拳把自己打晕了，说明我是很强呢还是很虚呢？</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;写在前面&quot;&gt;&lt;a href=&quot;#写在前面&quot; class=&quot;headerlink&quot; title=&quot;写在前面&quot;&gt;&lt;/a&gt;写在前面&lt;/h3&gt;&lt;p&gt;这个问题之所以会拿出来仔细分析，一方面是因为这个问题不是简单的应用崩溃而是框架层的报错，另一方面是因为希望通过这个问题梳理下
      
    
    </summary>
    
      <category term="稳定性" scheme="http://lihaizhou.top/categories/%E7%A8%B3%E5%AE%9A%E6%80%A7/"/>
    
    
  </entry>
  
  <entry>
    <title>关于网络&amp;wifi一些基础内容</title>
    <link href="http://lihaizhou.top/2021/01/24/%E5%85%B3%E4%BA%8E%E7%BD%91%E7%BB%9C-wifi%E4%B8%80%E4%BA%9B%E5%9F%BA%E7%A1%80%E5%86%85%E5%AE%B9/"/>
    <id>http://lihaizhou.top/2021/01/24/关于网络-wifi一些基础内容/</id>
    <published>2021-01-24T06:57:50.000Z</published>
    <updated>2021-10-16T05:39:05.530Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>记录一些网络以及wifi的基础内容，会持续补充，以便后续有需要的时候查漏补缺  </p><h2 id="网络分层"><a href="#网络分层" class="headerlink" title="网络分层"></a>网络分层</h2><p><img src="http://blog.lihaizhou.top/WIFI%26Network/wifi%26%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%8001.png" alt=""></p><ul><li>分层的原因？如果不分层的话是否可行？</li><li>有了IP地址为何还需要mac地址？仅从地址作用上看用ipv6来取代mac地址是否可以？</li></ul><h3 id="为何分层？"><a href="#为何分层？" class="headerlink" title="为何分层？"></a>为何分层？</h3><p><strong>Q1_个人理解</strong><br>这种问题网上一大堆,其实我们没有必要纠结这种问题，这种成熟的架构时至今日是这个样子的，必定有其道理，搜索了下网上对此的解释，有不少是拿比喻来解释。<br>通过比喻向初学者解释一个知识点其实是不合适的，但是我们往往在深刻理解了一个东西后会想到用一个比喻，试图用它向不懂的人解释。比喻的意义往往是一群懂的人之间心领神会的交流方式罢了，所以就我个人而言，学习一个知识点的时候最好不用试图通过比喻来理解。<br>我们从软件设计模式的角度来看，其实分层是不是有点像Andorid的架构设计模式，不论是MVC,MVP,MVVM等，其本质都是为了解耦, 为了更方便职责明确, 也便于后续的维护调试,后续修改的话只要修改一层即可而不会牵一发而动全身。  </p><p>既然你说是因为职责明确，那么每一层都有什么职责呢？<br>比如传输层解决的是进程定位的问题，网络层解决数据包寻路的问题，数据链路层解决局域网传输的问题等。<br><strong>归纳起来就是一句话：</strong><br>当一个系统足够复杂时，通过聚合分为不同层次或不同模块， 每层或模块都是内聚的，对外屏蔽复杂性。<br>那么宏观上看去，管理和问题定位很容易到具体层次和模块。 然后层层递进，很容易定位问题。  </p><h3 id="为何需要mac层？"><a href="#为何需要mac层？" class="headerlink" title="为何需要mac层？"></a>为何需要mac层？</h3><p><strong>Q2_个人理解</strong><br>这个问题在网上试图查找资料时，很多说的很多都是因为ip地址会变，mac不变的缘故。<br>但是包在到达目的地之前是不知道目标mac地址的，mac层包装ip层的时候，对方的mac层地址还不一定是目标（最终的）mac地址，有可能是相连的一台路由器的mac地址，解码之后看ip，发现ip不在这个局域网内，然后再次包装一层mac地址，发给相连（也有可能不是相连，反正就是根据某种规则规定的下一个路由器）路由器，所以ip地址会变，mac不变的这样的解释是不合理的吗？最起码我觉得这种说法没有解释清楚这个问题。<br>网卡出厂就设置了mac地址是唯一的，我们也知道ip地址是可变的，就算机器没有移动，一直处在一个局域网内，重启网络也可能会导致ip地址改变。<br>数据包上ip 地址的作用是在外网上投递用的，内网就不行了，必须要用mac，使用mac地址的其中一个原因就是为了在局域网内确认到那台正确的计算机。  </p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">在知乎上找到一个比较好的解释为何需要mac层，和上面的解释是一样的  </span><br><span class="line">信息传递时候，需要知道的其实就是两个地址：  </span><br><span class="line">    • 终点地址（Final destination address）  </span><br><span class="line">    • 下一跳的地址（Next hop address）  </span><br><span class="line">IP地址本质上是终点地址，它在跳过路由器（hop）的时候不会改变，而MAC地址则是下一跳的地址，每跳过一次路由器都会改变。</span><br></pre></td></tr></table></figure><p>归纳下来就是一句话：mac地址局域网寻址，ip地网络寻址<br>这就是为什么还要用MAC地址的原因之一，它起到了记录下一跳的信息的作用</p><h3 id="用ipv6来取代mac地址是否可以？"><a href="#用ipv6来取代mac地址是否可以？" class="headerlink" title="用ipv6来取代mac地址是否可以？"></a>用ipv6来取代mac地址是否可以？</h3><p>既然ipv6号称可以给世界上每一个沙子都分配一个ip地址，那为何不直接取消mac地址，给每一个网卡出场时分配一个ip地址。<br>这是一个看起来比较天马行空的问题。<br>前面提到mac地址起到“下一跳IP地址”的作用，那么我们用ipv6反正不用担心ip不够用的问题对吧，假设交换机也支持IP地址转发（现在的二层交换机不支持这样做），mac地址好像看上去也并不是必要的对吧？<br>当然了mac地址不仅仅是标记网卡这一个作用，先假设它只有这么一个作用，想想这样可行吗？<br>很快便想到一个问题就是这个ip地址得广播出去，假设地球上有几百亿的设备，转发匹配这几百亿的记录便不可能实现，需要的存储太大太大。<br>这个问题搜索了网上貌似相关的解答比较少，知乎上有一个回答我觉得比较好，照抄过来:<br>IPv6定义了多种地址，其中一种地址叫Link-local地址，看上去可以取代mac地址，可是二层三层的封装已经通行于全世界，ipv6何德何能可以打破所有网络设备，主机，都在使用的规范？打破规范带来的网络中断，迁移成本这些也是难以实现的<br>tcpip协议栈设计出来那天就没有自己定义二层协议，也没有取代二层协议，而是去兼容二层协议，仅此而已，让自己能跑在各种二层协议之上</p><h2 id="DHCP"><a href="#DHCP" class="headerlink" title="DHCP"></a>DHCP</h2><p><img src="http://blog.lihaizhou.top/WIFI%26Network/wifi%26%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%8002.png" alt=""><br>本地抓取的正常流程的bugreport，分别包含<code>logcat&amp;driver</code>日志片段，后续可以作为参考分析<br><img src="http://blog.lihaizhou.top/WIFI%26Network/wifi%26%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%8003.png" alt=""><br>静态分配和dhcp分配导致的ip冲突报文<br><img src="http://blog.lihaizhou.top/WIFI%26Network/wifi%26%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%8004.png" alt="">  </p><p>Q:  DHCP Offer 和 DHCP ACK是广播包吗？由什么因素决定的？<br>A：这个其实是取决于client端的ip协议栈的能力，可以抓个报文看下就知道了。<br>如果协议栈在初始化过程中，不接收单播IP报文，请在DHCP Discovery / Request报文的Flags里明确告知服务器，通过设置“BROADCAST flag = 1”，服务器就使用广播来和客户端通信。<br>如果协议栈在初始化过程中，可以接收单播IP报文，请在DHCP Discovery / Request报文的Flags里明确告知服务器，通过设置“BROADCAST flag = 0”，服务器就使用单播来和客户端通信。<br>既然广播方式通信适合所有的协议栈，统统使用广播不就ok了，为何要有这个Flags，岂不是多此一举？<br>单播最大的优点：通信是点对点方式，不会影响到广播域的其它主机。<br>广播的特点：通信是点对所有点的方式，会影响到广播域里其它所有主机  </p><p>链路层放置目标机器的mac地址即可将信息送达客户端机，非该mac地址的机器收到后会丢弃这个包，此时的ip层目标网络地址填的就是要分配给该客户端机的ip地址;<br> <a href="https://www.ietf.org/rfc/rfc2131.txt" target="_blank" rel="noopener">官方文档说明</a></p><p>Q: 是否存在静态ip和DHCP Server分配给Client的ip冲突的情况？ 有冲突后会怎么样？会导致网络访问异常？<br>A：网上找到一篇文章，解释的不错，地址：<a href="https://blog.csdn.net/Butingnal/article/details/76067092" target="_blank" rel="noopener">DHCP以及客户端是如何避免IP冲突</a><br>在最后的确认阶段，当Client收到<code>DHCP Server</code>发送的<code>DHCPACK</code>报文之后，并不会马上使用Server分配的这个地址，而是会发送目的地址为Server分配地址的ARP请求报文作最后的确认（即免费ARP）。<br>如果没有检测到冲突，则将此地址与自己绑定。如果检测到冲突，就向<code>DHCP Server</code>发送<code>DHCPDECLINE</code>报文，在<code>Request IP Address（option 50）</code>字段填入Server提供的发生冲突的IP地址.发送完成后，等待一段时间再开始重新申请IP地址，直至申请到一个可用的IP地址。  </p><p>Q：<code>DHCP server</code>的地址池是有限的吧？同时有大量的client发起请求会不会存在不够用的情况？<br>A: 服务器收到了Discover 包之后，就会从地址池中选择一个IP准备分配给请求者，当然正常情况下客户端收到服务器发送的Offer会回复Request进行确认，但是在泛洪攻击的场景下服务器会收到大量的Discover报文当然也会在地址池为这些请求者执行分配IP的操作并等待客户端的应答。<br>在没有得到客户端确认的情况下，服务器将会为客户端保留要分配的IP，当在大量泛洪攻击的场景下服务器的地址池很快就会满掉。从而影响正常客户端的使用。<br>那我们这个时候就有疑问了，能不能尽可能的扩大这个地址池呢？想象一个极端的情况，地址池中的ip数无穷无尽，这不就不存在这个问题了吗？<br>其实只要简单修改掩码，就可以实现更多的客户端接入，别说254，一万个254都装的下。<br>掩码是用来决定网段大小的，也就是说，一个网段能容纳多少个终端（电脑，手机，摄像头），是由掩码来决定的。<br>最常用的掩码是<code>255.255.255.0</code>，和题主说的一样，最大的可用ip数量只有254<br>但如果把掩码换成<code>255.255.0.0</code>，那么最大可用ip数量，就有256乘256减2，好几万了<br><strong>但是为什么不推荐一个网段主机数太多呢？</strong><br>在实际项目上，虽然通过掩码可以让网段变大，让网络的配置和调试变的简单，但往往还是不用大网段。原因就在于“广播域”<br>什么是广播域，顾名思义，就是1个主机发出的广播包，可以到达的范围。  </p><p>如果一个网段大，那么广播域就大，就像我们再嘈杂的环境里，会收到大量和自己无关的数据，这些数据将占用我们的带宽，以及消耗我们各个终端的计算资源。毕竟广播包，目标地址是所有人，所有人收到都不能视而不见，都要处理。<br>所以，当终端数比较多的时候，一般会采用多个网段，多个vlan（虚拟局域网）的方法，而不是一下搞个大网段。 </p><h2 id="网关"><a href="#网关" class="headerlink" title="网关"></a>网关</h2><p>这里穿插下网关的概念，什么是网关呢？<br>如果你去网上搜索，能搜索到的关于网关的解释大多是这样的:<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">网关往往是一个路由器，是一个三层转发的设备。那么啥叫三层设备？就是把 MAC 头和 IP 头都取下来，然后根据里面的内容，看看接下来把包往哪里转发的设备。</span><br></pre></td></tr></table></figure></p><p>个人理解：<br>说来惭愧，之前对于网关的认识以为就是路由器，其实这种认识是不准确的。<br>首先‘网关’一个大概念，不具体特指一类产品，只要连接两个不同的网络的设备都可以叫网关；而‘路由器’一般特指能够实现路由寻找和转发的特定类产品，路由器很显然能够实现网关的功能。<br>当然电信行业说的‘路由器’又和家用的‘路由器’两个概念。网关并不总是被视为路由器，路由器是最常见的网关，用于将家庭或企业网络连接到Internet。<br>PC本身不具备路由寻址能力，所以PC要把所有的IP包发送到一个默认的中转地址上面进行转发，也就是默认网关。这个网关可以在路由器上，可以在三层交换机上，可以在防火墙上，可以在服务器上，所以和物理的设备无关。<br>网关只针对某个局域网，是某个局域网的出口地址，而一个路由器由多个网关组成<br>任何一个想发往其他局域网的包，都会到达其中一只手，被拿进来，拿下 MAC 头和 IP 头，看一下，根据自己的路由算法，选择另一只手，加上 IP 头和 MAC 头，然后扔出去。<br>如果离开本局域网，就需要经过网关，网关是路由器的一个网口；路由器是一个三层设备，里面有如何寻找下一跳的规则；  </p><h2 id="WIFI漫游"><a href="#WIFI漫游" class="headerlink" title="WIFI漫游"></a>WIFI漫游</h2><p>下面这个图摘自高通文档上，主要是漫游的一个流程<br><img src="http://blog.lihaizhou.top/WIFI%26Network/wifi%26%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%8005.png" alt=""><br>代码中关于漫游的原因，更加细致<br><img src="http://blog.lihaizhou.top/WIFI%26Network/wifi%26%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%8006.png" alt="">  </p><p>本地抓取的9434附录屏的漫游日志，类型：Dense roaming<br><img src="http://blog.lihaizhou.top/WIFI%26Network/wifi%26%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%8007.png" alt=""><br>上面fw中打印的roam reason对应的代码地址(qcom)<br>vendor/qcom/opensource/wlan/fw-api/fw/wmi_unified.h<br><img src="http://blog.lihaizhou.top/WIFI%26Network/wifi%26%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%8008.png" alt="">  </p><p>顺便解释下本地抓取的这份漫游reason 7对应的是DENSE roaming的解释，摘自高通文档<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Dense roaming  </span><br><span class="line">Dense-<span class="function">roaming mechanism is a new feature of location retrieval <span class="title">function</span> <span class="params">(LRF)</span> 3.0. This feature retains high throughput when many roamable APs are present nearby and the data traffic is high then.</span></span><br><span class="line"><span class="function">The original Wi-Fi roaming mechanism is designed to enable roaming when the current RSSI value reaches the defined RSSI threshold value, <span class="keyword">for</span> example, -76 dBm.  </span></span><br><span class="line"><span class="function">However, in a high dense environment where there are many roamable APs, it is better to start roaming earlier when the traffic is high because high throughput is maintained   <span class="keyword">for</span> heavy traffic with minimal power consumption impact. Dense roaming functions in such a manner to retain high throughput during periods of heavy traffic.  </span></span><br><span class="line"><span class="function">To provide <span class="keyword">this</span> value-added enhancement, the dense roaming mechanism is designed with the following two principles.  </span></span><br><span class="line"><span class="function">■ Relying on other triggered scans, sniffing is performed on the management packets to determine the number of roamable APs that are present then in the environment.  </span></span><br><span class="line"><span class="function">■ If a dense roaming environment is <span class="title">found</span> <span class="params">(that is, the number of the found roamable APs is bigger than the configured dense roamable AP threshold value)</span>, and <span class="keyword">if</span> there is significant traffic at that moment, then <span class="keyword">switch</span> to use the dense RSSI threshold value so that the roaming is triggered earlier.</span></span><br></pre></td></tr></table></figure></p><p>MTK online上关于MTK的漫游策略如下图，其实和qcom大同小异，大的流程都是一样的<br><img src="http://blog.lihaizhou.top/WIFI%26Network/wifi%26%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%8009.png" alt=""><br>如下是平时分析漫游可能会用到的关键字</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//Logcat:  </span></span><br><span class="line">CTRL-EVENT-DISCONNECTED|CTRL-EVENT-CONNECTED|fetchRssiLinkSpeedAndFrequencyNative|NL80211_CMD_ROAM|(set AP RSN IE)|LOST_PROVISIONING|wpa_supplicant: wlan0: State</span><br><span class="line"></span><br><span class="line"><span class="comment">//fw log</span></span><br><span class="line">VDEV_MGR_MY_BEACON_RECEIVED|ROAM_LOW_RSSI_INTERRUPT|PEER_ASSOC|ROAM_BETTER_CANDIDATE_FOUND|ROAM_SCAN_REQUESTED|VDEV_MGR_FIRST_BMISS_DETECTED|ROAM_FINAL_BMISS_RECVD|roaming attempt to bssid|RSSI_MONITOR_GET_BEACON_RSSI_AVG</span><br></pre></td></tr></table></figure><ul><li>触发漫游的原因有哪些？</li><li>漫游到哪个候选AP(假设存在)? 有哪些评判条件？</li><li>漫游会断线吗？会重新走四次握手吗？</li></ul><h2 id="ARP-amp-NDP"><a href="#ARP-amp-NDP" class="headerlink" title="ARP&amp;NDP"></a>ARP&amp;NDP</h2><p><img src="http://blog.lihaizhou.top/WIFI%26Network/wifi%26%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%8010.png" alt=""><br>上面是ARP的一个简单流程，这里涉及到一个缓存的过程，大体解释如下:<br>为了避免机器每次都使用ARP协议发送ARP请求，在每台机器的本地会进行ARP缓存。<br>–&gt;只要涉及到缓存，那就是空间换时间的设计思想  </p><ol><li>一般机器都是先查本地ARP缓存  </li><li>本地ARP缓存查不到，再去发送ARP请求在局域网中去找目标IP地址对应的MAC地址<br>当然机器会不断地上线下线，IP 也可能会变，所以 ARP 的 MAC 地址缓存过一段时间就会过期  </li></ol><h3 id="ipv6-ND"><a href="#ipv6-ND" class="headerlink" title="ipv6 ND"></a>ipv6 ND</h3><p><img src="http://blog.lihaizhou.top/WIFI%26Network/wifi%26%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%8011.png" alt=""><br>地址解析过程中使用了两种ICMPv6报文：邻居请求报文NS（Neighbor Solicitation）和邻居通告报文NA（Neighbor Advertisement)。<br>    • NS报文：Type字段值为135，Code字段值为0，在地址解析中的作用类似于IPv4中的ARP请求报文。<br>    • NA报文：Type字段值为136，Code字段值为0，在地址解析中的作用类似于IPv4中的ARP应答报文。</p><p><img src="http://blog.lihaizhou.top/WIFI%26Network/wifi%26%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%8012.png" alt="">    </p><h3 id="NS报文"><a href="#NS报文" class="headerlink" title="NS报文"></a>NS报文</h3><p>  <img src="http://blog.lihaizhou.top/WIFI%26Network/wifi%26%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%8013.png" alt="">  </p><h3 id="arp-request"><a href="#arp-request" class="headerlink" title="arp request"></a>arp request</h3><p><img src="http://blog.lihaizhou.top/WIFI%26Network/wifi%26%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%8014.png" alt="">     </p><p>Q：什么是ARP风暴？<br>A：ARP广播时，交换机会将一个端口收到的包转发到其它所有的端口上。<br>比如数据包经过交换机A到达交换机B，交换机B又将包复制为多份广播出去。<br>如果整个局域网存在一个环路，使得数据包又重新回到了最开始的交换机A，这个包又会被A再次复制多份广播出去。<br>如此循环，数据包会不停得转发，而且越来越多，最终占满带宽，或者使解析协议的硬件过载，行成广播风暴。</p><h2 id="DNS"><a href="#DNS" class="headerlink" title="DNS"></a>DNS</h2><p><img src="http://blog.lihaizhou.top/WIFI%26Network/wifi%26%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%8015.png" alt=""><br>如果分析类似网页加载不出来的问题时候，我们首先需要清楚的知道加载一个网页的流程<br>    • DNS 解析:将域名解析成 IP 地址<br>    • TCP 连接：TCP 三次握手<br>    • 发送 HTTP 请求<br>    • 服务器处理请求并返回 HTTP 报文<br>    • 浏览器解析渲染页面<br>    • 断开连接：TCP 四次挥手  </p><p>Q: 对于已连接网络无法上网问题的快速排查思路？  </p><h2 id="断线问题"><a href="#断线问题" class="headerlink" title="断线问题"></a>断线问题</h2><p>如下是本地测试打印，操作步骤是主动删除已连接热点<br><img src="http://blog.lihaizhou.top/WIFI%26Network/wifi%26%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%8016.png" alt=""><br>如下是本地测试打印，操作步骤是超出范围断开<br><img src="https://raw.githubusercontent.com/hellolihaizhou/saveImg/master/wifi%26%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%8017.png" alt="">  </p><p>Q: 断线一般有哪些原因？<br>A:</p><ul><li>用户手动断开</li><li>FWK断开</li><li>Beacon miss断线</li><li>KickOut断线</li><li>Nud failed断线</li><li>Rx disassoc or deauth断线  </li></ul><p>Q: 如何通过日志如何快速定位断线是上层还是底层发起的？<br>A:如果是底层断线，会先收到底层断线发上来的<code>DISCONNECT Event</code>，然后<code>supplicant</code>才把state切到DISCONENCTED.<br>如果是上层断线，<code>disconnection request</code>会先到supplicant，supplicant state会先切到DISCONNECTED, 发送disconnect request给driver去真正端开wifi连接.<br>归纳下来就是迅速定位是底层还是上层有一个好的办法就是：<br>过滤这两个关键字：<code>wpa_supplicant: nl80211</code> , <code>wpa_supplicant: wlan0</code>看看先后关系  </p><p>Q: 有哪些日志关键字可以过滤来分析断线问题？<br>如下是一些关键字，当然前提你得清楚这些关键字的含义  </p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//bugreport：</span></span><br><span class="line">CMD_IP_REACHABILITY_LOST|NETWORK_DISCONNECTION_EVENT|Received Heart Beat Failure|dev wlan0 INCOMPLETE|get addr info failed|arp who-has|ICMPv4 dst|LOST_PROVISIONING|wma_peer_sta_kickout_event_handler|NetConnTag|No address associated with hostname|DnsMain|IcmpReader|NetworkProvider|NetworkDiagnostics|DnsService|PROBE_DNS</span><br><span class="line"><span class="comment">//driver: </span></span><br><span class="line">STA kickout|blm_fill_reject_list|wma_peer_sta_kickout_event_handler|Sending Deauth frame with reason</span><br><span class="line"><span class="comment">//fw</span></span><br><span class="line">ROAM_STA_KICKOUT_RECV|consecutive failure=</span><br></pre></td></tr></table></figure><p>fw的关键字主要是看<code>tx fail</code>的阀值是否达到了上限，很多都是<code>RSSI</code>值太低导致，还有一种常见的问题是AP没有回ack导致手机一直tx fail,最终触发<code>kickout</code>，这种需要提供<code>sniffer log</code>确认。  </p><h2 id="连接不上问题"><a href="#连接不上问题" class="headerlink" title="连接不上问题"></a>连接不上问题</h2><p>本地测试密码错误抓取的bugreport，以便后续分析日志对照<br><img src="http://blog.lihaizhou.top/WIFI%26Network/wifi%26%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%8018.png" alt="">    </p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//Auth fail</span></span><br><span class="line">rx Auth frame from peer with failure code对应的fail code参见 <span class="number">802.11</span> Association Status Codes</span><br><span class="line">https:<span class="comment">//wiki.n.miui.com/display/~lihaizhou/802.11+Association+Status+Codes</span></span><br><span class="line"></span><br><span class="line">eg: code = <span class="number">17</span> Association denied because AP is unable to handle additional associated stations</span><br><span class="line"></span><br><span class="line"><span class="comment">// portal fail</span></span><br><span class="line"><span class="number">2020</span>-<span class="number">12</span>-<span class="number">03</span>T18:<span class="number">08</span>:<span class="number">11.852</span> - PROBE_DNS connect.rom.miui.com <span class="number">12511</span>ms FAIL </span><br><span class="line"><span class="number">2020</span>-<span class="number">12</span>-<span class="number">03</span>T18:<span class="number">08</span>:<span class="number">39.391</span> - PROBE_HTTP http:<span class="comment">//connect.rom.miui.com/generate_204 Probe failed with exception java.net.UnknownHostException: Unable to resolve host "connect.rom.miui.com": No address associated with hostname</span></span><br><span class="line"><span class="number">2020</span>-<span class="number">12</span>-<span class="number">03</span>T18:<span class="number">08</span>:<span class="number">39.394</span> - Probably not a portal: exception java.net.UnknownHostException: Unable to resolve host <span class="string">"m.baidu.com"</span>: No address associated with hostname</span><br><span class="line"><span class="comment">//filter：</span></span><br><span class="line">Cannot add/update network|save network failed|All saved networks are lost|Association Rejection|CTRL-EVENT-ASSOC-REJECT|EVENT_DHCPACTION_TIMEOUT|NETWORK_SELECTION_DISABLED_BY_WRONG_PASSWORD|AUTHENTICATION_FAILURE|pre-shared key may be incorrect|wpa_supplicant: wlan0</span><br><span class="line"></span><br><span class="line"><span class="comment">//driver：</span></span><br><span class="line">Auth frame from peer with failure|Auth Failure occurred</span><br></pre></td></tr></table></figure><p>Q：连接不上通常有哪几种情形？如何快速甄别？  </p><p><strong>Auth失败</strong><br>一般driver日志中会打印出<code>Auth frame from peer with failure</code>后面对应code值，code值查阅<br>802.11 Association Status Codes即可，正常返回的是0，如果问题有sniffer的话，也可以看auth帧的status值<br>像数值17 对应的含义 <code>Association denied because AP is unable to handle additional associated stations</code> 被AP拒绝了，这时候同时连接AP的sta可能太多了超过了AP的负载<br><strong>四次握手异常</strong><br>1,2握手失败是密码错误导致，其它的可能是路由器设置问题<br><strong>DHCP失败</strong><br>DHCP请求没有回复，看看当时rssi判断信号弱不弱，为什么连接成功但是DHCP会失败：因为连接过程一直发送管理帧，数据小，DHCP是数据帧，比较大，在信号弱时无法正常交互。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;记录一些网络以及wifi的基础内容，会持续补充，以便后续有需要的时候查漏补缺  &lt;/p&gt;
&lt;h2 id=&quot;网络分层&quot;&gt;&lt;a href=&quot;#网
      
    
    </summary>
    
      <category term="网络" scheme="http://lihaizhou.top/categories/%E7%BD%91%E7%BB%9C/"/>
    
    
  </entry>
  
  <entry>
    <title>wifi断流问题的一般分析思路</title>
    <link href="http://lihaizhou.top/2021/01/08/wifi%E6%96%AD%E6%B5%81%E7%9A%84%E4%B8%80%E8%88%AC%E5%88%86%E6%9E%90%E6%80%9D%E8%B7%AF/"/>
    <id>http://lihaizhou.top/2021/01/08/wifi断流的一般分析思路/</id>
    <published>2021-01-08T08:01:12.000Z</published>
    <updated>2021-09-08T12:34:39.885Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>仅针对高通平台，旨在梳理出遇到此类问题的一般应对策略，作为工具篇查阅，快速分类出断流的原因  </p><h2 id="定位时间点"><a href="#定位时间点" class="headerlink" title="定位时间点"></a>定位时间点</h2><p>根据测试或用户反馈的时间点，先通过如下关键字过滤一遍，尝试定位到具体的时间点</p><p><strong>断流断连关键字</strong><br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CMD_IP_REACHABILITY_LOST|NETWORK_DISCONNECTION_EVENT|Received Heart Beat Failure|dev wlan0 INCOMPLETE|get addr info failed|arp who-has|ICMPv4 dst|LOST_PROVISIONING|wma_peer_sta_kickout_event_handler|NetConnTag|No address associated with hostname|DnsMain|IcmpReader|NetworkProvider|NetworkDiagnostics|DnsService|PROBE_DNS</span><br></pre></td></tr></table></figure></p><p>断流|AP连接不成功|AP心跳包接收失败||获取地址失败|arp包发送接收出问题|…….  </p><h2 id="是否是网络环境或RSSI太弱导致"><a href="#是否是网络环境或RSSI太弱导致" class="headerlink" title="是否是网络环境或RSSI太弱导致?"></a>是否是网络环境或RSSI太弱导致?</h2><p>搜索关键字<code>processed=L2ConnectedState&quot;</code>查看状态机状态，当时是否是连接上的，RSSI值是否太低了，TX RX的值是否太低了<br>类似如下<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rec[<span class="number">902</span>]: time=<span class="number">01</span>-<span class="number">03</span> <span class="number">15</span>:<span class="number">05</span>:<span class="number">15.447</span> processed=L2ConnectedState org=ConnectedState dest=&lt;<span class="keyword">null</span>&gt; what=CMD_RSSI_POLL screen=on <span class="number">56</span> <span class="number">0</span> <span class="string">"Xiaomi_8111_5G"</span> <span class="number">88</span>:c3:<span class="number">97</span>:<span class="number">32</span>:c6:cc rssi=-<span class="number">53</span> f=<span class="number">5805</span> sc=<span class="number">60</span> link=<span class="number">720</span> tx=<span class="number">0.1</span>, <span class="number">0.0</span>, <span class="number">0.0</span> rx=<span class="number">1.5</span> bcn=<span class="number">48014</span> [on:<span class="number">2941</span> tx:<span class="number">831</span> rx:<span class="number">24</span> period:<span class="number">3009</span>] from screen [on:<span class="number">79247</span> period:<span class="number">154965</span>] score=<span class="number">60</span></span><br></pre></td></tr></table></figure></p><p>正常来讲，rssi处于<code>-40~-60</code>之间还可以，<code>&lt;-65</code>代表当前信号比较差了  </p><h2 id="ARP-or-DNS是否有问题"><a href="#ARP-or-DNS是否有问题" class="headerlink" title="ARP or DNS是否有问题?"></a>ARP or DNS是否有问题?</h2><p>在bugreport中的<code>dump of service wifi</code> 中出现<code>CMD_IP_REACHABILITY_LOST</code>可以说明arp失败，或者搜索<code>NUD_FAILED</code>关键字，类似如下<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"> rec[<span class="number">135</span>]: time=<span class="number">09</span>-<span class="number">12</span> <span class="number">19</span>:<span class="number">51</span>:<span class="number">14.715</span> processed=L2ConnectedState org=ConnectedState dest=&lt;<span class="keyword">null</span>&gt; what=<span class="number">131221</span>(<span class="number">0x20095</span>) !CMD_IP_REACHABILITY_LOST rt=<span class="number">210940</span>/<span class="number">210940</span> FAILURE: LOST_PROVISIONING, NeighborEvent</span><br><span class="line">&#123;elapsedMs=<span class="number">210940</span>, <span class="number">192.168</span>.1.1, [(<span class="keyword">null</span>)], RTM_NEWNEIGH, NUD_FAILED</span><br></pre></td></tr></table></figure></p><p>还有一种方法是搜索arp who-has关键字看看arp有没有reply以及延迟高不高<br>Connectivity网络诊断过程会ping网关，失败则说明发生了断流，可以搜索下关键字NetworkDiagnostics,看下ping的情况以及DNS解析情况，类似下面的片段  </p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">NetworkDiagnostics:ifaces&#123;wlan0&#125; index&#123;<span class="number">24</span>&#125; network&#123;<span class="number">110</span>&#125; nethandle&#123;<span class="number">475852099597</span>&#125;</span><br><span class="line">  .  ICMPv4 dst&#123;<span class="number">8.8</span>.8.8&#125; src&#123;<span class="number">192.168</span>.31.186:<span class="number">94</span>&#125;: SUCCEEDED: <span class="number">1</span>/<span class="number">14</span> (<span class="number">4213</span>ms)</span><br><span class="line">  .  ICMPv4 dst&#123;<span class="number">192.168</span>.31.1&#125; src&#123;<span class="number">192.168</span>.31.186:<span class="number">93</span>&#125;: SUCCEEDED: <span class="number">1</span>/<span class="number">14</span> (<span class="number">4158</span>ms)</span><br><span class="line">  F  DNS UDP dst&#123;<span class="number">8.8</span>.8.8&#125; src&#123;<span class="number">192.168</span>.31.186:<span class="number">38481</span>&#125; qtype&#123;<span class="number">1</span>&#125; qname&#123;<span class="number">848815</span>-android-ds.metric.gstatic.com&#125;: FAILED: <span class="number">0</span>/<span class="number">8</span> (<span class="number">4112</span>ms)</span><br><span class="line">  F  DNS UDP dst&#123;<span class="number">192.168</span>.31.1&#125; src&#123;<span class="number">192.168</span>.31.186:<span class="number">39053</span>&#125; qtype&#123;<span class="number">1</span>&#125; qname&#123;<span class="number">295600</span>-android-ds.metric.gstatic.com&#125;: FAILED: <span class="number">0</span>/<span class="number">8</span> (<span class="number">4113</span>ms)</span><br><span class="line">  F  DNS TLS dst&#123;<span class="number">8.8</span>.8.8&#125; hostname&#123;&#125;: FAILED: java.net.SocketTimeoutException: failed to connect to /<span class="number">8.8</span>.8.8 (port <span class="number">853</span>) from /<span class="number">192.168</span>.31.186 (port <span class="number">45100</span>) after <span class="number">2500</span>ms (<span class="number">2501</span>ms)</span><br><span class="line">  F  DNS TLS dst&#123;<span class="number">192.168</span>.31.1&#125; hostname&#123;&#125;: FAILED: java.net.SocketTimeoutException: failed to connect to /<span class="number">192.168</span>.31.1 (port <span class="number">853</span>) from /<span class="number">192.168</span>.31.186 (port <span class="number">37304</span>) after <span class="number">2500</span>ms (<span class="number">2501</span>ms)</span><br><span class="line">NetworkProviders <span class="keyword">for</span>: Ethernet UntrustedWifiNetworkFactory WifiSlaveNetworkFactory WifiNetworkFactory TelephonyNetworkFactory[<span class="number">0</span>] WIFI_AWARE_FACTORY UntrustedWifiNetworkFactory TelephonyNetworkFactory[<span class="number">1</span>] PhoneSwitcherNetworkRequstListener</span><br></pre></td></tr></table></figure><p>其实就是通过Ping主流服务器IP地址来判断整体数据通路是否正常 ，通过DNS主流网站查询判断运营商DNS server 是否正常<br>查看DNS时长，日志看起来每五分钟就会检测一次<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">15</span>:<span class="number">00</span>:<span class="number">00.000</span>: &#123;netId=<span class="number">110</span>, WIFI, dns avg=<span class="number">1219</span>ms max=<span class="number">20026</span>ms err=<span class="number">2.0</span>% tot=<span class="number">201</span>, connect avg=<span class="number">0</span>ms max=<span class="number">5</span>ms err=<span class="number">0.5</span>% tot=<span class="number">191</span>, tcp avg_loss=<span class="number">0.2</span>% total_sent=<span class="number">8270</span> total_lost=<span class="number">16</span>, tcp rtt=<span class="number">110</span>ms, tcp sent-ack_diff=-<span class="number">1332</span>ms&#125;</span><br><span class="line"><span class="number">15</span>:<span class="number">05</span>:<span class="number">00.000</span>: &#123;netId=<span class="number">110</span>, WIFI, dns avg=<span class="number">313</span>ms max=<span class="number">12457</span>ms err=<span class="number">0.0</span>% tot=<span class="number">172</span>, connect avg=<span class="number">0</span>ms max=<span class="number">1</span>ms err=<span class="number">0.7</span>% tot=<span class="number">138</span>, tcp avg_loss=<span class="number">0.3</span>% total_sent=<span class="number">4798</span> total_lost=<span class="number">12</span>, tcp rtt=<span class="number">43</span>ms, tcp sent-ack_diff=-<span class="number">593</span>ms&#125;</span><br></pre></td></tr></table></figure></p><p>如果测试提供的是9434日志的话，一般其中会包含tcpdump日志，过滤下<code>dns||arp</code>, 这样看上去更直观  </p><h2 id="是否发生datastall？"><a href="#是否发生datastall？" class="headerlink" title="是否发生datastall？"></a>是否发生datastall？</h2><p>检查driver日志是否有fw传上来的<code>datastall</code>事件，这个谷歌机制是在亮屏下周期性比如一分钟检查一次TCP上行和下行数据，如果只有上行数据无下行数据包且达到临界值，就会认为当前网络异常，类似如下片段：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">13</span>:<span class="number">44</span>:<span class="number">35.605317</span> [kworker/u16:<span class="number">10</span>][<span class="number">0x96c51f025d</span>][<span class="number">13</span>:<span class="number">44</span>:<span class="number">35.602210</span>]wlan: [<span class="number">6253</span>:D:WMA] Received reason code <span class="number">6</span> from FW</span><br><span class="line"><span class="number">13</span>:<span class="number">44</span>:<span class="number">35.605322</span> [kworker/u16:<span class="number">10</span>][<span class="number">0x96c51f032a</span>][<span class="number">13</span>:<span class="number">44</span>:<span class="number">35.602220</span>]wlan: [<span class="number">6253</span>:D:WMA] Data Stall event:</span><br><span class="line"><span class="number">13</span>:<span class="number">44</span>:<span class="number">35.605389</span> [kworker/u16:<span class="number">10</span>][<span class="number">0x96c51f038a</span>][<span class="number">13</span>:<span class="number">44</span>:<span class="number">35.602225</span>]wlan: [<span class="number">6253</span>:D:WMA] data_stall_type: <span class="number">3</span> vdev_id_bitmap: <span class="number">1</span> reason_code1: <span class="number">0</span> reason_code2: <span class="number">7</span> recovery_type: <span class="number">0</span></span><br><span class="line"><span class="number">13</span>:<span class="number">44</span>:<span class="number">35.605397</span> [kworker/u16:<span class="number">10</span>][<span class="number">0x96c51f11a3</span>][<span class="number">13</span>:<span class="number">44</span>:<span class="number">35.602413</span>]wlan: [<span class="number">6253</span>:D:QDF] cds_set_log_completion: <span class="number">2136</span>: is_fatal <span class="number">1</span> indicator <span class="number">3</span> reason_code <span class="number">6</span> recovery needed <span class="number">0</span></span><br><span class="line"><span class="number">13</span>:<span class="number">44</span>:<span class="number">35.629190</span> [wlan_logging_th][<span class="number">0x96c51fc43e</span>][<span class="number">13</span>:<span class="number">44</span>:<span class="number">35.604795</span>]wlan: [<span class="number">900</span>:D:HDD] send_flush_completion_to_user: Sending flush done to userspace reason code <span class="number">6</span></span><br></pre></td></tr></table></figure></p><h2 id="检查TX-RX收发包是否正常？"><a href="#检查TX-RX收发包是否正常？" class="headerlink" title="检查TX RX收发包是否正常？"></a>检查TX RX收发包是否正常？</h2><p>通过搜索关键字<code>wlan_hdd_get_sta_status</code>查看driver日志，如果上面看过没有发生<code>data stall</code>的话，看看<code>rx pkt cnt</code>有没有增加，如果经常不增加，就是有问题，如何确定是路由器没有转发还是底下没收上来？需要sniffer<br>类似如下<code>RX pkt cnt</code>变化很小，这点不正常<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">15</span>:<span class="number">04</span>:<span class="number">57.822610</span> [wifico][<span class="number">0x183a3b70779</span>][<span class="number">15</span>:<span class="number">04</span>:<span class="number">57.369087</span>]wlan: [<span class="number">1372</span>:D:HDD] wlan_hdd_get_sta_stats: [TX: Reporting MCS rate <span class="number">8</span>, flags <span class="number">0x14</span> pkt cnt <span class="number">267148</span>, nss <span class="number">2</span>, bw <span class="number">4</span>]-[RX: Reporting MCS rate <span class="number">8</span>, flags <span class="number">0x14</span> pkt cnt <span class="number">450071</span>, nss <span class="number">2</span>, bw <span class="number">4</span>]</span><br><span class="line"></span><br><span class="line"><span class="number">15</span>:<span class="number">05</span>:<span class="number">00.379218</span> [wifico][<span class="number">0x183a728afa9</span>][<span class="number">15</span>:<span class="number">05</span>:<span class="number">00.378476</span>]wlan: [<span class="number">1372</span>:D:HDD] wlan_hdd_get_sta_stats: [TX: Reporting MCS rate <span class="number">8</span>, flags <span class="number">0x14</span> pkt cnt <span class="number">267148</span>, nss <span class="number">2</span>, bw <span class="number">4</span>]-[RX: Reporting MCS rate <span class="number">8</span>, flags <span class="number">0x14</span> pkt cnt <span class="number">450073</span>, nss <span class="number">2</span>, bw <span class="number">4</span>]</span><br><span class="line"></span><br><span class="line"><span class="number">15</span>:<span class="number">05</span>:<span class="number">03.686570</span> [wifico][<span class="number">0x183aa9a651c</span>][<span class="number">15</span>:<span class="number">05</span>:<span class="number">03.388042</span>]wlan: [<span class="number">1372</span>:D:HDD] wlan_hdd_get_sta_stats: [TX: Reporting MCS rate <span class="number">8</span>, flags <span class="number">0x14</span> pkt cnt <span class="number">267148</span>, nss <span class="number">2</span>, bw <span class="number">4</span>]-[RX: Reporting MCS rate <span class="number">8</span>, flags <span class="number">0x14</span> pkt cnt <span class="number">450074</span>, nss <span class="number">2</span>, bw <span class="number">4</span>]</span><br><span class="line"></span><br><span class="line"><span class="number">15</span>:<span class="number">05</span>:<span class="number">07.132915</span> [wifico][<span class="number">0x183ae0eb713</span>][<span class="number">15</span>:<span class="number">05</span>:<span class="number">06.406522</span>]wlan: [<span class="number">1372</span>:D:HDD] wlan_hdd_get_sta_stats: [TX: Reporting MCS rate <span class="number">8</span>, flags <span class="number">0x14</span> pkt cnt <span class="number">267148</span>, nss <span class="number">2</span>, bw <span class="number">4</span>]-[RX: Reporting MCS rate <span class="number">8</span>, flags <span class="number">0x14</span> pkt cnt <span class="number">450075</span>, nss <span class="number">2</span>, bw <span class="number">4</span>]</span><br><span class="line"></span><br><span class="line"><span class="number">15</span>:<span class="number">05</span>:<span class="number">09.422157</span> [wifico][<span class="number">0x183b18213a7</span>][<span class="number">15</span>:<span class="number">05</span>:<span class="number">09.421730</span>]wlan: [<span class="number">1372</span>:D:HDD] wlan_hdd_get_sta_stats: [TX: Reporting MCS rate <span class="number">8</span>, flags <span class="number">0x14</span> pkt cnt <span class="number">267148</span>, nss <span class="number">2</span>, bw <span class="number">4</span>]-[RX: Reporting MCS rate <span class="number">8</span>, flags <span class="number">0x14</span> pkt cnt <span class="number">450105</span>, nss <span class="number">2</span>, bw <span class="number">4</span>]</span><br><span class="line"></span><br><span class="line"><span class="number">15</span>:<span class="number">05</span>:<span class="number">13.535129</span> [wifico][<span class="number">0x183b4f56b07</span>][<span class="number">15</span>:<span class="number">05</span>:<span class="number">12.436868</span>]wlan: [<span class="number">1372</span>:D:HDD] wlan_hdd_get_sta_stats: [TX: Reporting MCS rate <span class="number">8</span>, flags <span class="number">0x14</span> pkt cnt <span class="number">267148</span>, nss <span class="number">2</span>, bw <span class="number">4</span>]-[RX: Reporting MCS rate <span class="number">8</span>, flags <span class="number">0x14</span> pkt cnt <span class="number">450107</span>, nss <span class="number">2</span>, bw <span class="number">4</span>]</span><br></pre></td></tr></table></figure></p><p>网络正常情况下tx/rx 的收发包是会持续增长的</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;仅针对高通平台，旨在梳理出遇到此类问题的一般应对策略，作为工具篇查阅，快速分类出断流的原因  &lt;/p&gt;
&lt;h2 id=&quot;定位时间点&quot;&gt;&lt;a 
      
    
    </summary>
    
      <category term="网络" scheme="http://lihaizhou.top/categories/%E7%BD%91%E7%BB%9C/"/>
    
    
  </entry>
  
  <entry>
    <title>漫游系列之Dense roaming</title>
    <link href="http://lihaizhou.top/2021/01/03/%E6%BC%AB%E6%B8%B8%E7%B3%BB%E5%88%97%E4%B9%8BDense-roaming/"/>
    <id>http://lihaizhou.top/2021/01/03/漫游系列之Dense-roaming/</id>
    <published>2021-01-03T03:44:39.000Z</published>
    <updated>2021-10-16T05:44:53.112Z</updated>
    
    <content type="html"><![CDATA[<p>本地抓了一份dense roaming的日志，环境是办公室环境下走动到信号相对较弱茶水间再走回来，期间发生两次dense roaming，日志如下：<br><img src="http://blog.lihaizhou.top/DenseRoaming/denseroam-1.png" alt=""></p><p>对于其中的reason=7代码中定义如下：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">typedef <span class="keyword">enum</span> &#123;</span><br><span class="line">    WMI_ROAM_TRIGGER_REASON_NONE = <span class="number">0</span>,</span><br><span class="line">    WMI_ROAM_TRIGGER_REASON_PER,</span><br><span class="line">    WMI_ROAM_TRIGGER_REASON_BMISS,</span><br><span class="line">    WMI_ROAM_TRIGGER_REASON_LOW_RSSI,</span><br><span class="line">    WMI_ROAM_TRIGGER_REASON_HIGH_RSSI,</span><br><span class="line">    WMI_ROAM_TRIGGER_REASON_PERIODIC,</span><br><span class="line">    WMI_ROAM_TRIGGER_REASON_MAWC,</span><br><span class="line">    WMI_ROAM_TRIGGER_REASON_DENSE,</span><br><span class="line">    WMI_ROAM_TRIGGER_REASON_BACKGROUND,</span><br><span class="line">    WMI_ROAM_TRIGGER_REASON_FORCED,</span><br><span class="line">    WMI_ROAM_TRIGGER_REASON_BTM,</span><br><span class="line">    WMI_ROAM_TRIGGER_REASON_UNIT_TEST,</span><br><span class="line">    WMI_ROAM_TRIGGER_REASON_BSS_LOAD,</span><br><span class="line">    WMI_ROAM_TRIGGER_REASON_DEAUTH,</span><br><span class="line">    WMI_ROAM_TRIGGER_REASON_IDLE,</span><br><span class="line">    <span class="comment">/*</span></span><br><span class="line"><span class="comment">     * <span class="doctag">NOTE:</span> don't add any more ROAM_TRIGGER_REASON values here.</span></span><br><span class="line"><span class="comment">     * There are checks in the FW that require the value of</span></span><br><span class="line"><span class="comment">     * WMI_ROAM_TRIGGER_REASON_MAX to be &lt; 16.</span></span><br><span class="line"><span class="comment">     * Add new ROAM_TRIGGER_REASON values below, inside the</span></span><br><span class="line"><span class="comment">     * WMI_ROAM_TRIGGER_EXT_REASON_ID enum.</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    WMI_ROAM_TRIGGER_REASON_MAX,</span><br><span class="line">&#125; WMI_ROAM_TRIGGER_REASON_ID;</span><br></pre></td></tr></table></figure></p><p>reason=7对应的原因是WMI_ROAM_TRIGGER_REASON_DENSE即dense roaming</p><p>高通对dense roaming的解释<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Dense roaming</span><br><span class="line">Dense-<span class="function">roaming mechanism is a new feature of location retrieval <span class="title">function</span> <span class="params">(LRF)</span> 3.0. This feature retains high throughput when many roamable APs are present nearby and the data traffic is high then.</span></span><br><span class="line"><span class="function">The original Wi-Fi roaming mechanism is designed to enable roaming when the current RSSI value reaches the defined RSSI threshold value, <span class="keyword">for</span> example, -76 dBm. However, in a high dense environment where there are many roamable APs, it is better to start roaming earlier when the traffic is high because high throughput is maintained <span class="keyword">for</span> heavy traffic with minimal power consumption impact. Dense roaming functions in such a manner to retain high throughput during periods of heavy traffic.</span></span><br><span class="line"><span class="function">To provide <span class="keyword">this</span> value-added enhancement, the dense roaming mechanism is designed with the following two principles.</span></span><br><span class="line"><span class="function">■ Relying on other triggered scans, sniffing is performed on the management packets to determine the number of roamable APs that are present then in the environment.</span></span><br><span class="line"><span class="function">■ If a dense roaming environment is <span class="title">found</span> <span class="params">(that is, the number of the found roamable APs is bigger than the configured dense roamable AP threshold value)</span>, and <span class="keyword">if</span> there is significant traffic at that moment, then <span class="keyword">switch</span> to use the dense RSSI threshold value so that the roaming is triggered earlier.</span></span><br></pre></td></tr></table></figure></p><p>Dense意思是密集，dense roaming从字面上意思是密集漫游，上面高通的一段话翻译下来就是：<br>密集漫游<br>密集漫游机制是位置检索功能（LRF）3.0上新增的新feature，<font color="#dd0000">当附近有许多可漫游AP且数据流量很高时，此功能可保持高吞吐量。</font><br>   </p><p>最初的Wi-Fi漫游机制设计是当RSSI值比较低的时候并达到定义的RSSI阈值（例如-76 dBm）时启用漫游。<br>但是，在具有许多可漫游AP的高密度环境中，在流量较高时更早开始漫游是一个更好的措施，因为对于高流量保持高吞吐量，这样对功耗的影响则最小， 密集漫游在繁忙流量期间保持高吞吐量的方式运行。</p><p>为了提供这种增强功能，dense roaming按照以下两个原理设计：</p><ol><li>依靠其他条件触发的扫描，对管理数据包执行嗅探以确定当时环境中存在的可漫游AP的数量。</li><li>如果找到密集漫游环境（即找到的可漫游AP的数量大于配置的密集可漫游AP阈值），并且如果此时有大量流量，<font color="#dd0000">则切换为使用dense RSSI阈值，这样漫游就提前触发了</font><br> </li></ol><p>Q：怎么判断当前符合密集漫游环境？<br>A：<br>Detection of dense environment<br>The dense-roaming mechanism detects if it is a dense environment using the following procedure:  </p><ol><li>With any scan triggered, for example, a host scan from Wi-Fi driver, the roaming module snoops toget the beacon or probe response management frames.  </li><li>If a roamable AP is found, then the roaming module increments an internal count of the roamableAPs.  </li><li>If the number of the roamable APs is greater than the groam_dense_min_aps INI parametervalue, where three is the default value, then change to use dense roaming threshold value as thenew threshold value.<br>The dense roaming threshold value comes from the original threshold valuewith the shift of INI parameter, groam_dense_rssi_thresh_offset value. For example, if theoriginal threshold value is -76 dBm and groam_dense_rssi_thresh_offset INI parametervalue is 10, then the dense roaming threshold value is -66 dBm.</li></ol><p>检测密集环境<br>密集漫游机制使用以下步骤检测当前是否是密集环境：  </p><ol><li>如果有任何扫描（例如，从Wi-Fi驱动程序进行主机扫描）发送的话，漫游模块都会监听以获取信标或探测响应管理帧。  </li><li>如果找到了一个可漫游AP，则漫游模块将增加该可漫游AP的内部计数。  </li><li>如果可漫游AP的数量大于groam_dense_min_aps INI参数值（默认值为3），<font color="#dd0000">则更改为使用密集漫游阈值作为新阈值。</font><br> 密集漫游阈值来自原始阈值，并带有INI参数的偏移groam_dense_rssi_thresh_offset值。<br> 例如，如果原始阈值是-76 dBm，并且groam_dense_rssi_thresh_offset INI参数值是10，则密集漫游阈值是-66 dBm。</li></ol><p>Q: 即便当前检测到dense roaming环境了，也不一定会触发dense roaming，为什么？<br>参见如下解释：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Dense roaming in dense environment  </span><br><span class="line">During the detection of a dense environment, dense-roaming mechanism is triggered and the followingactions are taken:  </span><br><span class="line"><span class="number">1</span>.  When the current RSSI breaches the dense roaming RSSI threshold value and the data traffic isabove the dense traffic threshold as defined by the INI parameter, gtraffic_threshold, then the active roam scan is triggered.  </span><br><span class="line"><span class="number">2</span>.  When the current RSSI breaches the dense roaming RSSI threshold value and the data traffic isbelow the dense traffic threshold, then update only the threshold value by RSSI different threshold values and <span class="keyword">do</span> not trigger the active roam scan.  </span><br><span class="line"><span class="number">3</span>.  When the RSSI threshold exceeds the original roaming threshold value, <span class="keyword">for</span> example, -<span class="number">76</span> dBm,then <span class="keyword">do</span> not consider the data traffic and trigger the active roam scan.  </span><br><span class="line"><span class="number">4</span>.  If skipping the active roam scan due to insufficient data traffic in the point mentioned previously,then take either of the following steps based on whichever occurs first:a.  If the <span class="keyword">new</span> threshold value is breached first, <span class="keyword">for</span> example, RSSI drops to -<span class="number">71</span> dBm, then check ifthe condition is as the steps <span class="number">1</span> or <span class="number">2</span> mentioned previously and take actions accordingly.b.  If the data traffic is above the dense traffic threshold, then trigger the roaming scan</span><br></pre></td></tr></table></figure></p><p>在密集环境中的密集漫游<br>  在检测密集环境时，将触发密集漫游机制，并采取以下措施：<br>  1.如果当前RSSI值超过了dense roaming的阈值，并且数据流量高于INI参数gtraffic_threshold定义的密集流量阈值时，这时候将触发活动漫游扫描。<br>  2.如果当前的RSSI超过了dense roaming的RSSI阈值并且数据流量低于密集流量阈值时，则仅更新阈值，并不触发漫游扫描。<br>  3.当RSSI阈值超过原始漫游阈值（例如-76 dBm）时，则无需考虑数据流量并触发活动漫游扫描。<br>  4.如果由于前面提到的数据通信量不足而跳过了主动漫游扫描，则采取以下步骤之一(根据哪种情况先发生)：<br>  a)  如果首先突破了新阈值，例如RSSI降至-71 dBm，则请检查条件是否符合前面提到的步骤1或2并采取相应措施<br>  b)  如果数据流量高于密集流量阈值，则触发漫游扫描</p><p>  个人理解：<br>dense roaming有自己的一个阈值，很显然这个值会低于原始的漫游阈值，假设是-66，我们知道原始的一般是-76，比如这个时候RSSI是-67已经超过了-66，并且这个时候数据流量大于规定的阈值，这种情况符合RSSI达到dense roaming阈值且处于大数据流量情况，此时直接触发漫游扫描。<br>但是如果此时虽然RSSI达到了但是数据流量不够大没有达标，那么只是更新dense roaming阈值，并不会触发漫游扫描。这里我们知道了原来dense roaming的阈值是动态变化的，这点后面看日志也能看出来。<br>这个时候假设dense roaming阈值调整了，比如又降低了一点达到了-71，这个时候会采取下面两个步骤之一，就看哪个先发生</p><ol><li>当前RSSI先达到新阈值了，则执行1&amp;2步骤</li><li>如果此时数据流量高于阈值了，直接漫游！</li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;本地抓了一份dense roaming的日志，环境是办公室环境下走动到信号相对较弱茶水间再走回来，期间发生两次dense roaming，日志如下：&lt;br&gt;&lt;img src=&quot;http://blog.lihaizhou.top/DenseRoaming/denseroam-
      
    
    </summary>
    
      <category term="网络" scheme="http://lihaizhou.top/categories/%E7%BD%91%E7%BB%9C/"/>
    
    
  </entry>
  
  <entry>
    <title>一个Beacon miss导致的掉线问题分析</title>
    <link href="http://lihaizhou.top/2021/01/02/%E4%B8%80%E4%B8%AABeacon-miss%E5%AF%BC%E8%87%B4%E7%9A%84%E6%8E%89%E7%BA%BF%E9%97%AE%E9%A2%98%E5%88%86%E6%9E%90/"/>
    <id>http://lihaizhou.top/2021/01/02/一个Beacon-miss导致的掉线问题分析/</id>
    <published>2021-01-02T06:53:50.000Z</published>
    <updated>2021-09-08T12:36:27.629Z</updated>
    
    <content type="html"><![CDATA[<p>复现步骤：测试机开启双WiFi且连接测试路由主5G，辅2.4G<br>问题现象：主wifi漫游后不久，辅WiFi出现断连<br>问题概率：必现  </p><h1 id="辅wifi为什么会断连？"><a href="#辅wifi为什么会断连？" class="headerlink" title="辅wifi为什么会断连？"></a>辅wifi为什么会断连？</h1><p>先看下辅wifi为何会断连，从测试同事提供的视频来看时间点大概是15:50:07左右  </p><h2 id="step1"><a href="#step1" class="headerlink" title="step1:"></a>step1:</h2><p>看下这个时间点的辅wifi状态机<br><code>tip: 过滤的关键字&quot;WifiClientModeImpl:&quot;,打印不同时间点的wifi状态转移变化</code></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rec[<span class="number">22</span>]: time=<span class="number">12</span>-<span class="number">30</span> <span class="number">15</span>:<span class="number">50</span>:<span class="number">07.841</span> processed=ConnectModeState org=ConnectedState dest=DisconnectedState what=SUPPLICANT_STATE_CHANGE_EVENT screen=on <span class="number">0</span> <span class="number">0</span> SSID: <span class="number">2.4</span> BSSID: <span class="number">00</span>:<span class="number">00</span>:<span class="number">00</span>:<span class="number">00</span>:<span class="number">00</span>:<span class="number">00</span> nid: <span class="number">1</span> state: DISCONNECTED</span><br></pre></td></tr></table></figure><h2 id="step2"><a href="#step2" class="headerlink" title="step2:"></a>step2:</h2><p>看下当前的信号强度以及断线reason值<br>//搜索关键字”NETWORK_DISCONNECTION_EVENT”, 代表网络断开的标志性日志，信号值-21说明信号强度很好，reason为0<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">12</span>-<span class="number">30</span> <span class="number">15</span>:<span class="number">50</span>:<span class="number">07.809</span> NETWORK_DISCONNECTION_EVENT local_gen=<span class="keyword">false</span> reason=<span class="number">0</span>:<span class="number">0x0</span> lastRssi=-<span class="number">21</span> lastFreq=<span class="number">2437</span> lastLinkSpeed=<span class="number">96</span> lastScore=<span class="number">60</span> mobileTxBytes=<span class="number">964</span> mobileRxBytes=<span class="number">476</span> totalTxBytes=<span class="number">711415</span> totalRxBytes=<span class="number">1741111</span> screenOn=<span class="keyword">true</span> cellularData=<span class="keyword">false</span>, supplicantStateChangeEvents: &#123; COMPLETED &#125;</span><br></pre></td></tr></table></figure></p><p>这个reason 0其实没有多大的参考意义，对应的802.11 Deauth Reason Codes表格中给出的解释是正常操作，具体的reason需要看fw打印的reason</p><h2 id="step3"><a href="#step3" class="headerlink" title="step3:"></a>step3:</h2><p>确认下辅wifi是底层断线还是上层断线<br>直接看<code>nl80211</code>收到断线的消息早于<code>wpa_supplicant: wlan1</code>可以说明是底层掉线</p><p>//logcat<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">12</span>-<span class="number">30</span> <span class="number">15</span>:<span class="number">50</span>:<span class="number">07.804</span> wifi <span class="number">4855</span> <span class="number">4855</span> D wpa_supplicant: nl80211: Drv Event <span class="number">48</span> (NL80211_CMD_DISCONNECT) received <span class="keyword">for</span> wlan1</span><br><span class="line"><span class="number">12</span>-<span class="number">30</span> <span class="number">15</span>:<span class="number">50</span>:<span class="number">07.804</span> wifi <span class="number">4855</span> <span class="number">4855</span> D wpa_supplicant: nl80211: Disconnect event</span><br><span class="line"><span class="number">12</span>-<span class="number">30</span> <span class="number">15</span>:<span class="number">50</span>:<span class="number">07.804</span> wifi <span class="number">4855</span> <span class="number">4855</span> D wpa_supplicant: wlan1: <span class="function">Event <span class="title">DEAUTH</span> <span class="params">(<span class="number">11</span>)</span> received</span></span><br><span class="line"><span class="function">12-30 15:50:07.804 wifi 4855 4855 D wpa_supplicant: wlan1: Deauthentication notification</span></span><br><span class="line"><span class="function">12-30 15:50:07.804 wifi 4855 4855 D wpa_supplicant: wlan1: * reason 0 <span class="params">(UNKNOWN)</span> locally_generated</span>=<span class="number">1</span></span><br><span class="line"><span class="number">12</span>-<span class="number">30</span> <span class="number">15</span>:<span class="number">50</span>:<span class="number">07.804</span> wifi <span class="number">4855</span> <span class="number">4855</span> D wpa_supplicant: <span class="function">Deauthentication frame <span class="title">IE</span><span class="params">(s)</span> - <span class="title">hexdump</span><span class="params">(len=<span class="number">0</span>)</span>: [NULL]</span></span><br><span class="line"><span class="function">12-30 15:50:07.804 wifi 4855 4855 I wpa_supplicant: wlan1: CTRL-EVENT-DISCONNECTED bssid</span>=<span class="number">3</span>a:<span class="number">72</span>:e4:<span class="number">68</span>:<span class="number">21</span>:e9 reason=<span class="number">0</span> locally_generated=<span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="number">12</span>-<span class="number">30</span> <span class="number">15</span>:<span class="number">50</span>:<span class="number">07.805</span> wifi <span class="number">4855</span> <span class="number">4855</span> D wpa_supplicant: wlan1: State: COMPLETED -&gt; DISCONNECTED</span><br></pre></td></tr></table></figure></p><h2 id="step4："><a href="#step4：" class="headerlink" title="step4："></a>step4：</h2><p>到这里我们只知道是底层断线的，具体原因还没找到，此时需要看下driver log以及fw log</p><p>//driver log<br>关键性日志<code>wma_roam_event_callback</code>，代表<code>driver</code>收到<code>fw roam</code>的<code>callback</code>，后面跟着的<code>reason=2</code> 代表本次打算去漫游的原因是<code>beacon miss</code>，但是其实后面并没有实际去漫游的动作，<br>包括<code>roam scan</code>也没有，是因为辅wifi底层不支持漫游，此时信号-25很好</p><pre><code class="java"><span class="number">15</span>:<span class="number">50</span>:<span class="number">07.679517</span> [schedu][<span class="number">0x2021a49e0</span>][<span class="number">15</span>:<span class="number">50</span>:<span class="number">07.675444</span>]wlan: [<span class="number">4730</span>:D:WMA] wma_roam_event_callback: Reason <span class="number">2</span>, Notif <span class="number">0</span> <span class="keyword">for</span> vdevid <span class="number">1</span>, rssi -<span class="number">25</span><span class="number">15</span>:<span class="number">50</span>:<span class="number">07.679946</span> [schedu][<span class="number">0x2021a508e</span>][<span class="number">15</span>:<span class="number">50</span>:<span class="number">07.675533</span>]wlan: [<span class="number">4730</span>:E:PE] lim_ps_offload_handle_missed_beacon_ind: <span class="number">1855</span>: Received Heart Beat Failure<span class="comment">//收到fw传上来的心跳包失败的消息</span><span class="number">15</span>:<span class="number">50</span>:<span class="number">07.679961</span> [schedu][<span class="number">0x2021a525e</span>][<span class="number">15</span>:<span class="number">50</span>:<span class="number">07.675557</span>]wlan: [<span class="number">4730</span>:E:PE] lim_send_heart_beat_timeout_ind: <span class="number">1830</span>: Heartbeat failure from Fw<span class="number">15</span>:<span class="number">50</span>:<span class="number">07.679977</span> [schedu][<span class="number">0x2021a5527</span>][<span class="number">15</span>:<span class="number">50</span>:<span class="number">07.675594</span>]wlan: [<span class="number">4730</span>:W:PE] lim_handle_heart_beat_failure: <span class="number">494</span>: Heartbeat Failure<span class="comment">//因为sta没有收到AP发的心跳beacon，所以sta在beacon timeout之前主动发了Probe Req报文探测下AP是否还在</span><span class="number">15</span>:<span class="number">50</span>:<span class="number">07.679984</span> [schedu][<span class="number">0x2021a55f7</span>][<span class="number">15</span>:<span class="number">50</span>:<span class="number">07.675605</span>]wlan: [<span class="number">4730</span>:D:PE] lim_handle_heart_beat_failure: <span class="number">515</span>: HB missed from AP. Sending Probe Req<span class="number">15</span>:<span class="number">50</span>:<span class="number">07.680005</span> [schedu][<span class="number">0x2021a5ada</span>][<span class="number">15</span>:<span class="number">50</span>:<span class="number">07.675670</span>]wlan: [<span class="number">4730</span>:D:PE] Probe req TX: vdev <span class="number">1</span> seq num <span class="number">2077</span> to <span class="number">3</span>a:<span class="number">72</span>:e4:<span class="number">68</span>:<span class="number">21</span>:e9 len <span class="number">158</span><span class="number">15</span>:<span class="number">50</span>:<span class="number">07.750957</span> [schedu][<span class="number">0x2021a6b29</span>][<span class="number">15</span>:<span class="number">50</span>:<span class="number">07.675887</span>]wlan: [<span class="number">4730</span>:D:PE] lim_handle_heart_beat_timeout_for_session: <span class="number">4610</span>: Sending Probe <span class="keyword">for</span> Session: <span class="number">1</span><span class="number">15</span>:<span class="number">50</span>:<span class="number">07.750989</span> [schedu][<span class="number">0x2021a6e9e</span>][<span class="number">15</span>:<span class="number">50</span>:<span class="number">07.675934</span>]wlan: [<span class="number">4730</span>:D:HDD] hdd_lost_link_info_cb: <span class="number">1323</span>: rssi on disconnect -<span class="number">25</span><span class="comment">//AP没有ACK</span><span class="number">15</span>:<span class="number">50</span>:<span class="number">07.750995</span> [schedu][<span class="number">0x20222d395</span>][<span class="number">15</span>:<span class="number">50</span>:<span class="number">07.704587</span>]wlan: [<span class="number">4730</span>:D:WMA] wma_process_mgmt_tx_completion: <span class="number">2613</span>: status: WMI_MGMT_TX_COMP_TYPE_COMPLETE_NO_ACK wmi_desc_id: <span class="number">63</span><span class="number">15</span>:<span class="number">50</span>:<span class="number">07.751023</span> [schedu][<span class="number">0x2022f8cef</span>][<span class="number">15</span>:<span class="number">50</span>:<span class="number">07.748018</span>]wlan: [<span class="number">4730</span>:I:PE] Deauth TX: vdev <span class="number">1</span> seq_num <span class="number">2078</span> reason <span class="number">4</span> waitForAck <span class="number">0</span> to <span class="number">3</span>a:<span class="number">72</span>:e4:<span class="number">68</span>:<span class="number">21</span>:e9 from <span class="number">34</span>:<span class="number">1</span>c:f0:<span class="number">6f</span>:b6:<span class="number">22</span><span class="number">15</span>:<span class="number">50</span>:<span class="number">07.751112</span> [schedu][<span class="number">0x2022fa17f</span>][<span class="number">15</span>:<span class="number">50</span>:<span class="number">07.748292</span>]wlan: [<span class="number">4730</span>:D:SME] csr_roam_chk_lnk_deauth_ind: <span class="number">12441</span>: DEAUTH Indication from MAC <span class="keyword">for</span> vdev_id <span class="number">1</span> bssid <span class="number">3</span>a:<span class="number">72</span>:e4:<span class="number">68</span>:<span class="number">21</span>:e9</code></pre><p><code>beacon miss</code>的发生不一定会立刻掉线，达到一定数量才会触发掉线吧?<br>接下来在fw log中证实下这个猜想</p><p>//fw log<br>//15:50:07 左右发生bmiss</p><p>//…省略cons_bmiss_count = 8之前的片段</p><pre><code class="java"><span class="number">15</span>:<span class="number">50</span>:<span class="number">05.820871</span> R0: FWMSG: [<span class="number">1891</span>d6b92] [ wlan_swbmiss_offload.c : <span class="number">865</span> ] SWBMISS_TIMER_FN: vdev_id=<span class="number">1</span>, curr_bmiss_bcnt=<span class="number">8</span>, pre_bmiss_detected=<span class="number">1</span>, first_bmiss_detected=<span class="number">0</span>, final_bmiss_detected=<span class="number">0</span>, b_timeout=<span class="number">1</span>, cons_bmiss_count = <span class="number">8</span><span class="number">15</span>:<span class="number">50</span>:<span class="number">05.822430</span> R0: FWMSG: [<span class="number">1893</span>b1a83] [ wlan_swbmiss_offload.c : <span class="number">865</span> ] SWBMISS_TIMER_FN: vdev_id=<span class="number">1</span>, curr_bmiss_bcnt=<span class="number">9</span>, pre_bmiss_detected=<span class="number">1</span>, first_bmiss_detected=<span class="number">0</span>, final_bmiss_detected=<span class="number">0</span>, b_timeout=<span class="number">1</span>, cons_bmiss_count = <span class="number">9</span><span class="number">15</span>:<span class="number">50</span>:<span class="number">05.862506</span> R0: FWMSG: [<span class="number">18958</span>dc54] [ wlan_swbmiss_offload.c : <span class="number">865</span> ] SWBMISS_TIMER_FN: vdev_id=<span class="number">1</span>, curr_bmiss_bcnt=<span class="number">10</span>, pre_bmiss_detected=<span class="number">1</span>, first_bmiss_detected=<span class="number">1</span>, final_bmiss_detected=<span class="number">0</span>, b_timeout=<span class="number">1</span>, cons_bmiss_count = <span class="number">10</span><span class="number">15</span>:<span class="number">50</span>:<span class="number">05.905835</span> R0: FWMSG: [<span class="number">189770</span>d97] [ wlan_swbmiss_offload.c : <span class="number">865</span> ] SWBMISS_TIMER_FN: vdev_id=<span class="number">1</span>, curr_bmiss_bcnt=<span class="number">11</span>, pre_bmiss_detected=<span class="number">1</span>, first_bmiss_detected=<span class="number">1</span>, final_bmiss_detected=<span class="number">0</span>, b_timeout=<span class="number">1</span>, cons_bmiss_count = <span class="number">11</span><span class="comment">//.....省略cons_bmiss_count = 12到cons_bmiss_count = 28的片段日志</span><span class="number">15</span>:<span class="number">50</span>:<span class="number">07.761702</span> R0: FWMSG: [<span class="number">18</span>b9308fb] [ wlan_swbmiss_offload.c : <span class="number">865</span> ] SWBMISS_TIMER_FN: vdev_id=<span class="number">1</span>, curr_bmiss_bcnt=<span class="number">29</span>, pre_bmiss_detected=<span class="number">1</span>, first_bmiss_detected=<span class="number">1</span>, final_bmiss_detected=<span class="number">0</span>, b_timeout=<span class="number">1</span>, cons_bmiss_count = <span class="number">2915</span>:<span class="number">50</span>:<span class="number">07.761875</span> R0: FWMSG: [<span class="number">18</span>b95f62e] [ wlan_swbmiss_offload.c : <span class="number">563</span> SWBMISS_NULL_SEND_CMPLT: vdev_id=<span class="number">1</span>, isQosNullSuccess=<span class="number">0</span>, isFinalBmiss=<span class="number">1</span>, first_bmiss_detected=<span class="number">1</span>, final_bmiss_detected=<span class="number">1</span>, fbmiss_evnt_posted=<span class="number">0</span>, vbmiss-&gt;connected = <span class="number">1</span>, cons_bmiss_count = <span class="number">30</span></code></pre><p>这里的<code>final_bmiss_detected</code>  ，<code>first_bmiss_detected</code>  解释对应如下</p><pre><code class="java">gRoamBmissFirstBcnt=<span class="number">10</span>After consecutive number of beacons missed as configured by gRoamBmissFirstBcnt, <span class="function">the system stays <span class="title">alive</span> <span class="params">(no power collapse)</span> t</span><span class="function">o receive beacons until <span class="keyword">final</span> <span class="title">BMISS</span> <span class="params">(consecutive number of beacons missed as configured by gRoamBmissFinalBcnt)</span> </span><span class="function"></span><span class="function">gRoamBmissFinalBcnt</span>=<span class="number">20</span>After consecutive number of beacons missed as configured by gRoamBmissFirstBcnt, <span class="function">the system stays <span class="title">alive</span> <span class="params">(no power collapse)</span> to receive beacons until <span class="keyword">final</span> <span class="title">BMISS</span> <span class="params">(consecutive number of beacons missed as configured by gRoamBmissFinalBcnt)</span></span><span class="function"></span><span class="function">If “p”<span class="params">(gRoamBmissFirstBcnt)</span> beacons are missed in a row, roaming <span class="keyword">module</span> will perform roaming scan and create a channel map.</span><span class="function">If “q”<span class="params">(gRoamBmissFinalBcnt)</span> more beacons are missed, it results in “<span class="keyword">final</span> beacon miss”.</span><span class="function"></span><span class="function">That is a trigger <span class="keyword">for</span> roaming. If we don’t find the candidate, <span class="keyword">this</span> will lead to disconnection.</span></code></pre><p>大概意思是有连续的10个<code>beacon missed</code>发生了，这个时候不会断线，会触发漫游并会继续接收beacon。</p><p>如果在前面连续十个<code>beacon missed</code>之后又发生连续20个<code>beacon missed</code>的话，则会进入<code>final beacon miss</code> ，这个时候如果还没有找到候选AP的话，会最终导致断线<br>所以到这里明白了fw确实总计发生了30次<code>beacon miss</code>，并且由于是辅wifi不支持漫游的缘故，最终以断线收场</p><h2 id="step5："><a href="#step5：" class="headerlink" title="step5："></a>step5：</h2><p>可是beacon miss的原因是什么呢？前面已经分析过断开时信号是-25说明不是信号弱导致，同时也看到了在超时掉线前sta有发probe request即空帧探测AP，没有收到AP的ACK，看上去大概率问题出在AP<br>但是测试同事提的这个问题是在主wifi漫游后才会出现辅wifi掉线，这和主wifi漫游有关系？和channel有关系？</p><p>下一步请求测试同事提供sniffer进一步证实, 此文待续</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;复现步骤：测试机开启双WiFi且连接测试路由主5G，辅2.4G&lt;br&gt;问题现象：主wifi漫游后不久，辅WiFi出现断连&lt;br&gt;问题概率：必现  &lt;/p&gt;
&lt;h1 id=&quot;辅wifi为什么会断连？&quot;&gt;&lt;a href=&quot;#辅wifi为什么会断连？&quot; class=&quot;header
      
    
    </summary>
    
      <category term="网络" scheme="http://lihaizhou.top/categories/%E7%BD%91%E7%BB%9C/"/>
    
    
  </entry>
  
  <entry>
    <title>对投屏工作的回顾小结(持续补充)</title>
    <link href="http://lihaizhou.top/2020/12/01/%E5%AF%B9%E6%8A%95%E5%B1%8F%E5%B7%A5%E4%BD%9C%E7%9A%84%E5%9B%9E%E9%A1%BE%E5%B0%8F%E7%BB%93-%E6%8C%81%E7%BB%AD%E8%A1%A5%E5%85%85/"/>
    <id>http://lihaizhou.top/2020/12/01/对投屏工作的回顾小结-持续补充/</id>
    <published>2020-12-01T09:08:00.000Z</published>
    <updated>2021-10-16T05:46:53.087Z</updated>
    
    <content type="html"><![CDATA[<p>前言<br>主要针对高通平台上的miracast投屏遇到的问题，顺便对miracast投屏的一点归纳总结，以便后续如再处理miracast投屏相关的工作，通过本篇文章能够快速重新开始。</p><p>以下主要通过一些QA方式来概述 </p><p>Q：高通上的投屏和谷歌原生的投屏有什么差别吗？</p><p>A：Google WFD 支持AVC, LPCM, and AAC 编码 并支持HDCP加密, 但是缺少对内容保护的支持<br>      通过使用Presentation、MediaRouter和DisplayManager api，它可以作为一个外部WFD提供给应用程序使用。<br>      按照高通文档的解释，谷歌的miracast和高通的相比，缺乏内容保护支持，性能较低，功耗较高，高通提供了一个增强的Miracast解决方案。</p><p>Q：Miracast Source 软件架构是怎样的？</p><p>A：<br><img src="http://blog.lihaizhou.top/Miracast/miracast.png" alt=""><br>个人理解红色标准1和2的代表视频数据的两种来源，分别是USB/摄像头和录制屏幕，4标注代表的是经过V4L2编码后的视频数据从给混合起Mux，5标注代表音频数据送给Mux，合成后压缩成MPEG-2格式的ts流，再通过RTP server即UDP传送，6标注代表的是RTSP的协议栈，RTSP是基于tcp的，主要是客户端和sink端的一系列交互和协商等。</p><p>Q：如果投屏失败了，从tcpdump上如何分析出是哪一步出错了？</p><p>A：正确的流程参见：<br><a href="http://lihaizhou.top/2020/11/30/%E4%BB%8Etcpdump%E7%9C%8Bmiracast%E7%9A%84play%E6%B5%81%E7%A8%8B/#more">从tcpdump看miracast的play流程(工具篇)</a></p><p>Q：怎么看SessionManagerService在miracast投屏环节中扮演的角色？</p><p>A：个人理解这个类承担的角色比较重要，实现是在vendor中，是一个binder的服务端，起到一个承上启下的作用。<br>      承上的是应用层以及fwk，承下的是主要native层的wifisession打交道。<br>      其实不妨看下这个类中的方法，比如startWfdSession，startUibcSession，setSurface，play, pause，tcpPlaybackControl等几乎都是对WFDSession中的接口所做的一层封装。<br>      所以比较核心的方法还得接着看native层的WFDSession，高通的真正实现封装在so中</p><p>Q：如果投屏遇到花屏了或者其他画面异常的情况，该如何判断是sink还是source的问题，如果是source的话，是哪一步的问题呢？</p><p>A：目前遇到的画面显示异常除了小部分是非问题比如输入法状态栏等隐私保护设计导致的，其他大部分都是网络环境导致的。这里先不考虑可能是sink端解码的问题，假如问题就出在source或者网络，可以先获取发送前的视频流dump.ts，这个ts流已经是音视频合成后的准备通过网络发送的数据。<br>如果这个ts流是正常的，就可以排除是source的问题了，如果这个ts流是有问题的话，就要考虑是不是V4L2编码后的数据是否是正常的了,这个时候可以抓取V4l2 dump获取到编码后的视频数据，这个数据是发给mux的，然后和av数据混合成ts流</p><p>Q：如何判断花屏是否因为是丢包率高导致的？</p><p>A：wireshark打开抓取的tcpdump，选择UDP packet，Right click -&gt; Decode as -&gt; RTP  Then from the tool bar, select Telephony -&gt; RTP-&gt;Stream analysis -&gt; Save Payload<br>. This will open a pop-up which shows the packet loss % rate.</p><p>Q: VirtualDisplay在miracast投屏中是何时创建的，扮演的作用？</p><p>A: 我们先说下手机普通录制视频的流程，一般会先用<code>MediaProjection</code>的<code>createVirtualDisplay</code>创建一个VirtualDisplay，createVirtualDisplay的参数有宽高dpi啥的，还有一个最重要的参数就是surface，这玩意其实就是指向一块内存，surface怎么创建呢，可以使用MediaCodec的createInputSurface创建一个输入surface，也可以自己创建，使用MediaCodec的API创建的话缺乏灵活性，没有办法对一帧一帧数据进行处理。录制屏幕的数据从而而来的呢？MediaCodec的createByCodecName创建一个编码器，然后调用其setCallback，在onOutputBufferAvailable中获取到buffer数据，然后这个时候就可以处理这些录屏数据了。<br>对于VirtualDisplay来说，帧数据的生产者是MediaProjection对象，消费者是向它注册的MediaCodec的Surface对象。</p><p>在miracast投屏环节中，VirtualDisplay是何时创建的呢？<br>WFDSession.java中的notify函数中如下方式：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">                            <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">notify</span><span class="params">(Bundle b, <span class="keyword">int</span> SessionId)</span> </span>&#123;</span><br><span class="line">                            <span class="comment">//....</span></span><br><span class="line">                            Surface surface = (Surface) (b</span><br><span class="line">                                    .getParcelable(<span class="string">"surface"</span>));</span><br><span class="line">                            <span class="keyword">if</span> (surface != <span class="keyword">null</span>) &#123;</span><br><span class="line">                                Log.d(mTAG, <span class="string">"Surface supplied by source modules"</span>);</span><br><span class="line">                                <span class="keyword">int</span> flags = <span class="number">0</span>;</span><br><span class="line">                                <span class="comment">// MIUI MOD: START</span></span><br><span class="line">                                <span class="comment">//flags |= DisplayManager.VIRTUAL_DISPLAY_FLAG_PUBLIC</span></span><br><span class="line">                                <span class="comment">//        | DisplayManager.VIRTUAL_DISPLAY_FLAG_PRESENTATION;</span></span><br><span class="line">                                flags |= DisplayManager.VIRTUAL_DISPLAY_FLAG_PUBLIC</span><br><span class="line">                                        | DisplayManager.VIRTUAL_DISPLAY_FLAG_PRESENTATION</span><br><span class="line">                                        | VIRTUAL_DISPLAY_FLAG_THE_THIRD_SCREEN_PROJECTION;</span><br><span class="line">                                <span class="comment">// END</span></span><br><span class="line">                                <span class="keyword">if</span> (secure == <span class="number">1</span>) &#123;</span><br><span class="line">                                    flags |= DisplayManager.VIRTUAL_DISPLAY_FLAG_SECURE;</span><br><span class="line"><span class="comment">//                                            | DisplayManager.VIRTUAL_DISPLAY_FLAG_SUPPORTS_PROTECTED_BUFFERS;</span></span><br><span class="line">                                &#125;</span><br><span class="line">                                mVirtualDisplayDPI = Math.min(width, height)</span><br><span class="line">                                        * DisplayMetrics.DENSITY_XHIGH / <span class="number">1080</span>;</span><br><span class="line">                                <span class="keyword">if</span> (mDisplayManager != <span class="keyword">null</span>) &#123;</span><br><span class="line">                                    mVirtualDisplay = mDisplayManager</span><br><span class="line">                                            .createVirtualDisplay(</span><br><span class="line">                                                    mPeerDevice.deviceName,</span><br><span class="line">                                                    width,</span><br><span class="line">                                                    height,</span><br><span class="line">                                                    mVirtualDisplayDPI,</span><br><span class="line">                                                    surface, flags);</span><br><span class="line">                                &#125;</span><br><span class="line">                            &#125;</span><br></pre></td></tr></table></figure></p><p>当上层调用创建好WFD session后才会创建这个VirtualDisplay</p><p>Q：隐私投屏是如何实现的？如何做到有些界面在sink端不显示？</p><p>A：我们在WFDSession中createVirtualDisplay时需要传入一个flag参数，文章便在这个flag上，这里新加一个针对隐私的flag，其他界面中的window如果配置了隐私flag的话就不会显示在sink端，fwk端在VirtualDisplayAdapter#performTraversalLocked中判断当前创建的virtualdisplay是否有这个flag，有的话就使能隐私投屏功能</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;前言&lt;br&gt;主要针对高通平台上的miracast投屏遇到的问题，顺便对miracast投屏的一点归纳总结，以便后续如再处理miracast投屏相关的工作，通过本篇文章能够快速重新开始。&lt;/p&gt;
&lt;p&gt;以下主要通过一些QA方式来概述 &lt;/p&gt;
&lt;p&gt;Q：高通上的投屏和谷歌原生
      
    
    </summary>
    
      <category term="网络" scheme="http://lihaizhou.top/categories/%E7%BD%91%E7%BB%9C/"/>
    
    
  </entry>
  
  <entry>
    <title>从tcpdump看miracast的play流程(工具篇)</title>
    <link href="http://lihaizhou.top/2020/11/30/%E4%BB%8Etcpdump%E7%9C%8Bmiracast%E7%9A%84play%E6%B5%81%E7%A8%8B/"/>
    <id>http://lihaizhou.top/2020/11/30/从tcpdump看miracast的play流程/</id>
    <published>2020-11-30T03:01:15.000Z</published>
    <updated>2021-10-16T06:00:43.111Z</updated>
    
    <content type="html"><![CDATA[<p>前言：<br>基于高通平台，其他平台都是类似的<br>本文作为工具篇，记录下来的目的是以便后续如再接触投屏工作能够快速对照上手</p><p>当我们开始准备连接sink设备时，开始的时候，source会创建一个socket监听着并等待sink端过来连接，sink端会触发”connect”的socket函数并开始tcp 握手之路，这个时候source接收到之后，它会触发”accept”的socket函数来处理sink发过俩的连接请求</p><p>开始是握手 Key Message #1~#4<br><img src="http://blog.lihaizhou.top/Miracast_play/miracast-play01.png" alt=""></p><p>RTSP connect M1~M8:<br><img src="http://blog.lihaizhou.top/Miracast_play/miracast-play02.png" alt=""></p><p>DHCP ACK<br><img src="http://blog.lihaizhou.top/Miracast_play/miracast-play03.png" alt=""></p><p>如果这里DHCP Discover -&gt; DHCP ACK耗时超过 5s, 对于一些sink设备来说它就不会继续发 SYN 消息了 ，因此连接会阻塞在这里<br>所以如果遇到sink没有发送SYN的话就要看看这里的DHCP是否耗时太久了</p><p>SYN handshake Sink should send SYN message to 7236 port at this step:<br><img src="http://blog.lihaizhou.top/Miracast_play/miracast-play04.png" alt=""></p><p>Get/Set parameter<br><img src="http://blog.lihaizhou.top/Miracast_play/miracast-play05.png" alt=""></p><p>Play<br><img src="http://blog.lihaizhou.top/Miracast_play/miracast-play06.png" alt=""></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;前言：&lt;br&gt;基于高通平台，其他平台都是类似的&lt;br&gt;本文作为工具篇，记录下来的目的是以便后续如再接触投屏工作能够快速对照上手&lt;/p&gt;
&lt;p&gt;当我们开始准备连接sink设备时，开始的时候，source会创建一个socket监听着并等待sink端过来连接，sink端会触发”c
      
    
    </summary>
    
      <category term="网络" scheme="http://lihaizhou.top/categories/%E7%BD%91%E7%BB%9C/"/>
    
    
  </entry>
  
  <entry>
    <title>一次SystemServer OOM导致的系统重启分析之路</title>
    <link href="http://lihaizhou.top/2020/11/25/%E4%B8%80%E6%AC%A1SystemServer-OOM%E5%AF%BC%E8%87%B4%E7%9A%84%E7%B3%BB%E7%BB%9F%E9%87%8D%E5%90%AF%E5%88%86%E6%9E%90%E4%B9%8B%E8%B7%AF/"/>
    <id>http://lihaizhou.top/2020/11/25/一次SystemServer-OOM导致的系统重启分析之路/</id>
    <published>2020-11-25T00:59:48.000Z</published>
    <updated>2021-10-16T06:14:02.373Z</updated>
    
    <content type="html"><![CDATA[<p><strong>测试步骤</strong><br>MTBF测试跑出来的机器重启，先解释下何为MTBF？<br><code>MTBF测试(Mean Time Between Failure)</code><br>主要测试终端在连续工作状态下，出现死机、重启、冻屏、应用强制关闭等严重故障的概率。通过在一个周期内以自动化方式反复执行规定用例，记录测试过程中被测终端出现的故障数</p><p><strong>复现概率</strong><br>1/200</p><p><strong>问题现象</strong><br>机器出现重启，并自动给出源头是OOM导致的结论</p><h1 id="初步分析"><a href="#初步分析" class="headerlink" title="初步分析"></a>初步分析</h1><p>正常步骤先看bugreport确定下是否是OOM导致的重启，搜索关键字”system_server_crash”或”am_crash”<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">2020</span>-<span class="number">12</span>-<span class="number">07</span> <span class="number">10</span>:<span class="number">56</span>:<span class="number">18</span> system_server_crash (text, <span class="number">346</span> bytes)</span><br><span class="line">Process: system_server</span><br><span class="line">java.lang.OutOfMemoryError: Heap of System_Server has allocated <span class="number">666</span>MB , So trigger OutOfMemoryError crash</span><br><span class="line">at com.android.server.WatchdogInjector.checkOOMState(WatchdogInjector.java:<span class="number">98</span>)</span><br><span class="line">at com.android.server.Watchdog.run(Watchdog.java:<span class="number">776</span>)</span><br><span class="line"></span><br><span class="line"><span class="number">12</span>-<span class="number">07</span> <span class="number">10</span>:<span class="number">56</span>:<span class="number">18.313</span>  <span class="number">1000</span>  <span class="number">1614</span>  <span class="number">1703</span> I am_crash: [<span class="number">1614</span>,<span class="number">0</span>,system_server,-<span class="number">1</span>,java.lang.OutOfMemoryError,Heap of System_Server has allocated <span class="number">666</span>MB , So trigger OutOfMemoryError crash,WatchdogInjector.java,<span class="number">98</span>]</span><br><span class="line"></span><br><span class="line"><span class="number">12</span>-<span class="number">07</span> <span class="number">10</span>:<span class="number">56</span>:<span class="number">18.312</span>  <span class="number">1000</span>  <span class="number">1614</span>  <span class="number">1703</span> D OOMEventManagerFK: dumpheap success : /data/anr/system_server_1614.hprof</span><br></pre></td></tr></table></figure></p><p>上面片段中可以看出当时SystemServer确实发生了OOM，日志中没有打出具体堆栈，这个时候去看下system_server_1614.hprof，这个应该是厂商定制化输出的，比如监测到SystemServer占据内存超过一定的阀值，就dump出这个hprof文件以便于分析<br><img src="http://blog.lihaizhou.top/SystemServerOOM/SystemServerOOM1.png" alt=""><br>这个文件打开后，最大的一块是有五百多个android.app.assist.AssistStructure实例</p><p><img src="http://blog.lihaizhou.top/SystemServerOOM/SystemServerOOM2.png" alt=""></p><p>接下来顺理成章的就看下android.app.assist.AssistStructure单个实例中的引用链关系了<br>直接点击Histogram搜索android.app.assist.AssistStructure即可<br><img src="http://blog.lihaizhou.top/SystemServerOOM/SystemServerOOM3.png" alt=""><br>选择outgoing reference后如下，可以看到有529个<br><img src="http://blog.lihaizhou.top/SystemServerOOM/SystemServerOOM4.png" alt=""><br>随便点击一个右键同样的选outgoing<br><img src="http://blog.lihaizhou.top/SystemServerOOM/SystemServerOOM5.png" alt=""></p><p>每个AssistStructure实例中都包含WifiConfigActivity，WifiConfigActivity是一个什么样的界面呢？<br>是一个对话框样式的Activity，包含了可以填充数据的编辑框。<br>其实我们到这里已经大致明白了，罪魁祸首基本可以认定是WifiConfigActivity了</p><p>从bugreport中寻找关于WifiConfigActivity的线索，查找system_server OOM之前的片段<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">12</span>-<span class="number">07</span> <span class="number">10</span>:<span class="number">56</span>:<span class="number">04.383</span>  <span class="number">1000</span>  <span class="number">1614</span>  <span class="number">2419</span> I WindowManager: Input event dispatching timed out sending to com.android.settings/com.android.settings.wifi.WifiConfigActivity.  Reason: e4a42fb com.android.settings/com.android.settings.wifi.WifiConfigActivity (server) is not responding. Waited <span class="number">8001</span><span class="function">ms <span class="keyword">for</span> <span class="title">FocusEvent</span><span class="params">(hasFocus=<span class="keyword">true</span>)</span></span></span><br></pre></td></tr></table></figure></p><p>可以看到当时的WifiConfigActivity界面是卡住了，无法响应事件，可能当时系统在不停的GC，再看下WifiConfigActivity的调起记录<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">12</span>-<span class="number">07</span> <span class="number">10</span>:<span class="number">55</span>:<span class="number">09.375</span>  <span class="number">1000</span>  <span class="number">1614</span> <span class="number">12880</span> I ActivityTaskManager: START u0 &#123;flg=<span class="number">0x10000000</span> cmp=com.android.settings/.wifi.WifiConfigActivity (has extras)&#125; from uid <span class="number">1000</span></span><br><span class="line"><span class="number">12</span>-<span class="number">07</span> <span class="number">10</span>:<span class="number">55</span>:<span class="number">18.151</span>  <span class="number">1000</span>  <span class="number">1614</span>  <span class="number">4490</span> I ActivityTaskManager: START u0 &#123;flg=<span class="number">0x10000000</span> cmp=com.android.settings/.wifi.WifiConfigActivity (has extras)&#125; from uid <span class="number">1000</span></span><br><span class="line"><span class="number">12</span>-<span class="number">07</span> <span class="number">10</span>:<span class="number">55</span>:<span class="number">21.185</span>  <span class="number">1000</span>  <span class="number">1614</span> <span class="number">12880</span> I ActivityTaskManager: START u0 &#123;flg=<span class="number">0x10000000</span> cmp=com.android.settings/.wifi.WifiConfigActivity (has extras)&#125; from uid <span class="number">1000</span></span><br><span class="line"><span class="number">12</span>-<span class="number">07</span> <span class="number">10</span>:<span class="number">55</span>:<span class="number">32.439</span>  <span class="number">1000</span>  <span class="number">1614</span>  <span class="number">5665</span> I ActivityTaskManager: START u0 &#123;flg=<span class="number">0x10000000</span> cmp=com.android.settings/.wifi.WifiConfigActivity (has extras)&#125; from uid <span class="number">1000</span></span><br><span class="line"><span class="number">12</span>-<span class="number">07</span> <span class="number">10</span>:<span class="number">55</span>:<span class="number">42.120</span>  <span class="number">1000</span>  <span class="number">1614</span>  <span class="number">8959</span> I ActivityTaskManager: START u0 &#123;flg=<span class="number">0x10000000</span> cmp=com.android.settings/.wifi.WifiConfigActivity (has extras)&#125; from uid <span class="number">1000</span></span><br><span class="line"><span class="number">12</span>-<span class="number">07</span> <span class="number">10</span>:<span class="number">55</span>:<span class="number">50.421</span>  <span class="number">1000</span>  <span class="number">1614</span>  <span class="number">4063</span> I ActivityTaskManager: START u0 &#123;flg=<span class="number">0x10000000</span> cmp=com.android.settings/.wifi.WifiConfigActivity (has extras)&#125; from uid <span class="number">1000</span></span><br><span class="line"><span class="number">12</span>-<span class="number">07</span> <span class="number">10</span>:<span class="number">56</span>:<span class="number">03.812</span>  <span class="number">1000</span>  <span class="number">1614</span> <span class="number">14712</span> I ActivityTaskManager: START u0 &#123;flg=<span class="number">0x10000000</span> cmp=com.android.settings/.wifi.WifiConfigActivity (has extras)&#125; from uid <span class="number">1000</span></span><br></pre></td></tr></table></figure></p><p>WifiConfigActivity什么时候会被调起呢，是在收到一个广播后，鉴于其启动模式是singleInstance<br>查阅代码发现这个文件有重写onNewIntent，所以再多次调用的情况下，onNewIntent会被多次触发<br>该函数里有一处代码<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">new</span> AccessPoint(<span class="keyword">this</span>, wifiConfiguration);</span><br></pre></td></tr></table></figure></p><p>这里直接传入了this且该类是singleInstance，所以这个对象是无法被GC的，会导致内存持续增加，其实日志中也有Settings OOM的片段打出来  </p><h1 id="修改方案"><a href="#修改方案" class="headerlink" title="修改方案"></a>修改方案</h1><p>修改方案如下：<br>传入this的地方改为弱引用，这样在该界面退出时activity可以正常被回收掉，另外新增一个文件继承自DialogInterface.OnDismissListener<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DetachWifiDialogListener</span> <span class="keyword">implements</span> <span class="title">DialogInterface</span>.<span class="title">OnDismissListener</span></span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">static</span> String TAG = DetachWifiDialogListener.class.getSimpleName();</span><br><span class="line">    <span class="keyword">private</span> Activity mActivity;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">DetachWifiDialogListener</span><span class="params">(Activity activity)</span> </span>&#123;</span><br><span class="line">        mActivity = activity;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onDismiss</span><span class="params">(DialogInterface dialog)</span> </span>&#123;</span><br><span class="line">       Log.d(TAG,<span class="string">"Dialog onDismiss"</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">clearOnDetach</span><span class="params">(Dialog dialog)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (dialog.getWindow() == <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        dialog.getWindow()</span><br><span class="line">                .getDecorView()</span><br><span class="line">                .getViewTreeObserver()</span><br><span class="line">                .addOnWindowAttachListener(<span class="keyword">new</span> ViewTreeObserver.OnWindowAttachListener() &#123;</span><br><span class="line">                    <span class="meta">@Override</span></span><br><span class="line">                    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onWindowAttached</span><span class="params">()</span> </span>&#123;</span><br><span class="line">                       Log.d(TAG, <span class="string">"dialog Attached to Window"</span>);</span><br><span class="line">                    &#125;</span><br><span class="line">                    <span class="meta">@Override</span></span><br><span class="line">                    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onWindowDetached</span><span class="params">()</span> </span>&#123;</span><br><span class="line">                        Log.d(TAG,<span class="string">"dialog Detached to Window"</span>);</span><br><span class="line">                        <span class="keyword">if</span>(mActivity != <span class="keyword">null</span>) &#123;</span><br><span class="line">                           mActivity.finish();</span><br><span class="line">                           mActivity = <span class="keyword">null</span>;</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>在弹出Dialog后执行clearOnDetach，及时的将Activity finish掉，并且在onPause中(这里因为此处场景特殊，一般在onDestory中)将Listener置空<br>目的是剪断这个引用链<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">dismissListener = <span class="keyword">new</span> DetachWifiDialogListener(mWifiConfigActivity.get());</span><br><span class="line"><span class="comment">//....</span></span><br><span class="line">mDialog.show();</span><br><span class="line">dismissListener.clearOnDetach(mDialog);</span><br></pre></td></tr></table></figure></p><p>本地测试下来，<code>dumpsys meminfo</code>出的Activity实例个数在Dialog消失后会减少，说明不存在内存泄露了</p><h1 id="常见示例"><a href="#常见示例" class="headerlink" title="常见示例"></a>常见示例</h1><p>再例举一个最常见的非静态内部类Handler泄漏例子，延迟发送一个消息，此时在消息处理之前退出该界面，就会存在该Activity泄漏的情形</p><p>此时在onDestory内执行<code>removeCallbacksAndMessages</code>，这样的话每次退出界面后就会清空该handler上所有的callback和消息，这样就不会存在<code>MessageQueue-&gt;Handler-&gt;Activity</code>这个引用链</p><p><img src="http://blog.lihaizhou.top/SystemServerOOM/SystemServerOOM6.png" alt=""></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;strong&gt;测试步骤&lt;/strong&gt;&lt;br&gt;MTBF测试跑出来的机器重启，先解释下何为MTBF？&lt;br&gt;&lt;code&gt;MTBF测试(Mean Time Between Failure)&lt;/code&gt;&lt;br&gt;主要测试终端在连续工作状态下，出现死机、重启、冻屏、应用强制关闭
      
    
    </summary>
    
      <category term="稳定性" scheme="http://lihaizhou.top/categories/%E7%A8%B3%E5%AE%9A%E6%80%A7/"/>
    
    
  </entry>
  
  <entry>
    <title>臭名昭著的bufferbloat</title>
    <link href="http://lihaizhou.top/2020/08/27/%E8%87%AD%E5%90%8D%E6%98%AD%E8%91%97%E7%9A%84bufferbloat/"/>
    <id>http://lihaizhou.top/2020/08/27/臭名昭著的bufferbloat/</id>
    <published>2020-08-27T09:47:35.000Z</published>
    <updated>2021-09-08T12:39:26.762Z</updated>
    
    <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>之前看tcp拥塞算法时了解过bufferbloat，明白网络设备的缓冲区是为了让丢包尽量晚点到来，但是大的缓冲区又加重了延时。<br>知乎有一个问题：<br>既然害怕缓冲区膨胀，为啥现在的路由器缓冲区要弄这么大？<br>本文参考很多网络上优秀的文章，希望借此能够比较全面的了解下bufferbloat</p><h1 id="出现背景"><a href="#出现背景" class="headerlink" title="出现背景"></a>出现背景</h1><p>1980s 以来，基于遗失 (Loss-based) 一直作为拥塞控制的算法标准，并沿用至今 (e.g., 慢启动、拥塞避免、快速重送/恢复)。<br>为使拥塞控制正常运作，必须及时回馈封包遗失的信息，使传送端能选择合适的传输速率。<br>随著科技进步，内存价格下跌，处处充满了大型缓冲区的网路设备，这对基于遗失的拥塞控制算法造成巨大的问题。<br>大型的缓存区使数据包不易被丢弃，而是在队列中缓慢地等待，TCP 传送端并不知道拥塞的发生，仍持续成长传输速率，<br>使网路产生高延迟、吞吐量下降的恶性循环，这就是恶名昭彰的 — — 缓冲区膨胀 (bufferbloat)</p><p><strong>摘抄维基百科上关于bufferbloat的定义</strong></p><p>缓冲膨胀是一种因数据包过度缓冲而引起的数据包交换网络高延迟原因。缓冲膨胀还可能导致数据包延迟变化（也称为抖动），并降低整体网络吞吐量。当路由器或交换机配置了过大的缓冲区时，对于许多交互式应用程序，例如IP语音（VoIP），在线游戏，甚至普通的网页浏览，即使是非常高速的网络也几乎无法使用。</p><p>一些通信设备制造商在他们的某些网络产品中不必要地设计了过大的缓冲区。在这种设备中，当网络链路拥塞时，就会发生缓冲膨胀，从而导致数据包在这些超大缓冲区中长时间排队。在先进先出队列系统中，过大的缓冲区会导致更长的队列和更高的延迟，并且不会提高网络吞吐量。</p><p>早在1985年就已经有人发现并描述了这种缓冲膨胀现象。从2009年开始，它受到了越来越广泛的关注</p><p>大多数TCP拥塞控制算法都依靠测量丢包的发生来确定连接两端之间的可用带宽。该算法会加快数据传输速度，直到数据包开始丢失，然后降低传输速率。理想情况下，他们会不断调整传输速率，直到达到链路的平衡速度为止。为了使算法能够选择合适的传输速度，必须及时收到有关丢包的反馈。使用已满的大缓冲区时，数据包虽然最后会到达目的地，但延迟较高。因为数据包没有丢失，所以即使上行链路饱和，TCP也不会减慢速度，从而进一步导致缓冲区饱和。仅在缓冲区完全饱和时才丢弃新到达的数据包。一旦发生这种情况，TCP可能认为连接的路径已更改而决定更激进地搜索寻找新的工作点</p><p>其实我们经常会陷入一个错误的做法：遇到缓存满的问题我们遇到后通常的简单做法就是先调大缓存，殊不知这种不经意的“偷懒”的做法对于整个网络可能是一种“作恶”。不仅仅是网络，我们程序中各种队列也可能面临这个问题，比如线程间的消息队列，当队列满的时候，问题的根本可能不是队列太小，而是生产线程产出的速度大于消费线程消费的速度，这时候应该：</p><p>（1）检查并解决消费线程的瓶颈；</p><p>（2）反馈给生产线程，如果就是性能/资源达到上限，要从源头慢下来；</p><p>bufferbloat现象不仅存在于路由器、交换机中，Linux操作系统对接收和发送队列的处理也同样会导致该现象的出现</p><p>至少到这儿我们明白了路由器携带很大的Buffer，是错误的！路由器Buffer在够用前提下越小越好，没有Buffer，自然就不会bloat, 但是不能没有Buffer，Buffer到底是用来干什么的？到底多少合适？<br>基于存储/转发TCP/IP网络上的路由器其根本任务不是做存储，而是做转发，存储只是在理论上不得已的一个手段，为什么这么说呢？<br>路由器的入口和出口分别接收到达的数据包和转发数据包，一台路由器上往往有多个接口同时全双工地进行接收/转发，数据包的到达频率是统计意义上的，符合泊松分布，然而数据包的发送则是固有的接口速率，这是分组交换网的核心根基！路由器扮演什么角色？它是一个典型的多服务台排队系统！所以路由器必须携带一个Buffer用来平滑泊松分布的包到达和固定速率的包发送之间的关系<br>其实这里和Andorid的渲染中的buffer生产消耗中间有个bufferqueue很像啊！归根结底这玩意就是为了平衡生产者消费者而诞生的</p><p>那么，设计多大的Buffer合适呢？按照排队理论的现成公式计算，够用即可！<br>其实我们可以想象一下极端的情况，把存储队列的Buffer设计成无穷大，从而转发延迟也将是无穷大(因为排队延迟会趋向无穷大)，会发生什么？无疑，这台路由器将会变成一个超级存储器，它将会拥有全世界所有的信息！<br>但是，它只是个转发设备啊，却装模作样当起了存储设备，这就是声名狼藉的Bufferbloat<br>Bufferbloat的恶劣影响并不是会造成丢包，而是会无端增加无辜连接的延迟，危害在于，由于Bufferbloat造成了整个大Buffer被填充，所有的数据包都将等待一个固有的排队延迟，这会严重影响任意经过的实时类应用！</p><p><strong>bufferbloat真的是网络设备商故意为之？</strong></p><p>很多文章只提到了是buffer愈来愈大导致，却没有或者很少提到为何会越来越大，有些文章只是讲述为了减少丢包，却没有讲述这种情况出现的背景缘由。其实这是一种不得已的行为，真正的原因也是最本质的原因在于：</p><p><strong>早期计算机的处理器性能决定了发包的速率，像思科这种厂商，他们的路由器，交换机的处理能力是发包的终端计算机难以企及的，这个阶段中间节点的高端设备只需要不多且固定数量的缓存，就可以暂时存储还没有来得及处理的数据包。<br>所以在那个计算机终端和网络核心交换设备处理性能差异巨大的年代，所有的计算机终端均采用“尽可能快”的方式发包时，这显然是提高效率的最佳做法。<br>但是后来时代变了！计算机终端的处理器，网卡性能和中间转发设备的距离越来越近，而中间转发设备的性能已经快达到极限，增加处理器和线卡的数量性价比远不如将来不及处理的数据暂时存起来，这带来了一种解决方案：增加缓存大小！这并没有解决问题，而是引入了问题，网络不再是一个用完即走的设施，而成了一个巨大的缓存设施，这就是人人唾弃的Bufferbloat！</strong></p><p>摘取Linux中国的一篇文章《从网络代码中移除“尽可能快”这个目标》中的一段内容<br>在演讲中，Van Jacobson 说互联网的这些已经发生了改变：</p><p><strong>在以前的互联网上，交换机可能总是拥有比服务器更快的网卡，所以这些位于互联网中间层的服务器也可能比客户端更快，并且并不能对客户端发送信息包的速率有多大影响。<br>很显然今天已经不是这样的了！众所周知，今天的计算机相比于 5 年前的计算机在速度上并没有多大的提升（我们遇到了某些有关光速的问题）。所以我想路由器上的大型交换机并不会在速度上大幅领先于数据中心里服务器上的网卡</strong></p><p>这篇文章同时提到了解决Bufferbloat的办法，就是：<strong>以更慢的速率发送更多的信息包以达到更好的性能！</strong></p><p>对于拥塞控制推出的背景历史，可以查看Van Jacobson在1988年推出的Congestion Avoidance and Control，文章开头就介绍了这篇论文的写作背景缘由</p><p>In October of ‘86, the Internet had the first of what became a series of ‘congestion collapses’. During this period, the data throughput from LBL to UC Berke- ley (sites separated by 400 yards and three IMP hops) dropped from 32 Kbps to 40 bps. Mike Karels 1 and I were fascinated by this sudden factor-of-thousand drop in bandwidth and embarked on an investigation of why things had gotten so bad. We wondered, in particular, if the 4.3BSD (Berkeley UNIX) TCP was mis-behaving or if it could be tuned to work better under abysmal net- work conditions. The answer to both of these questions was “yes”.</p><p>也正是在这一年拥塞控制被引入TCP，有点感慨，这是1988年推出的论文，中国进入互联网是在94年！</p><p><strong>摘自一篇比较喜欢的文章里的一句话：</strong><br>TCP拥塞控制的终极目标绝对不是加快数据发送的速度，这种理解非常自私且肤浅！它的终结目标是在公平占有带宽的前提下无限度提高带宽的利用率！<br>恰恰相反，所有的拥塞控制算法都是为了TCP可以在贪婪的时候悬崖勒马，大多数时候，拥塞控制是降低了数据发送的速度</p><p>如果不把公平性作为基本原则，那么整个环将不是闭合的，带宽资源早晚会用尽，此时盲目的AI非MD过程将会促使大家都想往前抢，最后谁也过不去，如此一来，互联网将完全不可用！基于这点，所有搞“TCP单边加速”的个人和厂商都是在做钻空子的坏事，其出发点就是错误的。当然，这类厂商的出发点往往不是TCP层面的，而是业务层面的，这倒是无可厚非，毕竟不是一个领域，我也无权过问太多，TCP对于它们而言只是工具，真到哪天互联网崩溃了，他们还是会用卡车运硬盘的方式来进行数据传输的，到时候，高速公路上堵的水泄不通的运硬盘的卡车与TCP一样，也只是个工具，而已</p><p>在BBR之前，Vegas算法则代表了一种正确的做法，它最终没有上位是因为Vegas部署有个前提，那就是同一时间全部部署成Vegas，然而这是不可能的，只要有Reno或者CUBIC在，Vegas的“正确做法”就会吃亏。现实就是这样，劣币驱良币，CUBIC明明是错误的算法，但因为它可以利用率很低但很简单的方法快速收敛到可用带宽，所以就一直是大家认可的算法，所有人都在默默忍受着Bufferbloat，而这个问题带来的额外排队延迟会大大降低交互式TCP连接的交互体验，同时严重影响实时性的协议，比如NTP之类。<br> CUBIC是一定会堵路的，Buffer被堵了之后，交互应用的数据就会被排队，时延增加，交互性自然下降。<br>我一直好奇的问题是，为什么Reno，CUBIC之流在经过慢启动之后的AI增窗过程叫做拥塞避免，相反，这种盲目的一路走到黑的增窗方式一定会导致拥塞的，即拥塞不可避免。这个过程是玷污了“拥塞避免”这个词呢，还是说仅仅是一个定义呢？</p><p>真正的拥塞控制就应该像城市快速路那样，在拥塞时排队缓行而不是造成bufferbloat！</p><p><strong>小结：</strong><br>TCP几乎全部都是以AIMD原则来运作的，UDP则是无限贪婪的。TCP的AI会造成主动丢包，这也是基于丢包的拥塞控制算法的核心，而MD会造成全局同步，这两点无疑造成了带宽利用率的低下，这是TCP的硬伤，不得不靠不断加大的路由器Buffer来弥补，至少是延迟了悲剧的发生，在延迟悲剧的这段时间内，路由器当然希望端系统可以意识到事情正在悄悄起变化并采取一些措施<br>或许TCP/IP的框架不该这么复杂，或许AIMD根本就不需要，事实上，是路由器不断加大的Buffer和AIMD一起纵容了坏事的频繁发生<br>路由器Buffer减小有什么好处呢？好处在于，即使有连接拼命去AI添堵，那么丢包会很快到来，并且很快反馈给发送方，于是发送方会执行MD以表示忏悔，整个过程中，实时流量不会受到丝毫影响</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h1&gt;&lt;p&gt;之前看tcp拥塞算法时了解过bufferbloat，明白网络设备的缓冲区是为了让丢包尽量晚点到来，但是大的缓冲区又加重了延时。&lt;br&gt;知乎有
      
    
    </summary>
    
      <category term="网络" scheme="http://lihaizhou.top/categories/%E7%BD%91%E7%BB%9C/"/>
    
    
  </entry>
  
  <entry>
    <title>BBR论文之读后感(三)</title>
    <link href="http://lihaizhou.top/2020/08/27/BBR%E8%AE%BA%E6%96%87%E4%B9%8B%E8%AF%BB%E5%90%8E%E6%84%9F-%E4%B8%89/"/>
    <id>http://lihaizhou.top/2020/08/27/BBR论文之读后感-三/</id>
    <published>2020-08-27T04:53:38.000Z</published>
    <updated>2021-10-16T06:40:48.773Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Matching-the-Packet-Flow-to-the-Delivery-Path"><a href="#Matching-the-Packet-Flow-to-the-Delivery-Path" class="headerlink" title="Matching the Packet Flow to the Delivery Path"></a>Matching the Packet Flow to the Delivery Path</h1><p>The core BBR algorithm has two parts:<br>When an ack is received</p><p>Each ack provides new RTT and average delivery rate measurements that update the RTprop and BtlBw estimates:</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">onAck</span>(<span class="params">packet</span>)</span></span><br><span class="line"><span class="function">  <span class="title">rtt</span> = <span class="title">now</span> - <span class="title">packet</span>.<span class="title">sendtime</span></span></span><br><span class="line"><span class="function">  <span class="title">update_min_filter</span>(<span class="params">RTpropFilter, rtt</span>)</span></span><br><span class="line"><span class="function">  <span class="title">delivered</span> += <span class="title">packet</span>.<span class="title">size</span></span></span><br><span class="line"><span class="function">  <span class="title">delivered_time</span> = <span class="title">now</span></span></span><br><span class="line"><span class="function">  <span class="title">deliveryRate</span> = (<span class="params">delivered - packet.delivered</span>) / (<span class="params">delivered_time - packet.delivered_time</span>)</span></span><br><span class="line"><span class="function">  <span class="title">if</span> (<span class="params">deliveryRate &gt; BtlBwFilter.currentMax || ! packet.app_limited</span>)</span></span><br><span class="line"><span class="function">     <span class="title">update_max_filter</span>(<span class="params">BtlBwFilter, deliveryRate</span>)</span></span><br><span class="line"><span class="function">  <span class="title">if</span> (<span class="params">app_limited_until &gt; <span class="number">0</span></span>)</span></span><br><span class="line"><span class="function">     <span class="title">app_limited_until</span> = <span class="title">app_limited_until</span> - <span class="title">packet</span>.<span class="title">size</span></span></span><br></pre></td></tr></table></figure><p>The if checks address the uncertainty issue described in the last paragraph: senders can be application limited, meaning the application runs out of data to fill the network. This is quite common because of request/response traffic. When there is a send opportunity but no data to send, BBR marks the corresponding bandwidth sample(s) as application limited (see send() pseudocode to follow). The code here decides which samples to include in the bandwidth model so it reflects network, not application, limits.<br>BtlBw is a hard upper bound on the delivery rate so a measured delivery rate larger than the current BtlBw estimate must mean the estimate is too low, whether or not the sample was app-limited. Otherwise, application-limited samples are discarded. (Figure 1 shows that in the app-limited region deliveryRate underestimates BtlBw. These checks prevent filling the BtlBw filter with underestimates which would cause data to be sent too slowly.)</p><p><strong>翻译：</strong> </p><p>BBR核心算法包含两大部分：<br>当收到一个ACK报文时：<br>每一个ACK提供了一个新的RTT和新的发送速率估计，BBR将以此为根据来更新RTprop和BtlBw<br>这里略去上面的英文中的伪代码部分<br>伪代码中的if语句是对上一段所讲的不确定性进行估计的：发送方可能受限于应用，发送数据太少，而并没有将管道填满。<br>当发送方采取的协议是request/response类时，这种现象是非常常见的。当没有数据可以发送时，BBR会将对应的带宽估计标志为是应用限制的（见下文伪代码中的send()）。这里的算法是为了决定流应该采集哪些数据，而避免采集那些被应用限制的而不是被网络限制的采集数据。<br>BtlBw是发送速率的上界，所以如果计算出的发送速率大于当前所估计的BtlBw值，那么这表示这个估计值太小了（无论该发送速率是否是应用限制的），我们都应该更新它。否则，那些被应用限制的采集数据将会被丢弃。（如图1所示，在app-limited区域中，deliveryRate低估了BtlBw。这些if判断避免BBR低估了BtlBw而导致发送低速率）。</p><p><strong>额外添加:</strong><br>这里计算发送速率的伪代码算法如此的通俗易懂，当然实际的源代码肯定是很复杂的，不过任何复杂算法最初的雏形一定是像这样简单纯朴</p><h1 id="When-data-is-sent"><a href="#When-data-is-sent" class="headerlink" title="When data is sent"></a>When data is sent</h1><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">To match the packet-arrival rate to the bottleneck link<span class="string">'s departure rate, BBR paces every data packet. (BBR must match the bottleneck rate, which means pacing is integral to the design and fundamental to operation—pacing_rate is BBR'</span>s primary control parameter. A secondary parameter, cwnd_gain, bounds inflight to a small multiple <span class="keyword">of</span> the BDP to handle common network and receiver pathologies (see the later section on Delayed and Stretched ACKs). Conceptually, the TCP send routine looks like the following code. (In Linux, sending uses the efficient FQ/pacing queuing discipline,<span class="number">4</span> which gives BBR line-rate single-connection performance on multigigabit links and handles thousands <span class="keyword">of</span> lower-rate paced connections <span class="keyword">with</span> negligible CPU overhead.)</span><br></pre></td></tr></table></figure><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">send</span>(<span class="params">packet</span>)</span></span><br><span class="line"><span class="function">  <span class="title">bdp</span> = <span class="title">BtlBwFilter</span>.<span class="title">currentMax</span> × <span class="title">RTpropFilter</span>.<span class="title">currentMin</span></span></span><br><span class="line"><span class="function">  <span class="title">if</span> (<span class="params">inflight &gt;= cwnd_gain × bdp</span>)</span></span><br><span class="line"><span class="function">     // <span class="title">wait</span> <span class="title">for</span> <span class="title">ack</span> <span class="title">or</span> <span class="title">retransmission</span> <span class="title">timeout</span></span></span><br><span class="line"><span class="function">     <span class="title">return</span></span></span><br><span class="line"><span class="function">  <span class="title">if</span> (<span class="params">now &gt;= nextSendTime</span>)</span></span><br><span class="line"><span class="function">     <span class="title">packet</span> = <span class="title">nextPacketToSend</span>(<span class="params"></span>)</span></span><br><span class="line"><span class="function">     <span class="title">if</span> (<span class="params">! packet</span>)</span></span><br><span class="line"><span class="function">        <span class="title">app_limited_until</span> = <span class="title">inflight</span></span></span><br><span class="line"><span class="function">        <span class="title">return</span></span></span><br><span class="line"><span class="function">     <span class="title">packet</span>.<span class="title">app_limited</span> = (<span class="params">app_limited_until &gt; <span class="number">0</span></span>)</span></span><br><span class="line"><span class="function">     <span class="title">packet</span>.<span class="title">sendtime</span> = <span class="title">now</span></span></span><br><span class="line"><span class="function">     <span class="title">packet</span>.<span class="title">delivered</span> = <span class="title">delivered</span></span></span><br><span class="line"><span class="function">     <span class="title">packet</span>.<span class="title">delivered_time</span> = <span class="title">delivered_time</span></span></span><br><span class="line"><span class="function">     <span class="title">ship</span>(<span class="params">packet</span>)</span></span><br><span class="line"><span class="function">     <span class="title">nextSendTime</span> = <span class="title">now</span> + <span class="title">packet</span>.<span class="title">size</span> / (<span class="params">pacing_gain × BtlBwFilter.currentMax</span>)</span></span><br><span class="line"><span class="function">  <span class="title">timerCallbackAt</span>(<span class="params">send, nextSendTime</span>)</span></span><br></pre></td></tr></table></figure><p><strong>翻译：</strong> </p><p>为了使得bottleneck链路的报文到达速率和报文离开速率相等，BBR必须进行packet paced。<br>BBR的发送速率必须与bottleneck的速率相等，这意味着BBR的实现需要pacing的支持——pacing_rate是BBR的一个主要控制参数！<br>第二个参数，cwnd_gain，将inflight控制为比BDP稍大一些，从而处理常见的网络机制和接收方机制（参见后文Dealyedand Stretched ACKs）。<br>TCP发送的时候做的事大概如上面的伪代码所示（在Linux中，可以使用FQ/pacing qdisc来发送数据，这可以使得BBR在与几千个低速率的paced流在千兆链路上很好地共存，并且使用FQ这种机制也不会额外造成CPU的负担）。</p><p><strong>额外添加：</strong></p><p>上面说的感觉听上去上挺合理，但是很容易产生这样的疑问：<br>端到端的TCP如何知道带宽到底是多少？如果用测量的话结果具有一个RTT的滞后性。因此你测得的结果永远都是以前的结果而不是现在的结果，由于网络情况存在随机性，更无法预测未来的情景，于是乎，完全按照瓶颈带宽来发送数据是不可能的，我们不得不承认这个结果是滞后的，或者说我们采集到的信息仅仅够算一个所谓的均值，不管怎么样，我们依然会选择Pacing的方式来发送数据，至少在没有新的有别于AIMD的全新数学模型出现之前吧。<br>如此一来，只要我们选择了Pacing，那么就必然要在TCP发送端内置一套数据采集和计算引擎，这是AIMD模型所不需要的。</p><h1 id="Steady-state-behavior"><a href="#Steady-state-behavior" class="headerlink" title="Steady-state behavior"></a>Steady-state behavior</h1><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">The rate and amount BBR sends is solely a <span class="function"><span class="keyword">function</span> <span class="title">of</span> <span class="title">the</span> <span class="title">estimated</span> <span class="title">BtlBw</span> <span class="title">and</span> <span class="title">RTprop</span>, <span class="title">so</span> <span class="title">the</span> <span class="title">filters</span> <span class="title">control</span> <span class="title">adaptation</span> <span class="title">in</span> <span class="title">addition</span> <span class="title">to</span> <span class="title">estimating</span> <span class="title">the</span> <span class="title">bottleneck</span> <span class="title">constraints</span>. <span class="title">This</span> <span class="title">creates</span> <span class="title">the</span> <span class="title">novel</span> <span class="title">control</span> <span class="title">loop</span> <span class="title">shown</span> <span class="title">in</span> <span class="title">figure</span> 2, <span class="title">which</span> <span class="title">illustrates</span> <span class="title">the</span> <span class="title">RTT</span> (<span class="params">blue</span>), <span class="title">inflight</span> (<span class="params">green</span>) <span class="title">and</span> <span class="title">delivery</span> <span class="title">rate</span> (<span class="params">red</span>) <span class="title">detail</span> <span class="title">from</span> 700 <span class="title">ms</span> <span class="title">of</span> <span class="title">a</span> 10-<span class="title">Mbps</span>, 40-<span class="title">ms</span> <span class="title">flow</span>. <span class="title">The</span> <span class="title">thick</span> <span class="title">gray</span> <span class="title">line</span> <span class="title">above</span> <span class="title">the</span> <span class="title">delivery</span>-<span class="title">rate</span> <span class="title">data</span> <span class="title">is</span> <span class="title">the</span> <span class="title">state</span> <span class="title">of</span> <span class="title">the</span> <span class="title">BtlBw</span> <span class="title">max</span> <span class="title">filter</span>. <span class="title">The</span> <span class="title">triangular</span> <span class="title">structures</span> <span class="title">result</span> <span class="title">from</span> <span class="title">BBR</span> <span class="title">cycling</span> <span class="title">pacing_gain</span> <span class="title">to</span> <span class="title">determine</span> <span class="title">if</span> <span class="title">BtlBw</span> <span class="title">has</span> <span class="title">increased</span>. <span class="title">The</span> <span class="title">gain</span> <span class="title">used</span> <span class="title">for</span> <span class="title">each</span> <span class="title">part</span> <span class="title">of</span> <span class="title">the</span> <span class="title">cycle</span> <span class="title">is</span> <span class="title">shown</span> <span class="title">time</span>-<span class="title">aligned</span> <span class="title">with</span> <span class="title">the</span> <span class="title">data</span> <span class="title">it</span> <span class="title">influenced</span>. <span class="title">The</span> <span class="title">gain</span> <span class="title">is</span> <span class="title">applied</span> <span class="title">an</span> <span class="title">RTT</span> <span class="title">earlier</span>, <span class="title">when</span> <span class="title">the</span> <span class="title">data</span> <span class="title">is</span> <span class="title">sent</span>. <span class="title">This</span> <span class="title">is</span> <span class="title">indicated</span> <span class="title">by</span> <span class="title">the</span> <span class="title">horizontal</span> <span class="title">jog</span> <span class="title">in</span> <span class="title">the</span> <span class="title">event</span> <span class="title">sequence</span> <span class="title">description</span> <span class="title">running</span> <span class="title">up</span> <span class="title">the</span> <span class="title">left</span> <span class="title">side</span>.</span></span><br></pre></td></tr></table></figure><p><strong>翻译：</strong></p><p>BBR的发送速率和发送数量完全就是一个关于BtlBw和RTprop的函数，所以BBR应该小心地估计这两个值。这创造了一种新型的闭环控制，如图2所示。图2显示了一个10Mbps，40ms的流在700ms中的RTT（蓝线），inflight（绿线）和发送速率（红线）变化过程。</p><p>注意图中在发送速率上方的灰线是BtlBw最大化滤波器的状态。图中产生的三角形形状是因为BBR的pacing_gain周期性的变化产生的，因为BBR必须以此来探测BtlBw是否提高了。图中展示了该增益值在一个周期不同时间的变化和其影响的数据变化</p><p><img src="http://blog.lihaizhou.top/BBR3/BBRpart3-1.png.png" alt=""></p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">BBR minimizes delay by spending most <span class="keyword">of</span> its time <span class="keyword">with</span> one BDP <span class="keyword">in</span> flight, paced at the BtlBw estimate. This moves the bottleneck to the sender so it can<span class="string">'t observe BtlBw increases. Consequently, BBR periodically spends an RTprop interval at a pacing_gain &gt; 1, which increases the sending rate and inflight. If BtlBw hasn'</span>t changed, then a queue is created at the bottleneck, increasing RTT, which keeps deliveryRate constant. (This queue is removed by sending at a compensating pacing_gain &lt; <span class="number">1</span> <span class="keyword">for</span> the next RTprop.) If BtlBw has increased, deliveryRate increases and the <span class="keyword">new</span> max immediately increases the BtlBw filter output, increasing the base pacing rate. Thus, BBR converges to the <span class="keyword">new</span> bottleneck rate exponentially fast. Figure <span class="number">3</span> shows the effect on a <span class="number">10</span>-Mbps, <span class="number">40</span>-ms flow <span class="keyword">of</span> BtlBw abruptly doubling to <span class="number">20</span> Mbps after <span class="number">20</span> seconds <span class="keyword">of</span> steady operation (left graph) then dropping to <span class="number">10</span> Mbps after another <span class="number">20</span> seconds <span class="keyword">of</span> steady operation at <span class="number">20</span> Mbps (right graph).</span><br></pre></td></tr></table></figure><p><strong>翻译：</strong></p><p>BBR将它的大部分时间的在外发送数据都保持为一个BDP大小，并且发送速率保持在估计得BtlBw值，这将会最小化时延。<br>但是这会把网络中的瓶颈链路移动到BBR发送方本身，所以BBR无法察觉BtlBw是否上升了。</p><p>所以，BBR周期性的在一个RTprop时间内将pacing_gain设为一个大于1的值，这将会增加发送速率和在外报文。如果BtlBw没有改变，那么这意味着BBR在网络中制造了队列，增大了RTT，而deliveryRate仍然没有改变。（这个队列将会在下个RTprop周期被BBR使用小于1的pacing_gain来消除）。</p><p>如果BtlBw增大了，那么deliveryRate增大了，并且BBR会立即更新BtlBw的估计值，从而增大了发送速率。通过这种机制，BBR可以以指数速度非常快地收敛到瓶颈链路。如图3显示的，我们在1条10Mbps，40ms的流在20s稳定运行之后将BtlBw提高了1倍（20Mbps），然后在第40s又将BtlBw恢复至20Mbps<br><img src="http://blog.lihaizhou.top/BBR3/BBRpart3-2.png.png" alt=""></p><p><strong>额外添加</strong></p><p><a href="https://blog.csdn.net/dog250/article/details/52972502?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522159850579919725211953968%2522%252C%2522scm%2522%253A%252220140713.130102334.pc%255Fblog.%2522%257D&amp;request_id=159850579919725211953968&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~blog~first_rank_v2~rank_blog_v1-13-52972502.pc_v2_rank_blog_v1&amp;utm_term=BBR&amp;spm=1018.2118.3001.4187" target="_blank" rel="noopener">https://blog.csdn.net/dog250/article/details/52972502?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522159850579919725211953968%2522%252C%2522scm%2522%253A%252220140713.130102334.pc%255Fblog.%2522%257D&amp;request_id=159850579919725211953968&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~blog~first_rank_v2~rank_blog_v1-13-52972502.pc_v2_rank_blog_v1&amp;utm_term=BBR&amp;spm=1018.2118.3001.4187</a></p><p>(BBR is a simple instance of a Max-plus control system, a new approach to control based on nonstandard algebra.12 This approach allows the adaptation rate [controlled by the max gain] to be independent of the queue growth [controlled by the average gain]. Applied to this problem, it results in a simple, implicit control loop where the adaptation to physical constraint changes is automatically handled by the filters representing those constraints. A conventional control system would require multiple loops connected by a complex state machine to accomplish the same result.)</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Matching-the-Packet-Flow-to-the-Delivery-Path&quot;&gt;&lt;a href=&quot;#Matching-the-Packet-Flow-to-the-Delivery-Path&quot; class=&quot;headerlink&quot; title=&quot;Ma
      
    
    </summary>
    
      <category term="网络" scheme="http://lihaizhou.top/categories/%E7%BD%91%E7%BB%9C/"/>
    
    
  </entry>
  
  <entry>
    <title>BBR论文之读后感(二)</title>
    <link href="http://lihaizhou.top/2020/08/27/BBR%E8%AE%BA%E6%96%87%E4%B9%8B%E8%AF%BB%E5%90%8E%E6%84%9F-%E4%BA%8C/"/>
    <id>http://lihaizhou.top/2020/08/27/BBR论文之读后感-二/</id>
    <published>2020-08-27T02:50:37.000Z</published>
    <updated>2021-10-16T06:42:53.147Z</updated>
    
    <content type="html"><![CDATA[<p>Characterizing the Bottleneck</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">A connection runs <span class="keyword">with</span> the highest throughput and lowest delay when (rate balance) the bottleneck packet arrival rate equals BtlBw and (full pipe) the total data <span class="keyword">in</span> flight is equal to the BDP (= BtlBw × RTprop).</span><br><span class="line"></span><br><span class="line">The first condition guarantees that the bottleneck can run at <span class="number">100</span> percent utilization. The second guarantees there is enough data to prevent bottleneck starvation but not overfill the pipe. The rate balance condition alone does not ensure there is no queue, only that it can<span class="string">'t change size (e.g., if a connection starts by sending its 10-packet Initial Window into a five-packet BDP, then runs at exactly the bottleneck rate, five of the 10 initial packets fill the pipe so the excess forms a standing queue at the bottleneck that cannot dissipate).</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Similarly, the full pipe condition does not guarantee there is no queue (e.g., a connection sending a BDP in BDP/2 bursts gets full bottleneck utilization, but with an average queue of BDP/4). The only way to minimize the queue at the bottleneck and all along the path is to meet both conditions simultaneously.</span></span><br></pre></td></tr></table></figure><p><strong>翻译：</strong></p><p>当一个连接满足以下两个条件时，它可以在达到最高的吞吐量的同时保持最低时延：</p><ol><li>速率平衡：瓶颈带宽的数据到达速率与BtlBw相等；</li><li>填满管道：所有的在外数据（inflight data）与BDP（带宽与时延的乘积）相等</li></ol><p>其中第一个约束保证了瓶颈带宽可以得到100%利用。而第二个约束保证了流有足够的数据来填满瓶颈链路而且同时不会溢出（排队）。</p><p>第一个条件本身并无法保证路径中不存在队列，它只能保证流的速率不发生改变（例如，考虑一个连接在一开始就发送了10个报文到一个BDP只有5个网络中，并且接下来一直保持瓶颈速率发送。这样子会导致在一开始就填满了管道，并且制造了5个报文的队列，并且这个队列永远不会被消灭）。</p><p>相似地，第二个条件也不能保证链路中没有队列。比如，一个连接可以以burst方式发送BDP数量的报文，若该连接每次发二分之一BDP来达到瓶颈带宽，并且发两次，此时full pipe条件得到满足了，然而网络中的平均队列长度是BDP/4。为了最小化网络中的队列长度，唯一的方式是同时满足以上两个条件。</p><p><strong>额外添加：</strong></p><p>两个条件缺一不可，如果只满足第一个条件，可能会出现实际发送数据超过BDP的情况，这样就会出现排队，如果只满足第二点的话，可能会存在数据包突发的情况，可以理解为中间网络设备转发处理速度赶不上发送端发送的速度了，这样也会有排队。<br>所以要想达到最优的情况，就是同时满足以上两个条件，多么理想的想法！</p><p>BtlBw and RTprop vary over the life of a connection, so they must be continuously estimated. TCP currently tracks RTT (the time interval from sending a data packet until it is acknowledged) since it’s required for loss detection. At any time t,</p><p><img src="http://blog.lihaizhou.top/BBR3/BBRpart2-1.png.png" alt=""></p><p>where 𝛈 ≥ 0 represents the “noise” introduced by queues along the path, the receiver’s delayed ack strategy, ack aggregation, etc. RTprop is a physical property of the connection’s path and changes only when the path changes. Since path changes happen on time scales » RTprop, an unbiased, efficient estimator at time T is</p><p><img src="http://blog.lihaizhou.top/BBR3/BBRpart2-2.png.png" alt=""></p><p>(i.e., a running min over time window WR (which is typically tens of seconds to minutes)</p><p><strong>翻译：</strong></p><p>然而，BtlBw和RTprop在整个连接的生命周期中可能是动态变化的，所以我们需要实时地对它们进行估计。<br>目前TCP为了检测丢包，必须实时地跟踪RTT的大小（发送数据到收到这个包的ack的时间），在任意的时间t</p><p>其中，最后一项表示“噪声”。造成噪声的因素主要有：链路队列，接收方的时延ACK配置，ACK聚合等因素等待。<br>RTprop是路径的物理特性，并且只有路径变化才会改变。由于一般来说路径变化的时间尺度远远大于RTprop（这说的是啥玩意，待理解）<br>所以RTprop可以由以下公式进行估计：</p><p>（在一个时间窗口中对RTT取最小值。一般将该窗口大小设置为几十秒至几分钟）</p><p>Unlike RTT, nothing in the TCP spec requires implementations to track bottleneck bandwidth, but a good estimate results from tracking delivery rate. When the ack for some packet arrives back at the sender, it conveys that packet’s RTT and announces the delivery of data inflight when that packet departed. Average delivery rate between send and ack is the ratio of data delivered to time elapsed: deliveryRate = Δdelivered/Δt. This rate must be ≤ the bottleneck rate (the arrival amount is known exactly so all the uncertainty is in the Δt, which must be ≥ the true arrival interval; thus, the ratio must be ≤ the true delivery rate, which is, in turn, upper-bounded by the bottleneck capacity). Therefore, a windowed-max of delivery rate is an efficient, unbiased estimator of BtlBw: </p><p><img src="http://blog.lihaizhou.top/BBR3/BBRpart2-3.png.png" alt=""></p><p>where the time window WB is typically six to ten RTTs.</p><p><strong>翻译：</strong></p><p>然而，bottleneck bandwidth的估计不像RTT那样方便，没有一种TCP spec要求实现算法来跟踪估计bottleneck带宽，但是，我们可以通过跟踪发送速率来估计bottleneck带宽。<br>当发送方收到一个ACK报文时，它可以计算出该报文的RTT，并且从发出报文到收到ack报文这段时间的data Inflight。这段时间内的平均发送速率就可以以此计算出来：deliveryRate = delta delivered/ delta t。这个计算出的速率必定小于bottleneck速率（因为delta delivered是确定的，但是delta t会较大）。因此，BtwBw可以根据以下公式进行估计</p><p>其中，时间窗口大小的值一般为6~10个RTT。</p><p><strong>额外增加：</strong><br>这里提到了BBR的deliveryRate的计算方式，这个公式看起来是如此的简单<br>1).应答了多少数据，记为delivered；<br>2).应答1)中的delivered这么多数据所用的时间，记为interval_us。<br>将上述二者相除，就能得到带宽：<code>bw = delivered/interval_us</code><br>这里的delivered只关注数据的大小，不关注数据的含义，比如delivered的采集中，bbr根本不管某一个应答是重传后的ACK确认的，正常ACK确认的，还是说SACK确认的。bbr只关心被应答了多少！<br>至于为什么能够不关注数据的含义，可以参考这篇文章：<br><a href="https://blog.csdn.net/dog250/article/details/52830576" target="_blank" rel="noopener">来自Google的TCP BBR拥塞控制算法解析</a><br>按照这个公式的计算方式其实是完全忽略了系统层面的TCP状态，计算带宽时它仅仅需要两个值就够了</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">TCP must record the departure time <span class="keyword">of</span> each packet to compute RTT. BBR augments that record <span class="keyword">with</span> the total data delivered so each ack arrival yields both an RTT and a delivery rate measurement that the filters convert to RTprop and BtlBw estimates.</span><br><span class="line"></span><br><span class="line">Note that these values are completely independent: RTprop can change (<span class="keyword">for</span> example, on a route change) but still have the same bottleneck, or BtlBw can change (<span class="keyword">for</span> example, when a wireless link changes rate) without the path changing. (This independence is why both constraints have to be known to match sending behavior to delivery path.) Since RTprop is visible only to the left <span class="keyword">of</span> BDP and BtlBw only to the right <span class="keyword">in</span> figure <span class="number">1</span>, they obey an uncertainty principle: whenever one can be measured, the other cannot. Intuitively, <span class="keyword">this</span> is because the pipe has to be overfilled to find its capacity, which creates a queue that obscures the length <span class="keyword">of</span> the pipe. For example, an application running a request/response protocol might never send enough data to fill the pipe and observe BtlBw.</span><br><span class="line"></span><br><span class="line">A multi-hour bulk data transfer might spend its entire lifetime <span class="keyword">in</span> the bandwidth-limited region and have only a single sample <span class="keyword">of</span> RTprop <span class="keyword">from</span> the first packet<span class="string">'s RTT. This intrinsic uncertainty means that in addition to estimators to recover the two path parameters, there must be states that track both what can be learned at the current operating point and, as information becomes stale, how to get to an operating point where it can be relearned.</span></span><br></pre></td></tr></table></figure><p><strong>翻译：</strong></p><p>TCP必须记录每个报文的离开时间从而计算RTT。BBR必须额外记录已经发送的数据大小，使得在收到每一个ACK之后，计算RTT及发送速率的值，最后得到RTprop和BtlBw的估计值。</p><p>值得注意的是，这两个值是完全独立的：RTprop可以发生变化然而保持bottleneck不变（比如发生路由变化），或者BtlBw可以变化而路径不变（比如无线链路速率发生变化）。（This independence is why both constraints have tobe known to match sending behavior to delivery path.）</p><p>如图1所示，只有在BDP的左边，才能观测到RTprop，并且只有在BDP的右边才能观测到BtlBw，他们遵循了一个不确定性原则：当其中一个可以被观测的时候，另外一个并不能。直觉地，这是因为为了观测出管道的容量，必须填满管道，而这会创造出一个队列从而无法观测到管道的长度。</p><p>例如，一个使用request/response协议的应用可能永远不会发送足够的数据来填满管道，并且观测到BtlBw。一个持续几个小时的大文件传输应用可能永远处在bandwidth-limited区域，而仅仅在第一个报文中的RTT采集到RTprop。这种不确定性机制意味着，在信息变得不明确的时候，必须要有机制来从当前的工作状态中学习到这两个值的其中一个，并且进入对应的工作区来重新学习这两个值。</p><p>下一篇讲进入公式的细节部分</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Characterizing the Bottleneck&lt;/p&gt;
&lt;figure class=&quot;highlight javascript&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;
      
    
    </summary>
    
      <category term="网络" scheme="http://lihaizhou.top/categories/%E7%BD%91%E7%BB%9C/"/>
    
    
  </entry>
  
  <entry>
    <title>BBR论文之读后感(一)</title>
    <link href="http://lihaizhou.top/2020/08/27/BBR%E8%AE%BA%E6%96%87%E4%B9%8B%E8%AF%BB%E5%90%8E%E6%84%9F-%E4%B8%80/"/>
    <id>http://lihaizhou.top/2020/08/27/BBR论文之读后感-一/</id>
    <published>2020-08-27T02:19:27.000Z</published>
    <updated>2021-10-16T06:41:19.641Z</updated>
    
    <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>拥塞控制本身是个比较发散的话题，首先需要说明一点我对这方面其实一窍不通，为了找资料在网上也看了不少文章，但是很多文章都是平铺直叙的讲述，所以很多没看完就放弃了。<br>于是打算看下论文《BBR: Congestion-Based Congestion Control》，这篇文章还是比较有意思，看完多少知道了一点BBR的皮毛。</p><p>因整篇论文内容较多，将分为六篇读后感</p><h1 id="BBR论文部分-1-6"><a href="#BBR论文部分-1-6" class="headerlink" title="BBR论文部分(1/6)"></a>BBR论文部分(1/6)</h1><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Measuring bottleneck bandwidth and round-trip propagation time</span><br><span class="line">Neal Cardwell, Yuchung Cheng, C. Stephen Gunn, Soheil Hassas Yeganeh, Van Jacobson</span><br><span class="line"></span><br><span class="line">By all accounts, today<span class="string">'s Internet is not moving data as well as it should. Most of the world'</span>s cellular users experience delays <span class="keyword">of</span> seconds to minutes; public Wi-Fi <span class="keyword">in</span> airports and conference venues is often worse. Physics and climate researchers need to exchange petabytes <span class="keyword">of</span> data <span class="keyword">with</span> global collaborators but find their carefully engineered multi-Gbps infrastructure often delivers at only a few Mbps over intercontinental distances<span class="number">.6</span></span><br><span class="line"></span><br><span class="line">These problems result <span class="keyword">from</span> a design choice made when TCP congestion control was created <span class="keyword">in</span> the <span class="number">1980</span>s—interpreting packet loss <span class="keyword">as</span> <span class="string">"congestion."</span><span class="number">13</span> This equivalence was <span class="literal">true</span> at the time but was because <span class="keyword">of</span> technology limitations, not first principles. As NICs (network interface controllers) evolved <span class="keyword">from</span> Mbps to Gbps and memory chips <span class="keyword">from</span> KB to GB, the relationship between packet loss and congestion became more tenuous.</span><br><span class="line"></span><br><span class="line">Today TCP<span class="string">'s loss-based congestion control—even with the current best of breed, CUBIC11—is the primary cause of these problems. When bottleneck buffers are large, loss-based congestion control keeps them full, causing bufferbloat. When bottleneck buffers are small, loss-based congestion control misinterprets loss as a signal of congestion, leading to low throughput. Fixing these problems requires an alternative to loss-based congestion control. Finding this alternative requires an understanding of where and how network congestion originates.</span></span><br></pre></td></tr></table></figure><p><strong>翻译</strong></p><p>因为各种原因，今天的互联网并不能像我们所期望的那样很好地传输数据。世界上大部分蜂窝网络用户都会经历几秒乃至几分钟的时延；在公共局域如机场和会议厅等，WIFI质量经常是非常差的。物理和气候学者想要与全球范围内的合作者传输千兆字节级别的数据，但可能会发现他们精心准备的Gbps级别的底层网络在洲际传输中只能达到Mbps级别。这些问题之所以会发生，是因为在80年代设计TCP拥塞控制的时候，TCP将丢包作为“拥塞”的信号。在那个年代，这个假设确实是正确的，但这是因为受限于技术原因。而当网卡的速率从Mbps级别进化为Gbps级别，内存从KB级别进化到GB级别之后，丢包与拥塞的关系变得不那么紧密了。</p><p>今天的这些TCP拥塞控制算法，包括至今为止最好的算法CUBIC，都是基于丢包的。他们是造成这些问题的主要元凶。当瓶颈链路的缓存较大时，这些基于丢包的拥塞控制算法流填满了缓存，造成了bufferbloat。当瓶颈链路的缓存较小时，这些算法会又将丢包作为发生拥塞的信号，从而降低速率导致了较低的吞吐量。</p><p>为了解决这些问题，必须提出一种不是基于丢包的拥塞控制算法，这需要设计者对网络拥塞是如何并且在哪里产生的有非常深刻的理解</p><p><strong>额外添加</strong></p><p>终端设备发的越来越快，中间网络设备的缓冲区越来越大，依靠丢包的算法不是那么明智了，所以需要一种新的拥塞控制算法，就是后面会提到的BBR</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">Congestion and Bottlenecks</span><br><span class="line"></span><br><span class="line">At any time, a (full-duplex) TCP connection has exactly one slowest link or bottleneck <span class="keyword">in</span> each direction. The bottleneck is important because:</span><br><span class="line"></span><br><span class="line">• It determines the connection<span class="string">'s maximum data-delivery rate. This is a general property of incompressible flow (e.g., picture a six-lane freeway at rush hour where an accident has reduced one short section to a single lane. The traffic upstream of the accident moves no faster than the traffic through that lane).</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">• It'</span>s where persistent queues form. Queues shrink only when a link<span class="string">'s departure rate exceeds its arrival rate. For a connection running at maximum delivery rate, all links upstream of the bottleneck have a faster departure rate so their queues migrate to the bottleneck.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Regardless of how many links a connection traverses or what their individual speeds are, from TCP'</span>s viewpoint an arbitrarily complex path behaves <span class="keyword">as</span> a single link <span class="keyword">with</span> the same RTT (round-trip time) and bottleneck rate. Two physical constraints, RTprop (round-trip propagation time) and BtlBw (bottleneck bandwidth), bound transport performance. (If the network path were a physical pipe, RTprop would be its length and BtlBw its minimum diameter.)</span><br><span class="line"></span><br><span class="line">Figure <span class="number">1</span> shows RTT and delivery rate variation <span class="keyword">with</span> the amount <span class="keyword">of</span> data <span class="keyword">in</span> flight (data sent but not yet acknowledged). Blue lines show the RTprop constraint, green lines the BtlBw constraint, and red lines the bottleneck buffer. Operation <span class="keyword">in</span> the shaded regions isn<span class="string">'t possible since it would violate at least one constraint. Transitions between constraints result in three different regions (app-limited, bandwidth-limited, and buffer-limited) with qualitatively different behavior.</span></span><br></pre></td></tr></table></figure><p><strong>翻译</strong></p><p>在一个TCP连接中，每个传输方向都存在一个最慢的链路，或者说瓶颈链路（bottleneck）。Bottleneck很重要！这是因为：</p><ol><li><p>它决定了该连接的最大传输速率（举个例子：如果高速公路上的某一段路发生了车祸，将会导致该道上的车速降低至那一段路的车速）。</p></li><li><p>它是造成队列的元凶！因为只有一个链路的离开速率大于它的到达速率，队列才会缩短。对于一个尽力传输最大速率的连接来说，因为其他的链路速率都比bottleneck大，所以最后会造成bottleneck的队列。</p></li></ol><p>无论一个TCP连接需要穿越多少链路，也无论这些链路的速率各自是多少，从TCP的角度来说，一个极其复杂路径的行为跟一条与它拥有相同RTT和bottleneck速率的简单链路一样（这句话不太好翻译，意思就是不管这条链路多么复杂，在tcp眼里和一条与这条复杂链路同样的RTT及bottleneck的简单链路是一样的）</p><p>这两个参数，RTprop（Round-trippropagation time）和BtlBw（bottleneck bandwidth），决定了传输的性能。</p><p>（打个比方，如果将一条网络路径类比为一个管道，RTprop就是管道的长度，BtlBw就是管道中最短的半径。）</p><p>图1展示了RTT和发送速率与发送数据大小的关系。</p><p>图中的蓝线受到了RTprop的约束，绿线受到BtlBw约束，红线受到瓶颈链路的缓存约束。注意阴影区域的部分是不可达的，因为这会至少违反一项约束。这三种约束形成了3不同的区域，分别为app-limited，bandwidth-limited，buffer-limited。在三种区域，流的行为是完全不同的</p><p><img src="http://blog.lihaizhou.top/BBR3/BBRpart1-1.png" alt=""></p><p><strong>额外添加</strong></p><p>这里重点提到了bottleneck，其实我们很容易想到如果这条链路上如果传输速率和瓶颈速度相近，是否会降低bottlebloat的概率呢？其实这只是其中一个条件，后面会提到。这里提到的两个参数后面会贯穿整篇论文：RTprop（Round-trippropagation time）和BtlBw（bottleneck bandwidth）</p><p>RTprop：光信号从A端到B端的最小时延（因为是一个来回其实是2倍时延），这取决于物理距离<br>BtlBw：在A到B的链路中，它的带宽取决于最慢的那段链路的带宽，称为瓶颈带宽，可以想象为光纤的粗细</p><p>上面的图中转折点有个词BDP，后面会频繁提及到：</p><p>BDP Bandwidth and Delay Product (整条物理链路（不含路由器缓存）所能储藏的比特数据之和，BDP = BtlBw * RTprop)，或者可以这样理解：Source 和 Destination 之间允许处在 Flying 状态的最大数据量。Flying 也叫 Inflights，就是发送了但还未收到的 Ack 的数据。</p><p>其实根据这个定义，我们很容易想到：如果当前的实际发送速率乘以延迟得到的值越接近 BDP 说明算法的效率越高。</p><p>再来看下上面的图，下面以上半图和下半图来称呼</p><p>上半图</p><pre><code>当链路上正在传输的比特数据未超过整条链路的物理容量（BDP）之前，传输时延的极限就是RTprop，对应上半图中蓝色的横线当数据塞满了整条链路的物理容量后，路由器开始启用缓存来存储比特数据，这相当于拉长了整个链路，造成传输时延开始变大，偏离了物理极限RTprop，于是有了slope = 1/BtlBw那条绿色斜线当路由器的缓存填满后（BDP+BtlBufSize），整条链路开始丢数据，1/BtlBw斜线消失，对应于上半图中红点虚线</code></pre><p>下半图<br>这里先说明下有一个需要注意的地方，就是下半图的纵坐标delivery rate，这里是BBR中定义的带宽，和我们平时理解的带宽可能还不太一样，我们平时直观上理解是数据在网线中的传输速率，这里指的是：数据量/从发送出去至收到ACK的时长</p><pre><code>当链路上正在传输的比特数据未超过整条链路的物理容量（BDP）之前，在B端观察到的数据带宽是逐渐往上涨的，对应下半图中蓝色斜线当数据塞满了整条链路的物理容量后，路由器开始启用缓存来存储比特数据，但不影响B端观察到的带宽，这个带宽的极限就是BtlBw，对应于图中那条绿色的BtlBw横线当路由器的缓存填满后（BDP+BtlBufSize），整条链路开始丢数据，但B端观察到的带宽极限还是BtlBw，对应于下半图中红点虚线</code></pre><p>上半图和下半图的斜率是怎么来的呢，我是这么理解的：<br>横坐标实际发送数据大小设为S，实际带宽这里设为R必定是小于等于<code>BtlBw</code>，实际时延这里设为T肯定是大于等于RTprop<br><code>S=T*R</code> 所以这里<code>T/S=1/R&gt;=1/BtlBw</code>,所以实际情况下斜率往往是比上半图中的更陡峭<br>同理下半图的斜率 <code>R/S=1/T&lt;=1/RTprop</code>,所以实际情况下下半图的斜率往往会更平缓些<br>上下半图的阴影部分是不可达，这个图画的真的是太棒了，一图胜千句！</p><p>当到达最大带宽的时候，RTT开始增长(所有不以增加速率为目的的缓存都是耍流氓！缓存不直接增加速率，缓存通过降低丢包来提高网络利用率！)，无论从RTT视图还是从带宽视图来看，两个操作点都是一致的，这是基本！那么bbr是怎么测量的呢？<br><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">先稳定住带宽，当带宽不再增加的时候，bbr认为已经达到最大带宽可，然后在此基础上测量RTT，带宽的RTT的操作点是重合的！就是这么简单且直接。</span><br></pre></td></tr></table></figure></p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">When there isn<span class="string">'t enough data in flight to fill the pipe, RTprop determines behavior; otherwise, BtlBw dominates. Constraint lines intersect at inflight = BtlBw × RTprop, a.k.a. the pipe'</span>s BDP (bandwidth-delay product). Since the pipe is full past <span class="keyword">this</span> point, the inflight - BDP excess creates a queue at the bottleneck, which results <span class="keyword">in</span> the linear dependence <span class="keyword">of</span> RTT on inflight data shown <span class="keyword">in</span> the upper graph. Packets are dropped when the excess exceeds the buffer capacity. Congestion is just sustained operation to the right <span class="keyword">of</span> the BDP line, and congestion control is some scheme to bound how far to the right a connection operates on average.</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure><p><strong>翻译</strong></p><p>当没有足够的数据来填满管道时，RTprop决定了流的行为（说的啥玩意没看懂）；<br>当有足够的数据填满时，那就变成了BtlBw来决定。这两条约束交汇在点inflight=BtlBw*RTprop，也就是管道的BDP（带宽与时延的乘积）。</p><p>当管道被填满时，那些超过的部分（inflight-BDP）就会在瓶颈链路中制造了一个队列，从而导致了RTT的增大，如上面那个图所示，当数据继续增加直到填满了缓存时，多余的报文就会被丢弃了。拥塞就是发生在BDP点的右边，而拥塞控制算法就是来控制流的平均工作点离BDP点有多远。</p><p><strong>额外添加</strong><br>带宽与时延的乘积-&gt;这里如果说是瓶颈带宽乘上最小时延会不会更好点？<br>这里的说的多余的报文就会被丢弃了就是我们经常说的缓冲区肿胀到一定程度，超过了缓冲区大小的报文被丢弃</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Loss-based congestion control operates at the right edge <span class="keyword">of</span> the bandwidth-limited region, delivering full bottleneck bandwidth at the cost <span class="keyword">of</span> high delay and frequent packet loss. When memory was expensive buffer sizes were only slightly larger than the BDP, which minimized loss-based congestion control<span class="string">'s excess delay. Subsequent memory price decreases resulted in buffers orders of magnitude larger than ISP link BDPs, and the resulting bufferbloat yielded RTTs of seconds instead of milliseconds.9</span></span><br></pre></td></tr></table></figure><p><strong>翻译</strong></p><p>基于丢包的拥塞控制算法工作在bandwidth-limited区域的右边界区域，尽管这种算法可以达到最大的传输速率，但是它是以高延迟和高丢包率作为代价的。在存储介质较为昂贵的时候，缓存大小只比BDP大一点，此时这种算法的时延并不会很高。然而，当存储介质变得便宜之后，交换机的缓存大小已经是ISP链路BDP的很多很多倍了，这导致了bufferbloat，从而导致了RTT从毫秒级升到了秒级</p><p><strong>额外添加</strong></p><p>bandwidth-limited区域就是开始缓存了排队了，但是还没超过最大缓存也就是还没丢白<br>它的右边区域说的就是填满缓冲区之后的片段，对应着高延迟和高丢包率<br>这里说的：当存储介质变得便宜之后，交换机的缓存大小已经是ISP链路BDP的很多很多倍了，这导致了bufferbloat<br>个人感觉说的不太好，倒不是说有错误，存储便宜所以缓存搞得大点只是一方面原因，还有更重要的一方面原因是</p><p>现在的终端设备比如计算机的性能已经今非昔比，和中间网络设备的差距越来越小，可以这样理解，终端设备发的越来越快，中间网络设备比如路由器转发的速度逐渐快被终端设备赶上来了，这个时候逼不得已就得加大缓存了，不然转发不过来了就得丢包，实则无奈之举</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">The left edge <span class="keyword">of</span> the bandwidth-limited region is a better operating point than the right. In <span class="number">1979</span> Leonard Kleinrock16 showed <span class="keyword">this</span> operating point was optimal, maximizing delivered bandwidth <span class="keyword">while</span> minimizing delay and loss, both <span class="keyword">for</span> individual connections and <span class="keyword">for</span> the network <span class="keyword">as</span> a whole8. Unfortunately, around the same time Jeffrey M. Jaffe14 proved it was impossible to create a distributed algorithm that converged to <span class="keyword">this</span> operating point. This result changed the direction <span class="keyword">of</span> research <span class="keyword">from</span> finding a distributed algorithm that achieved Kleinrock<span class="string">'s optimal operating point to investigating different approaches to congestion control.</span></span><br></pre></td></tr></table></figure><p><strong>翻译</strong></p><p>工作在bandwidth-limited区域的左边界比工作在右边界好。在1979年Leonard Kleinrock就展示了，无论是对流自身而言，或是对整个网络来说，工作在左边界是最优点，这个点在实现最大传输速率的同时，保持了低时延和低丢包。不幸的是，当时Jeffrey M.Jaffe也同时证明了不可能存在一个分布式算法可以收敛到这个边界点，这使得学术研究不再尝试去设计可以工作在该边界点的分布式算法</p><p><strong>额外添加</strong><br>bandwidth-limited区域的左边界临界点是最佳的，这个看图很直观，此时数据量刚好是BDP</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Our group at Google spends hours each day examining TCP packet header captures <span class="keyword">from</span> all over the world, making sense <span class="keyword">of</span> behavior anomalies and pathologies. Our usual first step is finding the essential path characteristics, RTprop and BtlBw. That these can be inferred <span class="keyword">from</span> traces suggests that Jaffe<span class="string">'s result might not be as limiting as it once appeared. His result rests on fundamental measurement ambiguities (e.g., whether a measured RTT increase is caused by a path-length change, bottleneck bandwidth decrease, or queuing delay increase from another connection'</span>s traffic). Although it is impossible to disambiguate any single measurement, a connection<span class="string">'s behavior over time tells a clearer story, suggesting the possibility of measurement strategies designed to resolve ambiguity.</span></span><br><span class="line"><span class="string">&#125;);</span></span><br></pre></td></tr></table></figure><p><strong>翻译</strong></p><p>我们谷歌工作组每天花了大量的时间来查看从世界各地发来的TCP报文头部，从而对流的异常行为有了很深的了解。<br>我们通常首先计算出流最重要的两个参数：RTprop和BtlBw，这两个参数都可以从trace中推断出来。这表明Jaffe的结论可能不再适用。他当时做出这个结论是因为测量具有模糊性（例如，RTT的增加有可能是因为流的路径改变了，也有可能是瓶颈链路的带宽减少了，也有可能是因为别的流竞争而导致队列等等）。尽管不可能在单次测量中得到非常可靠的值，但是一个持续时间较长的连接会告诉你很多信息，从中或许可以设法来估计得到一个可靠的值</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Combining these measurements <span class="keyword">with</span> a robust servo loop using recent control systems advances12 could result <span class="keyword">in</span> a distributed congestion-control protocol that reacts to actual congestion, not packet loss or transient queue delay, and converges <span class="keyword">with</span> high probability to Kleinrock<span class="string">'s optimal operating point. Thus began our three-year quest to create a congestion control based on measuring the two parameters that characterize a path: bottleneck bandwidth and round-trip propagation time, or BBR.</span></span><br></pre></td></tr></table></figure><p><strong>翻译</strong></p><p>使用最近在控制领域中提出的鲁棒伺服环来对这些观测结果进行处理(这句话不知道咋翻译)，可以设计出一种分布式拥塞控制协议。该协议可以针对真实的拥塞进行反应，而不是基于丢包或者短暂的队列时延的，它可以大概率收敛到Kleinrock的最优边界点。</p><p>因此这推动了我们近三年的研究——如何基于这两个观测参数bottleneck带宽及RTT（这就是BBR缩写的来源，bottleneck bandwidth and round-trip propagation time）来设计拥塞控制算法。</p><p><strong>额外添加</strong></p><p>因为基于丢包探测的算法总会使inflight的数据量达到BDP+BtlBufSize这个状态，在现代的路由器中由于缓存很大，相当于把物理链路人为的拉长了，使数据传输的延时变大，即RTT变大。</p><p>下一篇将进入今天讨论的主题BBR</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h1&gt;&lt;p&gt;拥塞控制本身是个比较发散的话题，首先需要说明一点我对这方面其实一窍不通，为了找资料在网上也看了不少文章，但是很多文章都是平铺直叙的讲述，所以
      
    
    </summary>
    
      <category term="网络" scheme="http://lihaizhou.top/categories/%E7%BD%91%E7%BB%9C/"/>
    
    
  </entry>
  
</feed>
