<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>李海洲</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://lihaizhou.top/"/>
  <updated>2022-04-19T07:10:17.063Z</updated>
  <id>http://lihaizhou.top/</id>
  
  <author>
    <name>Steven Li</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Android S Doze模式</title>
    <link href="http://lihaizhou.top/2022/04/19/Android-S-Doze%E6%A8%A1%E5%BC%8F/"/>
    <id>http://lihaizhou.top/2022/04/19/Android-S-Doze模式/</id>
    <published>2022-04-19T06:19:53.000Z</published>
    <updated>2022-04-19T07:10:17.063Z</updated>
    
    <content type="html"><![CDATA[<h4 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h4><p>基于<code>Android S</code>梳理下Doze 机制</p><h4 id="认识-Doze"><a href="#认识-Doze" class="headerlink" title="认识 Doze"></a>认识 Doze</h4><blockquote><p>如果用户未插接设备的电源，在屏幕关闭的情况下，让设备在一段时间内保持不活动状态，那么设备就会进入Doze 模式。<br>在Doze 模式下，系统会尝试通过限制应用访问占用大量网络和 CPU 资源的服务来节省电量。它还会阻止应用访问网络，并延迟其作业、同步和标准闹钟。<br>系统会定期退出Doze 模式一小段时间，让应用完成其延迟的活动。在此维护期内，系统会运行所有待处理的同步、作业和闹钟，并允许应用访问网络。</p></blockquote><p><img src="http://blog.lihaizhou.top/Doze/doze_1.png" alt=""><br>(摘自 <a href="https://developer.android.google.cn/training/monitoring-device-state/doze-standby" target="_blank" rel="noopener">https://developer.android.google.cn/training/monitoring-device-state/doze-standby</a>)</p><p>关于上面这张图的理解：</p><ol><li>当设备灭屏且未充电下，一段时间后会先进入图中的第一个Doze 即light doze 状态。</li><li>light doze 阶段对应用限制措施相比deep doze 会少一些，light doze阶段同样有窗口期，窗口期内会解除对应用的限制措施。</li><li>一段时间后，如设备处于静止状态，会进入到deep doze，从图中可以看到deep doze 阶段对应用的限制措施会有所增加，比如增加了Alarm、Wifi扫描等限制。</li><li>在deep doze 阶段，如没有外在条件改变比如位置移动、亮屏等，会在deep doze 和窗口期之间循环切换。</li></ol><h4 id="应用行为限制"><a href="#应用行为限制" class="headerlink" title="应用行为限制"></a>应用行为限制</h4><p>deep doze 阶段对应用的行为限制如下：</p><blockquote><p>暂停访问网络。<br>系统忽略唤醒锁定。<br>标准 AlarmManager 闹钟（包括 setExact() 和 setWindow()）推迟到下一个维护期。<br>如果您需要设置在设备处于低电耗模式时触发的闹钟，请使用 setAndAllowWhileIdle() 或 setExactAndAllowWhileIdle()。<br>使用 setAlarmClock() 设置的闹钟将继续正常触发，系统会在这些闹钟触发之前不久退出低电耗模式。<br>系统不执行 WLAN 扫描。<br>系统不允许运行同步适配器。<br>系统不允许运行 JobScheduler。</p></blockquote><p>(引用自 <a href="https://developer.android.google.cn/training/monitoring-device-state/doze-standby" target="_blank" rel="noopener">https://developer.android.google.cn/training/monitoring-device-state/doze-standby</a>)<br>而对于应用进入light doze状态的话，应用限制会减少很多，只有网络限制、不允许运行同步适配器、不允许运行 JobScheduler这三种类型的限制措施，同时窗口间隔会更短。</p><h4 id="Doze-状态集"><a href="#Doze-状态集" class="headerlink" title="Doze 状态集"></a>Doze 状态集</h4><p>deep doze 和light doze 的关系</p><ul><li>进入deep doze 状态前提之一是设备已经静止了一段时间，而进入light doze 则不需要这个条件。</li><li>deep doze 和light doze 可以在设备中同时运行，简单来说就是在进入deep之前，两个状态机的代码都会执行。</li><li>设备进入deep doze 状态之前必须先经过light doze。</li><li>如果设备进入了deep doze，那么light doze 的状态机代码就不会跑了。</li></ul><p>下面介绍下deep doze 和light doze 的状态集<br><strong>Deep doze</strong><br><img src="http://blog.lihaizhou.top/Doze/doze_2.png" alt="enter description here"><br><strong>Light doze</strong><br><img src="http://blog.lihaizhou.top/Doze/doze_3.png" alt="enter description here"></p><h4 id="Doze-状态机"><a href="#Doze-状态机" class="headerlink" title="Doze 状态机"></a>Doze 状态机</h4><h5 id="Light-Doze-状态机"><a href="#Light-Doze-状态机" class="headerlink" title="Light Doze 状态机"></a>Light Doze 状态机</h5><p>light doze 的代码状态机<br><img src="http://blog.lihaizhou.top/Doze/doze_4.png" alt="enter description here"></p><p>Light doze 图形状态机<br><img src="http://blog.lihaizhou.top/Doze/doze_5.png" alt="enter description here"></p><p>下面我们将尽可能用通俗易懂的话来解释上面这张light doze 图形状态机</p><ol><li>假设用户正在使用手机，此时停留在Active 状态。</li><li>用户使用一段时间后，关闭了屏幕且未在充电，则进入LIGHT_STATE_INACTIVE 状态。</li><li>3 分钟之后进入到PRE_IDLE 状态，这个阶段处理未完成的事务。</li><li>5 分钟之后会进入到LIGHT_STATE_IDLE 状态，这个时候会根据当前设备是否联网而选择进入不同的状态，有网络的话则进入到MAINTANCE 状态，否则进入WAITING_FOR_NETWORK 状态。</li><li>设备有网络的情况下，状态会在IDLE 和 MAINTANCE 之间交替切换。</li></ol><p>PS：停留在light idle 时长并不会随着转换次数N的增加而无限增长，会受到最大值<code>DEFAULT_LIGHT_MAX_IDLE_TIMEOUT = 15 min</code>的限制</p><h5 id="Deep-Doze-状态机"><a href="#Deep-Doze-状态机" class="headerlink" title="Deep Doze 状态机"></a>Deep Doze 状态机</h5><p>Deep doze 的状态机相较于light doze 而言稍显复杂一些<br><img src="http://blog.lihaizhou.top/Doze/doze_6.png" alt="enter description here"></p><p>Deep doze 图形状态机<br><img src="http://blog.lihaizhou.top/Doze/doze_7.png" alt="enter description here"></p><p>下面我们将尽可能用通俗易懂的话来解释上面这张deep doze 图形状态机</p><ol><li>假设用户正在使用手机，此时停留在Active 状态。</li><li>用户使用一段时间后，关闭了屏幕且未在充电，设备将很快进入InActive 状态。</li><li>过了30 min之后，进入Idle_pending状态并停留5 min。</li><li>5 min后进入Sensing 状态，这个阶段会检测设备是否有转向变化。</li><li>没有转向变化的话，会进入到Locating 状态并停留30s，这个阶段会检测位置是否变化。</li><li>位置没有变化的话，30s 后将进入Idle 状态即deep doze。</li><li>Idle 状态停留60乘以2的N次方时间后(N是Idle 和窗口期转换的次数，初始值0)，会进入到窗口期，窗口期内应用的限制措施会被解除。<br>在窗口期停留5乘以2的N次方时间(N是Idle 和窗口期转换的次数，初始值0)后，会再次进入Idle，此后如没有外在条件变化的话，则会在idle 和窗口期之间交替切换。</li></ol><p>PS：停留在deep idle 时长并不会随着转换次数N的增加而无限增长，会受到最大值<code>DEFAULT_MAX_IDLE_TIMEOUT = 6 h</code>的限制</p><p><strong>Q：进入到deep Idle 状态后，是如何限制应用行为的？</strong><br>A：<code>stepIdleStateLocked</code>函数扮演了重要的角色，主要用于切换状态机，<br>当<code>STATE_IDLE_MAINTENANCE</code> 切换到<code>STATE_IDLE</code> 后，会发一个<code>MSG_REPORT_IDLE_ON</code>消息</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@VisibleForTesting</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">stepIdleStateLocked</span><span class="params">(String reason)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (DEBUG) Slog.d(TAG, <span class="string">"stepIdleStateLocked: mState="</span> + mState);</span><br><span class="line">    EventLogTags.writeDeviceIdleStep();</span><br><span class="line">            <span class="comment">//....</span></span><br><span class="line">            <span class="keyword">switch</span> (mState) &#123;</span><br><span class="line">            <span class="comment">//....</span></span><br><span class="line">            <span class="keyword">case</span> STATE_IDLE_MAINTENANCE:</span><br><span class="line">            <span class="comment">//Doze 相关状态的停留时间都是通过Alarm 的超时来实现的</span></span><br><span class="line">            <span class="comment">//超出mNextIdleDelay时间后，检测条件满足的话会再次进入STATE_IDLE_MAINTENANCE</span></span><br><span class="line">            scheduleAlarmLocked(mNextIdleDelay, <span class="keyword">true</span>);</span><br><span class="line">            <span class="keyword">if</span> (DEBUG) Slog.d(TAG, <span class="string">"Moved to STATE_IDLE. Next alarm in "</span> + mNextIdleDelay +<span class="string">" ms."</span>);</span><br><span class="line">            <span class="comment">//Idle 状态停留的时间, IDLE_FACTO为2，所以是2的N次方</span></span><br><span class="line">            mNextIdleDelay = (<span class="keyword">long</span>)(mNextIdleDelay * mConstants.IDLE_FACTOR);</span><br><span class="line">            <span class="keyword">if</span> (DEBUG) Slog.d(TAG, <span class="string">"Setting mNextIdleDelay = "</span> + mNextIdleDelay);</span><br><span class="line">            mIdleStartTime = SystemClock.elapsedRealtime();</span><br><span class="line">            mNextIdleDelay = Math.min(mNextIdleDelay, mConstants.MAX_IDLE_TIMEOUT);</span><br><span class="line">            <span class="comment">//首次的话mNextIdleDelay是0，所以首次Idle 停留时间就是IDLE_TIMEOUT</span></span><br><span class="line">            <span class="comment">//即60 * 60 * 1000L(60min)</span></span><br><span class="line">            <span class="keyword">if</span> (mNextIdleDelay &lt; mConstants.IDLE_TIMEOUT) &#123;</span><br><span class="line">                mNextIdleDelay = mConstants.IDLE_TIMEOUT;</span><br><span class="line">            &#125;</span><br><span class="line">            moveToStateLocked(STATE_IDLE, reason);</span><br><span class="line">            <span class="comment">//进入到Idle 状态后，light 状态就不会运行了并取消light相关的alram超时</span></span><br><span class="line">            <span class="keyword">if</span> (mLightState != LIGHT_STATE_OVERRIDE) &#123;</span><br><span class="line">                mLightState = LIGHT_STATE_OVERRIDE;</span><br><span class="line">                cancelLightAlarmLocked();</span><br><span class="line">            &#125;</span><br><span class="line">            addEvent(EVENT_DEEP_IDLE, <span class="keyword">null</span>);</span><br><span class="line">            mGoingIdleWakeLock.acquire();</span><br><span class="line">            <span class="comment">//发送 REPORT_IDLE_ON消息</span></span><br><span class="line">            mHandler.sendEmptyMessage(MSG_REPORT_IDLE_ON);</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">            <span class="comment">//...</span></span><br><span class="line">            &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>进入到处理<code>MSG_REPORT_IDLE_ON</code> 消息环节，这个环节主要是通知其它模块起来做限制措施。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">handleMessage</span><span class="params">(Message msg)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (DEBUG) Slog.d(TAG, <span class="string">"handleMessage("</span> + msg.what + <span class="string">")"</span>);</span><br><span class="line">        <span class="keyword">switch</span> (msg.what) &#123;</span><br><span class="line">            <span class="comment">//....</span></span><br><span class="line">            <span class="keyword">case</span> MSG_REPORT_IDLE_ON:</span><br><span class="line">            <span class="keyword">case</span> MSG_REPORT_IDLE_ON_LIGHT: &#123;</span><br><span class="line">                <span class="comment">// mGoingIdleWakeLock is held at this point</span></span><br><span class="line">                EventLogTags.writeDeviceIdleOnStart();</span><br><span class="line">                <span class="keyword">final</span> <span class="keyword">boolean</span> deepChanged;</span><br><span class="line">                <span class="keyword">final</span> <span class="keyword">boolean</span> lightChanged;</span><br><span class="line">                <span class="keyword">if</span> (msg.what == MSG_REPORT_IDLE_ON) &#123;</span><br><span class="line">                    deepChanged = mLocalPowerManager.setDeviceIdleMode(<span class="keyword">true</span>);</span><br><span class="line">                    lightChanged = mLocalPowerManager.setLightDeviceIdleMode(<span class="keyword">false</span>);</span><br><span class="line">                &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                    <span class="comment">//触发powerManager模块调用setDeviceIdleMode做wakelock的释放</span></span><br><span class="line">                    deepChanged = mLocalPowerManager.setDeviceIdleMode(<span class="keyword">false</span>);</span><br><span class="line">                    lightChanged = mLocalPowerManager.setLightDeviceIdleMode(<span class="keyword">true</span>);</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">try</span> &#123;</span><br><span class="line">                    <span class="comment">//触发NetworkPolicy模块调用setDeviceIdleMode做应用的网络限制</span></span><br><span class="line">                    mNetworkPolicyManager.setDeviceIdleMode(<span class="keyword">true</span>);</span><br><span class="line">                    mBatteryStats.noteDeviceIdleMode(msg.what == MSG_REPORT_IDLE_ON</span><br><span class="line">                            ? BatteryStats.DEVICE_IDLE_MODE_DEEP</span><br><span class="line">                            : BatteryStats.DEVICE_IDLE_MODE_LIGHT, <span class="keyword">null</span>, Process.myUid());</span><br><span class="line">                &#125; <span class="keyword">catch</span> (RemoteException e) &#123;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="comment">//....</span></span><br><span class="line">            &#125; <span class="keyword">break</span>;</span><br><span class="line">                    <span class="comment">//....</span></span><br><span class="line">            &#125;</span><br></pre></td></tr></table></figure><p>同样的，当切换到窗口期后会发一个<code>MSG_REPORT_IDLE_OFF</code> 消息，并通知PowerMS、Network等模块解除对应用的限制措施。</p><h4 id="Doze-白名单"><a href="#Doze-白名单" class="headerlink" title="Doze 白名单"></a>Doze 白名单</h4><p>当设备处于Idle 状态下的时候，位于白名单下的应用行为不受doze 机制限制。<br>当前系统维护了三种类型的白名单<br><strong>1.system-excidle(System app)</strong><br>这种名单只针对doze 模式起作用，对于应用处于idle情况下不会生效。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">* Package names the system has white-listed to opt out of power save restrictios, * except for device idle mode.</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> ArrayMap&lt;String, Integer&gt; mPowerSaveWhitelistAppsExceptIdle = <span class="keyword">new</span> ArrayMap&lt;&gt;();</span><br></pre></td></tr></table></figure><p><strong>2.system(System app)</strong><br>这种类型的名单对doze 和App standby模式均会起效，用户无法在电池优化界面手动修改其状态。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">* Package names the system has white-listed to opt out of power save restriction   * s for all modes.</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> ArrayMap&lt;String, Integer&gt; mPowerSaveWhitelistApps = <span class="keyword">new</span> ArrayMap&lt;&gt;();</span><br></pre></td></tr></table></figure></p><p><strong>3.user</strong><br>这种类型的名单对doze 和App standby模式均会起效<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Package names the user has white-listed to opt out of power save restrictions.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> ArrayMap&lt;String, Integer&gt; mPowerSaveWhitelistUserApps = <span class="keyword">new</span> ArrayMap&lt;&gt;();</span><br></pre></td></tr></table></figure></p><p>User 这种白名单通常可以用户自行设置，设置中的电池优化选项对应的正是这种类型，如果希望某个应用不走doze，则将该应用的电池优化关闭即可。</p><p>上面三种类型可以通过<code>dumpsys deviceidle whitelist</code> 命令查询<br><img src="http://blog.lihaizhou.top/Doze/doze_8.png" alt="enter description here"><br>上图可以看到微信和飞书在user 白名单中，也就说doze 下不会对这两个应用的行为比如联网进行限制。至于为何这两个三方应用会加到白名单中，是因为它们没有使用任何系统级推送通道，但是由于它们的用户群体比较庞大，最好是加入到白名单，以免出现灭屏后收不到消息引起客诉。</p><p>加到白名单中的应用会通过层层调用到PMS、Network、Alarm等模块中，这些模块中对白名单应用会正常放行，不会做特殊的限制措施。</p><p>调用<code>addPowerSaveWhitelistApps</code> 后的时序如下：<br><img src="http://blog.lihaizhou.top/Doze/doze_9.png" alt="enter description here"></p><h4 id="常见问题-Q-amp-A"><a href="#常见问题-Q-amp-A" class="headerlink" title="常见问题 Q&amp;A"></a>常见问题 Q&amp;A</h4><p><strong>Q：Doze 和省电模式(Battery saver) 差异？</strong><br>A:省电模式是Google 自<code>Android L</code>版本引入的省电策略<br>省电模式的限制措施以及触发条件：<br>1.应用处于后台且不在白名单中的话，禁止联网。<br>2.电量低于一定阈值(默认15%)且未充电情况下则自动触发，高于一定阈值或充上电后会自动关闭，用户可以通过设置中的开关项主动打开，另外省电模式的触发阈值也可手动调整.</p><p>归纳下来:<br>1.两者触发机制不同<br>2.限制措施有部分重叠，比如都会限制应用联网<br>3.共用白名单<code>deviceidle.xml</code>，所以应用是否进入省电模式同样可以在电池优化界面设置。</p><p><strong>Q：Doze 和应用待机(App standby) 差异?</strong><br>A:<code>App Standby</code>是一种电池管理技术，根据应用最近使用时间和使用频率分为不同的组，开发者选项中的待机应用菜单，对应用使用jobs，alarm，network进行不同程度限制，达到省电的目的。<br>当用户不触摸使用应用程序一段时间时，该应用程序处于App Standby状态，系统将把该App标志为空闲状态。除非触发以下任意条件，应用程序将退出App Standby状态：</p><blockquote><p>The user explicitly launches the app.<br>The app has a process currently in the foreground (either as an activity or foreground service, or in use by another activity or foreground service).<br>The app generates a notification that users see on the lock screen or in the notification tray.<br>The app is an active device admin app (for example, a device policy controller). Although they generally run in the background, device admin apps never enter App Standby because they must remain available to receive policy from a server at any time.<br>(引用自 <a href="https://developer.android.com/training/monitoring-device-state/doze-standby" target="_blank" rel="noopener">https://developer.android.com/training/monitoring-device-state/doze-standby</a>)<br>归纳：<br>1.两者进入条件不同，比如Doze 前提条件之一是灭屏，而App standby 则不需要灭屏。<br>2.共用白名单deviceidle.xml，除了system-excidle，因为system-excidle是只限制doze。</p></blockquote><p><strong>Q：Doze 和深度睡眠差异?</strong><br>A：Doze 在sleep 之前，doze 阶段会解除应用的wakelock，限制联网，但是程序还是可以运行的。<br>但是设备一旦进入深度睡眠，进程会被冻结，CPU挂起。<br>还有一点差异是进入doze 状态不受wakelock 影响，也就是是不管当前是否存在wakelock 没有释放都不会影响设备进doze，doze 状态的进入只取决于超时阈值以及一堆传感器判断。但是进入深度睡眠之前，如果应用持有wakelock 则不会进入到深度睡眠模式。</p><p><strong>Q：如何调试模拟Doze？</strong><br>A: 本地可以通过如下命令进行调试验证</p><ol><li>开启Doze<br>adb shell dumpsys deviceidle enable<br>或者在MTK平台上执行 adb shell setprop persist.config.AutoPowerModes 1 </li><li>模拟移除电源<br>adb shell dumpsys battery unplug </li><li>调试Doze状态<br>adb shell dumpsys deviceidle step 每执行一次就切换一次状态</li><li>Dump Doze 状态分析<br>查询白名单情况：adb shell dumpsys deviceidle </li><li>开启Doze dubug 调试开关<br>如需要本地调试验证问题的话，可以将DeviceIdleController.java文件中的<br>private static final boolean DEBUG = false;</li></ol><h4 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h4><p>关于Android S上的Doze 机制介绍到这里。</p><h4 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h4><p><a href="https://developer.android.google.cn/training/monitoring-device-state/doze-standby?hl=en" target="_blank" rel="noopener">https://developer.android.google.cn/training/monitoring-device-state/doze-standby?hl=en</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h4&gt;&lt;p&gt;基于&lt;code&gt;Android S&lt;/code&gt;梳理下Doze 机制&lt;/p&gt;
&lt;h4 id=&quot;认识-Doze&quot;&gt;&lt;a href=&quot;#认识-D
      
    
    </summary>
    
      <category term="Android" scheme="http://lihaizhou.top/categories/Android/"/>
    
    
  </entry>
  
  <entry>
    <title>ART 虚拟机｜Dex2oat 调优实践之路</title>
    <link href="http://lihaizhou.top/2022/03/20/ART-%E8%99%9A%E6%8B%9F%E6%9C%BA%EF%BD%9CDex2oat-%E8%B0%83%E4%BC%98%E5%AE%9E%E8%B7%B5%E4%B9%8B%E8%B7%AF/"/>
    <id>http://lihaizhou.top/2022/03/20/ART-虚拟机｜Dex2oat-调优实践之路/</id>
    <published>2022-03-20T14:45:02.000Z</published>
    <updated>2022-04-10T14:45:56.837Z</updated>
    
    <content type="html"><![CDATA[<h4 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h4><p>我们都知道Dex2oat对应用的启动速度、以及日常使用的流畅度起到了重要作用，不过Google现有的dex2oat机制存在着明显的局限性。</p><ol><li>开机/OTA等场景，容易整机卡顿及开机时间长。</li><li>Idle下的触发条件苛刻，发挥空间有限。</li></ol><p>前段时间研究了下dex2oat的原理机制，并且对一些场景下的dex2oat行为做了客制化，打算做下小结，以便后续回顾完善。</p><p>涉及代码均基于Android S</p><h4 id="基本概述"><a href="#基本概述" class="headerlink" title="基本概述"></a>基本概述</h4><p>一个App经过优化dex2oat的大致流程如下<br><img src="http://blog.lihaizhou.top/ART_dex2oat/dex2oat_1.png" alt="摘自谷歌开发者网站"><br>(图片来源：谷歌开发者网站)</p><p>简单的理解就是优化是以dex文件中的method为单位，dex2oat在优化时，会根据需要优化一定量的method，也就是说并不是优化的method都会被翻译成oat模式。</p><p>根据优化的method的量的多少，分为如下几种：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">enum</span> Filter &#123;</span><br><span class="line">    kAssumeVerified,      <span class="comment">// Skip verification but mark all classes as verified anyway.</span></span><br><span class="line">    kExtract,             <span class="comment">// Delay verication to runtime, do not compile anything.</span></span><br><span class="line">    kVerify,              <span class="comment">// Only verify classes.</span></span><br><span class="line">    kSpaceProfile,        <span class="comment">// Maximize space savings based on profile.</span></span><br><span class="line">    kSpace,               <span class="comment">// Maximize space savings.</span></span><br><span class="line">    kSpeedProfile,        <span class="comment">// Maximize runtime performance based on profile.</span></span><br><span class="line">    kSpeed,               <span class="comment">// Maximize runtime performance.</span></span><br><span class="line">    kEverythingProfile,   <span class="comment">// Compile everything capable of being compiled based on profile.</span></span><br><span class="line">    kEverything,          <span class="comment">// Compile everything capable of being compiled.</span></span><br><span class="line">  &#125;;</span><br></pre></td></tr></table></figure><p>上面列举出的这些模式，简单理解就是越往下的模式，优化的程度越深，自然而然性能会越加流畅，不过耗费的时间以及空间也会随之增长。</p><h4 id="触发时机"><a href="#触发时机" class="headerlink" title="触发时机"></a>触发时机</h4><p><img src="http://blog.lihaizhou.top/ART_dex2oat/dex2oat_2.png" alt=""><br>(图片来源：谷歌开发者网站)</p><ol><li>首次开机<br>开机过程中PMS扫描手机中的各个目录，安装的时候，会对这些App进行dex2oat。如果说App比较多，或者dex2oat比较慢，那么开机时间就会比较长。</li><li>应用安装/启动<br>其实流程还是会走PMS流程，由PMS执行安装的运行，并发起dex2oat的动作。</li><li>系统空闲时<br>系统处于空闲时，且满足一系列的条件比如充电等，会对应用进行dex2oat，在正式dex2oat之前同样会进行一系列的判断，比如根据profile的更新量决定是否进行本次优化，这部分也是我们客制化的重点。<br>对应到源码中，触发的原因会更加丰富一些</li></ol><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Compilation reasons.</span></span><br><span class="line">   <span class="keyword">public</span> <span class="keyword">static</span> final <span class="keyword">int</span> REASON_UNKNOWN = <span class="number">-1</span>;</span><br><span class="line">   <span class="keyword">public</span> <span class="keyword">static</span> final <span class="keyword">int</span> REASON_FIRST_BOOT = <span class="number">0</span>;</span><br><span class="line">   <span class="keyword">public</span> <span class="keyword">static</span> final <span class="keyword">int</span> REASON_BOOT = <span class="number">1</span>;</span><br><span class="line">   <span class="keyword">public</span> <span class="keyword">static</span> final <span class="keyword">int</span> REASON_INSTALL = <span class="number">2</span>;</span><br><span class="line">   <span class="keyword">public</span> <span class="keyword">static</span> final <span class="keyword">int</span> REASON_BACKGROUND_DEXOPT = <span class="number">3</span>;</span><br><span class="line">   <span class="keyword">public</span> <span class="keyword">static</span> final <span class="keyword">int</span> REASON_AB_OTA = <span class="number">4</span>;</span><br><span class="line">   <span class="keyword">public</span> <span class="keyword">static</span> final <span class="keyword">int</span> REASON_INACTIVE_PACKAGE_DOWNGRADE = <span class="number">5</span>;</span><br><span class="line">   <span class="keyword">public</span> <span class="keyword">static</span> final <span class="keyword">int</span> REASON_SHARED = <span class="number">6</span>;</span><br><span class="line">   <span class="keyword">public</span> <span class="keyword">static</span> final <span class="keyword">int</span> REASON_AGRESSIVE = <span class="number">10000</span>;</span><br><span class="line"></span><br><span class="line">   <span class="keyword">public</span> <span class="keyword">static</span> final <span class="keyword">int</span> REASON_LAST = REASON_SHARED;</span><br></pre></td></tr></table></figure><p>我们可以通过命令查询项目上的配置情况<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">lihaizhou@lihaizhou:~$ adb shell getprop |grep pm.dex</span><br><span class="line">[pm.dexopt.ab-ota]: [speed-profile]</span><br><span class="line">[pm.dexopt.bg-dexopt]: [speed-profile]</span><br><span class="line">[pm.dexopt.boot]: [verify]</span><br><span class="line">[pm.dexopt.first-boot]: [quicken]</span><br><span class="line">[pm.dexopt.inactive]: [verify]</span><br><span class="line">[pm.dexopt.install]: [speed-profile]</span><br><span class="line">[pm.dexopt.shared]: [speed]</span><br></pre></td></tr></table></figure></p><p>这里顺便提一下，从前面的描述，我们知道系统处于idle且满足充电条件下，才会触发后台dex2oat。那么这里的idle是如何定义的，需要等多长时间呢？<br><code>frameworks/base/core/res/res/values/config.xml</code><br><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">integer</span> <span class="attr">name</span>=<span class="string">"config_jobSchedulerInactivityIdleThreshold"</span>&gt;</span>1860000<span class="tag">&lt;/<span class="name">integer</span>&gt;</span></span><br></pre></td></tr></table></figure></p><p>对于jobscheduler而言，这个阈值设定的是31min，当用户没有交互超过31min后会认为当前设备处于idle状态。</p><h4 id="原理机制"><a href="#原理机制" class="headerlink" title="原理机制"></a>原理机制</h4><p>本文只讨论idle下的dex2oat，其它场景下如install、开机后的dex2oat等，流程几乎是一致的。<br><code>BackgroundDexOptService @schedule</code></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Schedule a daily job which scans installed packages and compiles</span></span><br><span class="line"><span class="comment">// those with fresh profiling data.</span></span><br><span class="line">js.schedule(<span class="keyword">new</span> JobInfo.Builder(JOB_IDLE_OPTIMIZE, sDexoptServiceName)</span><br><span class="line">            .setRequiresDeviceIdle(<span class="keyword">true</span>)</span><br><span class="line">            .setRequiresCharging(<span class="keyword">true</span>)</span><br><span class="line">            .setPeriodic(IDLE_OPTIMIZATION_PERIOD)</span><br><span class="line">            .build());</span><br></pre></td></tr></table></figure><p>可以看到需要满足的条件还是比较苛刻的，需要满足idle状态，且处于充电条件下，检测周期为一天，均满足的情况下才会触发dex2oat。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">onStartJob</span><span class="params">(JobParameters params)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (DEBUG) &#123;</span><br><span class="line">            Slog.i(TAG, <span class="string">"onStartJob"</span>);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// <span class="doctag">NOTE:</span> PackageManagerService.isStorageLow uses a different set of criteria from</span></span><br><span class="line">        <span class="comment">// the checks above. This check is not "live" - the value is determined by a background</span></span><br><span class="line">        <span class="comment">// restart with a period of ~1 minute.</span></span><br><span class="line">        PackageManagerService pm = (PackageManagerService)ServiceManager.getService(<span class="string">"package"</span>);</span><br><span class="line">        <span class="keyword">if</span> (pm.isStorageLow()) &#123;</span><br><span class="line">            Slog.i(TAG, <span class="string">"Low storage, skipping this run"</span>);</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">final</span> ArraySet&lt;String&gt; pkgs = pm.getOptimizablePackages();</span><br><span class="line">        <span class="keyword">if</span> (pkgs.isEmpty()) &#123;</span><br><span class="line">            Slog.i(TAG, <span class="string">"No packages to optimize"</span>);</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        mThermalStatusCutoff =</span><br><span class="line">            SystemProperties.getInt(<span class="string">"dalvik.vm.dexopt.thermal-cutoff"</span>, THERMAL_CUTOFF_DEFAULT);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">boolean</span> result;</span><br><span class="line">        <span class="keyword">if</span> (params.getJobId() == JOB_POST_BOOT_UPDATE) &#123;</span><br><span class="line">            result = runPostBootUpdate(params, pm, pkgs);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            result = runIdleOptimization(params, pm, pkgs);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> result;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>主要关注runIdleOptimization，略过部分流程。<br><code>BackgroundDexOptService @optimizePackage</code> <code>frameworks/base/services/core/java/com/android/server/pm/BackgroundDexOptService.java</code></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">    *</span></span><br><span class="line"><span class="comment">    * Optimize package if needed. Note that there can be no race between</span></span><br><span class="line"><span class="comment">    * concurrent jobs because PackageDexOptimizer.performDexOpt is synchronized.</span></span><br><span class="line"><span class="comment">    * <span class="doctag">@param</span> pm An instance of PackageManagerService</span></span><br><span class="line"><span class="comment">    * <span class="doctag">@param</span> pkg The package to be downgraded.</span></span><br><span class="line"><span class="comment">    * <span class="doctag">@param</span> isForPrimaryDex. Apps can have several dex file, primary and secondary.</span></span><br><span class="line"><span class="comment">    * <span class="doctag">@return</span> true if the package was downgraded.</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">   <span class="function"><span class="keyword">private</span> <span class="keyword">boolean</span> <span class="title">optimizePackage</span><span class="params">(PackageManagerService pm, String pkg,</span></span></span><br><span class="line"><span class="function"><span class="params">           <span class="keyword">boolean</span> isForPrimaryDex)</span> </span>&#123;</span><br><span class="line">       <span class="keyword">int</span> reason = PackageManagerService.REASON_BACKGROUND_DEXOPT;</span><br><span class="line">       <span class="keyword">int</span> dexoptFlags = DexoptOptions.DEXOPT_CHECK_FOR_PROFILES_UPDATES</span><br><span class="line">               | DexoptOptions.DEXOPT_BOOT_COMPLETE</span><br><span class="line">               | DexoptOptions.DEXOPT_IDLE_BACKGROUND_JOB;</span><br><span class="line"></span><br><span class="line">       <span class="comment">// System server share the same code path as primary dex files.</span></span><br><span class="line">       <span class="comment">// PackageManagerService will select the right optimization path for it.</span></span><br><span class="line">       <span class="keyword">return</span> (isForPrimaryDex || PLATFORM_PACKAGE_NAME.equals(pkg))</span><br><span class="line">           ? performDexOptPrimary(pm, pkg, reason, dexoptFlags)</span><br><span class="line">           : performDexOptSecondary(pm, pkg, reason, dexoptFlags);</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure><p>我们以<code>performDexOptPrimary</code>为例，继续往下看</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">boolean</span> <span class="title">performDexOptPrimary</span><span class="params">(PackageManagerService pm, String pkg, <span class="keyword">int</span> reason,</span></span></span><br><span class="line"><span class="function"><span class="params">           <span class="keyword">int</span> dexoptFlags)</span> </span>&#123;</span><br><span class="line">       <span class="keyword">int</span> result = trackPerformDexOpt(pkg, <span class="comment">/*isForPrimaryDex=*/</span> <span class="keyword">false</span>,</span><br><span class="line">               () -&gt; pm.performDexOptWithStatus(<span class="keyword">new</span> DexoptOptions(pkg, reason, dexoptFlags)));</span><br><span class="line">       <span class="keyword">return</span> result == PackageDexOptimizer.DEX_OPT_PERFORMED;</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure><p><code>frameworks/base/services/core/java/com/android/server/pm/PackageManagerService.java</code></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Perform dexopt on the given package and return one of following result:</span></span><br><span class="line"><span class="comment"> *  &#123;<span class="doctag">@link</span> PackageDexOptimizer#DEX_OPT_SKIPPED&#125;</span></span><br><span class="line"><span class="comment"> *  &#123;<span class="doctag">@link</span> PackageDexOptimizer#DEX_OPT_PERFORMED&#125;</span></span><br><span class="line"><span class="comment"> *  &#123;<span class="doctag">@link</span> PackageDexOptimizer#DEX_OPT_FAILED&#125;</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="comment">/* package */</span> <span class="function"><span class="keyword">int</span> <span class="title">performDexOptWithStatus</span><span class="params">(DexoptOptions options)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> performDexOptTraced(options);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>省略部分中间调用过程<br><code>PackageDexOptimizer.java@ performDexOptLI</code><br>frameworks/base/services/core/java/com/android/server/pm/PackageDexOptimizer.java</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">    * Performs dexopt on all code paths of the given package.</span></span><br><span class="line"><span class="comment">    * It assumes the install lock is held.</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">   <span class="meta">@GuardedBy</span>(<span class="string">"mInstallLock"</span>)</span><br><span class="line">   <span class="function"><span class="keyword">private</span> <span class="keyword">int</span> <span class="title">performDexOptLI</span><span class="params">(AndroidPackage pkg, @NonNull PackageSetting pkgSetting,</span></span></span><br><span class="line"><span class="function"><span class="params">           String[] targetInstructionSets, CompilerStats.PackageStats packageStats,</span></span></span><br><span class="line"><span class="function"><span class="params">           PackageDexUsage.PackageUseInfo packageUseInfo, DexoptOptions options)</span> </span>&#123;</span><br><span class="line">           <span class="comment">//....</span></span><br><span class="line">           <span class="keyword">final</span> String compilerFilter = getRealCompilerFilter(pkg,</span><br><span class="line">               options.getCompilerFilter(), isUsedByOtherApps);</span><br><span class="line">           <span class="comment">// If we don't have to check for profiles updates assume</span></span><br><span class="line">           <span class="comment">// PROFILE_ANALYSIS_DONT_OPTIMIZE_SMALL_DELTA which will be a no-op with respect to</span></span><br><span class="line">           <span class="comment">// profiles.</span></span><br><span class="line">           <span class="keyword">final</span> <span class="keyword">int</span> profileAnalysisResult = options.isCheckForProfileUpdates()</span><br><span class="line">                   ? analyseProfiles(pkg, sharedGid, profileName, compilerFilter)</span><br><span class="line">                   : PROFILE_ANALYSIS_DONT_OPTIMIZE_SMALL_DELTA;    </span><br><span class="line">           <span class="comment">// Get the dexopt flags after getRealCompilerFilter to make sure we get the correct</span></span><br><span class="line">           <span class="comment">// flags.</span></span><br><span class="line">           <span class="keyword">final</span> <span class="keyword">int</span> dexoptFlags = getDexFlags(pkg, pkgSetting, compilerFilter, options);</span><br><span class="line"></span><br><span class="line">           <span class="keyword">for</span> (String dexCodeIsa : dexCodeInstructionSets) &#123;</span><br><span class="line">               <span class="keyword">int</span> newResult = dexOptPath(pkg, pkgSetting, path, dexCodeIsa, compilerFilter,</span><br><span class="line">                       profileAnalysisResult, classLoaderContexts[i], dexoptFlags, sharedGid,</span><br><span class="line">                       packageStats, options.isDowngrade(), profileName, dexMetadataPath,</span><br><span class="line">                       options.getCompilationReason());</span><br><span class="line">                <span class="comment">//....</span></span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">//....</span></span><br><span class="line">      &#125;</span><br></pre></td></tr></table></figure><ol><li>getRealCompilerFilter：获取该pkg实际的编译模式</li><li>analyseProfiles：检测profile是否更新，并确定是否需要优化。</li><li>dexOptPath：实际的优化工作</li></ol><p>略过部分中间调用流程，dexOptPath函数经过层层调用，最终会通过跨进程来到<br><code>frameworks/native/cmds/installd/dexopt.cpp @ dexopt</code><br>该函数内容较长，拆分开来</p><ol><li>根据应用的路径解析其dex文件</li></ol><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">UniqueFile in_dex(open(dex_path, O_RDONLY, 0), dex_path);</span><br><span class="line">    <span class="keyword">if</span> (in_dex.fd() &lt; <span class="number">0</span>) &#123;</span><br><span class="line">        *error_msg = StringPrintf(<span class="string">"installd cannot open '%s' for input during dexopt"</span>, dex_path);</span><br><span class="line">        LOG(ERROR) &lt;&lt; *error_msg;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol start="2"><li>生成对应的oat文件</li></ol><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">RestorableFile out_oat =</span><br><span class="line">            open_oat_out_file(dex_path, oat_dir, is_public, uid, instruction_set, is_secondary_dex);</span><br><span class="line"><span class="keyword">if</span> (out_oat.fd() &lt; <span class="number">0</span>) &#123;</span><br><span class="line">    *error_msg = <span class="string">"Could not open out oat file."</span>;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol start="3"><li>调用dex2oat 二进制文件去做实际的oat工作</li></ol><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">bool</span> use_dex2oat64 = <span class="literal">false</span>;</span><br><span class="line">    <span class="comment">// Check whether the device even supports 64-bit ABIs.</span></span><br><span class="line">    <span class="keyword">if</span> (!GetProperty(<span class="string">"ro.product.cpu.abilist64"</span>, <span class="string">""</span>).empty()) &#123;</span><br><span class="line">      use_dex2oat64 = GetBoolProperty(<span class="string">"dalvik.vm.dex2oat64.enabled"</span>, <span class="literal">false</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">const</span> <span class="keyword">char</span>* dex2oat_bin = select_execution_binary(</span><br><span class="line">        (use_dex2oat64 ? kDex2oat64Path : kDex2oat32Path),</span><br><span class="line">        (use_dex2oat64 ? kDex2oatDebug64Path : kDex2oatDebug32Path),</span><br><span class="line">        background_job_compile);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">auto</span> execv_helper = <span class="built_in">std</span>::make_unique&lt;ExecVHelper&gt;();</span><br><span class="line"></span><br><span class="line">    LOG(VERBOSE) &lt;&lt; <span class="string">"DexInv: --- BEGIN '"</span> &lt;&lt; dex_path &lt;&lt; <span class="string">"' ---"</span>;</span><br><span class="line"></span><br><span class="line">    RunDex2Oat runner(dex2oat_bin, execv_helper.get());</span><br><span class="line">    runner.Initialize(out_oat.GetUniqueFile(), out_vdex.GetUniqueFile(), out_image.GetUniqueFile(),</span><br><span class="line">                      in_dex, in_vdex, dex_metadata, reference_profile, class_loader_context,</span><br><span class="line">                      join_fds(context_input_fds), swap_fd.get(), instruction_set, compiler_filter,</span><br><span class="line">                      debuggable, boot_complete, for_restore, target_sdk_version,</span><br><span class="line">                      enable_hidden_api_checks, generate_compact_dex, use_jitzygote_image,</span><br><span class="line">                      compilation_reason);</span><br></pre></td></tr></table></figure><p>至此，idle下的dex2oat流程梳理完毕。</p><p>画了一个核心的调用过程<br><img src="http://blog.lihaizhou.top/ART_dex2oat/dex2oat_3.png" alt=""></p><h4 id="影响因素"><a href="#影响因素" class="headerlink" title="影响因素"></a>影响因素</h4><p>dex2oat 优化后虽然能够增加应用运行的流畅度， 但是如果在短时间内大量发起则会影响用户界面操作， 造成整机性能问题，所以我们对dex2oat的预期效果就是尽可能的快完成，尽可能不影响用户。<br>那么有哪些因素会影响dex2oat的执行时长呢？</p><ol><li>工作量<br>dex2oat发生的时候，会将原文件中的dex文件抽出来，逐个指令的判断，然后进行翻译，并生成大量的中间内容。并占用所有有CPU（目前的策略是有多少个核，就启动多少个线程）。<br>对于单个应用而言，选择不同的模式该应用优化的耗时也会不一样，比如选择everything和interpret-only这两种不同的模式，耗时可能会悬殊几倍。</li><li>线程数<br>启动的线程数越多，dex2oat就会在越短的时间内完成<br>启动的线程数以及耗时时长可以通过日志打印查看</li></ol><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">LogCompletionTime</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="comment">// Note: when creation of a runtime fails, e.g., when trying to compile an app but when there</span></span><br><span class="line">    <span class="comment">//       is no image, there won't be a Runtime::Current().</span></span><br><span class="line">    <span class="comment">// Note: driver creation can fail when loading an invalid dex file.</span></span><br><span class="line">    LOG(INFO) &lt;&lt; <span class="string">"dex2oat took "</span></span><br><span class="line">              &lt;&lt; PrettyDuration(NanoTime() - start_ns_)</span><br><span class="line">              &lt;&lt; <span class="string">" ("</span> &lt;&lt; PrettyDuration(ProcessCpuNanoTime() - start_cputime_ns_) &lt;&lt; <span class="string">" cpu)"</span></span><br><span class="line">              &lt;&lt; <span class="string">" (threads: "</span> &lt;&lt; thread_count_ &lt;&lt; <span class="string">") "</span></span><br><span class="line">              &lt;&lt; ((Runtime::Current() != <span class="literal">nullptr</span> &amp;&amp; driver_ != <span class="literal">nullptr</span>) ?</span><br><span class="line">                  driver_-&gt;GetMemoryUsageString(kIsDebugBuild || VLOG_IS_ON(compiler)) :</span><br><span class="line">                  <span class="string">""</span>);</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><ol start="3"><li>EMMC性能<br>如果dex文件比较大，会产生大量的中间内容，这些在memory当中是保存不下的，所以采用了swap机制，会将一些内容交换到EMMC当中，而且有大量的读操作，同时会将结果保存至emmc当中，所以emmc的性能也是非常关键的。</li><li>负载：整机负载较高的话，dex2oat容易拿不到足够的cpu资源，也会造成耗时变长。</li><li>内存：如果处于低内存情况下的话，容易引起IO拉升，可能会导致dex2oat遇到IO上的瓶颈。 </li></ol><h4 id="优化方案"><a href="#优化方案" class="headerlink" title="优化方案"></a>优化方案</h4><p>我们对dex2oat的客制化优化方案如下图所示:<br><img src="http://blog.lihaizhou.top/ART_dex2oat/dex2oat_4.png" alt=""></p><p>基本思路：</p><ol><li>增加周期性后台优化策略，同样需要满足一定的条件如idle下且Charge情况下，对于热点应用以及小的dex文件进行优化。</li><li>为了避免开机时间过长，系统启动过程中不再对所有应用进行dex2oat，开机后接收到开机广播delay十分钟，对热点应用进行dex2oat优化。</li><li>根据系统负载的情况，动态调整dex2oat使用的线程数以及编译模式。</li></ol><p>为了测试应用在优化后的性能表现，通过高速相机测试做完dex2oat后应用启动速度均值提升15%左右，掉帧情况也得到了大幅缓解。</p><h4 id="拓展"><a href="#拓展" class="headerlink" title="拓展"></a>拓展</h4><p>我们顺便介绍下谷歌的Baseline profile<br>Android 9 (API 级别 28) 在 Play Cloud 中引入了 ART 优化配置文件，以缩短应用启动时间。<br>基准配置文件在构建时创建，作为 APK 的一部分发送到 Play 中，然后在下载应用时，从 Play 发送至用户。<br><img src="http://blog.lihaizhou.top/ART_dex2oat/dex2oat_5.png" alt=""><br>(图片摘自开发者网站)<br>从上面的描述我们可以得知，profile文件由应用开发者按照谷歌提供的规则，在构建时就创建好，然后通过play商店上架。当用户下载该应用时，profile连同apk会一起安装，这样就可以确保用户在首次安装时便能享受到性能的提升。<br>这种做法相对于系统现有的dex2oat机制来说，所做的事情显得轻量很多，对系统负担也会大幅降低。<br>因为profile由应用开发者提供，这就使得profile变得不再神秘。因为开发者有源代码，并且熟悉自己的业务流程，这样的话开发者本地构建profile后可以不断的调试并测试性能的数据，最终提供一份最优的基准profile。</p><h4 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h4><p>至此，关于dex2oat原理及客制化修改介绍到这里。<br>其实不管是谷歌的dex2oat策略，还是厂商的客制化方案，其目的都是明确的：<br>尽可能在用户的使用过程中，能够享受到直接运行机器码所带来的性能提升，同时避免dex2oat本身的工作对系统带来的负面影响。</p><h4 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h4><p><a href="https://blog.csdn.net/feelabclihu/article/details/105502166" target="_blank" rel="noopener">https://blog.csdn.net/feelabclihu/article/details/105502166</a><br><a href="https://developer.android.google.cn/" target="_blank" rel="noopener">https://developer.android.google.cn/</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;写在前面&quot;&gt;&lt;a href=&quot;#写在前面&quot; class=&quot;headerlink&quot; title=&quot;写在前面&quot;&gt;&lt;/a&gt;写在前面&lt;/h4&gt;&lt;p&gt;我们都知道Dex2oat对应用的启动速度、以及日常使用的流畅度起到了重要作用，不过Google现有的dex2oat机制存在着
      
    
    </summary>
    
      <category term="ART" scheme="http://lihaizhou.top/categories/ART/"/>
    
    
  </entry>
  
  <entry>
    <title>网络 | 拥塞控制算法之BBR</title>
    <link href="http://lihaizhou.top/2022/03/01/%E7%BD%91%E7%BB%9C-%E6%8B%A5%E5%A1%9E%E6%8E%A7%E5%88%B6%E7%AE%97%E6%B3%95%E4%B9%8BBBR/"/>
    <id>http://lihaizhou.top/2022/03/01/网络-拥塞控制算法之BBR/</id>
    <published>2022-03-01T14:50:11.000Z</published>
    <updated>2022-05-22T06:56:23.843Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>TCP BBR（Bottleneck Bandwidth and Round-trip propagation time）是由Google 设计，于2016年发布的拥塞算法。<br>以往的大部分拥塞控制算法都是基于丢包来作为降低传输速率的信号，而BBR 则基于模型主动探测。<br>目前已经在Google 内部大范围使用并随着linux 4.9 版本正式发布。</p></blockquote><h4 id="Bufferbloat"><a href="#Bufferbloat" class="headerlink" title="Bufferbloat"></a>Bufferbloat</h4><p>在讨论BBR 之前不得不先说下Bufferbloat，在BBR 出来之前的拥塞控制算法无一例外都和网络缓存耦合在了一起，所以都会存在发生Bufferbloat 的情况。</p><p><strong>关于bufferbloat的定义</strong></p><blockquote><p>Bufferbloat is a cause of high latency and jitter in packet-switched networks caused by excess buffering of packets. Bufferbloat can also cause packet delay variation (also known as jitter), as well as reduce the overall network throughput. When a router or switch is configured to use excessively large buffers, even very high-speed networks can become practically unusable for many interactive applications like voice over IP (VoIP), audio streaming, online gaming, and even ordinary web browsing.<br>Some communications equipment manufacturers designed unnecessarily large buffers into some of their network products. In such equipment, bufferbloat occurs when a network link becomes congested, causing packets to become queued for long periods in these oversized buffers. In a first-in first-out queuing system, overly large buffers result in longer queues and higher latency, and do not improve network throughput. It can also be induced by specific slow-speed connections hindering the ontime delivery of other packets.</p></blockquote><p>大多数的拥塞控制算法都是基于丢包来测算带宽，有丢包发生便会降低传输速率。<br>中间网络设备引入大的缓冲区虽然可以降低丢包的发生，但是会导致TCP 对网络阻塞敏感度的降低，直到缓冲区满了并开始出现丢包，TCP 才开始降窗。</p><p>另外，由于缓冲区的增大，会导致延迟增加。试着想象一下如果这个缓冲区是一个非常大的的数据池，那么延迟将会上升到一个非常糟糕的地步。</p><p>你可能会觉得Bufferbloat 的产生似乎是一个错误。</p><p>那么它的产生历史缘由是什么呢？</p><blockquote><p>在以前的互联网上，交换机可能总是拥有比服务器更快的网卡，所以这些位于互联网中间层的服务器也可能比客户端更快，并且并不能对客户端发送信息包的速率有多大影响。<br>很显然今天已经不是这样的了！众所周知，今天的计算机相比于 5 年前的计算机在速度上并没有多大的提升（我们遇到了某些有关光速的问题）。所以我想路由器上的大型交换机并不会在速度上大幅领先于数据中心里服务器上的网卡。</p></blockquote><p>(摘自Van Jacobson的netdev演讲)</p><p><strong>如何理解这段话呢？</strong><br>早期终端设备和网络核心交换设备性能上存在明显的悬殊，像思科这类厂商，他们的中间路由设备的处理能力是能够甩开一众终端设备的。<br>在这个时期，中间设备的缓存就显得不那么重要了，可能只需很少的缓存就够用了，对于终端设备而言，只需要考虑发送的尽可能的快就行！<br>随着时代的发展，终端处理器以及网卡性能的不断提升，不断缩小了和中间转发设备性能上的差距。</p><p>这个时候问题就出现了:<br>中间转发设备似乎不太来得及处理数据包了!</p><p>这就需要想办法尽快解决没有来得及处理的数据包，提升处理器性能或增加处理器都是办法，但这些方法都没有直接搞一个大缓存来的简单又有性价比。<br>这样一来，引入Buffer 其实违背了中间转发设备本身的角色定位，它的角色应该只是转发，而不应该成为一个缓存设备。</p><p>对于Bufferbloat，你可以鄙视它，甚至厌恶它，但它却是时代变迁下的产物。</p><h4 id="BBR-原理"><a href="#BBR-原理" class="headerlink" title="BBR 原理"></a>BBR 原理</h4><p>BBR 的诞生解决了Bufferbloat 问题，关于它的诞生缘由，BBR 论文[3]是这样描述的：</p><blockquote><p>These problems result from a design choice made when TCP congestion control was created in the 1980s—interpreting packet loss as “congestion.”13 This equivalence was true at the time but was because of technology limitations, not first principles. As NICs (network interface controllers) evolved from Mbps to Gbps and memory chips from KB to GB, the relationship between packet loss and congestion became more tenuous.<br>Today TCP’s loss-based congestion control—even with the current best of breed, CUBIC11—is the primary cause of these problems. When bottleneck buffers are large, loss-based congestion control keeps them full, causing bufferbloat. When bottleneck buffers are small, loss-based congestion control misinterprets loss as a signal of congestion, leading to low throughput. Fixing these problems requires an alternative to loss-based congestion control. Finding this alternative requires an understanding of where and how network congestion originates.</p></blockquote><p>(摘自BBR论文&lt;BBR: Congestion-Based Congestion Control&gt;)</p><p>简单的理解就是基于丢包的拥塞控制算法，在缓冲区缓存比较大的时候，会使得缓冲区被填满最终造成bufferbloat。而当缓冲区缓存较小时，基于丢包的拥塞算法可能会误判为此时网络拥塞，并降低吞吐量，所以要想解决这种问题，就需要找到一种不是基于丢包的拥塞控制算法。<br>于是，BBR 诞生了。</p><p>在讲解BBR之前，先了解几个参数名词，这几个名词会贯穿本文</p><ol><li>RTprop（Round-trippropagation time）：最小时延，一个来回所以其实是两倍时延</li><li>BtlBw（bottleneck bandwidth）：瓶颈带宽</li><li>BDP = BtlBw * RTprop：整条链路所能存储的数据值(不含路由缓存)</li><li>BtlBufSize ：链路上所有的中间路由缓存之和<br>BBR论文中对两者关系用了一个比喻来说明<br>If the network path were a physical pipe, RTprop would be its length and BtlBw its minimum diameter.<br>其实根据这个定义，我们很容易想到：<br>如果当前的实际发送速率乘以延迟得到的值越接近 BDP 说明算法的效率越高。</li></ol><p>下图是这几个参数之间的关系<br><img src="http://blog.lihaizhou.top/BBR/BBR_1.png" alt=""><br>(这张图原图摘自BBR论文，笔者加了一些自己的理解在上面)</p><p>个人理解</p><ol><li>数据刚开始传输时，这个时候显然数据量未填充满也就是未达到BDP，此时传输速率持续上升，RTT处于最优状态也就是最小时延，这是一个传输通畅的阶段。</li><li>当数据填充超过BDP时，数据会使用到路由的缓存区，这个时候RTT会开始上升，但是发送速率还维持不变，这个阶段处于一个缓冲阶段，一旦越过BDP分界线就说明拥塞开始出现了。</li><li>当数据填充超过（BDP+BtlBufSize）大小后，此时没有地方能够存储下没有来得及发送的数据，丢包开始产生！关于图中笔者标记出来的丢包临界点，基于丢包的拥塞算法几乎都是以此为收敛点，尽可能的填充满网络和缓存，认为此举是可以提高网络利用率和减少丢包，一旦出现丢包，就开始降低数据的发送量并再次向这个错误的收敛靠近。<br>BBR的目标收敛点都是围绕着图中理想收敛点位置，而基于丢包的cubic/Reno等算法都是围绕着如何收敛到丢包临界点上，因为它们总是将缓存考虑在内，这其实是一个错误的做法。BBR</li></ol><p>关于图中的斜率，个人理解如下：<br>假设某一时刻实际发送数据大小为S，实际带宽为R，R必定是 &lt;= BtlBw，实际时延设为<code>T&gt;=RTprop</code>。<br>这一时刻的数据量 S=T*R， 所以这里<code>T/S = 1/R &gt;= 1/BtlBw</code>，所以实际情况下斜率往往是比上半图中的更陡峭，同理下半图的斜率 R/S = 1/T &lt;= 1/RTprop，所以实际情况下下半图的斜率往往会更平缓些，图中的阴影部分是不可达的。</p><p>关于发送速率的计算方式，BBR论文中是这样解释的</p><blockquote><p>Unlike RTT, nothing in the TCP spec requires implementations to track bottleneck bandwidth, but a good estimate results from tracking delivery rate. When the ack for some packet arrives back at the sender, it conveys that packet’s RTT and announces the delivery of data inflight when that packet departed. Average delivery rate between send and ack is the ratio of data delivered to time elapsed: deliveryRate = Δdelivered/Δt. This rate must be ≤ the bottleneck rate (the arrival amount is known exactly so all the uncertainty is in the Δt, which must be ≥ the true arrival interval; thus, the ratio must be ≤ the true delivery rate, which is, in turn, upper-bounded by the bottleneck capacity). </p></blockquote><p>简单理解为</p><ol><li>应答了多少数据，记为delivered；</li><li>应答delivered这么多数据所用时间，记为interval_us。<br>将上述二者相除，就能得到带宽：bw = delivered/interval_us</li></ol><p>从前面那张图我们可以发现，如果测量BtlBw则需要填满buffer，测量RTprop 需要排空buffer也就是不能使用buffer，所以BBR的BtlBw和RTprop无法同时测量的。<br>那么BBR是怎么做得呢？下面会结合源码分别进行分析</p><h5 id="Startup"><a href="#Startup" class="headerlink" title="Startup"></a>Startup</h5><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/* We use a high_gain value of 2/ln(2) because it's the smallest pacing gain</span></span><br><span class="line"><span class="comment"> * that will allow a smoothly increasing pacing rate that will double each RTT</span></span><br><span class="line"><span class="comment"> * and send the same number of packets per RTT that an un-paced, slow-starting</span></span><br><span class="line"><span class="comment"> * Reno or CUBIC flow would:</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">const</span> <span class="keyword">int</span> bbr_high_gain  = BBR_UNIT * <span class="number">2885</span> / <span class="number">1000</span> + <span class="number">1</span>;</span><br></pre></td></tr></table></figure><p>这个值主要用于计算<code>pacing_rate</code>，至于这个初始值为何是2/ln(2)这样一个写死的值，笔者翻阅了BBR论文并找到没有提及原因的地方，猜测可能是实测算出的最优值。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/* Initialize pacing rate to: high_gain * init_cwnd / RTT. */</span></span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">bbr_init_pacing_rate_from_rtt</span><span class="params">(struct sock *sk)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">        <span class="class"><span class="keyword">struct</span> <span class="title">tcp_sock</span> *<span class="title">tp</span> = <span class="title">tcp_sk</span>(<span class="title">sk</span>);</span></span><br><span class="line">        <span class="class"><span class="keyword">struct</span> <span class="title">bbr</span> *<span class="title">bbr</span> = <span class="title">inet_csk_ca</span>(<span class="title">sk</span>);</span></span><br><span class="line">        u64 bw;</span><br><span class="line">        u32 rtt_us;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (tp-&gt;srtt_us) &#123;                <span class="comment">/* any RTT sample yet? */</span></span><br><span class="line">                rtt_us = max(tp-&gt;srtt_us &gt;&gt; <span class="number">3</span>, <span class="number">1U</span>);</span><br><span class="line">                bbr-&gt;has_seen_rtt = <span class="number">1</span>;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;                         <span class="comment">/* no RTT sample yet */</span></span><br><span class="line">                rtt_us = USEC_PER_MSEC;         <span class="comment">/* use nominal default RTT */</span></span><br><span class="line">        &#125;</span><br><span class="line">        bw = (u64)tp-&gt;snd_cwnd * BW_UNIT;</span><br><span class="line">        do_div(bw, rtt_us);</span><br><span class="line">        sk-&gt;sk_pacing_rate = bbr_bw_to_pacing_rate(sk, bw, bbr_high_gain);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在Startup阶段，pacing_rate在每次收到一个ACK后，都会提高bbr_high_gain的值。<br>BBR计算拥塞窗口是用“当前采集到的速率”乘以“当前采集到的最小RTT”来计算的，这就造成了“当前发送窗口”和“当前已经提高的速率”之间的不匹配，所以，计算拥塞窗口的时候，gain因子也必须是bbr_high_gain，从而可以吸收掉速率的实际提升.</p><h5 id="ProbeRTT"><a href="#ProbeRTT" class="headerlink" title="ProbeRTT"></a>ProbeRTT</h5><p>到这里，我们知道要想达到理想收敛点，就需要找到最小时延和瓶颈带宽<br>我们先来讨论下BBR是如何找到最小RTT的<br>如果了解过Vegas算法原理的人，应该知道Vegas对时延的波动比较敏感，即便一次不是真的拥塞导致的RTT增加都会导致其降窗。<br>那么BBR是基于时延找最小RTT的吗？并不是，下面会讲述</p><p>最小RTT的有效时间是10s<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/* Window length of min_rtt filter (in sec): */</span></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">const</span> u32 bbr_min_rtt_win_sec = <span class="number">10</span>;</span><br><span class="line"><span class="comment">/* Minimum time (in ms) spent at bbr_cwnd_min_target in BBR_PROBE_RTT mode: */</span></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">const</span> u32 bbr_probe_rtt_mode_ms = <span class="number">200</span>;</span><br></pre></td></tr></table></figure></p><p>探测最小RTT需要最少4个数据包，这是为了兼顾延迟ACK。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/* Try to keep at least this many packets in flight, if things go smoothly. For</span></span><br><span class="line"><span class="comment"> * smooth functioning, a sliding window protocol ACKing every other packet</span></span><br><span class="line"><span class="comment"> * needs at least 4 packets in flight:</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">const</span> u32 bbr_cwnd_min_target = <span class="number">4</span>;</span><br></pre></td></tr></table></figure><p>更新最小RTT核心函数 bbr_update_min_rtt，这个函数较长，我们将其拆分开来进行讨论</p><p>1.如果本次RTT时间小于最小RTT时间值或者最小RTT时间有效时间到了，则更新最小RTT值</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/* Track min RTT seen in the min_rtt_win_sec filter window: */</span></span><br><span class="line">  filter_expired = after(tcp_jiffies32,</span><br><span class="line">                         bbr-&gt;min_rtt_stamp + bbr_min_rtt_win_sec * HZ);</span><br><span class="line">  <span class="keyword">if</span> (rs-&gt;rtt_us &gt;= <span class="number">0</span> &amp;&amp;</span><br><span class="line">      (rs-&gt;rtt_us &lt; bbr-&gt;min_rtt_us ||</span><br><span class="line">       (filter_expired &amp;&amp; !rs-&gt;is_ack_delayed))) &#123;</span><br><span class="line">          bbr-&gt;min_rtt_us = rs-&gt;rtt_us;</span><br><span class="line">          bbr-&gt;min_rtt_stamp = tcp_jiffies32;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><p>2.最小RTT时间过期了且当前未处于PROBE_RTT模式，则切换模式到RTT，降低发送速率<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (bbr_probe_rtt_mode_ms &gt; <span class="number">0</span> &amp;&amp; filter_expired &amp;&amp;</span><br><span class="line">       !bbr-&gt;idle_restart &amp;&amp; bbr-&gt;mode != BBR_PROBE_RTT) &#123;</span><br><span class="line">           bbr-&gt;mode = BBR_PROBE_RTT;  <span class="comment">/* dip, drain queue */</span></span><br><span class="line">           bbr_save_cwnd(sk);  <span class="comment">/* note cwnd so we can restore it */</span></span><br><span class="line">           bbr-&gt;probe_rtt_done_stamp = <span class="number">0</span>;</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure></p><p>3.如果此时处于<code>PROBE_RTT</code>模式下，首先设置app_limited 是为了表面这个时间区域内BW参与最大值计算。inflight数据包小于等于<code>bbr_cwnd_min_target</code>即四个数据包时，同时满足一些其它条件后，开始更新本次最小RTT侦测结束时间戳，也就是当前时间加上200ms，并将本次已delivered数据赋值给下个RTT。   </p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (bbr-&gt;mode == BBR_PROBE_RTT) &#123;</span><br><span class="line">               <span class="comment">/* Ignore low rate samples during this mode. */</span></span><br><span class="line">               tp-&gt;app_limited =</span><br><span class="line">                       (tp-&gt;delivered + tcp_packets_in_flight(tp)) ? : <span class="number">1</span>;</span><br><span class="line">               <span class="comment">/* Maintain min packets in flight for max(200 ms, 1 round). */</span></span><br><span class="line">               <span class="keyword">if</span> (!bbr-&gt;probe_rtt_done_stamp &amp;&amp;</span><br><span class="line">                   tcp_packets_in_flight(tp) &lt;= bbr_cwnd_min_target) &#123;</span><br><span class="line">                       bbr-&gt;probe_rtt_done_stamp = tcp_jiffies32 +</span><br><span class="line">                               msecs_to_jiffies(bbr_probe_rtt_mode_ms);</span><br><span class="line">                       bbr-&gt;probe_rtt_round_done = <span class="number">0</span>;</span><br><span class="line">                       bbr-&gt;next_rtt_delivered = tp-&gt;delivered;</span><br><span class="line">               &#125; <span class="keyword">else</span> <span class="keyword">if</span> (bbr-&gt;probe_rtt_done_stamp) &#123;</span><br><span class="line">                       <span class="keyword">if</span> (bbr-&gt;round_start)</span><br><span class="line">                               bbr-&gt;probe_rtt_round_done = <span class="number">1</span>;</span><br><span class="line">                       <span class="keyword">if</span> (bbr-&gt;probe_rtt_round_done)</span><br><span class="line">                               bbr_check_probe_rtt_done(sk);</span><br><span class="line">               &#125;</span><br><span class="line">       &#125;</span><br></pre></td></tr></table></figure><h5 id="ProbeBW"><a href="#ProbeBW" class="headerlink" title="ProbeBW"></a>ProbeBW</h5><p>增益系数数组</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/* The pacing_gain values for the PROBE_BW gain cycle, to discover/share bw: */</span></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">const</span> <span class="keyword">int</span> bbr_pacing_gain[] = &#123;</span><br><span class="line">        BBR_UNIT * <span class="number">5</span> / <span class="number">4</span>,        <span class="comment">/* probe for more available bw */</span></span><br><span class="line">        BBR_UNIT * <span class="number">3</span> / <span class="number">4</span>,        <span class="comment">/* drain queue and/or yield bw to other flows */</span></span><br><span class="line">        BBR_UNIT, BBR_UNIT, BBR_UNIT, <span class="comment">/* cruise at 1.0*bw to utilize pipe, */</span></span><br><span class="line">        BBR_UNIT, BBR_UNIT, BBR_UNIT  <span class="comment">/* without creating excess queue... */</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><ol><li>bbr_pacing_gain[0]<br>这个阶段gain的值是1.25，也是BBR的初始值，这个阶段意味着BBR会试图增加发送量，尽可能多的占用带宽，占满新进的多余的带宽，目的是提升资源的利用率，不过这个阶段可能会出现队列的产生以及RTT变长的情况。<br>bbr_pacing_gain[0]退出条件时：<br>已经运行超过了一个最小RTT时间并且要么发生了丢包，要么本次ACK到来前的inflight的值已经等于窗口值了。[引用2]</li><li>bbr_pacing_gain[1]<br>bbr_pacing_gain[1] 这个阶段gain的值为0.75，假设此时正处于增益阶段，此时一个新的连接发起，可能会导致正处于增益阶段的连接的inflight满载，这个时候就需要切换到bbr_pacing_gain[1] 状态，在出让部分带宽后尽快进入平稳期，这个阶段体现了BBR的公平性。<br>这个阶段时间较短，一旦完成出让带宽就退出，最多停留不超过一个最短RTT时间。</li><li>bbr_pacing_gain[2]…. bbr_pacing_gain[7]<br>这个阶段代表的是平稳期，至少停留6个RTT</li></ol><p>进入<code>PROBE_BW</code>状态后会反复的在上面三个步骤之间循环：加速、减速、匀速。。。。<br><img src="http://blog.lihaizhou.top/BBR/BBR_2.png" alt=""><br>(图片摘自BBR论文，笔者加了些理解) </p><p>这个时候，设想下如果上面的数组中移除掉后面的六个元素，也就是移除平稳期，会出现什么样的情况呢？<br>因为一旦进入平稳期由于至少停留6个RTT的限制，导致在这期间如果有富余带宽，BBR是无法抢占的，所以如果一旦移除到平稳期，带来的就是更快的发现富余带宽，代价就是比较网络比较颠簸，对于一些如下载类的业务有益，不适用于如直播类业务。</p><p>关于bbr_pacing_gain增益数组的作用，归纳下来就是：<br><code>BBR会尽可能的抢占更多带宽，一旦有了新的连接之后，如果出现本次窗口估值等于上次的inflight值，说明这个时候带宽被填满了。此时旧连接的gain值下降进而让出部分带宽给新连接，在至少6个RTT周期内也就是平稳期，这个阶段旧连接不会抢占更多带宽，直到6个RTT后，旧连接会试图抢占更多带宽，周而复始。</code></p><p>bbr_update_bw 函数</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/* Estimate the bandwidth based on how fast packets are delivered */</span></span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">bbr_update_bw</span><span class="params">(struct sock *sk, <span class="keyword">const</span> struct rate_sample *rs)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">        <span class="class"><span class="keyword">struct</span> <span class="title">tcp_sock</span> *<span class="title">tp</span> = <span class="title">tcp_sk</span>(<span class="title">sk</span>);</span></span><br><span class="line">        <span class="class"><span class="keyword">struct</span> <span class="title">bbr</span> *<span class="title">bbr</span> = <span class="title">inet_csk_ca</span>(<span class="title">sk</span>);</span></span><br><span class="line">        u64 bw;</span><br><span class="line"></span><br><span class="line">        bbr-&gt;round_start = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">if</span> (rs-&gt;delivered &lt; <span class="number">0</span> || rs-&gt;interval_us &lt;= <span class="number">0</span>)</span><br><span class="line">                <span class="keyword">return</span>; <span class="comment">/* Not a valid observation */</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">/* See if we've reached the next RTT */</span></span><br><span class="line">        <span class="keyword">if</span> (!before(rs-&gt;prior_delivered, bbr-&gt;next_rtt_delivered)) &#123;</span><br><span class="line">                bbr-&gt;next_rtt_delivered = tp-&gt;delivered;</span><br><span class="line">                bbr-&gt;rtt_cnt++;</span><br><span class="line">                bbr-&gt;round_start = <span class="number">1</span>;</span><br><span class="line">                bbr-&gt;packet_conservation = <span class="number">0</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        bbr_lt_bw_sampling(sk, rs);</span><br><span class="line"></span><br><span class="line">        <span class="comment">/* Divide delivered by the interval to find a (lower bound) bottleneck</span></span><br><span class="line"><span class="comment">         * bandwidth sample. Delivered is in packets and interval_us in uS and</span></span><br><span class="line"><span class="comment">         * ratio will be &lt;&lt;1 for most connections. So delivered is first scaled.</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        <span class="comment">//计算当前实际带宽</span></span><br><span class="line">        bw = div64_long((u64)rs-&gt;delivered * BW_UNIT, rs-&gt;interval_us);</span><br><span class="line"></span><br><span class="line">        <span class="comment">/* If this sample is application-limited, it is likely to have a very</span></span><br><span class="line"><span class="comment">         * low delivered count that represents application behavior rather than</span></span><br><span class="line"><span class="comment">         * the available network rate. Such a sample could drag down estimated</span></span><br><span class="line"><span class="comment">         * bw, causing needless slow-down. Thus, to continue to send at the</span></span><br><span class="line"><span class="comment">         * last measured network rate, we filter out app-limited samples unless</span></span><br><span class="line"><span class="comment">         * they describe the path bw at least as well as our bw model.</span></span><br><span class="line"><span class="comment">         *</span></span><br><span class="line"><span class="comment">         * So the goal during app-limited phase is to proceed with the best</span></span><br><span class="line"><span class="comment">         * network rate no matter how long. We automatically leave this</span></span><br><span class="line"><span class="comment">         * phase when app writes faster than the network can deliver :)</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        <span class="comment">//加入新的样本</span></span><br><span class="line">        <span class="keyword">if</span> (!rs-&gt;is_app_limited || bw &gt;= bbr_max_bw(sk)) &#123;</span><br><span class="line">                <span class="comment">/* Incorporate new sample into our max bw filter. */</span></span><br><span class="line">                minmax_running_max(&amp;bbr-&gt;bw, bbr_bw_rtts, bbr-&gt;rtt_cnt, bw);</span><br><span class="line">        &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这个函数主要做的事比较清晰，主要是更新RTT周期、通过已delivered数据 * BW_UNIT/采样时间得出带宽值，并将带宽和min rtt加入到新的RTT和BW样本。</p><p>通过对<code>ProbeRTT</code>和<code>ProbeBW</code>的分析，可以知道BBR其实大部分时候都是在ProbeBW和ProbeRTT状态之间切换，并且绝大部分时间是停留在ProbeBW上。<br>根据代码可以得到如下一个简要的图：<br><img src="http://blog.lihaizhou.top/BBR/BBR_3.png" alt=""></p><p>可以看出大部分时候都停留在<code>ProbeBW</code>上，在<code>ProbeRTT</code>停留的时间很短，这其实符合BBR的初衷：尽可能的多占用带宽并且尽量不占用缓存。</p><p>根据前面的代码梳理，画了一张状态机的流转图<br><img src="http://blog.lihaizhou.top/BBR/BBR_4.png" alt=""><br>如果我们用一个精简的图来看这个过程的话，大致如下<br><img src="http://blog.lihaizhou.top/BBR/BBR_5.png" alt=""></p><h4 id="BBR-优缺点"><a href="#BBR-优缺点" class="headerlink" title="BBR 优缺点"></a>BBR 优缺点</h4><p>从前面的讨论中，我们知道BBR的优势，也不难发现其劣势。</p><h5 id="BBR-优势"><a href="#BBR-优势" class="headerlink" title="BBR 优势"></a>BBR 优势</h5><p>1.在长传即大RTT场景下优势明显<br>有一种典型的场景便是”长肥管道”，在TCP连接中，较长的距离意味着RTT的增加，进而意味着窗口打开的更慢，对于像Cubic这类AIMD的拥塞算法而言，它们的慢启动过程会越长 ，这就是Reno家族算法的典型弊端。<br>另外，对于Cubic这类算法而言，更容易出现缓冲区被占满的情况，也就是我们前面提到的bufferbloat，这是为何呢？<br>一窗数据只有在得到ACK确认后才会清除，RTT越小意味着缓冲区能够越快腾出空间，发生bufferbloat概率也越低。反之RTT越大的话，越容易出现bufferbloat的情形<br>而BBR设计之初，就没有将中间缓存考虑在内，从本文前面的收敛图可以看出</p><ul><li>BBR的理想带宽收敛点是在缓冲区即将被填充的时候，此时BtlBW最大，RTT最小</li><li>而对于Reno家族算法而言，其收敛点是缓冲区被填满的时候，此时BtlBW最大，但RTT也最大。</li></ul><p>归纳下来：<br>对于长肥管道这种场景，Cubic这类传统算法表现会异常脆弱，一旦有丢包立马械 投降，执行MD     过程，这个过程是一个快速降窗的过程，前功尽弃。<br>而BBR的优势在于不会导致bufferbloat，且对丢包不敏感使得其不会出现激进降窗的行为。</p><p>2.抢占带宽能力强<br>BBR其实大部分时候都是在ProbeBW和ProbeRTT状态之间切换，并且绝大部分时间是停留在ProbeBW上。ProbeBW阶段会不断的试探剩余可用带宽，短时间内占据更多的带宽。</p><p>3.平稳发送<br>由于其平稳期至少待够6个RTT周期才行，这使得该阶段的发送速率比较平稳，比较适合音视频领域比如视频直播这种对稳定性要求较高的场景。</p><h5 id="BBR-不足之处"><a href="#BBR-不足之处" class="headerlink" title="BBR 不足之处"></a>BBR 不足之处</h5><p>1.对带宽变化不敏感<br>从前面原理分析环节，我们知道BBR减损期会让出部分带宽，一旦这个时候被其它流占据了话，BBR要等到度过本地”漫长”的平稳期，等到下个增益周期才能发现。<br>也就是说BBR在ProbeBW状态下，只有在ProbeMore周期才能感受到带宽的变化，后面的ProbeDrain以及平稳期对于带宽的变化都无法感知，如果这个阶段实际带宽降低，BBR需要多个RTT周期才能收敛到实际的带宽位置。</p><p>2.ProbeRTT阶段导致发送速率下降太多<br>这个阶段由于只发四个包，导致发送速率迅速下降，虽然时间很短，但是如果应用在一些对实时性要求很高的音视频场景下，就会出现卡顿现象。<br>解决方案有多种，根据实际业务需要可以减少ProbeRTT时间甚至直接拿掉ProbeRTT阶段。</p><p>3.抗RTT抖动能力差<br>一个典型的场景便是BBR在WIFI弱网下表现不佳，这里的弱网不是指的是网络质量差，速度慢。<br>而是指的是WIFI场景下的稳定性相比于有线网络而言，逊色太多。由于无线网络是共享介质的，几乎无法在信号不冲突的前提下同时发送和接收。<br>所以在WIFI场景下，接入的终端设备一多，RTT抖动会越明显，这种情况下BBR测算出的BDP很可能就不准确了，可能会低于实际带宽数据。</p><p>综合来看：<br>个人理解目前为止并没有一种拥塞算法能够适应各种网络环境，是否选择BBR需要根据自己的业务场景需要。BBR存在不少优势的同时，也存在不少劣势。<br>应用BBR之后如存在问题，只要不是先天不足，都可以根据业务需要对BBR进行修改。<br>比如对于下载业务应用BBR的话是否可以将平稳期移除，这样虽然带来了网络颠簸，但是对于用户而言带来的变化时下载更快了。<br>再比如对于稳定性要求高的音视频业务，是否可以缩短ProbeRTT时间甚至直接拿掉ProbeRTT阶段，这样的话就不会存在ProbeRTT阶段发包速率掉下来导致的卡顿。</p><h4 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h4><p>至此，对于BBR的一个小结到此结束，由于理解水平有限，可能有不足或理解错误的地方，希望以后回顾时能够再完善下。</p><h4 id="参考文章"><a href="#参考文章" class="headerlink" title="参考文章"></a>参考文章</h4><ol><li>BBR论文 <a href="https://www.cis.upenn.edu/~cis553/files/BBR.pdf" target="_blank" rel="noopener">https://www.cis.upenn.edu/~cis553/files/BBR.pdf</a></li><li>[引用1] Startup阶段拥塞窗口计算的滞后性</li><li>[引用2] 从TCP拥塞本质看BBR算法及其收敛性</li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;TCP BBR（Bottleneck Bandwidth and Round-trip propagation time）是由Google 设计，于2016年发布的拥塞算法。&lt;br&gt;以往的大部分拥塞控制算法都是基于丢包来作为降低传输速率的信号，而B
      
    
    </summary>
    
      <category term="网络" scheme="http://lihaizhou.top/categories/%E7%BD%91%E7%BB%9C/"/>
    
    
  </entry>
  
  <entry>
    <title>ANR原理分析及常见案例</title>
    <link href="http://lihaizhou.top/2022/02/10/ANR%E5%8E%9F%E7%90%86%E5%88%86%E6%9E%90%E5%8F%8A%E5%B8%B8%E8%A7%81%E6%A1%88%E4%BE%8B/"/>
    <id>http://lihaizhou.top/2022/02/10/ANR原理分析及常见案例/</id>
    <published>2022-02-10T13:20:55.000Z</published>
    <updated>2022-04-11T01:16:26.193Z</updated>
    
    <content type="html"><![CDATA[<p>最近看了下ANR代码，结合之前项目上的一些ANR案例，打算对ANR的原理以及常见案例做下小结，涉及的代码均基于<code>Android S</code></p><p>画了一张图，列举了可能导致ANR的一些影响因素<br><img src="http://blog.lihaizhou.top/ANR/ANR_1.png" alt="ANR影响因素"></p><h4 id="原理机制"><a href="#原理机制" class="headerlink" title="原理机制"></a>原理机制</h4><p>我们平时遇到的ANR问题大部分都是input ANR类型，所以以input ANR为例进行梳理，这块机制并不复杂，只梳理埋计时和check超时的代码部分。<br>正常输入事件的分发流程如下<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">InputDispatcher::dispatchOnce() </span><br><span class="line">-&gt;InputDispatcher::dispatchOnceInnerLocked </span><br><span class="line">-&gt;InputDispatcher::dispatchKeyLocked </span><br><span class="line">-&gt;InputDispatcher::findFocusedWindowTargetsLocked</span><br><span class="line">       ......</span><br></pre></td></tr></table></figure></p><p><code>findFocusedWindowTargetsLocked</code>这个函数从字面很好理解: 查找有焦点window。<br>因函数较长，我们将其拆分开来进行梳理<br><strong>Step1: 未找到focused的window，也没有找到focused的application，drop该事件</strong></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// If there is no currently focused window and no focused application</span></span><br><span class="line"><span class="comment">// then drop the event.</span></span><br><span class="line"><span class="keyword">if</span> (focusedWindowHandle == <span class="literal">nullptr</span> &amp;&amp; focusedApplicationHandle == <span class="literal">nullptr</span>) &#123;</span><br><span class="line">    ALOGI(<span class="string">"Dropping %s event because there is no focused window or focused application in "</span></span><br><span class="line">          <span class="string">"display %"</span> PRId32 <span class="string">"."</span>,</span><br><span class="line">          NamedEnum::<span class="built_in">string</span>(entry.type).c_str(), displayId);</span><br><span class="line">    <span class="keyword">return</span> InputEventInjectionResult::FAILED;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>Step2: 未找到focused的window，有focused的application，这是最为常见的情况</strong></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (focusedWindowHandle == <span class="literal">nullptr</span> &amp;&amp; focusedApplicationHandle != <span class="literal">nullptr</span>) &#123;</span><br><span class="line">       <span class="keyword">if</span> (!mNoFocusedWindowTimeoutTime.has_value()) &#123;</span><br><span class="line">           <span class="comment">// We just discovered that there's no focused window. Start the ANR timer</span></span><br><span class="line">           <span class="built_in">std</span>::chrono::nanoseconds timeout = focusedApplicationHandle-&gt;getDispatchingTimeout(</span><br><span class="line">                   DEFAULT_INPUT_DISPATCHING_TIMEOUT);</span><br><span class="line">           <span class="comment">//更新超时时间，该focused事件开始进入计时</span></span><br><span class="line">           mNoFocusedWindowTimeoutTime = currentTime + timeout.count();</span><br><span class="line">           mAwaitedFocusedApplication = focusedApplicationHandle;</span><br><span class="line">           mAwaitedApplicationDisplayId = displayId;</span><br><span class="line">           ALOGW(<span class="string">"Waiting because no window has focus but %s may eventually add a "</span></span><br><span class="line">                 <span class="string">"window when it finishes starting up. Will wait for %"</span> PRId64 <span class="string">"ms"</span>,</span><br><span class="line">                 mAwaitedFocusedApplication-&gt;getName().c_str(), millis(timeout));</span><br><span class="line">           *nextWakeupTime = *mNoFocusedWindowTimeoutTime;</span><br><span class="line">           <span class="keyword">return</span> InputEventInjectionResult::PENDING;</span><br><span class="line">       &#125; <span class="keyword">else</span> <span class="keyword">if</span> (currentTime &gt; *mNoFocusedWindowTimeoutTime) &#123;</span><br><span class="line">           <span class="comment">// Already raised ANR. Drop the event</span></span><br><span class="line">           ALOGE(<span class="string">"Dropping %s event because there is no focused window"</span>,</span><br><span class="line">                 NamedEnum::<span class="built_in">string</span>(entry.type).c_str());</span><br><span class="line">           <span class="keyword">return</span> InputEventInjectionResult::FAILED;</span><br><span class="line">       &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">           <span class="comment">//说明之前已经埋过计时，此时还未到超时时间则继续等待</span></span><br><span class="line">           <span class="comment">// Still waiting for the focused window</span></span><br><span class="line">           <span class="keyword">return</span> InputEventInjectionResult::PENDING;</span><br><span class="line">       &#125;</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure><p><strong>Step3: 重置超时时间</strong></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// we have a valid, non-null focused window</span></span><br><span class="line">resetNoFocusedWindowTimeoutLocked();</span><br></pre></td></tr></table></figure><p>执行到这步，说明本次<code>findFocusedWindowTargetsLocked</code>找到了非空的window，这种情况下会<code>resetNoFocusedWindowTimeoutLocked。</code><br>除此之外，系统还有多个场景下也会触发该重置接口，比如</p><ol><li>setFocusedApplicationLocked  当前focused应用发生变化</li><li>setInputDispatchMode  调用了分发模式</li><li>resetAndDropEverythingLocked  这个接口存在多处会调用，比如stopFreezingDisplayLocked解冻屏幕、performEnableScreen亮屏等场景</li></ol><p><strong>Step4: 其它窗口异常情况</strong><br>如果当前window存在异常情况，也会做pending处理，同样可能会成为造成ANR的原因<br>比如窗口处于paused状态</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (focusedWindowHandle-&gt;getInfo()-&gt;paused) &#123;</span><br><span class="line">    ALOGI(<span class="string">"Waiting because %s is paused"</span>, focusedWindowHandle-&gt;getName().c_str());</span><br><span class="line">    <span class="keyword">return</span> InputEventInjectionResult::PENDING;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>还有其他情况也会导致pending，如窗口未连接、窗口连接已满、窗口连接已死亡等，不再一一列出。<br>这里提到了造成消息pending的情况，我们自然会想到那什么场景下消息会drop掉呢？<br><code>frameworks/native/services/inputflinger/dispatcher/InputDispatcher.cpp</code><br><img src="http://blog.lihaizhou.top/ANR/ANR_2.png" alt=""><br>大致有如上几种场景会造成消息drop，dropInboundEventLocked的触发时机是在<code>InputDispatcher::dispatchOnceInnerLocked</code>中。<br>到这里我们已经清楚了埋下超时时间的流程，那么什么时候会检查超时时间有没有到呢？<br><code>InputDispatcher.cpp@dispatchOnce-&gt; InputDispatcher.cpp@processAnrsLocked</code><br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Check if any of the connections' wait queues have events that are too old.</span></span><br><span class="line"><span class="comment"> * If we waited for events to be ack'ed for more than the window timeout, raise an ANR.</span></span><br><span class="line"><span class="comment"> * Return the time at which we should wake up next.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">nsecs_t</span> InputDispatcher::processAnrsLocked() &#123;</span><br><span class="line">    <span class="keyword">const</span> <span class="keyword">nsecs_t</span> currentTime = now();</span><br><span class="line">    <span class="keyword">nsecs_t</span> nextAnrCheck = LONG_LONG_MAX;</span><br><span class="line">    <span class="comment">// Check if we are waiting for a focused window to appear. Raise ANR if waited too long</span></span><br><span class="line">    <span class="keyword">if</span> (mNoFocusedWindowTimeoutTime.has_value() &amp;&amp; mAwaitedFocusedApplication != <span class="literal">nullptr</span>) &#123;</span><br><span class="line">        <span class="keyword">if</span> (currentTime &gt;= *mNoFocusedWindowTimeoutTime) &#123;</span><br><span class="line">            processNoFocusedWindowAnrLocked();</span><br><span class="line">            mAwaitedFocusedApplication.reset();</span><br><span class="line">            mNoFocusedWindowTimeoutTime = <span class="built_in">std</span>::nullopt;</span><br><span class="line">            <span class="keyword">return</span> LONG_LONG_MIN;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="comment">//mNoFocusedWindowTimeoutTime代表的是这个window超时的时间点</span></span><br><span class="line">            <span class="comment">// Keep waiting. We will drop the event when mNoFocusedWindowTimeoutTime comes.</span></span><br><span class="line">            nextAnrCheck = *mNoFocusedWindowTimeoutTime;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Check if any connection ANRs are due</span></span><br><span class="line">    nextAnrCheck = <span class="built_in">std</span>::min(nextAnrCheck, mAnrTracker.firstTimeout());</span><br><span class="line">    <span class="keyword">if</span> (currentTime &lt; nextAnrCheck) &#123; <span class="comment">// most likely scenario</span></span><br><span class="line">        <span class="keyword">return</span> nextAnrCheck;          <span class="comment">// everything is normal. Let's check again at nextAnrCheck</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// If we reached here, we have an unresponsive connection.</span></span><br><span class="line">    sp&lt;Connection&gt; connection = getConnectionLocked(mAnrTracker.firstToken());</span><br><span class="line">    <span class="keyword">if</span> (connection == <span class="literal">nullptr</span>) &#123;</span><br><span class="line">        ALOGE(<span class="string">"Could not find connection for entry %"</span> PRId64, mAnrTracker.firstTimeout());</span><br><span class="line">        <span class="keyword">return</span> nextAnrCheck;</span><br><span class="line">    &#125;</span><br><span class="line">    connection-&gt;responsive = <span class="literal">false</span>;</span><br><span class="line">    <span class="comment">// Stop waking up for this unresponsive connection</span></span><br><span class="line">    mAnrTracker.eraseToken(connection-&gt;inputChannel-&gt;getConnectionToken());</span><br><span class="line">    onAnrLocked(connection);</span><br><span class="line">    <span class="keyword">return</span> LONG_LONG_MIN;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>如果当前时间已经满足超时时间，则触发onAnrLocked</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">void</span> InputDispatcher::onAnrLocked(<span class="built_in">std</span>::<span class="built_in">shared_ptr</span>&lt;InputApplicationHandle&gt; application) &#123;</span><br><span class="line">    <span class="built_in">std</span>::<span class="built_in">string</span> reason =</span><br><span class="line">            StringPrintf(<span class="string">"%s does not have a focused window"</span>, application-&gt;getName().c_str());</span><br><span class="line">    updateLastAnrStateLocked(*application, reason);</span><br><span class="line"></span><br><span class="line">    <span class="built_in">std</span>::<span class="built_in">unique_ptr</span>&lt;CommandEntry&gt; commandEntry = <span class="built_in">std</span>::make_unique&lt;CommandEntry&gt;(</span><br><span class="line">            &amp;InputDispatcher::doNotifyNoFocusedWindowAnrLockedInterruptible);</span><br><span class="line">    commandEntry-&gt;inputApplicationHandle = <span class="built_in">std</span>::move(application);</span><br><span class="line">    postCommandLocked(<span class="built_in">std</span>::move(commandEntry));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>onAnrLocked函数的主要作用是将<code>doNotifyNoFocusedWindowAnrLockedInterruptible</code>通过<code>postCommandLocked</code>塞进队列中。<br>在下一次<code>InputDispatcher.dispatchOnce</code>中会执行<code>runCommandsLockedInterruptible</code><br><img src="http://blog.lihaizhou.top/ANR/ANR_3.png" alt=""></p><p><code>runCommandsLockedInterruptible</code>方法很简单，取出所有的Command执行一遍<br><img src="http://blog.lihaizhou.top/ANR/ANR_4.png" alt=""><br>这里顺便提一下，我们平时分析日志时经常会遇到类似这样的片段<br><img src="http://blog.lihaizhou.top/ANR/ANR_5.png" alt=""><br><img src="http://blog.lihaizhou.top/ANR/ANR_6.png" alt=""><br><img src="http://blog.lihaizhou.top/ANR/ANR_7.png" alt=""><br>上面的日志片段其实是在processAnrsLocked中打印的，这块日志打印在S上已经被谷歌移除了。</p><h4 id="分析步骤"><a href="#分析步骤" class="headerlink" title="分析步骤"></a>分析步骤</h4><p><strong>Step1：系统环境因素</strong><br>首先判断下是否受环境因素影响，这里所说的系统环境因素通常指的是整机负载/低内存/系统异常等，下面以高负载和低内存这两个场景为例进行说明<br>一. 受整机负载影响<br>搜索<code>ANR in</code>关键词<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">01</span><span class="number">-29</span> <span class="number">06</span>:<span class="number">24</span>:<span class="number">46.618452</span>  <span class="number">1210</span>  <span class="number">5962</span> I AnrManager: ANR in com.journeyui.calculator (com.journeyui.calculator/.Calculator), time=<span class="number">260439862</span></span><br><span class="line"><span class="number">01</span><span class="number">-29</span> <span class="number">06</span>:<span class="number">24</span>:<span class="number">46.618452</span>  <span class="number">1210</span>  <span class="number">5962</span> I AnrManager: Reason: Input dispatching timed out (ActivityRecord&#123;<span class="number">51e27</span>ca u0 com.journeyui.calculator/.Calculator t1837&#125; does <span class="keyword">not</span> have a focused window)</span><br><span class="line"><span class="number">01</span><span class="number">-29</span> <span class="number">06</span>:<span class="number">24</span>:<span class="number">46.618452</span>  <span class="number">1210</span>  <span class="number">5962</span> I AnrManager: Load: <span class="number">31.7</span> / <span class="number">33.43</span> / <span class="number">30.98</span></span><br><span class="line"><span class="number">01</span><span class="number">-29</span> <span class="number">06</span>:<span class="number">24</span>:<span class="number">46.618452</span>  <span class="number">1210</span>  <span class="number">5962</span> I AnrManager: Android time :[<span class="number">2022</span><span class="number">-01</span><span class="number">-29</span> <span class="number">06</span>:<span class="number">24</span>:<span class="number">46.60</span>] [<span class="number">260451.594</span>]</span><br><span class="line"><span class="number">01</span><span class="number">-29</span> <span class="number">06</span>:<span class="number">24</span>:<span class="number">46.618452</span>  <span class="number">1210</span>  <span class="number">5962</span> I AnrManager: CPU usage from <span class="number">167270</span>ms to <span class="number">0</span>ms ago (<span class="number">2022</span><span class="number">-01</span><span class="number">-29</span> <span class="number">06</span>:<span class="number">21</span>:<span class="number">47.589</span> to <span class="number">2022</span><span class="number">-01</span><span class="number">-29</span> <span class="number">06</span>:<span class="number">24</span>:<span class="number">34.860</span>) with <span class="number">99</span>% awake:</span><br><span class="line"><span class="number">01</span><span class="number">-29</span> <span class="number">06</span>:<span class="number">24</span>:<span class="number">46.618452</span>  <span class="number">1210</span>  <span class="number">5962</span> I AnrManager:   <span class="number">226</span>% <span class="number">1210</span>/system_server: <span class="number">173</span>% user + <span class="number">52</span>% kernel / faults: <span class="number">1026822</span> minor <span class="number">8</span> major</span><br><span class="line"><span class="number">01</span><span class="number">-29</span> <span class="number">06</span>:<span class="number">24</span>:<span class="number">46.618452</span>  <span class="number">1210</span>  <span class="number">5962</span> I AnrManager:   <span class="number">125</span>% <span class="number">459</span>/logd: <span class="number">16</span>% user + <span class="number">109</span>% kernel / faults: <span class="number">408</span> minor</span><br><span class="line"><span class="number">01</span><span class="number">-29</span> <span class="number">06</span>:<span class="number">24</span>:<span class="number">46.618452</span>  <span class="number">1210</span>  <span class="number">5962</span> I AnrManager:   <span class="number">29</span>% <span class="number">21567</span>/com.journeyui.globalsearch: <span class="number">18</span>% user + <span class="number">10</span>% kernel / faults: <span class="number">45071</span> minor <span class="number">25</span> major</span><br><span class="line"><span class="number">01</span><span class="number">-29</span> <span class="number">06</span>:<span class="number">24</span>:<span class="number">46.618452</span>  <span class="number">1210</span>  <span class="number">5962</span> I AnrManager:   <span class="number">26</span>% <span class="number">639</span>/surfaceflinger: <span class="number">18</span>% user + <span class="number">8.6</span>% kernel / faults: <span class="number">4704</span> minor</span><br><span class="line"><span class="number">01</span><span class="number">-29</span> <span class="number">06</span>:<span class="number">24</span>:<span class="number">46.618452</span>  <span class="number">1210</span>  <span class="number">5962</span> I AnrManager:   <span class="number">26</span>% <span class="number">20889</span>/com.yulong.android.gamecenter: <span class="number">16</span>% user + <span class="number">9.3</span>% kernel / faults: <span class="number">21143</span> minor</span><br><span class="line"><span class="number">01</span><span class="number">-29</span> <span class="number">06</span>:<span class="number">24</span>:<span class="number">46.618452</span>  <span class="number">1210</span>  <span class="number">5962</span> I AnrManager:   <span class="number">24</span>% <span class="number">29706</span>/com.sohu.inputmethod.sogou:home: <span class="number">16</span>% user + <span class="number">8.6</span>% kernel / faults: <span class="number">21832</span> minor</span><br><span class="line"><span class="number">01</span><span class="number">-29</span> <span class="number">06</span>:<span class="number">24</span>:<span class="number">46.618452</span>  <span class="number">1210</span>  <span class="number">5962</span> I AnrManager:   <span class="number">24</span>% <span class="number">545</span>/com.android.messaging: <span class="number">15</span>% user + <span class="number">9</span>% kernel / faults: <span class="number">26023</span> minor <span class="number">2</span> major</span><br><span class="line"><span class="number">01</span><span class="number">-29</span> <span class="number">06</span>:<span class="number">24</span>:<span class="number">46.618452</span>  <span class="number">1210</span>  <span class="number">5962</span> I AnrManager:   <span class="number">19</span>% <span class="number">803</span>/guardserver: <span class="number">3</span>% user + <span class="number">16</span>% kernel</span><br><span class="line"><span class="comment">//....</span></span><br><span class="line"><span class="number">01</span><span class="number">-29</span> <span class="number">06</span>:<span class="number">24</span>:<span class="number">46.618452</span>  <span class="number">1210</span>  <span class="number">5962</span> I AnrManager:   <span class="number">1.7</span>% <span class="number">3589</span>/com.journeyui.calculator: <span class="number">1</span>% user + <span class="number">0.6</span>% kernel / faults: <span class="number">3365</span> minor <span class="number">5</span> major</span><br><span class="line"><span class="comment">//.....</span></span><br><span class="line"><span class="number">01</span><span class="number">-29</span> <span class="number">06</span>:<span class="number">24</span>:<span class="number">46.618480</span>  <span class="number">1210</span>  <span class="number">5962</span> I AnrManager: <span class="number">85</span>% TOTAL: <span class="number">42</span>% user + <span class="number">33</span>% kernel + <span class="number">0</span>% iowait + <span class="number">0</span>% softirq</span><br></pre></td></tr></table></figure></p><ol><li><code>ANR in com.journeyui.calculator</code>  ANR进程名</li><li><code>Reason: Input dispatching timed out (ActivityRecord{51e27ca u0 com.journeyui.calculator/.Calculator t1837} does not have a focused window)</code><br>ANR原因，通俗的解释是：输入事件落到了<br>com.tencent.mm/.ui.LauncherUI这个窗口上，该窗口直到超时时间到了仍未响应输入事件，input超时时间系统默认是5s(我们客制化为8s)。</li><li>Load: 31.7 / 33.43 / 30.98  前 1，前 5，前 15 分钟的负载，我们通常看变化趋势。</li><li><code>2022-01-29 06:21:47.589 to 2022-01-29 06:24:34.860</code>  统计的时间区域</li><li><code>85% TOTAL: 42% user + 33% kernel + 0% iowait + 0% softirq</code><br>这行是我们通常比较关注的，代表了整体的负载情况，85% TOTAL说明整机负载很高。</li><li>图中(4)-(5)之间的片段则是各个进程占据的CPU情况, 发生ANR的进程<code>com.journeyui.calculator</code>的CPU占用只有1.7%<br>PS: 整机CPU loading很高转给系统同事分析 </li></ol><p>二. 整机内存<br>我们知道通常内存紧张的时候，kswapd线程会活跃起来进行回收内存<br>比如下面这个案例<br><img src="http://blog.lihaizhou.top/ANR/ANR_8.png" alt=""><br>通常认为kswapd的CPU占据排进top3的话，这个问题受系统低内存影响比较大。<br>为何低内存会可能和ANR扯上关系呢？<br>因为整机一旦陷入低内存，会表现的响应慢以及多场景下操作卡顿。<br>比如启动应用时间变长 、滑动列表会掉更多帧、LMKD活跃杀进程以释放更多内存。<br>PS: 这个时候如果现场还在的话，可以执行通过adb shell cat proc/meminfo查看下内存情况</p><p>低内存对整机性能的影响</p><ol><li>从过往分析的Systrace来看，低内存会出现大量的Uninterruptible Sleep | WakeKill - Block I/O block信息都是wait_on_page_bit_killable.<br>它的链路是do_page_fault —&gt; lock_page_or_retry -&gt; wait_on_page_bit_killable，由于低内存可能触发的fast path 回收 \ kswapd 回收 \ direct reclaim 回收 \ LMK杀进程回收等行为，造成do_page_fault 高频发生。<br>当出现大量的 IO 操作的时候，应用主线程的 Uninterruptible Sleep 也会变多，此时涉及到 io 操作（比如 view ，读文件，读配置文件、读 odex 文件），都会触发 Uninterruptible Sleep ， 导致整个操作的时间变长，这就解释了为何低内存下为何应用响应卡顿。</li><li>另外低内存的时候，kswapd0和HeapTaskDaemon线程会非常活跃，从我们过往的分析来看，低内存时kswapd0和HeapTaskDaemon线程会跑在大核，占据很多的CPU资源，并且会和前台应用争抢CPU资源，这就可能会出现前台进程得不到足够的CPU资源而出现响应卡顿。</li><li>低内存时查杀进程，有些进程被kill后会立刻restart，我们之前项目上遇到过低内存时，persistent服务进程被kill立马restart，陷入了一种”死循环”，导致整机严重卡顿以及发烫。<br>所以，如果分析ANR问题遇到这种kswapd占据很高(通常认为排到top3内)，基本可以认为该问题是由于系统环境因素导致。<br>另外这个时候，如果搜索”lowmemorykiller”关键词，可以看到问题时间区域会有较多的查杀进程行为，我们通常看”lowmemorykiller”这一行杀的进程adj值，adj值越低，说明当前系统内存越吃紧。</li></ol><p>小结：如果出现了整机高负载或者低内存的情况，ANR的进程可能只是充当了受害者的角色。</p><p><strong>Step2: 分析堆栈</strong><br>如果前面已经排除了系统环境影响因素的话，那么接下来就要分析具体的callstack了<br>搜索”am_anr”关键字<br><img src="http://blog.lihaizhou.top/ANR/ANR_9.png" alt=""><br>时间点: <code>01-25 14:40:44</code>，进程号是17728<br>根据时间戳找到anr文件下对应的trace文件<br><img src="http://blog.lihaizhou.top/ANR/ANR_10.png" alt=""><br>文件头部看下进程号再次确认下<br><img src="http://blog.lihaizhou.top/ANR/ANR_11.png" alt=""><br>搜索关键字”sysTid=17728”, 这里的17728就是上面”am_anr”中包含的进程号也是主线程号<br><img src="http://blog.lihaizhou.top/ANR/ANR_12.png" alt=""></p><ol><li>线程运行状态</li><li>nice值代表该线程优先级，nice的取值范围为-20到19，通常来说nice的值越大，进程的优先级就越低，获得CPU调用的机会越少，nice值越小，进程的优先级则越高，获得CPU调用的机会越多。</li><li>utm：该线程在用户态所执行的时间(单位是jiffies）<br>stm：该线程在内核态所执行的时间<br>该线程的cpu耗时是两者相加(utm+stm)，utm,stm 单位换算成时间单位为 1 比 10ms</li><li>core：跑在哪个核上，core=7表示打印这段日志时该线程跑在大核CPU7上</li><li>函数调用堆栈</li></ol><h4 id="典型案例"><a href="#典型案例" class="headerlink" title="典型案例"></a>典型案例</h4><h5 id="主线程耗时操作"><a href="#主线程耗时操作" class="headerlink" title="主线程耗时操作"></a>主线程耗时操作</h5><p>这种情况是最为常见一种类型<br>比如下面这个案例，是com.tencent.qqlive的ANR，callstack如下<br><img src="http://blog.lihaizhou.top/ANR/ANR_13.png" alt=""><br>通常来说，如果打印的堆栈是ANR进程的堆栈，业务验证证实这段代码确实存在耗时的可能，那么根据callstack位置找到代码修改即可。</p><h5 id="主线程-Blocked-waiting-Sleeping"><a href="#主线程-Blocked-waiting-Sleeping" class="headerlink" title="主线程 Blocked/waiting/Sleeping"></a>主线程 Blocked/waiting/Sleeping</h5><p>主线程当前的状态是(1)Blocked, 原因是它在等锁(2) 0x06573567，而0x06573567被(3)线程13所持有<br><img src="http://blog.lihaizhou.top/ANR/ANR_14.png" alt=""><br>看下tid=13线程 CallStack，在该份trace文件中搜索关键字”0x06573567”找到线程13的堆栈。<br><img src="http://blog.lihaizhou.top/ANR/ANR_15.png" alt=""><br>除了主线程陷入Blocked这种比较常见的情况之外，通常是由于真正持有锁的线程在做繁琐的事务或是发生了死锁，除此之外还有一些少见的情况</p><ol><li>主线程处于waiting状态，说明其正在等待其他线程来notify它，堆栈同样是等锁，分析思路一样。</li><li>主线程处于Sleeping状态，说明当前线程主动调用sleep，其堆栈通常是sleeping on &lt;锁ID&gt;。</li></ol><h5 id="Binder-block"><a href="#Binder-block" class="headerlink" title="Binder block"></a>Binder block</h5><p>这种情况比较常见，比如A进程在主线程中向B进程发起binder请求，B进程因为一些原因比如正在处理耗时消息或网络异常等原因，无法及时响应A进程的binder的请求，造成A进程一直阻塞等待binder的返回结果最终ANR。<br>比如下面这个案例<br><img src="http://blog.lihaizhou.top/ANR/ANR_16.png" alt=""><br>keyguard模块做native层的binder通信，阻塞等待对端结果返回。<br>涉及一个问题：我们该如何快速找到binder对端信息？<br>对于mtk平台而言，anr文件下的binderinfo会打印出binder交互的信息<br>搜索关键字”outgoing transaction” 表示的是当前线程扮演的是Client角色，向其它进程发起binder。<br><img src="http://blog.lihaizhou.top/ANR/ANR_17.png" alt=""><br>28444这个进程中28536这个线程向22767这个进程发起了binder请求。<br>需要注意一点的是：22767:0这里0代表的是server端当前没有可用binder线程。<br>如果binderinfo文件中没有找到的话，也可以在kernel日志中搜索”binder : release”关键词，这行日志通常是binder所在进程结束时会吐出来。</p><h5 id="Binder-池耗尽"><a href="#Binder-池耗尽" class="headerlink" title="Binder 池耗尽"></a>Binder 池耗尽</h5><p>应用的Binder池最多支持16个binder线程，SystemServer比较特殊支持最多32个binder线程。<br>那么什么样的场景下可能会出现Binder 池耗尽的情况呢？<br>比如进程A发送太多重复binder请求给进程B，那么就会导致短时间内接收端进程B的binder线程池被占满，从而处理不了A进程发过来的binder请求。<br>比如下面这段日志<br><img src="http://blog.lihaizhou.top/ANR/ANR_18.png" alt=""><br>和上面binder block同样的分析策略，找到对端是谁以及对端的callstack即可，不再详细展开。</p><h5 id="陷阱堆栈"><a href="#陷阱堆栈" class="headerlink" title="陷阱堆栈"></a>陷阱堆栈</h5><p>何为陷阱堆栈，即出现的callstack并非真正的凶手，比如我们最为常见的CallStack落在nativePollOnce上，这种情况说明当前主线程的消息队列是空闲的，在等待处理下一个msg，打印日志时真正的block消息已经走完了。<br>以下面这个计算器的anr案例<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">01</span><span class="number">-29</span> <span class="number">06</span>:<span class="number">24</span>:<span class="number">46.618452</span>  <span class="number">1210</span>  <span class="number">5962</span> I AnrManager: ANR in com.journeyui.calculator (com.journeyui.calculator/.Calculator), time=<span class="number">260439862</span></span><br><span class="line"><span class="number">01</span><span class="number">-29</span> <span class="number">06</span>:<span class="number">24</span>:<span class="number">46.618452</span>  <span class="number">1210</span>  <span class="number">5962</span> I AnrManager: Reason: Input dispatching timed out (ActivityRecord&#123;<span class="number">51e27</span>ca u0 com.journeyui.calculator/.Calculator t1837&#125; does <span class="keyword">not</span> have a focused window)</span><br><span class="line"><span class="number">01</span><span class="number">-29</span> <span class="number">06</span>:<span class="number">24</span>:<span class="number">46.618452</span>  <span class="number">1210</span>  <span class="number">5962</span> I AnrManager: Load: <span class="number">31.7</span> / <span class="number">33.43</span> / <span class="number">30.98</span></span><br><span class="line"><span class="number">01</span><span class="number">-29</span> <span class="number">06</span>:<span class="number">24</span>:<span class="number">46.618452</span>  <span class="number">1210</span>  <span class="number">5962</span> I AnrManager: Android time :[<span class="number">2022</span><span class="number">-01</span><span class="number">-29</span> <span class="number">06</span>:<span class="number">24</span>:<span class="number">46.60</span>] [<span class="number">260451.594</span>]</span><br><span class="line"><span class="number">01</span><span class="number">-29</span> <span class="number">06</span>:<span class="number">24</span>:<span class="number">46.618452</span>  <span class="number">1210</span>  <span class="number">5962</span> I AnrManager: CPU usage from <span class="number">167270</span>ms to <span class="number">0</span>ms ago (<span class="number">2022</span><span class="number">-01</span><span class="number">-29</span> <span class="number">06</span>:<span class="number">21</span>:<span class="number">47.589</span> to <span class="number">2022</span><span class="number">-01</span><span class="number">-29</span> <span class="number">06</span>:<span class="number">24</span>:<span class="number">34.860</span>) with <span class="number">99</span>% awake:</span><br><span class="line"><span class="number">01</span><span class="number">-29</span> <span class="number">06</span>:<span class="number">24</span>:<span class="number">46.618452</span>  <span class="number">1210</span>  <span class="number">5962</span> I AnrManager:   <span class="number">226</span>% <span class="number">1210</span>/system_server: <span class="number">173</span>% user + <span class="number">52</span>% kernel / faults: <span class="number">1026822</span> minor <span class="number">8</span> major</span><br><span class="line"><span class="number">01</span><span class="number">-29</span> <span class="number">06</span>:<span class="number">24</span>:<span class="number">46.618452</span>  <span class="number">1210</span>  <span class="number">5962</span> I AnrManager:   <span class="number">125</span>% <span class="number">459</span>/logd: <span class="number">16</span>% user + <span class="number">109</span>% kernel / faults: <span class="number">408</span> minor</span><br><span class="line"><span class="number">01</span><span class="number">-29</span> <span class="number">06</span>:<span class="number">24</span>:<span class="number">46.618452</span>  <span class="number">1210</span>  <span class="number">5962</span> I AnrManager:   <span class="number">29</span>% <span class="number">21567</span>/com.journeyui.globalsearch: <span class="number">18</span>% user + <span class="number">10</span>% kernel / faults: <span class="number">45071</span> minor <span class="number">25</span> major</span><br><span class="line"><span class="number">01</span><span class="number">-29</span> <span class="number">06</span>:<span class="number">24</span>:<span class="number">46.618452</span>  <span class="number">1210</span>  <span class="number">5962</span> I AnrManager:   <span class="number">26</span>% <span class="number">639</span>/surfaceflinger: <span class="number">18</span>% user + <span class="number">8.6</span>% kernel / faults: <span class="number">4704</span> minor</span><br><span class="line"><span class="number">01</span><span class="number">-29</span> <span class="number">06</span>:<span class="number">24</span>:<span class="number">46.618452</span>  <span class="number">1210</span>  <span class="number">5962</span> I AnrManager:   <span class="number">26</span>% <span class="number">20889</span>/com.yulong.android.gamecenter: <span class="number">16</span>% user + <span class="number">9.3</span>% kernel / faults: <span class="number">21143</span> minor</span><br><span class="line"><span class="number">01</span><span class="number">-29</span> <span class="number">06</span>:<span class="number">24</span>:<span class="number">46.618452</span>  <span class="number">1210</span>  <span class="number">5962</span> I AnrManager:   <span class="number">24</span>% <span class="number">29706</span>/com.sohu.inputmethod.sogou:home: <span class="number">16</span>% user + <span class="number">8.6</span>% kernel / faults: <span class="number">21832</span> minor</span><br><span class="line"><span class="number">01</span><span class="number">-29</span> <span class="number">06</span>:<span class="number">24</span>:<span class="number">46.618452</span>  <span class="number">1210</span>  <span class="number">5962</span> I AnrManager:   <span class="number">24</span>% <span class="number">545</span>/com.android.messaging: <span class="number">15</span>% user + <span class="number">9</span>% kernel / faults: <span class="number">26023</span> minor <span class="number">2</span> major</span><br><span class="line"><span class="comment">//...</span></span><br><span class="line"><span class="number">01</span><span class="number">-29</span> <span class="number">06</span>:<span class="number">24</span>:<span class="number">46.618452</span>  <span class="number">1210</span>  <span class="number">5962</span> I AnrManager:   <span class="number">1.7</span>% <span class="number">3589</span>/com.journeyui.calculator: <span class="number">1</span>% user + <span class="number">0.6</span>% kernel / faults: <span class="number">3365</span> minor <span class="number">5</span> major</span><br><span class="line"><span class="comment">//...</span></span><br><span class="line"><span class="number">01</span><span class="number">-29</span> <span class="number">06</span>:<span class="number">24</span>:<span class="number">46.618480</span>  <span class="number">1210</span>  <span class="number">5962</span> I AnrManager: <span class="number">75</span>% TOTAL: <span class="number">42</span>% user + <span class="number">33</span>% kernel + <span class="number">0</span>% iowait + <span class="number">0</span>% softirq</span><br></pre></td></tr></table></figure></p><p>整机负载很高，但是前台进程com.journeyui.calculator占用只有1.7%，top5中没有kswapd的身影，排除低内存的影响。<br>PS: SystemServer占据如果稍高可能是正常的，Dump Trace时需要获取系统整体及各进程 CPU 使用情况，短时间内会造成SystemServer升高。<br>接着event日志中搜索”am_anr”关键字<br><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">01-29 06:24:34.907471  1210  5962 I am_anr  : [0,3589,com.journeyui.calculator,684244549,Input dispatching timed out (ActivityRecord&#123;51e27ca u0 com.journeyui.calculator/.Calculator t1837&#125; does not have a focused window)]</span><br></pre></td></tr></table></figure></p><p>找到对应的anr文件<br><img src="http://blog.lihaizhou.top/ANR/ANR_19.png" alt=""><br>callstack落在了nativePollOnce上<br>我们前面说过落在nativePollOnce上，说明应用已经idle了<br>那么什么情况下会出现落在nativePollOnce上呢？</p><ol><li>应用主线程历史调度中存在严重耗时的消息</li><li>应用主线程历史调度中存在多个耗时的消息</li><li>应用主线程历史调度中存在大量消息比如高频发送消息</li><li>应用主线程本身并不耗时，而是受到系统环境因素影响(IO/低内存/高负载等)<br>那么历史调度中的耗时消息我们应该如何得知？<br>谷歌本身在系统多处都加有耗时消息打印，比如我们常见的日志Looper  : Slow dispatch等。</li></ol><p>通常手机厂商也会做日志增强，常见的思路如下:</p><ol><li>监控主线程的binder transaction的耗时情况， 超过阈值时输出相应的目标调用信息。</li><li>当某个线程等待lock的时间blocked超过阈值，则输出当前的持锁状态。</li><li>主线程的生命周期回调方法执行时间超过阈值，则输出相应信息。</li><li>当system_server等进程的线程池使用完, 无空闲线程时, 则binder通信都处于饥饿状态, 则饥饿状态超过一定阈值则输出信息。</li><li>当任意进程的非oneway的Binder调用耗时超过一定阈值的时候，输出Slow Binder信息。</li><li>当SystemServer进程响应其它任意Java进程的非oneway的Binder调用，耗时超过一定阈值的时候，输出Slow Binder信息</li></ol><p>一些头部应用厂商如字节跳动有自研的Raster消息监控平台，出现这种落在<code>nativePollOnce</code>上查找历史耗时消息即可。<br>除了落在<code>nativePollOnce</code>的情况，还有一种情况则更加隐蔽，也更容易将我们带偏分析的方向。<br>那就是callstack打印出来确实是应用自身的堆栈，但是根据callstack找到对应代码后发现根本不可能会出现耗时，说明真正的”凶手”藏身在历史消息中。</p><h5 id="应用内存问题"><a href="#应用内存问题" class="headerlink" title="应用内存问题"></a>应用内存问题</h5><p>我们平时也会经常遇到这样的情况：应用自身内存使用不当导致的ANR<br>比如下面的美团ANR案例<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">01</span><span class="number">-08</span> <span class="number">14</span>:<span class="number">53</span>:<span class="number">20.130</span>  <span class="number">1074</span> <span class="number">32039</span> I AnrManager: ANR in com.sankuai.meituan (com.sankuai.meituan/com.meituan.android.pt.homepage.activity.MainActivity), time=<span class="number">48329538</span></span><br><span class="line"><span class="number">01</span><span class="number">-08</span> <span class="number">14</span>:<span class="number">53</span>:<span class="number">20.130</span>  <span class="number">1074</span> <span class="number">32039</span> I AnrManager: Reason: Input dispatching timed out (c961943 com.sankuai.meituan/com.meituan.android.pt.homepage.activity.MainActivity (server) is <span class="keyword">not</span> responding. Waited <span class="number">8006</span>ms <span class="keyword">for</span> MotionEvent)</span><br><span class="line"><span class="number">01</span><span class="number">-08</span> <span class="number">14</span>:<span class="number">53</span>:<span class="number">20.130</span>  <span class="number">1074</span> <span class="number">32039</span> I AnrManager: Load: <span class="number">27.74</span> / <span class="number">27.04</span> / <span class="number">27.19</span></span><br><span class="line"><span class="number">01</span><span class="number">-08</span> <span class="number">14</span>:<span class="number">53</span>:<span class="number">20.130</span>  <span class="number">1074</span> <span class="number">32039</span> I AnrManager: Android time :[<span class="number">2022</span><span class="number">-01</span><span class="number">-08</span> <span class="number">14</span>:<span class="number">53</span>:<span class="number">20.10</span>] [<span class="number">48351.410</span>]</span><br><span class="line"><span class="number">01</span><span class="number">-08</span> <span class="number">14</span>:<span class="number">53</span>:<span class="number">20.130</span>  <span class="number">1074</span> <span class="number">32039</span> I AnrManager: CPU usage from <span class="number">9706</span>ms to <span class="number">0</span>ms ago (<span class="number">2022</span><span class="number">-01</span><span class="number">-08</span> <span class="number">14</span>:<span class="number">52</span>:<span class="number">48.524</span> to <span class="number">2022</span><span class="number">-01</span><span class="number">-08</span> <span class="number">14</span>:<span class="number">52</span>:<span class="number">58.230</span>):</span><br><span class="line"><span class="number">01</span><span class="number">-08</span> <span class="number">14</span>:<span class="number">53</span>:<span class="number">20.130</span>  <span class="number">1074</span> <span class="number">32039</span> I AnrManager:   <span class="number">100</span>% <span class="number">32613</span>/com.sankuai.meituan: <span class="number">99</span>% user + <span class="number">1.5</span>% kernel / faults: <span class="number">72075</span> minor</span><br><span class="line"><span class="number">01</span><span class="number">-08</span> <span class="number">14</span>:<span class="number">53</span>:<span class="number">20.130</span>  <span class="number">1074</span> <span class="number">32039</span> I AnrManager:   <span class="number">24</span>% <span class="number">16662</span>/com.ss.android.ugc.aweme:miniappX: <span class="number">17</span>% user + <span class="number">7.3</span>% kernel / faults: <span class="number">1762</span> minor</span><br><span class="line"><span class="number">01</span><span class="number">-08</span> <span class="number">14</span>:<span class="number">53</span>:<span class="number">20.130</span>  <span class="number">1074</span> <span class="number">32039</span> I AnrManager:   <span class="number">17</span>% <span class="number">4548</span>/com.ss.android.ugc.aweme: <span class="number">11</span>% user + <span class="number">5.9</span>% kernel / faults: <span class="number">2500</span> minor</span><br><span class="line"><span class="number">01</span><span class="number">-08</span> <span class="number">14</span>:<span class="number">53</span>:<span class="number">20.130</span>  <span class="number">1074</span> <span class="number">32039</span> I AnrManager:   <span class="number">11</span>% <span class="number">1074</span>/system_server: <span class="number">8</span>% user + <span class="number">3.6</span>% kernel / faults: <span class="number">6412</span> minor <span class="number">1</span> major</span><br><span class="line"><span class="comment">//...</span></span><br><span class="line"><span class="number">01</span><span class="number">-08</span> <span class="number">14</span>:<span class="number">53</span>:<span class="number">20.130</span>  <span class="number">1074</span> <span class="number">32039</span> I AnrManager: <span class="number">30</span>% TOTAL: <span class="number">21</span>% user + <span class="number">8.1</span>% kernel + <span class="number">0.1</span>% iowait + <span class="number">1</span>% softirq</span><br></pre></td></tr></table></figure></p><p>整机负载不高，且kswapd占比很低，基本可以排除系统环境影响<br><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">01-08 14:52:58.243  1074 32039 I am_anr  : [0,32613,com.sankuai.meituan,949501508,Input dispatching timed out (c961943 com.sankuai.meituan/com.meituan.android.pt.homepage.activity.MainActivity (server) is not responding. Waited 8006ms for MotionEvent)]</span><br></pre></td></tr></table></figure></p><p>时间点14:52:58，进程号32613<br>因为这份日志缺少anr文件，所以我们直接看系统日志<br>在案发时间点附近，我们发现出现有大量的GC片段<br><img src="http://blog.lihaizhou.top/ANR/ANR_20.png" alt=""><br>Clamp target GC heap from这行日志是在SetIdealFootprint即调整目标堆上限值时会打印，这块不太熟悉的话可以参见我们之前发表过的一篇文章<android s="" art="" gc基础篇="">。<br>日志说明当前应用堆使用已超出上限512M，为了分配新的对象，一直持续的阻塞GC再尝试分配。<br>通过日志我们可以发现，尽管应用持续的阻塞GC，但是内存依旧没有降下来。<br>对于应用内存使用问题，通常有如下几种情况</android></p><ol><li>频繁的生成临时对象导致堆内存增长迅速，达到下次堆GC触发阈值后便会触发Bg GC，进而导致回收线程跑大核和前台应用争抢CPU。<br>另外GC回收阶段会存在一次锁堆，应用的主线程会被pause，这种情况下势必会造成应用使用卡顿甚至ANR。</li><li>比较常见的一种情况是应用发生了较为严重的内存泄漏，导致GC一直无法回收足够的内存。</li><li>申请大内存触发阻塞GC以申请到足够的内存，这种情况一般会引起黑屏卡顿。</li><li>还有一种情况，我们知道系统低内存时会触发OnTrimMemory回调，如果应用在OnTrimMemory中并且是在主线程中直接调用显式GC接口即System.gc()，也容易引起应用卡顿。</li></ol><p>上面这些情况虽不一定会导致ANR，但是应用操作卡顿可能在所难免。</p><h4 id="写在最后"><a href="#写在最后" class="headerlink" title="写在最后"></a>写在最后</h4><p>通常ANR是卡顿的一种严重表现形式，所以遇到卡顿问题时应趁早解决，防患于未然。</p><h4 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h4><p><a href="https://www.androidperformance.com/" target="_blank" rel="noopener">https://www.androidperformance.com/</a><br><a href="https://blog.csdn.net/feelabclihu/article/details/120574383" target="_blank" rel="noopener">https://blog.csdn.net/feelabclihu/article/details/120574383</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;最近看了下ANR代码，结合之前项目上的一些ANR案例，打算对ANR的原理以及常见案例做下小结，涉及的代码均基于&lt;code&gt;Android S&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;画了一张图，列举了可能导致ANR的一些影响因素&lt;br&gt;&lt;img src=&quot;http://blog.lih
      
    
    </summary>
    
      <category term="ANR" scheme="http://lihaizhou.top/categories/ANR/"/>
    
    
  </entry>
  
  <entry>
    <title>优化实践: 高刷下列表滑动出现卡顿掉帧</title>
    <link href="http://lihaizhou.top/2021/11/27/%E4%BC%98%E5%8C%96%E5%AE%9E%E8%B7%B5-%E9%AB%98%E5%88%B7%E4%B8%8B%E5%88%97%E8%A1%A8%E6%BB%91%E5%8A%A8%E5%87%BA%E7%8E%B0%E5%8D%A1%E9%A1%BF%E6%8E%89%E5%B8%A7/"/>
    <id>http://lihaizhou.top/2021/11/27/优化实践-高刷下列表滑动出现卡顿掉帧/</id>
    <published>2021-11-27T04:08:46.000Z</published>
    <updated>2022-03-12T14:31:55.044Z</updated>
    
    <content type="html"><![CDATA[<h4 id="问题背景"><a href="#问题背景" class="headerlink" title="问题背景"></a>问题背景</h4><p>近期我们的测试同事，上报了一些操作掉帧的问题，对比机选取的是同配置的荣耀x20。<br>以微信为例，如下是测试提供的测试报告<br><img src="http://blog.lihaizhou.top/%E9%AB%98%E5%88%B7%E4%B8%8B%E6%BB%91%E5%8A%A8%E5%8D%A1%E9%A1%BF/gaoshua_kadun1.png" alt="图片"><br>这份perfdog报告的操作步骤对应的是上下滑动微信列表，数据上看，测试机表现似乎比对比机逊色一些。<br>打算实际对比体验下，在两台机器上安装同版本的微信，清理后台任务，并确保两台机器上的微信均已完成dex2oat且dex2oat模式一样。<br>实际对比测试下来的主观感受是: 在我们的测试机上，滑动松开手指后会概率性出现顿挫感，荣耀机器上滑动的fling阶段比较平滑，虽然偶尔也会有顿挫，对比体验上确实优于我们的测试机</p><p>基于数据报告以及主观测试感受，说明我们的机器在部分场景操作上可能确实存在性能问题，于是开始着手调查这个问题背后的原因。<br>PS: 本文深受<a href="https://www.androidperformance.com/" target="_blank" rel="noopener">androidperformance系列文章</a>启发</p><h4 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h4><p>我们的测试机和对比机均支持120hz高刷，实测在滑动场景下，两者屏幕的刷新率均为120hz，意味着都是8.3ms刷新一次屏幕，滑动松开手指后的fling阶段，两者软件上均为120fps。<br>需要注意一点的是: </p><blockquote><p>120hz指的是屏幕这个硬件刷新画面的频率，是一个硬件的概念。而软件的120fps则是一个软件的概念，表示1秒内生产120帧。<br>一般而言，屏幕刷新率和软件的fps是对应的，比如60hz对应60fps，120hz对应120fps，只有这样用户体验才是最佳的，两者是通过Vsync 机制做到同步，如果屏的刷新率和软件不匹配的话，效果上势必会打折扣，还可能造成无端的功耗开销。<br>比如屏幕刷新率是 60 hz，软件是 120 fps，那么软件每秒绘制的120次有一半是没有显示就被抛弃了的。</p></blockquote><p>以我们这个案例来说，滑动微信列表松开手指后，此时屏的刷新率是120hz，系统为了适配这个120hz，会将Vsync的周期设置为8.3ms，意味着每隔 8.3 ms，Vsync-app 信号就会到来唤醒 Choreographer 来做 App 的绘制渲染操作。<br>App绘制渲染完成后，会将buffer给SurfaceFlinger对应的App所在的bufferQueue队列中，SurfaceFlinger同样需要等Vsync-sf信号，等到信号后SurfaceFlinger开始合成工作并最终送给屏显示，这个过程中如果有一个步骤耗时长了都有可能导致最终一帧花费时间超出8.3ms。</p><h4 id="原因分析"><a href="#原因分析" class="headerlink" title="原因分析"></a>原因分析</h4><p>有了这些基础知识铺垫后，下面从系统全局来分析<br>先看下手指松开fling阶段的应用绘制片段<br><img src="http://blog.lihaizhou.top/%E9%AB%98%E5%88%B7%E4%B8%8B%E6%BB%91%E5%8A%A8%E5%8D%A1%E9%A1%BF/gaoshua_kadun2.png" alt="图片"><br>可以看到，在fling阶段，我们的测试机有很多黄帧，对比机上只有少数的几帧是黄色的<br>这里先解释下黄色帧的含义</p><blockquote><p>黄帧表示这一帧的耗时超过了1个 Vsync 周期，但是小于 2 个 Vsync 周期。<br>黄帧的出现表示这一帧可能存在性能问题，可能掉帧了，注意这里用了可能这个词，因为TripleBuffer机制，即便主线程这一帧超过一个Vsync周期，由于多buffer缓冲，这一帧不一定会掉帧，我们后面会单独成文介绍这块。<br>绿帧表示这一帧在规定时间内及时完成了，耗时不超过1个 Vsync 周期</p></blockquote><p>再看下Sf区域的情况<br><img src="http://blog.lihaizhou.top/%E9%AB%98%E5%88%B7%E4%B8%8B%E6%BB%91%E5%8A%A8%E5%8D%A1%E9%A1%BF/gaoshua_kadun3.png" alt="图片"><br>两者Vsync间隔都是8.3ms，对比机的Sf主线程在大部分时候，都能在Vsync-sf到来后的8.3ms内及时完成，画面上看有条不紊。</p><p>再看下我们的测试机情况，很容易发现由于单次处理比较耗时，出现了堆积延后的情况，这也导致了在屏幕上看到的画面不是很流畅的缘故。<br>通过对比应用fling阶段主线程区域，绘制区域，Sf区域，很快便发现了我们的测试机输在了CPU频率上<br><img src="http://blog.lihaizhou.top/%E9%AB%98%E5%88%B7%E4%B8%8B%E6%BB%91%E5%8A%A8%E5%8D%A1%E9%A1%BF/gaoshua_kadun4.png" alt="图片"><br>从上图可以看出，我们的测试机在应用主线程处理过程中，很多时候CPU频率会掉的很低。<br>比如图中圈出的红色位置，我们测试机在这一帧的应用主线程处理上耗时12ms，虽然是落在大核CPU6上，但是频率只有650Mkhz。<br>再看下竞品机的应用主线程处理阶段CPU情况，在手指触摸后，其频率迅速提升，并且在手指松开后的fling阶段，对比机仍然能够维持一两秒的CPU高频。</p><p>到这里，我们明白了差距在哪里，我们的测试机在手指松开后的fling阶段CPU落下来，而对比机能够在fling阶段维持高频。</p><h4 id="修改方案"><a href="#修改方案" class="headerlink" title="修改方案"></a>修改方案</h4><p>原因在于MTk的powerHal配置有误导致触摸提频未起效，将大核和小核的CPU频率分别限制为不低于1.75Ghz和2.2Ghz(天花板分别为2G和2.4G)<br>并且boost持续时间限定为2s<br><img src="http://blog.lihaizhou.top/%E9%AB%98%E5%88%B7%E4%B8%8B%E6%BB%91%E5%8A%A8%E5%8D%A1%E9%A1%BF/gaoshua_kadun5.png" alt="图片"><br>再次测试微信滑动列表的场景，可以看到修改后，处理堆积延后的现象消失</p><p>再看下应用区域的fling阶段<br><img src="http://blog.lihaizhou.top/%E9%AB%98%E5%88%B7%E4%B8%8B%E6%BB%91%E5%8A%A8%E5%8D%A1%E9%A1%BF/gaoshua_kadun6.png" alt="图片"><br>从图中可以看到修改后，fling阶段黄色帧大幅减少，基本达到了竞品机的表现</p><h4 id="写在最后"><a href="#写在最后" class="headerlink" title="写在最后"></a>写在最后</h4><p>120fps最大的挑战在于一帧的完成必须在8.3ms内完成，细化一点就是App 和 SurfaceFlinger 及其相关的进程端 (加上 crtc 和 hw service)花费的时间总和必须在 8.3ms 之内, 这就需要App侧和Sf侧都不能出现较长耗时，才可以保证不掉帧.<br>高刷下的掉帧原因可能有很多，就笔者遇到的场景有低内存下kswapd跑大核、同步GC、温升限频、IO、Vsync不均、GPU&amp;CPU性能不足等场景，当然最常见的场景还是应用自身绘制超时导致。<br>这个案例根因在于高刷场景下没有提供足够的CPU性能。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;问题背景&quot;&gt;&lt;a href=&quot;#问题背景&quot; class=&quot;headerlink&quot; title=&quot;问题背景&quot;&gt;&lt;/a&gt;问题背景&lt;/h4&gt;&lt;p&gt;近期我们的测试同事，上报了一些操作掉帧的问题，对比机选取的是同配置的荣耀x20。&lt;br&gt;以微信为例，如下是测试提供的测试报告
      
    
    </summary>
    
      <category term="性能" scheme="http://lihaizhou.top/categories/%E6%80%A7%E8%83%BD/"/>
    
    
  </entry>
  
  <entry>
    <title>优化实践:从系统层面优化应用启动速度</title>
    <link href="http://lihaizhou.top/2021/11/19/%E4%BC%98%E5%8C%96%E5%AE%9E%E8%B7%B5-%E4%BB%8E%E7%B3%BB%E7%BB%9F%E5%B1%82%E9%9D%A2%E4%BC%98%E5%8C%96%E5%BA%94%E7%94%A8%E5%90%AF%E5%8A%A8%E9%80%9F%E5%BA%A6/"/>
    <id>http://lihaizhou.top/2021/11/19/优化实践-从系统层面优化应用启动速度/</id>
    <published>2021-11-19T02:00:24.000Z</published>
    <updated>2022-03-12T14:31:44.408Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>应用的启动表现特别是冷启动的速度，是用户对App的第一印象。很多时候也会被评测机构用来测试一个手机性能的依据，所以对启动速度的优化一直以来是App和手机厂商发力的重点</p></blockquote><h4 id="故事背景"><a href="#故事背景" class="headerlink" title="故事背景"></a>故事背景</h4><p>最近，测试提了很多应用启动速度落后于竞品荣耀x20的问题单<br>以其中的支付宝为例, 如下是测试提供的支付宝冷启数据<br>(通过高速相机，以手指松开为起点，以首页内容加载出为结束点)<br><img style="margin: left;" src="http://blog.lihaizhou.top/startProcess/startProcess1.png"></p><p>从高速相机均值数据上，我们的机器上冷启支付宝比竞品机慢了29%，另外通过实测同时打开，直观感受上发现绝大部分时候确实慢于竞品机。<br>顺便说一句:<br><code>测试冷启速度最佳方式是通过高速相机，这种方式最贴近用户实际感受，其次便是通过Systrace，但是Systrace的结束帧的确定是个技术活(没有源码情况下)。</code></p><h4 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h4><p>本文将以支付宝为例进行讨论，对于支付宝这种体积的App，在启动过程中会起来上百个业务操作，但是其冷启耗时却能够控制在几百毫秒，我觉得已经是非常之优秀了。<br>其实这种头部App会有专门的性能团队进行优化，相信支付宝已经做了很多的优化工作。<br>PS: 本文深受<a href="https://www.androidperformance.com/" target="_blank" rel="noopener">androidperformance系列文章</a>启发</p><p>本文将致力于回答如下两个问题</p><ol><li>同样的App版本，同样的配置，为何我们的机器启动速度会比竞品机慢？</li><li>如何优化提升我们机器上的应用启动速度？</li></ol><h4 id="大纲"><a href="#大纲" class="headerlink" title="大纲"></a>大纲</h4><ol><li>App和系统角度分别看启动速度优化</li><li>CPU提频</li><li>Dex2oat策略优化</li><li>抑制GC次数</li><li>IO优化</li><li>优化后实测数据</li><li>写在最后</li><li>参考文献</li></ol><h4 id="App-amp-系统角度看启动速度优化"><a href="#App-amp-系统角度看启动速度优化" class="headerlink" title="App&amp;系统角度看启动速度优化"></a>App&amp;系统角度看启动速度优化</h4><h5 id="应用角度看启动优化"><a href="#应用角度看启动优化" class="headerlink" title="应用角度看启动优化"></a>应用角度看启动优化</h5><p>对于应用启动优化手段比较常规，主要有如下几种:</p><ol><li>启动页主题之类的替换，达到视觉上的速度加快，并非真的快了。</li><li>初始化的生命周期内一些繁重业务或者库加载尽可能的延迟加载，异步加载，用的时候再加载。</li><li>布局上的优化，尽可能降低布局的复杂度，在需要用的时再加载</li><li>主动dex2oat，需要注意的是在Android10+上谷歌限制了应用进程主动dex2oat，但是其实还是有办法触发，只是实现上会稍微麻烦一点，这里不展开讨论。</li></ol><p>这些常规的优化步骤是最基础的，但是实际优化起来并不一定容易，特别是一些庞大的团队合作App。<br>之前在小米做过启动优化的工作，由于项目业务代码实在太繁杂，初始化代码里充斥了各种回调各种插件，还有很多锁等待，文件读写，反射hook，网络操作等耗时的操作，梳理优化的过程需要有足够的耐心，需要不少的沟通成本。<br>对于应用开发人员而言，分析应用自身的耗时分析手段比较常规，最常见的手段就是Systrace，traceview，simpleperf等，实在不行代码里进行插桩埋点，因为有源代码，一切都好办。<br>而对于一些头部App比如抖音支付宝等，这类App往往有专门的性能团队，可能会涉及到GC优化，dex2oat优化，文件重排列降低IO次数等门槛较高的方向。</p><h5 id="系统全局角度看启动优化"><a href="#系统全局角度看启动优化" class="headerlink" title="系统全局角度看启动优化"></a>系统全局角度看启动优化</h5><p>对于系统工程师而言，需要关注从驱动上报input事件到首页第一帧画面合成的整个过程。<br>主要会涉及input事件传递，一帧的渲染，CPU&amp;GPU的调度频率，Surfaceflinger的合成等等。</p><h4 id="CPU提频"><a href="#CPU提频" class="headerlink" title="CPU提频"></a>CPU提频</h4><p>下图是启动过程中主线程的CPU频率<br><img src="http://blog.lihaizhou.top/startProcess/startProcess2.png" alt=""><br>mtk默认已有实现在进程创建后boost持续10s，从上面Systrace可以看到主线程绘制running的片段是跑在大核上且频率已是最高。<br>但是在对比竞品机Systrace时，笔者发现竞品机surfaceflinger很多时候会跑在大核上，而我们的机器没有跑在大核的时候，其单次onMessageReceived耗时很多时候只有我们的一半。<br>这里先解释下onMessageReceived的作用，主要是处理两个Message</p><ol><li>MessageQueue::INVALIDATE — 主要是执行 handleMessageTransaction&amp;handleMessageInvalidate</li><li>MessageQueue::REFRESH — 主要是执行 handleMessageRefresh 方法<br>可以简单的理解为这块的消息处理越快，合成的速度也会越快，画面能够提早显示出来，降低掉帧的概率。<br>这个时候，你可能会有疑问了，竞品机是做了绑大核处理了吗？</li></ol><p>下面我们看下两者cpuset的差异<br><img src="http://blog.lihaizhou.top/startProcess/startProcess3.png" alt=""><br>可以看到竞品机器对于surfaceflinger设置的是前台进程组，我们的机器遵循的是原生System-background，这也意味着我们机器上surfaceflinger只能跑在0-5核上。<br>那么谷歌设计限制在System-background上基于什么考虑呢？猜测是因为绝大部分时候，这个设计都可以满足需求，占用大核的话可能会导致某些情况下加剧大核队列的负载。</p><h4 id="Dex2oat策略优化"><a href="#Dex2oat策略优化" class="headerlink" title="Dex2oat策略优化"></a>Dex2oat策略优化</h4><p>我们知道dex2oat在优化时，会根据需要优化一定量的method。也就是说并不是优化的method都会被翻译成oat模式。根据优化的method的量的多少，可以分为几种常见的模式：<br><code>verify、quicken、space-profile、space、speed-profile、speed、everything</code><br>字面上比较好理解， 越后面的类型编译时间越长，占用的空间也越大，运行时打开速度也越快，典型空间换时间思路的体现。</p><p>下面是我们的机器和对比机上参数的对比<br><img src="http://blog.lihaizhou.top/startProcess/startProcess4.png" alt=""><br>参数是一致的，其实这也是平台默认的配置, 这些参数中有一项是install时的选择的模式: speed-profile.<br>这里说下speed和speed-profile的区别，speed-profile是对profile中的热点函数进行编译，可以简单理解为是局部编译，而speed是全编。<br>对于dex2oat的调优，其实策略比较常规，根据不同的场景和负载，选择不同的模式。除了原生的idle模式下优化，新增了热点应用的周期性dex2oat。</p><h4 id="降低GC的频率"><a href="#降低GC的频率" class="headerlink" title="降低GC的频率"></a>降低GC的频率</h4><p>之前处理过的性能案例中，有不少是GC引起的性能问题。<br>将友商oppo的修改合入：<br>大意是在进程状态变化触发的GC转换中，如果当前堆增长(自上次GC以来)大小未达到可增长的1/4，则跳过本次GC，这样可以降低启动过程中GC的频率。<br>另外，谷歌在Android R上的一笔GC优化修改，也是降低启动过程中的GC频率<br><img src="http://blog.lihaizhou.top/startProcess/startProcess5.png" alt=""><br>大意就是应用启动过程中等进程fork结束之后，将堆上限阈值调整到最大，因为我们知道GC的触发时机主要取决于堆实际增长是否触及上限值，这样一来的话，进程启动过程中GC的概率就会降低，等两秒钟过后，再将堆上限阈值恢复回来。<br>这些修改的目的都是为了降低GC对启动速度的影响，其实GC的影响不光光在启动上，对于整机的流畅度都起到了很重要影响。</p><h4 id="IO优化"><a href="#IO优化" class="headerlink" title="IO优化"></a>IO优化</h4><p>当内核发起一个读请求时（例如进程发起 read() 请求），首先会检查请求的数据是否缓存到了 pagecache 中。如果有，那么直接从内存中读取，不需要访问磁盘，这被称为 cache命中（cache hit）。如果 cache 中没有请求的数据，即 cache 未命中（cache miss），就必须从磁盘中读取数据。<br>然后内核将读取的数据缓存到 cache 中，这样后续的读请求就可以命中 cache 了。Page 可以只缓存一个文件部分的内容，不需要把整个文件都缓存进来。对磁盘的数据进行缓存从而提高性能主要是基于两个因素：</p><ol><li>磁盘访问的速度比内存慢好几个数量级（毫秒和纳秒的差距）。</li><li>被访问过的数据，有很大概率会被再次访问。</li></ol><p>对于一些头部App比如支付宝就对Apk中的文件进行了重排优化，大意就是:<br><code>通过文件重布局，将启动阶段需要用到的文件在 APK 文件中排布在一起，尽可能的利用 pagecache 机制，用最少的磁盘 IO 次数，读取尽可能多的启动阶段需要的文件，减少 IO 开销，从而达到提升启动性能的目的</code></p><p>上面是App中的IO优化策略，从系统角度的优化策略比较复杂，需要对文件系统比较熟悉, 后续会单独成文记录IO这块的内容</p><h4 id="最终优化效果"><a href="#最终优化效果" class="headerlink" title="最终优化效果"></a>最终优化效果</h4><p>当前采用了如下三种方式对启动性能进行了优化</p><ol><li>对SurfaceFlinger占据的CPU资源调整</li><li>针对不同场景下的dex2oat进行了编译模式调优</li><li>启动过程中降低GC次数<br>影响其实最大的是dex2oat</li></ol><p>在优化后的版本上，我们再次使用高速相机对支付宝进行测试<br><img src="http://blog.lihaizhou.top/startProcess/startProcess6.png" alt=""></p><h4 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h4><p><a href="https://developer.android.google.cn/topic/performance/vitals/launch-time" target="_blank" rel="noopener">https://developer.android.google.cn/topic/performance/vitals/launch-time</a><br><a href="https://source.android.com/devices/tech/dalvik/configure" target="_blank" rel="noopener">https://source.android.com/devices/tech/dalvik/configure</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;应用的启动表现特别是冷启动的速度，是用户对App的第一印象。很多时候也会被评测机构用来测试一个手机性能的依据，所以对启动速度的优化一直以来是App和手机厂商发力的重点&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id=&quot;故事背景&quot;&gt;&lt;a href=
      
    
    </summary>
    
      <category term="性能" scheme="http://lihaizhou.top/categories/%E6%80%A7%E8%83%BD/"/>
    
    
  </entry>
  
  <entry>
    <title>Systrace角度: 拆解分析应用的启动流程</title>
    <link href="http://lihaizhou.top/2021/11/11/Systrace%E8%A7%92%E5%BA%A6-%E6%8B%86%E8%A7%A3%E5%88%86%E6%9E%90%E5%BA%94%E7%94%A8%E7%9A%84%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B/"/>
    <id>http://lihaizhou.top/2021/11/11/Systrace角度-拆解分析应用的启动流程/</id>
    <published>2021-11-11T11:40:26.000Z</published>
    <updated>2022-03-12T14:33:11.630Z</updated>
    
    <content type="html"><![CDATA[<p>上周看了一个支付宝启动速度逊色于对比机的案例，花了些时间整理了下这个过程。<br>应用启动过程中牵扯的知识点较多，基本涵盖了Android几大重要的子系统，非一篇文章能够讲清。<br>本文将以支付宝为例，介绍下从input事件触发到首页帧显示完成的整个流程，后面会单独成文介绍与竞品的差异分析。</p><p>本文深受<a href="https://www.androidperformance.com/" target="_blank" rel="noopener">androidperformance系列文章</a>启发</p><h4 id="测试步骤"><a href="#测试步骤" class="headerlink" title="测试步骤"></a>测试步骤</h4><ol><li>使用user版本，开机后连接信号好的WIFI网络，清理后台所有程序。登录支付宝账号后先启动几次，最后再forceStop</li><li>手机放置五分钟后，确保机器未发热，此时打开Systrace录制，通过高速相机拍摄，点击icon冷启，再forceStop下，再次冷启，循环做五组<br>取耗时最长一次925ms为例进行分析，时间范围起始点:   以手指落下接触到icon为起点，以支付宝首页内容完全加载出为结束点</li></ol><h4 id="Input事件"><a href="#Input事件" class="headerlink" title="Input事件"></a>Input事件</h4><p><img src="http://blog.lihaizhou.top/Systrace_process_start/processStart1.png" alt="img"></p><p>关键时间点</p><ol><li>AppLaunch_dispatchPtr:Up:  5s 617ms</li><li>Launcher中接收到input事件:   5s 620ms<br>从up事件到Launcher接收到最早的input事件耗时约3ms</li></ol><p>这个过程大致就是：</p><ol><li>inputReader从Eventhub中获取到input事件后</li><li>inputReader将事件给inputDispatcher，inputDispatcher会将事件放到 “iq” 队列中(图中没有列出)</li><li>这个时候开始寻找处理这个input事件的目标窗口了，这个案例中对应的就是Launcher，找到后放在oq队列中，等着发送给Launcher</li><li>事件发送出去后，将事件放到图中的wq队列中，等Launcher消费过这个事件后，会通知inputDisp已经消费完成，图中的wq凸起点会消失</li></ol><p>这里顺便说下，我们平时经常会遇到input类型的ANR，对应的正是wq的等待时长。<br>简单理解就是事件发给应用窗口了，这个时候开始倒计时，如果5s内(我们项目上客制化为8s)应用窗口没有告知inputDispatcher这个事件消费完成，说明应用窗口无响应了，就会触发ANR。<br>如果5s内应用窗口处理完成了并告知inputDispatcher后，inputDispatcher就会从 “wq” 队列中及时移除待处理事件避免ANR。</p><h4 id="创建进程"><a href="#创建进程" class="headerlink" title="创建进程"></a>创建进程</h4><p><img src="http://blog.lihaizhou.top/Systrace_process_start/processStart2.png" alt="img"></p><p>时间关键点: </p><ol><li><p>fork进程起点 5s 652ms，耗时6ms<br>这里顺便介绍下关于fork进程花费时间的优化，Android R上新增了一个usap的机制，大意是会预先fork一些空进程放在池中，这样可以省去应用fork的时间。<br>有些厂商会定制化这块内容，将这些预先fork出来的空进程指定包名，比如用户感知较强的微信支付宝等，这样的在支付宝冷启时，这里就不会有fork的片段，其实就是空间换时间的做法。<br>但是这种做法不太适合小内存机器，相比内存的额外开销所带来的仅仅几毫秒的提速，似乎并不是特别划算。</p></li><li><p>Launcher将自身pause 5s 665ms<br>大概过程就是检测到前台此时resume状态的Activity是Launcher界面，就会通知桌面应用的 Activity 进入 Paused 状态，有些厂商会定制化桌面icon按压的效果，我手头的小米手机上按压会有一个置灰缩小的动画。</p></li></ol><p>Launcher onpause执行完成之后，便会开始启动动画，对应的会是一连串的帧。<br><img src="http://blog.lihaizhou.top/Systrace_process_start/processStart3.png" alt="img"></p><p>前面的内容大致对应了<br>点击icon-&gt;input事件的分发-&gt; fork进程 -&gt; Launcher onpause<br>launcher启动动画的过程中，支付宝开始同步执行生命周期，如果支付宝生命周期执行结束，则启动动画也会结束并切换到应用窗口</p><h4 id="应用初始化环节"><a href="#应用初始化环节" class="headerlink" title="应用初始化环节"></a>应用初始化环节</h4><p>这块大致的过程是:<br>ZygoteInit-&gt;ActivityThreadMain-&gt;BindApplication-&gt;StartActivity-&gt;onresume-&gt;doFrame-&gt;display</p><p>对于应用开发人员而言，关注点是从BindApplication开始，这个时间点是应用开发者最早能够控制的时间点。<br>ZygoteInit-&gt;ActivityThreadMain</p><ul><li>ZygoteInit -&gt; 5s 669ms   标识支付宝进程初始化开始，创建binder线程池之类的事务</li><li>ActivityThreadMain  -&gt; 5s 670ms  创建并启动主线程的 loop 消息循环；通过 binder 调用 AMS 的 attachApplication 接口将自己 attach 注册到 AMS 中。</li></ul><h5 id="bindApplication"><a href="#bindApplication" class="headerlink" title="bindApplication"></a>bindApplication</h5><p><img src="http://blog.lihaizhou.top/Systrace_process_start/processStart4.png" alt="img"><br>关键时间点<br>bindApplication 起始点5s 676ms，耗时112ms<br>bindApplication段CPU运行情况<br><img src="http://blog.lihaizhou.top/Systrace_process_start/processStart5.png" alt="img"></p><p>bindApplication耗时拆分<br><img src="http://blog.lihaizhou.top/Systrace_process_start/processStart6.png" alt="img"></p><h5 id="activityStart"><a href="#activityStart" class="headerlink" title="activityStart"></a>activityStart</h5><p><img src="http://blog.lihaizhou.top/Systrace_process_start/processStart7.png" alt="img"></p><p>这个过程简单概述下来就是</p><ol><li>创建 Activity 的 Context；</li><li>通过反射创建 Activity 对象；</li><li>执行 Activity 的 attach 动作，其中会创建应用窗口的 PhoneWindow 对象并设置 WindowManage；</li><li>执行应用 Activity 的 onCreate 生命周期函数，并在 setContentView 中创建窗口的 DecorView 对象；</li></ol><p>activityStart时间段CPU执行情况<br><img src="http://blog.lihaizhou.top/Systrace_process_start/processStart8.png" alt="img"><br>activityStart拆分耗时<br><img src="http://blog.lihaizhou.top/Systrace_process_start/processStart9.png" alt="img"></p><h5 id="activityResume"><a href="#activityResume" class="headerlink" title="activityResume"></a>activityResume</h5><p><img src="http://blog.lihaizhou.top/Systrace_process_start/processStart10.png" alt="img"></p><p>这个阶段主要对应的操作</p><ol><li>执行应用 Activity 的 onResume 生命周期函数；</li><li>执行 WindowManager 的 addView 动作开启视图绘制逻辑；</li><li>创建 Activity 的 ViewRootImpl 对象；</li><li>执行 ViewRootImpl 的 setView 函数开启 UI 界面绘制动作；</li></ol><p><img src="http://blog.lihaizhou.top/Systrace_process_start/processStart11.png" alt="img"></p><h4 id="SplashActivity首帧"><a href="#SplashActivity首帧" class="headerlink" title="SplashActivity首帧"></a>SplashActivity首帧</h4><p>市面上有很多应用打开后会有一个启动界面，这个界面叫做SplashActivity，一般会在这个页面可以做一些App数据初始化的工作。<br>如果应用没有SplashActivity的话，那这个环节可以直接跳过直接来到应用首页帧即可。</p><p><img src="http://blog.lihaizhou.top/Systrace_process_start/processStart12.png" alt="img"><br>关键时间点: 启动页首帧 5s 893ms ,耗时37ms</p><p>首帧绘制结束时间点 5s931ms<br><img src="http://blog.lihaizhou.top/Systrace_process_start/processStart13.png" alt="img"></p><p>注意一点的是: 这里的finish draw只有在mDrawsNeededToReport为0时才会打印</p><p>mDrawsNeededToReport的含义是<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">A count of the number of calls to pendingDrawFinished we require to notify the WM drawing is complete.</span><br></pre></td></tr></table></figure></p><p>简单的理解这次的绘制序列结束后会打印，所以我们在首页帧后面找不到finish draw是因为首页会加载很多内容，对应的是会有很多帧才能完成，所以首页帧的结束点用finish draw并不适用。</p><p>还有一点值得注意，因为我们这个案例中是以支付宝为例的，支付宝是有SplashActivity的 ，所以Systrace中你所看到的launching: com.eg.android.AlipayGphone耗时不能代表整个启动过程。<br>只能粗略的代表启动到SplashActivity首帧的耗时， 但是可以在和竞品数据对比时作为一个参考指标</p><p>可以看到launching: com.eg.android.AlipayGphone共计耗费了286.6ms<br><img src="http://blog.lihaizhou.top/Systrace_process_start/processStart14.png" alt="img"></p><p>到这里 , 从dispatchPtr:Up的5s 617ms到SplashActivity首帧绘制结束时间点5s931ms，共耗时314ms</p><h4 id="首页帧"><a href="#首页帧" class="headerlink" title="首页帧"></a>首页帧</h4><p><img src="http://blog.lihaizhou.top/Systrace_process_start/processStart15.png" alt="img"></p><p>这一帧的cpu运行情况<br><img src="http://blog.lihaizhou.top/Systrace_process_start/processStart16.png" alt="img"></p><p>cpu运行情况<br><img src="http://blog.lihaizhou.top/Systrace_process_start/processStart17.png" alt="img"></p><p>渲染结束后将buffer queue到SF的队列中<br><img src="http://blog.lihaizhou.top/Systrace_process_start/processStart18.png" alt="img"></p><h4 id="冷启动结束帧"><a href="#冷启动结束帧" class="headerlink" title="冷启动结束帧"></a>冷启动结束帧</h4><p>对于有源码的应用，定义结束帧会比较简单，加载哪个view或layout能够大致代表界面内容显示完全作为owner你是清楚的。<br>但是对于三方应用比如我们这个案例，没有其源代码，可以通过高速相机先大致确认下时间范围，然后在范围区域内的几帧逐一看。<br>可以先查看下支付宝首页的布局，比如这里home_advertisement.xml对应主界面上的中间广告页，这个布局的加载完成，其后面紧跟着的一帧我我们就认为是结束帧。<br>所以我们在对比竞品的Systrace时也要以home_advertisement.xml加载后的一帧为结束点。</p><p><img src="http://blog.lihaizhou.top/Systrace_process_start/processStart19.png" alt="img"></p><p>SF侧以及渲染线程侧</p><p><img src="http://blog.lihaizhou.top/Systrace_process_start/processStart20.png" alt="img"><br><img src="http://blog.lihaizhou.top/Systrace_process_start/processStart21.png" alt="img"></p><p>关键时间点:<br>SF中bufferQueue对应的支付宝这一帧的buffer被消费后的时间点是 6s554ms<br>这个时间点可以基本认为是冷启动最后的时间点</p><p>到这里我们计算下冷启的大概耗时</p><ul><li><p>inputReader中读取到up事件起始点 : 5s 617ms</p></li><li><p>首页内容完全加载第一帧时间点: 6s554ms</p></li></ul><p>整个冷启动过程共计耗时937ms，和我们高速相机测算的925ms比较接近</p><h4 id="写在最后"><a href="#写在最后" class="headerlink" title="写在最后"></a>写在最后</h4><p>到这里，对于支付宝的整个启动流程拆解结束，希望通过本文能够加深对应用启动流程的理解，后面会另行成文分析和竞品机的差异细节。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;上周看了一个支付宝启动速度逊色于对比机的案例，花了些时间整理了下这个过程。&lt;br&gt;应用启动过程中牵扯的知识点较多，基本涵盖了Android几大重要的子系统，非一篇文章能够讲清。&lt;br&gt;本文将以支付宝为例，介绍下从input事件触发到首页帧显示完成的整个流程，后面会单独成文介
      
    
    </summary>
    
      <category term="性能" scheme="http://lihaizhou.top/categories/%E6%80%A7%E8%83%BD/"/>
    
    
  </entry>
  
  <entry>
    <title>案例分析:打开应用后操作界面无响应(Systrace)</title>
    <link href="http://lihaizhou.top/2021/11/08/%E6%A1%88%E4%BE%8B%E5%88%86%E6%9E%90-%E5%88%87%E6%8D%A2%E5%BA%94%E7%94%A8%E5%90%8E%E9%AB%98%E6%A6%82%E7%8E%87%E6%93%8D%E4%BD%9C%E6%97%A0%E5%93%8D%E5%BA%94-Systrace/"/>
    <id>http://lihaizhou.top/2021/11/08/案例分析-切换应用后高概率操作无响应-Systrace/</id>
    <published>2021-11-08T02:34:51.000Z</published>
    <updated>2021-11-08T06:45:49.000Z</updated>
    
    <content type="html"><![CDATA[<h4 id="问题现象"><a href="#问题现象" class="headerlink" title="问题现象"></a>问题现象</h4><p>打开应用(热启动)后，概率性出现手指滑动界面无任何响应(界面控件支持上下滑动)</p><h4 id="Systrace角度分析"><a href="#Systrace角度分析" class="headerlink" title="Systrace角度分析"></a>Systrace角度分析</h4><p>先看下应用区域帧绘制的情况</p><p><img src="http://blog.lihaizhou.top/Systrace_cpmpact/Systrace_compact2.png" alt="图片"></p><p>这个时间段除了开头的几帧，后面几乎是空白的，复现时手指明明是一直滑动的。</p><p>先确认下input事件是否正常，在分析input事件流转是否正常之前</p><p>我们先简单的介绍下input事件大概的流转过程</p><blockquote><p>1.触摸屏每隔几毫秒扫描一次，如果有触摸事件，那么把事件上报到对应的驱动</p><p>2.InputReader 读取触摸事件交给 InputDispatcher 进行事件派发</p><p>3.InputDispatcher 将触摸事件发给注册了 Input 事件的 App</p><p>4.app 拿到事件之后，进行 Input 事件分发，如果此事件分发的过程中，App的</p><p>UI 发生变化，那么会请求 Vsync，则进行一帧的绘制</p></blockquote><p>先看下input down的时间点</p><p><img src="http://blog.lihaizhou.top/Systrace_cpmpact/Systrace_compact3.png" alt="图片"></p><p>后面的事件是连续且密集的，说明我们复现抓取的时候，报点是没有问题的。</p><p>这个时候我们注意到一个奇怪的现象，outBoundQueue和waitQueue是空的。</p><p>关于outBoundQueue和waitQueue简单介绍下</p><blockquote><p>1.当应用窗口准备就绪，将mPendingEvent转移到outBoundQueue队列，对应的是即将要被派发给对应 AppConnection 的事件。</p><p>2.当outBoundQueue不为空，且应用管道对端连接状态正常，则将数据从outboundQueue中取出事件，放入waitQueue队列，记录的是已经派发给 AppConnection 但是 App 还在处理没有返回处理成功的事件。</p></blockquote><p>如果outBoundQueue和waitQueue是空的话，说明此时应用窗口未就绪。我们操作时窗口明明可见的，难道应用D状态了？</p><p>带着这个疑问，我们再次回到应用所在区域</p><p><img src="http://blog.lihaizhou.top/Systrace_cpmpact/Systrace_compact4.png" alt="图片"></p><p>可以看到飞书热启后，多个运行线程处于非IO导致的D状态，另外结合基本没有占据CPU资源这一情况。</p><p>可以认定之所以应用没有响应down事件，正是由于其处于非IO导致的D状态。</p><p>下面就需要调查为何应用D状态了，很快在应用区域注意到一个现象</p><p><img src="http://blog.lihaizhou.top/Systrace_cpmpact/Systrace_compact5.png" alt="图片"></p><p>我们知道匿名页被压缩换到Zram通常出现在kswapd回收内存场景中。</p><p>但是还有一种场景我们可能会忽略，那就是adj变化触发的进程压缩同样会消费Zram。</p><p>为了验证是进程压缩导致，来到压缩线程所在区域。为了看起来更直观，将down事件和压缩线程放在一起</p><p><img src="http://blog.lihaizhou.top/Systrace_cpmpact/Systrace_compact6.png" alt="图片"></p><p>到这里我们可以确定飞书之所以没有响应到input down事件，正是由于其当时正在进行进程压缩从而导致其处于D状态。</p><h4 id="问题完整时间线"><a href="#问题完整时间线" class="headerlink" title="问题完整时间线"></a>问题完整时间线</h4><p>到这里我们将这个案例完整的故事情节还原出来</p><ol><li><p>在一次退出飞书后，此时引起adj变化，进入压缩判断环节，此时满足一系列条件(如匿名页大小, 前后时间差, adj值)后，压缩线程开始对飞书应用进行压缩。</p></li><li><p>很快再次打开飞书(29s793ms)</p></li><li><p>此时手指按下开始滑动(29s988ms)(不松手)，注意这个时候压缩还未完成，飞书仍处于进程压缩导致的D状态中，所以未能响应down事件。</p><p>我们知道一个事件序列是由down+若干move+up组成，由于down事件丢失以至于后面的move事件未能响应。</p></li><li><p>飞书压缩完成(30s598ms)，该主界面进程压缩过程持续约882.6ms，完成后飞书解除D状态。</p></li></ol><p>这个过程简单点说，在飞书可见后，如果上次压缩未完成，这时候手指按下的down事件都会被丢弃。</p><p>这也解释了为何该问题在快速切换场景下更容易出现</p><h4 id="压缩速度"><a href="#压缩速度" class="headerlink" title="压缩速度"></a>压缩速度</h4><p>这个时候，你可能会觉得疑惑，是不是压缩速度慢导致的这个问题?</p><p>下面我们将试着计算问题时的”压缩速度”, 这里对压缩速度之所以加引号后面会解释</p><p><img src="http://blog.lihaizhou.top/Systrace_cpmpact/Systrace_compact7.png" alt="图片"></p><p>从我们这次复现的Systrace来看，飞书压缩完成后，其Swap占据从118.8M增长到232.7M，共计压缩了约114M的匿名页，共计耗时882ms</p><p>用压缩量除以耗时时间得出”压缩速度”约129M/s。</p><p>影响压缩速度的因素可能有哪些呢？</p><p><strong>主要是压缩算法，CPU频率，DDR频率，内存读写性能这几方面因素</strong></p><p>我们从Systrace中再看下压缩期间的CPU运行情况</p><p><img src="http://blog.lihaizhou.top/Systrace_cpmpact/Systrace_compact8.png" alt="图片"></p><p>可以看到有较多的Runnable (Preempted)，说明该时间段内可能负载较重，存在CPU争抢的情况。</p><p>除了等CPU的片段外，还有很多片段跑在了小核上</p><p><img src="http://blog.lihaizhou.top/Systrace_cpmpact/Systrace_compact9.png" alt="图片"></p><p>这也是为何上面提到的”压缩速度”加引号的原因。正好压缩的耗时882ms并不是一直在running状态。</p><p>其实这点比较好理解，好比你开车上班，短短的五公里的车程却有二十个红绿灯，这个时候用路程除以耗时得出的”车速”，严格意义上说并不准确。</p><h4 id="测试实验"><a href="#测试实验" class="headerlink" title="测试实验"></a>测试实验</h4><p>我们前面已经发现压缩期间很多片段跑在了小核上，那么如果给压缩线程更高的CPU资源权重，是否能提升”压缩速度”呢？</p><p>于是，对压缩线程占据CPU的权重进行调整后，再次抓取了一份Systrace</p><p><img src="http://blog.lihaizhou.top/Systrace_cpmpact/Systrace_compact10.png" alt="图片"></p><p>从修改后抓取的Systrace可以看到，这次压缩线程确实大部分时候跑在了大核上。</p><p>从图中可以看到本次压缩了约144M匿名页，耗时约450ms，”压缩速度”约320M/s</p><p>相比修改前，”压缩速度”提升了近三倍，但是其实仍然不够快，还是会有一定概率发生手指按下时，正好落在压缩未完成的时间段内，只是相比之前大幅降低了该问题复现概率。</p><h4 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h4><p>如果压缩算法已经确认是最优的选择(平衡压缩率和解压缩速度)情况下，通过尽量赋予压缩线程更高的CPU优先级确实能够缩短耗时(假设压缩量固定)，但是最大的影响因素在于内存读写性能。</p><hr><p>愿你秃顶归来，内心依旧少年</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;问题现象&quot;&gt;&lt;a href=&quot;#问题现象&quot; class=&quot;headerlink&quot; title=&quot;问题现象&quot;&gt;&lt;/a&gt;问题现象&lt;/h4&gt;&lt;p&gt;打开应用(热启动)后，概率性出现手指滑动界面无任何响应(界面控件支持上下滑动)&lt;/p&gt;
&lt;h4 id=&quot;Systrace角度
      
    
    </summary>
    
      <category term="性能" scheme="http://lihaizhou.top/categories/%E6%80%A7%E8%83%BD/"/>
    
    
  </entry>
  
  <entry>
    <title>第三视角: 一个ART GC的优化故事</title>
    <link href="http://lihaizhou.top/2021/11/01/%E7%AC%AC%E4%B8%89%E8%A7%86%E8%A7%92-%E4%B8%80%E4%B8%AAART-GC%E7%9A%84%E4%BC%98%E5%8C%96%E6%95%85%E4%BA%8B/"/>
    <id>http://lihaizhou.top/2021/11/01/第三视角-一个ART-GC的优化故事/</id>
    <published>2021-11-01T08:54:55.000Z</published>
    <updated>2022-03-12T14:16:15.509Z</updated>
    
    <content type="html"><![CDATA[<h4 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h4><p>从事过整机性能优化的同事，在实际项目上相信都遇到过GC引起的性能问题。有了上一篇文章<android s="" art="" gc基础="">的铺垫，阅读本文将会比较轻松。<br>笔者在梳理GC这块的代码过程中，深感其复杂并非一蹴而就，如果你对其某处代码的设计缘由不甚理解，不妨试着去追踪它的提交记录。<br>通过其一系列的patch更新以及comment，跟着提交owner的思路历程，便可以了解这个”成品”是如何被加工出来的。</android></p><h4 id="故事的缘起"><a href="#故事的缘起" class="headerlink" title="故事的缘起"></a>故事的缘起</h4><p>笔者在梳理GC这块的代码时，偶然看到一处友商的提交，不禁有点好奇。为了探究其修改的缘由，仔细阅读了这笔修改的提交更新以及所有的comment之后，觉得其中一些思路对我们有启发作用，故而决定将这个思路过程尽可能的还原出来。<br>PS: 友商员工技术之扎实令人印象深刻，采用第三视角纯粹是为了提升趣味性，本文无任何戏谑意思</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">主角: 卢卡斯(谷歌员工)，大壮(友商员工)    </span><br><span class="line">配角: 汉斯(谷歌员工)   </span><br><span class="line">旁白: 笔者</span><br></pre></td></tr></table></figure><h4 id="故事开始"><a href="#故事开始" class="headerlink" title="故事开始"></a>故事开始</h4><p>大壮在国内一家手机厂商搬砖，负责整机性能方面的研究。最近大壮有点闷闷不乐，项目上一些GC相关的性能问题困扰了他许久，具体是什么GC问题呢？<br>大壮通过不限于Systrace等手段，发现在一些场景下比如后台运行较多应用时，GC会消耗较多CPU资源，加剧系统负担，表现出的现象就是更加卡顿了。<br>于是，自信上进的大壮开始着手调研该如何解决这个问题，最终有了一个方案：<br>既然GC会在后台运行较多应用时争抢CPU，那么在CPU负载高的时候降低GC的触发，CPU负载低的时候再恢复，这不就可以了吗？</p><ol><li>怎么降低GC频率呢？Multiplier机制。</li><li>怎么统计CPU负载呢？大壮看了下代码中原本就有GC期间占据的CPU数据。</li></ol><p>看起来小菜一碟嘛，熟悉GC流程代码的大壮很快就做出了第一笔修改。</p><h5 id="修改Multiplier"><a href="#修改Multiplier" class="headerlink" title="修改Multiplier"></a>修改Multiplier</h5><p>考虑到HeapGrowthMultiplier这个接口是谷歌原有的，存在多处会调用，为了不影响其他调用,贴心的大壮加了一个单独的接口HeapGrowthMultiplierExt,  这个接口最终会调用HeapGrowthMultiplier，只是在此之前会有一些判断条件。比如是否处于亮屏，不同的radio下返回不同的Multiplier值。<br>通过前一篇文章的分析，我们知道Multiplier的改变会引起下次GC水位的提升，总的而言，值越高GC的触发频率就会更低。<br>runtime/gc/collector/garbage_collector.cc<br><img src="http://blog.lihaizhou.top/ART_story/GC_story1.png" alt="图片"><br>runtime/gc/heap.cc</p><p><img src="http://blog.lihaizhou.top/ART_story/GC_story2.png" alt="图片"></p><h5 id="降低GC转换的次数"><a href="#降低GC转换的次数" class="headerlink" title="降低GC转换的次数"></a>降低GC转换的次数</h5><p><img src="http://blog.lihaizhou.top/ART_story/GC_story3.png" alt="图片"><br>前后台切换会导致GC转换，大壮心想有一些本身占据堆内存就比较小的进程，他们很多时候的GC转换带来的收益并不明显。<br>特别是内存比较充足的项目这种GC转换似乎有点多余，那么通过判断堆使用大小，去掉一些”不必要”的GC转换，这样就可以降低系统负担。</p><p>旁白:<br>为了可拓展性，尽可能的不要引入硬编码，即便你是通过大量数据实测出来的最优值，除非是一些约定俗成的值。提到硬编码这种情况，在实际项目上经常出现，很多时候这种代码的引入，是由于Reviewer的疏忽没有发现或者说默许了。</p><h4 id="谷歌Review"><a href="#谷歌Review" class="headerlink" title="谷歌Review"></a>谷歌Review</h4><p>很快，大壮的提交修改引起了卢卡斯的注意，看完了大壮的修改后，卢卡斯脑袋上顶着大大的问号。<br>对于如下大壮添加的计算gc期间CPU负载的做法。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">uint64_t gc_cpu_time = thread_cpu_end_time - thread_cpu_start_time;  </span><br><span class="line">float ratio = static_cast&lt;float&gt;(gc_cpu_time) / duration_ns;</span><br></pre></td></tr></table></figure></p><p>卢卡斯认为这只是本次GC周期内的CPU负载情况，且这个值在绝大部分时候都应该是接近1的，并不能说明未来一段时间的CPU情况。<br>另外，GC等待checkpoint或者其他原因都可能会导致GC等待，但是这些等待的时间不会计入gc_cpu_time中，所以这种计算方式只能说一定程度上可能暗示了当前的负载情况，但是远远达不到可靠的地步。</p><p>旁白：<br>注意这里谷歌提到了未来的CPU使用情况，是因为这个比例值是本次GC周期计算的，你可以理解为是一个瞬时值，但是抑制GC的情况是需要等到<br>下次GC触发才会发生的，是一个未来发生的事情，那么等到下次GC的时候，本次GC算出的负载可能就不适用了。</p><p>大壮：<br>大壮看完大G的回复之后，虎躯一震，这修改。。怕是要凉啊！于是大壮赶紧回复到：<br>在一些性能较差设备上，如果后台开启很多应用，很多时候这个比例值会低于0.5甚至触及0.2。<br>另外，我们做过功耗测试，这修改后的效果杠杠的，改善很明显(使用时间增加了18分钟)。</p><p>卢卡斯：<br>看完大壮理直气壮的回复后，卢卡斯回复到：这里亮屏的判断，并根据不同的radio返回不同的Multiplier，这个修改同样会作用到所有系统进程(如system_server、systemui等)，作用于<br>系统进程是一种错误的行为。还有根据不同的radio即你认为的代表负载情况，返回不同的Multiplier值。这些Multiplier值你是怎么得出来的？<br>比如你上面写的当ratio &lt; 0.3时，返回Multiplier 6，这个值6怎么来的？为何不是返回8？为啥不是9？为啥不是一个10000000000？(谷歌没说这句话)。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (screenOn) &#123;</span><br><span class="line">    <span class="keyword">float</span> ratio = current_gc_iteration_.GetRunningRatio();</span><br><span class="line">    <span class="keyword">if</span> (!CareAboutPauseTimes()) &#123;</span><br><span class="line">      <span class="keyword">if</span> (ratio &lt; <span class="number">0.3</span>) <span class="keyword">return</span> <span class="number">6.0</span>;</span><br><span class="line">      <span class="keyword">if</span> (ratio &lt; <span class="number">0.5</span>) <span class="keyword">return</span> <span class="number">4.0</span>;</span><br><span class="line">      <span class="keyword">if</span> (ratio &lt; <span class="number">0.7</span>) <span class="keyword">return</span> <span class="number">2.0</span>;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="keyword">if</span> (ratio &lt; <span class="number">0.3</span>) <span class="keyword">return</span> <span class="number">7.0</span>;</span><br><span class="line">      <span class="keyword">if</span> (ratio &lt; <span class="number">0.6</span>) <span class="keyword">return</span> <span class="number">5.0</span>;</span><br><span class="line">    &#125;</span><br><span class="line"><span class="comment">//....</span></span><br></pre></td></tr></table></figure><p>旁白：给谷歌提代码一定要避免提交这种硬编码</p><p>大壮：<br>此时的大壮，刚从食堂吃完午饭回来的路上，一路上大壮都在和同事吐槽食堂的饭菜又贵又难吃。<br>坐到座位上，看到卢卡斯的连环追问，大壮有点发蒙。这些数据我经过一些性能和功耗测试，是有帮助的，既然你们提出来这样的修改不合理，那么请告诉我,还有没有其它办法可以降低高负载情况下GC的频率。</p><p>卢卡斯:<br>此时的卢卡斯正喝着咖啡，窗外阳光正明媚，卢卡斯回过头和旁边的汉斯说到，这天气不去钓鱼真是浪费生命啊，汉斯点头如蒜捣，没错没错。<br>这个时候，卢卡斯看了下时间快4点了，准备收拾下班，这个时候看到了大壮的comment，回复到:<br>在堆使用较少的情况下不进行GC我觉得有意义，这种情况下我认为是可以直接跳过GC转换的，而不是引入进程状态切换次数这个变量。</p><p>旁白：谷歌的这句话，在一些场景下跳过GC更有意义，正是这句话改变了修改的方向</p><p>卢卡斯旁边的汉斯看到了大壮的这段回复，心里OS: 上一次这么无语还是在上一次, 忍不住回复到：<br>卢卡斯，大壮的这种改法让我感觉也很不舒服，也许我们在一些场景下GC的次数有点多了，但是能不能用更合理的方式来解决这个问题呢？比如依据自上次GC以来分配的字节数作为依据, 对于某些应用程序来说，转换可能会频繁发生，并且每次执行GC并不总是可取的。<br>用比例值或许更合理？例如:“如果我们已经消耗了超过30%的free heap，我们将在转换时GC”。</p><p>旁白：汉斯的这句话奠定了这个修改的基本方向，依据自上次GC以来的分配数值作为依据，采用比例的方式，不用管这个进程的大小。</p><p>大壮：<br>此时的大壮正在工位上，跟旁边的测试妹纸炫耀自己昨天一口气钓了十几斤的鲫鱼，妹纸看大壮的眼神满是崇拜。大壮说的有点渴了，坐下来喝口水时，看到了卢卡斯的回复，思考片刻后，觉得谷歌提出的修改建议确实更加合理。<br>于是讲起了之前遇到的案例:<br>最早是我们遇到的一个Launcher的卡顿例子，同一uid下的5个进程同时在后台执行collectorTransionGc，导致系统负载过高。四个子进程的堆大小都小于5MB，不信我给你们看Systrace。对于这种内存消耗很小的进程，真的大可不必每次都GC，所以我们希望能够限制这种类型的collectortransiongc。因为从实际用户的GC数据中可以发现，这种类型的CollectorTransitionGC的总量非常大。</p><p>卢卡斯:<br>卢卡斯觉得不应该仅限于小内存进程，应该一视同仁，所以卢卡斯觉得基于堆的大小进行限制不是太好。卢卡斯想起了汉斯提出的建议: 根据自上次GC以来分配的大小作为跳过GC转换的条件。<br>汉斯的这个建议确实更加合理一些，这样的话，所有的应用都有机会跳过一些”不必要”的GC。卢卡斯想了下，与其跳过一些转换GC，不如让它更简单，比如: 如果自上次GC以来的分配小于3MB，GC转换时跳过GC。</p><p>旁白:<br>卢卡斯认同汉斯的通过自上次GC以来分配的大小作为依据，但是忽略了汉斯提出另一个意见，那就是通过堆空闲内存的使用率来作为触发条件，这里卢卡斯提出的小于3M就不进行GC，也正是这句话给了大壮一些误导。</p><p>大壮:<br>听完卢卡斯说的堆使用小于3M就不进行GC转换后，大壮进行了一次修改，加了一个阈值<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="keyword">constexpr</span> <span class="keyword">size_t</span> kDefaultTransitionThreshold = <span class="number">5</span> * MB;</span><br></pre></td></tr></table></figure></p><p>并且在GC转换的地方加了一个判断，如果低于这个阈值，就跳过本次的GC转换<br><img src="http://blog.lihaizhou.top/ART_story/GC_story4.png" alt="图片"></p><p>卢卡斯:<br>看完大壮的修改后，卢卡斯后悔了，这里搞个固定的阈值看起来并不合适。因为如果这个进程是一个占用内存比较小的进程，那么5M对于这个进程来说并不容易达到，这会导致GC的触发频率被大幅降低，导致这个进程的堆大小”不合适”的增大。<br>这个时候卢卡斯想起了汉斯的通过比例的建议，没错，通过比例更合理一些，于是卢卡斯提出了: 上次GC后新增大小如果小于<br>UnignedDifference(target_footprint_.load(std::memory_order_relaxed)- num_bytes_alive_after_gc_)/4 话，则跳过本次GC转换，并且对于LowMemoryMode设备避免跳过GC</p><p>旁白：卢卡斯的这番话基本成形了这个修改，即消耗没有达到堆空闲的1/4，此时有GC转换请求的话，则直接丢弃。</p><p>大壮：<br>看完卢卡斯的建议后，大壮开始着手进行了修改，关于如何计算GC后新分配的值。<br>大壮想到了在GC后算出已分配的减去GC前计算出的已分配大小，修改完之后再次更新了patch，很快卢卡斯在大壮的修改下加了comment<br><img src="http://blog.lihaizhou.top/ART_story/GC_story5.png" alt="图片"></p><p>旁白：这是并发GC的特色所在，分配的同时可能伴随着GC，所以需要考虑GC期间释放的空间大小。</p><h4 id="最终修改思想"><a href="#最终修改思想" class="headerlink" title="最终修改思想"></a>最终修改思想</h4><ol><li>进程状态变化触发GC转换</li><li>计算出自上次GC后新分配字节大小，由于并发缘故，需考虑GC期间释放字节数。</li><li>堆可增长上限减去自上次GC后已分配数值，得出的值即可增长空间，取其四分之一作为分界线</li><li>上次GC后新分配字节数值如果小于第三步算出的可增长空间的1/4，则跳过本次GC转换请求。</li></ol><h4 id="写在最后"><a href="#写在最后" class="headerlink" title="写在最后"></a>写在最后</h4><p>谈到设计思想，笔者想起一句话：Talk is cheap. Show me the code!<br>每次看到这句话，都感觉被无端斥责了一番。<br>笔者曾经特地查询了下Linus说这句话的语境背景，最后得出结论Linus说这句话时，其实是在一个讨论回复中，结合当时的上下文语境，Linus说出这句时明显是带有情绪的，但是奇怪的是这句特定语境下的话，在国内却被大肆宣传甚至被一些人奉为经典。<br>笔者在实际项目上见到过太多shit一样的代码，盲目的追求代码数量，粗制滥造毫无设计可言，更不要说代码规范这些基础原则了，阅读起来你都恨不得砸了键盘。<br>如果你很崇尚“show me the code”，给你这样一堆dog shit代码，你能从中看出什么呢？<br>并不是盲目崇拜谷歌，笔者在阅读谷歌代码的提交记录过程中，能够感受到其思维之严谨，考虑之周到，修改之谨慎。所以推荐大家空闲的时候，可以多阅读谷歌的修改记录。<br>最后多说一句，笔者粗浅的认为，相比于最终的成品代码，当然前提是优秀的代码。笔者认为其思路旅程也很重要，因为是人的思想最终孕育出这块美丽的代码。</p><hr><p>只要不给社会添麻烦，做一个废柴并不丢人</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h4&gt;&lt;p&gt;从事过整机性能优化的同事，在实际项目上相信都遇到过GC引起的性能问题。有了上一篇文章&lt;android s=&quot;&quot; art=&quot;&quot; gc基础=&quot;&quot;
      
    
    </summary>
    
      <category term="ART" scheme="http://lihaizhou.top/categories/ART/"/>
    
    
  </entry>
  
  <entry>
    <title>对Android S ART GC的源码梳理</title>
    <link href="http://lihaizhou.top/2021/10/27/%E5%AF%B9Android-S-ART-GC%E7%9A%84%E6%BA%90%E7%A0%81%E6%A2%B3%E7%90%86/"/>
    <id>http://lihaizhou.top/2021/10/27/对Android-S-ART-GC的源码梳理/</id>
    <published>2021-10-27T01:58:43.000Z</published>
    <updated>2022-03-12T14:19:48.350Z</updated>
    
    <content type="html"><![CDATA[<h4 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h4><p>本文是GC系列文章的首篇，主要为下一篇《第三视角: 一个ART GC优化的故事》文章做铺垫。<br>本文将根据下面的大纲，简单的介绍下GC相关的基础知识，GC这块的内容较多，也相对较为复杂。如果想要研究清楚细节，需要花费较多的时间，也需要有读者有足够的耐心和相关知识背景。<br>本文深受<a href="https://juejin.cn/post/6875678394332217357" target="_blank" rel="noopener">ART虚拟机 | GC的触发时机和条件</a>一文的启发</p><p>文中涉及代码均摘自Android S。</p><h4 id="大纲"><a href="#大纲" class="headerlink" title="大纲"></a>大纲</h4><ul><li>研究ART GC目的</li><li>ART GC诞生背景</li><li>里程碑(引入CC)</li><li>ART GC重要特性</li><li>ART GC类别划分</li><li>Multiplier的引入</li><li>堆可分配字节数的计算</li><li>GC触发阈值的计算</li><li>从Systrace角度看GC</li><li>参数修改策略</li><li>写在最后</li><li>参考文献</li></ul><h4 id="研究ART-GC目的"><a href="#研究ART-GC目的" class="headerlink" title="研究ART GC目的"></a>研究ART GC目的</h4><p>尽管GC经过多年发展已得到显著改进，但是在实际项目中仍然会遇到很多GC引起的性能问题。<br>特别是小内存项目上(低于6G)尤为明显，遇到的大部分问题来自于应用不规范的行为，小部分是由于GC机制在特定场景下导致的性能问题。</p><p>GC性能问题主要分为两类：</p><ol><li>对于应用而言，如果代码中存在频繁分配对象、存在内存泄漏、存在主动调用GC接口等问题都有可能导致GC性能问题。<br>主要体现在GC运行的线程HeapTaskDaemon占据CPU资源较多或争抢大核，可能会引起绘制得不到及时调度，导致掉帧的情况。</li><li>另外对于GC机制本身而言，虽然Google一直在优化，但是现在仍然存在一些场景下的表现无法令我们足够满意。<br>比如高负载时争抢CPU资源，小内存进程在某些场景下的频繁触发，多进程应用启动时由于GC导致的卡顿黑屏等现象。</li></ol><h4 id="GC诞生背景"><a href="#GC诞生背景" class="headerlink" title="GC诞生背景"></a>GC诞生背景</h4><p>当我们在学习新技术的时候，了解其诞生背景及其演进变化的历程，再结合具体的代码细节，将有助于我们对这个技术形成一个连续的认知。</p><p>举个网络拥塞控制的例子，网上关于拥塞控制算法的文章铺天盖地，几乎都在讨论其中的代码细节。<br>但是其诞生的历史背景及其本质是为了解决什么问题，却很少有文章能真正解释清楚。<br><strong>为什么说历史背景至关重要</strong><br>还是以拥塞控制为例，如果你不了解1986年的网络大崩溃事件发生的原因，也就无法理解1988年Jacobson提出的TCP拥塞控制的论文。<br>进而即便你多么熟悉TCP的代码细节，你也无法理解这一切实现背后的真正的逻辑，甚至会草率错误的认为拥塞控制是为了加快发包的速度，以至于后面关于这方面的工作很可能是扯淡。</p><p>再回到本文的主题GC，聊下GC诞生的背景</p><blockquote><p><em>1960</em> 年前后诞生于 <em>MIT</em> 的 <em>Lisp</em> 语言是第一种高度依赖于动态内存分配技术的语言，<em>Lisp</em> 语言先天就具有的动态内存管理特性要求 <em>Lisp</em> 语言的设计者必须解决堆中每一个内存块的自动释放问题（否则， <em>Lisp</em> 程序员就必然被程序中不计其数的 <em>free</em> 或 <em>delete</em> 语句淹没），这直接导致了垃圾收集技术的诞生和发展。</p><p><em>J. McCarthy 作为 Lisp</em> 之父，他在发明 <em>Lisp</em> 语言的同时也第一次完整地描述了垃圾收集的算法和实现方式。</p><p>有兴趣的话可以网上搜索这篇文章, 讲的比较详细 &lt;GC技术简单而有趣的发展史&gt;</p></blockquote><h4 id="里程碑-引入CC"><a href="#里程碑-引入CC" class="headerlink" title="里程碑(引入CC)"></a>里程碑(引入CC)</h4><p><code>史前时代Dalvik-&gt;ART的诞生(Android 4.4)-&gt;发展的ART(Android 5.0 ~ 7.0)-&gt;重大变革的ART(Android 8.0 引入Concurrent Copying)-&gt;Android 10开始再次引入分代.</code><br>8.0版本上引入的Concurrent Copying是一项重大改革，大幅提升了Android手机的整机性能表现。<br>8.0版本的GC相比之前的版本改进和提升如下:</p><ul><li>GC always compacts the heap: 32% smaller heap sizes on average compared to Android 7.0.</li><li>Compaction enables thread local bump pointer object allocation: Allocations are 70% faster than in Android 7.0.</li><li>Offers 85% smaller pause times for the H2 benchmark compared to the Android 7.0 GC.</li><li>Pause times no longer scale with heap size; apps should be able to use large heaps without worrying about jank.</li><li>GC implementation detail - Read barriers:</li><li>Read barriers are a small amount of work done for each object field read.</li><li>These are optimized in the compiler, but might slow down some use cases.</li></ul><h4 id="重要特性"><a href="#重要特性" class="headerlink" title="重要特性"></a>重要特性</h4><p>下面简单介绍CC上几种主要的特性，如果阅读过程中有些名词不明其意，大可不必感到困惑。<br>知道其大概的角色作用即可，后面的GC系列文章会对每个特性展开来详细梳理。</p><h5 id="RegionTLAB"><a href="#RegionTLAB" class="headerlink" title="RegionTLAB"></a>RegionTLAB</h5><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">CC enables use of a bump-pointer allocator called RegionTLAB. </span><br><span class="line">This allocates a thread-local allocation buffer (TLAB) to each </span><br><span class="line">app thread, which can then allocate objects out of its TLAB by </span><br><span class="line">bumping the "top" pointer, without any synchronization.</span><br></pre></td></tr></table></figure><p>这里提到的TLAB 即 thread-local allocation buffer，AllocObjectWithAllocator中会先检测如果当前线程TLAB区域的剩余空间可以容纳下这次分配的对象，则在TLAB区域中直接分配。<br>分配算法采用Bump Pointer的方式，仅仅更新已分配区域的游标，简单高效。<br>art/runtime/gc/heap-inl.h<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// If we have a thread local allocation we don't need to update bytes allocated.</span></span><br><span class="line"><span class="keyword">if</span> (IsTLABAllocator(allocator) &amp;&amp; byte_count &lt;= self-&gt;TlabSize()) &#123;</span><br><span class="line">  obj = self-&gt;AllocTlab(byte_count);</span><br><span class="line">  DCHECK(obj != <span class="literal">nullptr</span>) &lt;&lt; <span class="string">"AllocTlab can't fail"</span>;</span><br><span class="line">  obj-&gt;SetClass(klass);</span><br><span class="line">  <span class="keyword">if</span> (kUseBakerReadBarrier) &#123;</span><br><span class="line">    obj-&gt;AssertReadBarrierState();</span><br><span class="line">  &#125;</span><br><span class="line">  bytes_allocated = byte_count;</span><br><span class="line">  usable_size = bytes_allocated;</span><br><span class="line">  no_suspend_pre_fence_visitor(obj, usable_size);</span><br><span class="line">  QuasiAtomic::ThreadFenceForConstructor();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>值得注意的一点是，TLAB在创建之初，它的大小已经计入了num_bytes_allocated_，所以这次虽然分配了新的对象，但num_bytes_allocated_没必要增加，这实际上是一种空间换时间的策略，代价就是会导致num_bytes_allocated_略大于真实使用的字节数。</p><p>谷歌对此修改的commit message:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">New TLAB allocator doesn&apos;t increment bytes allocated </span><br><span class="line">until we allocate a new TLAB. This increases allocation </span><br><span class="line">performance by avoiding a CAS.</span><br><span class="line"></span><br><span class="line">MemAllocTest:</span><br><span class="line">Before GSS TLAB: 3400ms.</span><br><span class="line">After GSS TLAB: 2750ms.</span><br></pre></td></tr></table></figure></p><h5 id="Read-barrier"><a href="#Read-barrier" class="headerlink" title="Read barrier"></a>Read barrier</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">CC performs heap defragmentation by concurrently copying </span><br><span class="line">objects without pausing app threads. This is achieved with </span><br><span class="line">the help of a read-barrier which intercepts reference reads </span><br><span class="line">from the heap, without the need of any intervention from </span><br><span class="line">the app developer.</span><br></pre></td></tr></table></figure><p>CC可以通过在不暂停应用线程的情况下并发复制对象来执行堆碎片整理。这是在read-barrier的帮助下实现的，read-barrier会拦截来自堆的引用读取，无需开发者进行任何干预。<br>注意对第一句话的理解，应用GC的时候不会暂停应用，也就是说这个时候可能存在分配对象的行为，说的其实正是并发。<br>后面的实际案例在计算自上次GC后新分配大小时会用到这一点，目前的GC都是支持read-barrier的，read-barrier的诞生是为了更大程度的降低GC暂停时间。</p><h5 id="一次暂停"><a href="#一次暂停" class="headerlink" title="一次暂停"></a>一次暂停</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">GC only has one small pause, which is constant in time </span><br><span class="line">with regards to the heap size.</span><br></pre></td></tr></table></figure><p>对Dalvik有所了解的话，都知道Dalvik在mark阶段需要暂停应用线程两次，sweep阶段需要暂停一次，三次的STW开销会带来明显的卡顿。<br>到了ART时代，启动 GC 后不再是两次暂停，而是一次暂停，因为（packard pre-cleaning）的存在，在暂停前就做了许多事情，减轻了暂停时的工作量。</p><h5 id="支持分代"><a href="#支持分代" class="headerlink" title="支持分代"></a>支持分代</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">CC extends to be a generational GC in Android 10 and higher. </span><br><span class="line">It enables collecting young objects, which often become </span><br><span class="line">unreachable fairly quickly, with little effort. </span><br><span class="line">This helps by increasing GC throughput and considerably </span><br><span class="line">delaying the need to perform a full-heap GC.</span><br></pre></td></tr></table></figure><p>谷歌对分代的支持历经开，关，开，具体的缘由没有细跟，不过最新Android版本支持分代，分代的好处谷歌解释为更加轻松回收存留期较短的对象，有助于提升GC的吞吐量，并且降低full GC的时机。<br>注意这里提到了一个GC吞吐量的概念，笔者之前从事过网络工作，所以自然而然的想到了WIFI的吞吐量，WIFI吞吐量可以简单的理解为单位时间内通过某个信道的数据量。</p><p>那么这里的GC 吞吐量指的又是什么呢？ <strong>可以理解为单位时间内释放的字节数</strong></p><h4 id="GC类别的划分"><a href="#GC类别的划分" class="headerlink" title="GC类别的划分"></a>GC类别的划分</h4><p>对GC的分类有不同的指标，可以从是否并发，回收力度等指标分类。</p><h5 id="回收力度划分"><a href="#回收力度划分" class="headerlink" title="回收力度划分"></a>回收力度划分</h5><p>art/runtime/gc/collector/gc_type.h<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">art/runtime/gc/collector/gc_type.h// The type of collection to be performed. //The ordering of the enum matters, it is used to determine which GCs are run first.enum GcType &#123;// Placeholder for when no GC has been performed.kGcTypeNone,// Sticky mark bits GC that attempts to only free objects allocated since the last GC.kGcTypeSticky,// Partial GC that marks the application heap but not the Zygote.kGcTypePartial,// Full GC that marks and frees in both the application and Zygote heap.kGcTypeFull,// Number of different GC types.kGcTypeMax,&#125;;</span><br></pre></td></tr></table></figure></p><p>如下摘自谷歌的一笔commit message：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">The new behaviour has that we do sticky GC until we have </span><br><span class="line">less space remaining than minimum free after the GC. </span><br><span class="line">When this occurs, we set the next GC to be a partial GC.</span><br><span class="line"></span><br><span class="line">After a partial / full GC we grow the heap and set the </span><br><span class="line">next GC to be a sticky GC. This prevents the heap from </span><br><span class="line">always growing more than the target utilization, </span><br><span class="line">while ensuring that we do sticky GC often.</span><br></pre></td></tr></table></figure></p><p>建议随着后面不断的深入学习再回过来读这段话，相信会理解的更深。<br>大概意思是我们会尽可能的使用sticky的回收方式，这种回收只会回收自上次GC以来新分配的对象，是一种轻量回收方式，但是回收力度有限。</p><p>当剩余的可用空间低于设定的最小值即min_free，此时将下次GC类别设定为partial GC，加大回收的力度，但是当我们使用partial GC或者full GC后，应该将下次GC类型设定为sticky，从而避免堆的使用率经常超过目标值(默认0.75)，所以需要经常进行sticky方式的回收。</p><h5 id="对应用影响程度划分"><a href="#对应用影响程度划分" class="headerlink" title="对应用影响程度划分"></a>对应用影响程度划分</h5><p>如果基于GC对应用状态的影响分类的话，大致可以分为并发类和阻塞类。<br>并发类GC：GC在GC回收线程(HeapTaskDaemon)执行，阻塞类GC在进程的工作线程执行。</p><p><img src="http://blog.lihaizhou.top/ART_GC/ART_GC1.png" alt="图片"><br>需要注意这里的GcCauseBackground，这里的“Background”并不是指应用切到后台才会执行GC，而是GC在运行时基本不会影响其他线程的执行，即并发GC。</p><p>有了上面的知识铺垫，下面将进入本文最重要的部分，将依次介绍Multiplier的引入，target_size计算过程，concurrent_start_bytes_计算过程这三部分。<br>这三部分相互关联，为了能够更直观的理解这三部分的关系，本地画了一个整体的概览图(花了大半小时画完…….)，后面的内容主要也是围绕下面这个图进行讲解。<br><img src="http://blog.lihaizhou.top/ART_GC/ART_GC2.png" alt="图片"><br>现在看不懂没有关系，在阅读完后面的内容之后，再回过头来看这个图，相信会理解的更加深刻。</p><h4 id="Multiplier的引入"><a href="#Multiplier的引入" class="headerlink" title="Multiplier的引入"></a>Multiplier的引入</h4><p>我们在后面计算预留内存的时候，不论是否是sticky回收，都会使用到Multiplier。<br>这个值主要是为了前台应用设定的，引入该值目的是为了提升前台应用的性能，代价是堆的利用率下降，关于对性能的影响，下面会进行说明。</p><p>先看下对于Multiplier的值来源<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">art/runtime/runtime.cc</span><br><span class="line"><span class="comment">//Extra added to the default heap growth multiplier. </span></span><br><span class="line"><span class="comment">//Used to adjust the GC ergonomics for the read barrier config.</span></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">constexpr</span> <span class="keyword">double</span> kExtraDefaultHeapGrowthMultiplier = kUseReadBarrier ? <span class="number">1.0</span> : <span class="number">0.0</span>;</span><br><span class="line"><span class="keyword">float</span> foreground_heap_growth_multiplier;</span><br><span class="line"><span class="keyword">if</span> (is_low_memory_mode_ &amp;&amp; !runtime_options.Exists(Opt::ForegroundHeapGrowthMultiplier)) &#123;</span><br><span class="line">   <span class="comment">// If low memory mode, use 1.0 as the multiplier by default.</span></span><br><span class="line">   foreground_heap_growth_multiplier = <span class="number">1.0f</span>;</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">   foreground_heap_growth_multiplier =</span><br><span class="line">   runtime_options.GetOrDefault(Opt::ForegroundHeapGrowthMultiplier) +</span><br><span class="line">   kExtraDefaultHeapGrowthMultiplier;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>后台时Multiplier为1，我们主要看下前台的值，最新Android版本上都是支持ReadBarrier的，那么kExtraDefaultHeapGrowthMultiplier值也就是1。<br>再看下ForegroundHeapGrowthMultiplier的值来源于如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">static constexpr double kDefaultHeapGrowthMultiplier = 2.0;</span><br></pre></td></tr></table></figure><p>所以对于前台应用，Multiplier默认的值是2+1=3。</p><p>下面讲的堆大小的调整，下次GC触发阈值计算都是在GrowForUtilization中发生的，而GrowForUtilization又是在CollectGarbageInternal触发的，所以有必要先介绍下CollectGarbageInternal主要做的事情:</p><ol><li>调用RequestTrim做实际的堆裁剪，将空闲内存归还给系统，这块的内容细节较多，后面会另起一篇文章进行详细的介绍；</li><li>第二步会执行SelfDeletingTask* clear = reference_processor_-&gt;CollectClearedReferences(self);</li><li>第三步也是我们本文重点介绍的一步，这一步将进行堆大小的调整以及计算下次触发GC的阈值</li></ol><p>那么什么时候会触发CollectGarbageInternal进行垃圾回收呢？<br><strong>在ART分配对象失败或者已使用内存超过某个设定的阈值就会触发</strong></p><h4 id="堆最大可分配字节数的计算"><a href="#堆最大可分配字节数的计算" class="headerlink" title="堆最大可分配字节数的计算"></a>堆最大可分配字节数的计算</h4><p>堆最大可分配字节数指的是代码中的target_size，一个仅具有指导意义的最大可分配字节数，为何说仅有指导意义，后面会解释。</p><p>在此之前，我们先了解下Sticky GC是什么？<br>谷歌对此的定义如下:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Sticky mark bits GC that attempts to only free objects </span><br><span class="line">allocated since the last GC.</span><br></pre></td></tr></table></figure></p><p>Sticky GC只会回收自上次GC以来新分配的对象，是分代GC下的一种GC类型，也可以理解为Young-generation GC，那么非kGcTypeSticky指的是哪些GC类别呢？对应Partial GC以及Full GC。</p><p>那么什么时候会使用Sticky GC，什么时候会触发Partial GC以及Full GC呢？后面GC系列文章会进行讲解，总体而言，执行Sticky GC频率最高，最低是Full GC。</p><p>下面会看下kGcTypeSticky以及非kGcTypeSticky类别GC的target_size计算过程。</p><h5 id="非kGcTypeSticky-GC"><a href="#非kGcTypeSticky-GC" class="headerlink" title="非kGcTypeSticky GC"></a>非kGcTypeSticky GC</h5><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (gc_type != collector::kGcTypeSticky) &#123;  </span><br><span class="line"><span class="comment">// Grow the heap for non sticky GC.  </span></span><br><span class="line"><span class="keyword">uint64_t</span> delta = bytes_allocated * (<span class="number">1.0</span> / GetTargetHeapUtilization() - <span class="number">1.0</span>);  </span><br><span class="line">DCHECK_LE(delta, <span class="built_in">std</span>::numeric_limits&lt;<span class="keyword">size_t</span>&gt;::max()) &lt;&lt; <span class="string">"bytes_allocated="</span> &lt;&lt;bytes_allocated  &lt;&lt; <span class="string">" target_utilization_="</span> &lt;&lt; target_utilization_;</span><br><span class="line">grow_bytes = <span class="built_in">std</span>::min(delta, <span class="keyword">static_cast</span>&lt;<span class="keyword">uint64_t</span>&gt;(max_free_));</span><br><span class="line">grow_bytes = <span class="built_in">std</span>::max(grow_bytes, <span class="keyword">static_cast</span>&lt;<span class="keyword">uint64_t</span>&gt;(min_free_));</span><br><span class="line">target_size = bytes_allocated + <span class="keyword">static_cast</span>&lt;<span class="keyword">uint64_t</span>&gt;(grow_bytes * multiplier);  </span><br><span class="line">next_gc_type_ = collector::kGcTypeSticky;&#125;</span><br></pre></td></tr></table></figure><p>注意这行代码<br><code>bytes_allocated * (1.0 / GetTargetHeapUtilization() - 1.0);</code><br>这里有一个容易陷入的误区，如果单纯的看头文件中的定义注释</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//Target ideal heap utilization ratio, implements //dalvik.system.VMRuntime.getTargetHeapUtilization.double GetTargetHeapUtilization() </span></span><br><span class="line"><span class="keyword">const</span> &#123;</span><br><span class="line">   <span class="keyword">return</span> target_utilization_;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>可能会认为这个值返回的是默认的最优值0.75，其实这个值是一个动态变化的值，当一次GC发生后，堆的大小会resize。<br>此时GetTargetHeapUtilization的值等于存活对象大小除以堆的大小，算出的delta是除去已分配的字节数后空闲的大小。<br>算出delta后，我们接着往下看，可以看到grow_bytes并不单纯由delta决定，还会受到max_free_以及min_free_的影响，最终确保grow_bytes 的值不会超出这两个值范围。<br>这里的max_free_本意是target_size与已分配内存间可允许的最大差异，差异过小会导致GC频繁，差异过大会延迟下一次GC的到来，目前很多设备将这个值设为8M，min_free_为512K。其实针对RAM超过6G的大内存设备，Google建议可以提高min_free_，用空间换时间获取更好的GC性能。</p><p>有了grow_bytes 之后，再根据如下代码<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bytes_allocated + static_cast&lt;uint64_t&gt;(grow_bytes * multiplier);</span><br></pre></td></tr></table></figure></p><p>计算出目标堆大小。<br>大致的过程可以用下图表示<br><img src="http://blog.lihaizhou.top/ART_GC/ART_GC3.png" alt="图片"></p><h5 id="kGcTypeSticky-GC"><a href="#kGcTypeSticky-GC" class="headerlink" title="kGcTypeSticky GC"></a>kGcTypeSticky GC</h5><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// If we have freed enough memory, shrink the heap back down.</span></span><br><span class="line"><span class="keyword">const</span> <span class="keyword">size_t</span> adjusted_max_free = <span class="keyword">static_cast</span>&lt;<span class="keyword">size_t</span>&gt;(max_free_ * multiplier);</span><br><span class="line"><span class="keyword">if</span> (bytes_allocated + adjusted_max_free &lt; target_footprint) &#123;</span><br><span class="line">    target_size = bytes_allocated + adjusted_max_free;  </span><br><span class="line">    grow_bytes = max_free_;</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">target_size = <span class="built_in">std</span>::max(bytes_allocated, target_footprint);  </span><br><span class="line"><span class="comment">// The same whether jank perceptible or not; just avoid the adjustment.  </span></span><br><span class="line">grow_bytes = <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>对于本次是非kGcTypeSticky回收的方式，设定下次GC类型稍微复杂一些，会涉及到吞吐量之类的指标，后面的GC系列文章中会细谈，这里只关注target_size的计算过程。</p><ul><li>如果bytes_allocated + adjusted_max_free &lt; target_footprint说明此次的GC回收效果明显，注意这里grow_bytes 的值被赋予了max_free_，表示倾向于预留max_free_的空间大小，所以对于这个判断条件中的情况，其grow_bytes 会是一个恒定的值即max_free_。</li><li>否则的话即else中的情况，target_size的值是对bytes_allocated和target_footprint两者取最大，到这里你可能会疑惑bytes_allocated较大的情况，其实是有这个可能的，因为并发的缘故，可能存在GC期间分配大小大于回收数值的情况。</li></ul><p>那么此时target_size设定为bytes_allocated，下次分配对象时，bytes_allocated 立马就超出了target_size，会不会导致分配失败的情况？<br>其实不会，唯一限制堆内存分配的只有growth_limit_，这也解释了为何我们前面说target_size只有指导意义，但是这种情况确实会立即触发一次GC。</p><p>下面是谷歌的一段commit message对OOM的解释<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Are we out of memory, and thus should force a GC or fail?</span><br><span class="line">For concurrent collectors,out of memory is defined by growth_limit_</span><br><span class="line">For nonconcurrent collectors it is defined by target_footprint_ </span><br><span class="line">unless grow is set.If grow is set, the limit is growth_limit_ </span><br><span class="line">and we adjust target_footprint_to accomodate the allocation.</span><br></pre></td></tr></table></figure></p><p>这个时候，你可能还有疑问，为啥不将此时的target_size适当的增大，其实是因为此时的GC是Sticky，只回收自上次GC以来新分配的对象，回收力度是比较小的。<br>如果它释放的空间不多，接下来还可以用Full GC来更彻底地回收。<br>换言之，只有等Full GC回收完，才决定将GC的水位提升，因为这时已经尝试了所有回收策略。</p><p><strong>再回到上面提到的问题，multiplier的引入为何能够提升前台应用的性能？</strong><br>关于target_size 的计算过程中，不论是否是kGcTypeSticky方式，都涉及到了multiplier因子，multiplier的引入直接改变了前台应用的target_size值，此时你可能会疑惑这样的话堆使用率不就下降了吗？ <strong>其实这是一种空间换时间的做法</strong></p><p>如果堆大小扩展的不多，那么对于前台应用很快就会用完，下次GC便会早早的到来，虽说现在只有一次暂停，但是仍然可能会带来性能问题。<br>引入multiplier之后，前台应用有了足够的堆空间，会延迟下次GC到来的时间，也可以理解为降低GC的频率。</p><p>画了一个堆大小调整图，针对delta处于min_free和max_free之间的情况<br><img src="http://blog.lihaizhou.top/ART_GC/ART_GC4.png" alt="图片"><br>堆空间调整过程明白了，那么下次GC触发阈值是如何计算出来的呢？</p><h4 id="GC触发阈值的计算"><a href="#GC触发阈值的计算" class="headerlink" title="GC触发阈值的计算"></a>GC触发阈值的计算</h4><p>下面我们将继续往下看，下次GC触发阈值在代码中指的是concurrent_start_bytes_。<br>当我们在Java中通过new分配对象时，VM会调用AllocObjectWithAllocator来执行真实的分配。<br>在每一次成功分配Java对象后，都会去检测是否需要进行下一次GC，这就是GcCauseBackground GC的触发时机。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">AllocObjectWithAllocator-&gt;CheckConcurrentGCForJava-&gt;ShouldConcurrentGCForJava</span><br></pre></td></tr></table></figure><p>关键代码<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">inline</span> <span class="keyword">bool</span> Heap::ShouldConcurrentGCForJava(</span><br><span class="line">    <span class="keyword">size_t</span> new_num_bytes_allocated) &#123;</span><br><span class="line">    <span class="comment">// For a Java allocation, we only check whether the number // of Java allocated bytes excceeds a threshold. </span></span><br><span class="line">    <span class="comment">// By not considering native allocation here, we (a) ensure that Java heap bounds are</span></span><br><span class="line">    <span class="comment">// maintained, and (b) reduce the cost of the check here.</span></span><br><span class="line">    <span class="keyword">return</span> new_num_bytes_allocated &gt;= concurrent_start_bytes_;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>触发的条件需要满足一个判断，就是最后一行代码new_num_bytes_allocated(所有已分配的字节数，包括此次新分配的对象) &gt;= concurrent_start_bytes_(下一次GC触发的阈值)，就请求一次新的GC。<br>new_num_bytes_alloated是当前分配时计算的，concurrent_start_bytes_是上次GC结束时计算的。</p><h5 id="更新target-footprint-值"><a href="#更新target-footprint-值" class="headerlink" title="更新target_footprint_ 值"></a>更新target_footprint_ 值</h5><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (!ignore_target_footprint_) &#123;</span><br><span class="line">    SetIdealFootprint(target_size);</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">void</span> Heap::SetIdealFootprint(<span class="keyword">size_t</span> target_footprint) &#123;</span><br><span class="line">   <span class="keyword">if</span> (target_footprint &gt; GetMaxMemory()) &#123;</span><br><span class="line">       VLOG(gc) &lt;&lt; <span class="string">"Clamp target GC heap from "</span> &lt;&lt; PrettySize(target_footprint) &lt;&lt; <span class="string">" to "</span></span><br><span class="line">       &lt;&lt; PrettySize(GetMaxMemory());</span><br><span class="line">       target_footprint = GetMaxMemory();</span><br><span class="line">   &#125;</span><br><span class="line">   target_footprint_.store(target_footprint, <span class="built_in">std</span>::memory_order_relaxed);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>存储target_size的值，并通过target_size更新target_footprint_ 的值</p><h5 id="concurrent-start-bytes"><a href="#concurrent-start-bytes" class="headerlink" title="concurrent_start_bytes_"></a>concurrent_start_bytes_</h5><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Minimum amount of remaining bytes before a concurrent GC is triggered.</span></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">constexpr</span> <span class="keyword">size_t</span> kMinConcurrentRemainingBytes = <span class="number">128</span> * KB;</span><br><span class="line"><span class="keyword">static</span> <span class="keyword">constexpr</span> <span class="keyword">size_t</span> kMaxConcurrentRemainingBytes = <span class="number">512</span> * KB;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (IsGcConcurrent()) &#123;</span><br><span class="line">    <span class="keyword">const</span> <span class="keyword">uint64_t</span> freed_bytes = current_gc_iteration_.GetFreedBytes() +</span><br><span class="line">    current_gc_iteration_.GetFreedLargeObjectBytes() +</span><br><span class="line">    current_gc_iteration_.GetFreedRevokeBytes();</span><br><span class="line">    <span class="comment">// Records the number of bytes allocated at the time of GC finish,excluding the number of</span></span><br><span class="line">    <span class="comment">// bytes allocated during GC.</span></span><br><span class="line">    num_bytes_alive_after_gc_ = UnsignedDifference(bytes_allocated_before_gc, freed_bytes);</span><br><span class="line">    <span class="comment">// Bytes allocated will shrink by freed_bytes after the GC runs, so if we want to figure out</span></span><br><span class="line">    <span class="comment">// how many bytes were allocated during the GC we need to add freed_bytes back on.</span></span><br><span class="line">    <span class="comment">// Almost always bytes_allocated + freed_bytes &gt;= bytes_allocated_before_gc.</span></span><br><span class="line">    <span class="keyword">const</span> <span class="keyword">size_t</span> bytes_allocated_during_gc =</span><br><span class="line">          UnsignedDifference(bytes_allocated + freed_bytes, bytes_allocated_before_gc);</span><br><span class="line">    <span class="comment">// Calculate when to perform the next ConcurrentGC.</span></span><br><span class="line">    <span class="comment">// Estimate how many remaining bytes we will have when we need to start the next GC.</span></span><br><span class="line">    <span class="keyword">size_t</span> remaining_bytes = bytes_allocated_during_gc;</span><br><span class="line">    remaining_bytes = <span class="built_in">std</span>::min(remaining_bytes, kMaxConcurrentRemainingBytes);</span><br><span class="line">    remaining_bytes = <span class="built_in">std</span>::max(remaining_bytes, kMinConcurrentRemainingBytes);</span><br><span class="line">    <span class="keyword">size_t</span> target_footprint = target_footprint_.load(<span class="built_in">std</span>::memory_order_relaxed);</span><br><span class="line">    <span class="keyword">if</span> (UNLIKELY(remaining_bytes &gt; target_footprint)) &#123;</span><br><span class="line">       <span class="comment">// A never going to happen situation that from the estimated allocation rate we will exceed</span></span><br><span class="line">      <span class="comment">// the applications entire footprint with the given estimated allocation rate. Schedul</span></span><br><span class="line">      <span class="comment">// another GC nearly straight away.</span></span><br><span class="line">      remaining_bytes = <span class="built_in">std</span>::min(kMinConcurrentRemainingBytes, target_footprint);</span><br><span class="line">     &#125;</span><br><span class="line">     DCHECK_LE(target_footprint_.load(<span class="built_in">std</span>::memory_order_relaxed), GetMaxMemory());</span><br><span class="line">     <span class="comment">// Start a concurrent GC when we get close to the estimated remaining bytes. When the</span></span><br><span class="line">     <span class="comment">// allocation rate is very high, remaining_bytes could tell us that we should start a GC</span></span><br><span class="line">     <span class="comment">// right away.</span></span><br><span class="line">     concurrent_start_bytes_ = <span class="built_in">std</span>::max(target_footprint - remaining_bytes, bytes_allocated);</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure><p>整个处理过程大致流程如下：</p><ol><li>num_bytes_alive_after_gc_此次GC结束后已分配的字节数，不包括GC期间新分配的字节数</li><li>bytes_allocated_during_gcGC<br>期间分配的字节数，计算很简单，通过bytes_allocated_before_gc减去freed_bytes就 是新增的，因为由于并发的缘故，分配和回收很可能是同步进行的，这个思想将贯穿整个GC机制。</li><li>remaining_bytes这个值指的是gc期间新分配对象的大小。<br>同样的，对于预留值也有范围限制，限制在128 <em> KB到512 </em> KB范围之间之间。</li></ol><p>最后再来看这个计算公式concurrent_start_bytes_ =<br><code>std::max(target_footprint - remaining_bytes, bytes_allocated);</code></p><p>之所以需要用target_footprint减去remaining_bytes，是因为在理论意义上，target_footprint_代表当前堆的最大可分配字节数。而由于是同步GC，回收的过程中可能会有其他线程依然在分配。<br>所以为了保证下次GC的顺利进行，需要将这段时间分配的内存空间预留出来。<br>总结下concurrent_start_bytes_ 的值计算过程:<br><strong>用heap resize之后计算出的target_size减去remaining_bytes后的数值，得出来的concurrent_start_bytes_ 作为下次是否触发GC的阈值。</strong></p><h5 id="Systrace角度看GC"><a href="#Systrace角度看GC" class="headerlink" title="Systrace角度看GC"></a>Systrace角度看GC</h5><p>我们平时工作中，分析GC性能问题用到最多的便是Systrace<br>下面抓取一次抖音包含启动过程的Systrace，看下GC情况以及堆大小的变化情况。<br>在启动过程中，堆的大小持续增长<br><img src="http://blog.lihaizhou.top/ART_GC/ART_GC5.png" alt="图片"></p><p>启动结束后约1s左右，有一次Background young concurrent copying GC<br><img src="http://blog.lihaizhou.top/ART_GC/ART_GC6.png" alt="图片"></p><p>可以看到heap size从59M下降到约11M<br>此时处于前台很快数值上升，并触发Background concurrent copying GC<br><img src="http://blog.lihaizhou.top/ART_GC/ART_GC7.png" alt="图片"></p><p>这两次GC类型都是并发GC，以界面显示后的第一次Background young concurrent copying GC为例<br>从Systrace大致可以看到其流程是<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">InitializePhase(995us692ns)-&gt;CopyingPhase(84ms258us385ns) -&gt;ReclaimPhase(11ms 166us 769ns)</span><br></pre></td></tr></table></figure></p><p>对应到代码中大致流程如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CollectGarbageInternal---&gt; collector---&gt;Run(开始真正的GC流程)---&gt; RunPhases(GC实际处理)</span><br></pre></td></tr></table></figure></p><h4 id="参数修改策略"><a href="#参数修改策略" class="headerlink" title="参数修改策略"></a>参数修改策略</h4><p>通过上面的梳理，我们知道GC的触发以及堆大小的调整会受到max_free_，min_free_，kDefaultTargetUtilization 这些参数影响，这些参数其实有系统属性暴露在外，厂商可以根据实际的需求进行修改。<br>以max_free为例，看了下手头的4G手机项目上默认值是8M，从前面的梳理我们知道，如果增大max_free会导致应用的预留空闲内存增大，相应的应用占用内存大小也会增大，这是带来的弊端。<br>但是好处显而易见，GC的频率会降低，性能会有所提升，所以这是一个权衡的策略。</p><p>如果项目上实测发现GC频繁触发，可以适当的增大max_free的值再进行测试，谷歌的建议是不要修改，除非有大量可靠的测试数据做支撑说明修改后的参数确实有提升。</p><p>下面是我手头4G内存手机打印的参数<br><img src="http://blog.lihaizhou.top/ART_GC/ART_GC8.png" alt="图片"></p><h4 id="写在最后"><a href="#写在最后" class="headerlink" title="写在最后"></a>写在最后</h4><p>至此，本文结合Android S源码和systrace对ART GC的基础知识介绍完毕。<br>在书写本文期间，阅读了网上一些优秀的资源，如老罗，芦航，oppo内核等人书写的ART技术文章，受益匪浅，在此感谢这些技术大咖的无私分享。<br>最后说两句，GC对Android整机性能表现起到至关重要的影响，关于ART GC的性能一直是Google在主导优化，同时也是SOC厂商，各家手机厂商长期以来一直努力优化的方向。<br>我们希望通过对ART GC领域的持续研究，为后面的实际问题分析乃至GC机制的优化修改提供技术支撑。</p><h4 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h4><ol><li>ART运行时Foreground GC和Background GC切换过程分<br><a href="https://www.kancloud.cn/alex_wsc/androids/472237" target="_blank" rel="noopener">https://www.kancloud.cn/alex_wsc/androids/472237</a></li><li>Android性能优化（31）—虚拟机调优<br><a href="https://blog.csdn.net/zhangbijun1230/article/details/79996702" target="_blank" rel="noopener">https://blog.csdn.net/zhangbijun1230/article/details/79996702</a></li><li>ART虚拟机 | GC的触发时机和条件<br><a href="https://juejin.cn/post/6875678394332217357" target="_blank" rel="noopener">https://juejin.cn/post/6875678394332217357</a></li></ol><hr><p>时间真快，不知不觉今天已经周三了，印象中上次周三的时候还是在上周</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h4&gt;&lt;p&gt;本文是GC系列文章的首篇，主要为下一篇《第三视角: 一个ART GC优化的故事》文章做铺垫。&lt;br&gt;本文将根据下面的大纲，简单的介绍下GC相
      
    
    </summary>
    
      <category term="ART" scheme="http://lihaizhou.top/categories/ART/"/>
    
    
  </entry>
  
  <entry>
    <title>对进程压缩消费Zram速度的优化</title>
    <link href="http://lihaizhou.top/2021/10/16/%E5%AF%B9%E8%BF%9B%E7%A8%8B%E5%8E%8B%E7%BC%A9%E6%B6%88%E8%B4%B9Zram%E9%80%9F%E5%BA%A6%E7%9A%84%E4%BC%98%E5%8C%96/"/>
    <id>http://lihaizhou.top/2021/10/16/对进程压缩消费Zram速度的优化/</id>
    <published>2021-10-16T02:32:08.000Z</published>
    <updated>2021-10-16T04:59:55.000Z</updated>
    
    <content type="html"><![CDATA[<h4 id="从全局看Zram"><a href="#从全局看Zram" class="headerlink" title="从全局看Zram"></a>从全局看Zram</h4><p><img src="http://blog.lihaizhou.top/%E8%BF%9B%E7%A8%8B%E5%8E%8B%E7%BC%A9%E6%B6%88%E8%80%97Zram/gaitubao_Zram.png" alt="Zram的消费"></p><h4 id="修改演变历程"><a href="#修改演变历程" class="headerlink" title="修改演变历程"></a>修改演变历程</h4><p><img src="http://blog.lihaizhou.top/%E8%BF%9B%E7%A8%8B%E5%8E%8B%E7%BC%A9%E6%B6%88%E8%80%97Zram/shuiyin_yanbian.png" alt="进程压缩对Zram的消耗修改时间线"></p><h4 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h4><p>当前的修改方案可能不是最优方案，但是解决了之前遇到的实际问题，后面如果遇到新的问题可能还会进行调整。</p><hr><p>Have a good day~</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;从全局看Zram&quot;&gt;&lt;a href=&quot;#从全局看Zram&quot; class=&quot;headerlink&quot; title=&quot;从全局看Zram&quot;&gt;&lt;/a&gt;从全局看Zram&lt;/h4&gt;&lt;p&gt;&lt;img src=&quot;http://blog.lihaizhou.top/%E8%BF%9B%
      
    
    </summary>
    
      <category term="内存" scheme="http://lihaizhou.top/categories/%E5%86%85%E5%AD%98/"/>
    
    
  </entry>
  
  <entry>
    <title>AMS锁严重竞争导致的整机卡顿</title>
    <link href="http://lihaizhou.top/2021/09/18/AMS%E9%94%81%E4%B8%A5%E9%87%8D%E7%AB%9E%E4%BA%89%E5%AF%BC%E8%87%B4%E7%9A%84%E6%95%B4%E6%9C%BA%E5%8D%A1%E9%A1%BF/"/>
    <id>http://lihaizhou.top/2021/09/18/AMS锁严重竞争导致的整机卡顿/</id>
    <published>2021-09-18T02:37:49.000Z</published>
    <updated>2021-10-16T05:13:46.000Z</updated>
    
    <content type="html"><![CDATA[<h5 id="日志抓取"><a href="#日志抓取" class="headerlink" title="日志抓取"></a>日志抓取</h5><p>在问题机器上抓了一份Systrace<br>1.操作步骤: 进入设置界面滑动再退出<br>2.问题现象: 进入设置出现较长时间白屏，退出时有拖影，下拉状态栏尤为卡顿，解锁亮屏很慢。</p><h5 id="问题分析"><a href="#问题分析" class="headerlink" title="问题分析"></a>问题分析</h5><p>从下图可以看到进入设置时，Resume耗时近400ms，主要耗费在等binder上<br><img src="http://blog.lihaizhou.top/AMS_lock/broadcast1.png" alt=""><br>来到对端1188_19线程所在区域，看下这个时间点1188_19在做什么操作？<br><img src="http://blog.lihaizhou.top/AMS_lock/broadcast2.png" alt=""><br>1188_19是SystemServer中的线程，从上图可以看出，它在等AMS锁<br>到这里大致梳理如下<br>1.进入设置应用走到onResume环节时，调用到AMS的registerReceiverWithFeature注册广播，这是应用启动过程中很常见的操作，但是此时registerReceiverWithFeature执行操作被block了，因为执行registerReceiverWithFeature需要申请到AMS锁才行。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> Intent <span class="title">registerReceiverWithFeature</span><span class="params">(IApplicationThread caller, String callerPackage,</span></span></span><br><span class="line"><span class="function"><span class="params">   String callerFeatureId, IIntentReceiver receiver, IntentFilter filter,</span></span></span><br><span class="line"><span class="function"><span class="params">   String permission, <span class="keyword">int</span> userId, <span class="keyword">int</span> flags)</span> </span>&#123;</span><br><span class="line">   <span class="comment">//省略部分代码</span></span><br><span class="line">   <span class="keyword">boolean</span> instantApp;</span><br><span class="line">   <span class="keyword">synchronized</span>(<span class="keyword">this</span>) &#123;</span><br><span class="line">      <span class="keyword">if</span> (caller != <span class="keyword">null</span>) &#123;</span><br><span class="line">          callerApp = getRecordForAppLocked(caller);</span><br><span class="line">          <span class="keyword">if</span> (callerApp == <span class="keyword">null</span>) &#123;</span><br><span class="line">              <span class="keyword">throw</span> <span class="keyword">new</span> SecurityException(</span><br><span class="line">                  <span class="string">"Unable to find app for caller "</span> + caller</span><br><span class="line">                      + <span class="string">" (pid="</span> + Binder.getCallingPid()</span><br><span class="line">                      + <span class="string">") when registering receiver "</span> + receiver);</span><br><span class="line">          &#125;</span><br><span class="line">          <span class="comment">//省略部分代码</span></span><br><span class="line">      &#125;</span><br><span class="line">    <span class="comment">//省略部分代码</span></span><br></pre></td></tr></table></figure><p>2.此时Settings的registerReceiverWithFeature在等ActivityManagerService#finishReceiver释放锁，但其实ActivityManagerService#finishReceiver本身也是在等锁，锁在1188_6这个线程手中。<br>图中有一处waiters=6说明还有其它六处加上这次调用共计7处在等AMS的锁<br>纵观整个应用操作片段，发现很多地方都在等AMS锁，这也说明了为何系统会全局卡顿。</p><p>看下真正持有锁的1188_6这个线程,这个线程持有锁的这段时间内，大部分时候都是running状态<br><img src="http://blog.lihaizhou.top/AMS_lock/broadcast3.png" alt=""><br>全局搜索了下在一分钟不到的时间内触发了197次，而且单次基本都在200ms之久。<br><img src="http://blog.lihaizhou.top/AMS_lock/broadcast4.png" alt=""><br>为此对比了下正常情况下的Systrace，两分钟的时间内共触发14次，平均一分钟7次，且每次updateOomAdj_finishReceiver执行时间都不超过1ms<br><img src="http://blog.lihaizhou.top/AMS_lock/broadcast5.png" alt=""></p><p>到这里大概整理下<br>1.<strong>为何updateOomAdj_finishReceiver会调用这么频繁?</strong><br>  updateOomAdj_finishReceiver是在广播处理结束后会触发调用，问题机器上一分钟调用197次，正常情况下一分钟调用次数是个位数.<br>2.<strong>为何updateOomAdj_finishReceiver耗时这么久?</strong><br>  单次执行都在200ms左右，这也意味着每次持有AMS锁大概200ms，也就意味着一分钟的时间finishReceiver持有AMS锁时间高达39s，这也解释了从Systrace看很多地方都在等AMS锁。<br>  测试了下正常情况下，updateOomAdj_finishReceiver单次执行时间最长一般不会超过1ms</p><p>下面先从广播来源分析，updateOomAdj_finishReceiver触发频繁的原因</p><h6 id="频繁触发原因"><a href="#频繁触发原因" class="headerlink" title="频繁触发原因"></a>频繁触发原因</h6><p>以导致设置应用resume耗时严重的这次updateOomAdj_finishReceiver为例<br><img src="http://blog.lihaizhou.top/AMS_lock/broadcast6.png" alt=""><br>1416对应的是SystemUI中线程，直接来到SystemServer区域看下广播部分<br><img src="http://blog.lihaizhou.top/AMS_lock/broadcast7.png" alt=""><br>再从全局来看<br><img src="http://blog.lihaizhou.top/AMS_lock/broadcast8.png" alt=""><br>可以看到com.android.providers.media.module以及SystemUI这两个模块在交替不间断的发送android.intent.action.MEDIA_SCANNER_SCAN_FILE这个广播，查看代码得知是com.android.providers.media.module这个模块处理扫描文件事务后会发送MEDIA_SCANNER_SCAN_FILE这个广播给SystemUI，SystemUI收到这个广播进行一系列的业务处理，然后再次发送MEDIA_SCANNER_SCAN_FILE这个广播出来。<br>这种业务设计肯定是不合理的，这里暂不继续讨论这种做法的缘由。</p><h6 id="单次处理耗时"><a href="#单次处理耗时" class="headerlink" title="单次处理耗时"></a>单次处理耗时</h6><p><img src="http://blog.lihaizhou.top/AMS_lock/broadcast9.png" alt=""><br>从上图可以看到，问题发生时，SystemUI模块中单次处理该模块耗时达到1s多，这也和问题机器上SystemUI下拉栏滑动极其卡顿能够对应上。<br>结论: SystemUI主线程中广播处理耗时导致滑动很卡顿</p><h5 id="问题结论"><a href="#问题结论" class="headerlink" title="问题结论"></a>问题结论</h5><p>主要由于如下两点原因导致:<br>1.SystemUI中不合理的高频广播，导致AMS@finishReceiver触发频繁并持有AMS锁，造成了全局AMS锁争抢极其严重。<br>2.SystemUI主线程中单次处理广播耗时较长，加剧了卡顿的现象。</p><p>PS: SystemUI这个模块比较特殊，它不像其他应用模块。对于应用模块而言，即便是一直收发广播，卡顿也只是会局限在这个应用操作环节中，不会影响到其他模块。但是SystemUI就不同了，它是可以一直运行着，并且此时你可以操作其他任何应用。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h5 id=&quot;日志抓取&quot;&gt;&lt;a href=&quot;#日志抓取&quot; class=&quot;headerlink&quot; title=&quot;日志抓取&quot;&gt;&lt;/a&gt;日志抓取&lt;/h5&gt;&lt;p&gt;在问题机器上抓了一份Systrace&lt;br&gt;1.操作步骤: 进入设置界面滑动再退出&lt;br&gt;2.问题现象: 进入设置出现较长时
      
    
    </summary>
    
      <category term="性能" scheme="http://lihaizhou.top/categories/%E6%80%A7%E8%83%BD/"/>
    
    
  </entry>
  
  <entry>
    <title>GC超时导致的后台应用崩溃问题分析</title>
    <link href="http://lihaizhou.top/2021/09/08/GC%E8%B6%85%E6%97%B6%E5%AF%BC%E8%87%B4%E7%9A%84%E5%90%8E%E5%8F%B0%E5%BA%94%E7%94%A8%E5%B4%A9%E6%BA%83%E9%97%AE%E9%A2%98%E5%88%86%E6%9E%90/"/>
    <id>http://lihaizhou.top/2021/09/08/GC超时导致的后台应用崩溃问题分析/</id>
    <published>2021-09-08T11:55:06.000Z</published>
    <updated>2022-03-12T14:32:46.809Z</updated>
    
    <content type="html"><![CDATA[<h3 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h3><p>这个问题之所以会拿出来仔细分析，一方面是因为这个问题不是简单的应用崩溃而是框架层的报错，另一方面是因为希望通过这个问题梳理下后台GC的超时检测机制怎样的，这样我们后面在应用层如果重写<code>finalize</code>方法回收时会考虑的更加全面点。</p><h3 id="问题背景"><a href="#问题背景" class="headerlink" title="问题背景"></a>问题背景</h3><p>复现概率: 偶现<br>问题版本: <code>Android R</code><br>问题现象: 处于微信界面，突然弹出王者荣耀停止运行</p><h3 id="初步分析"><a href="#初步分析" class="headerlink" title="初步分析"></a>初步分析</h3><p>拿到问题日志后，先看下报错的堆栈<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">09</span>-<span class="number">02</span> <span class="number">20</span>:<span class="number">53</span>:<span class="number">26.679</span>  <span class="number">2073</span>  <span class="number">2089</span> E AndroidRuntime: FATAL EXCEPTION: FinalizerWatchdogDaemon</span><br><span class="line"><span class="number">09</span>-<span class="number">02</span> <span class="number">20</span>:<span class="number">53</span>:<span class="number">26.679</span>  <span class="number">2073</span>  <span class="number">2089</span> E AndroidRuntime: Process: com.tencent.tmgp.sgame:xg_vip_service, PID: <span class="number">2073</span></span><br><span class="line"><span class="number">09</span>-<span class="number">02</span> <span class="number">20</span>:<span class="number">53</span>:<span class="number">26.679</span>  <span class="number">2073</span>  <span class="number">2089</span> E AndroidRuntime: java.util.concurrent.TimeoutException: android.database.BulkCursorToCursorAdaptor.finalize() timed out after <span class="number">10</span> seconds</span><br><span class="line"><span class="comment">//省略部分堆栈</span></span><br><span class="line"><span class="number">09</span>-<span class="number">02</span> <span class="number">20</span>:<span class="number">53</span>:<span class="number">26.679</span>  <span class="number">2073</span>  <span class="number">2089</span> E AndroidRuntime:at android.database.AbstractCursor.finalize(AbstractCursor.java:<span class="number">524</span>)</span><br><span class="line"><span class="number">09</span>-<span class="number">02</span> <span class="number">20</span>:<span class="number">53</span>:<span class="number">26.679</span>  <span class="number">2073</span>  <span class="number">2089</span> E AndroidRuntime:at java.lang.Daemons$FinalizerDaemon.doFinalize(Daemons.java:<span class="number">291</span>)</span><br><span class="line"><span class="number">09</span>-<span class="number">02</span> <span class="number">20</span>:<span class="number">53</span>:<span class="number">26.679</span>  <span class="number">2073</span>  <span class="number">2089</span> E AndroidRuntime:at java.lang.Daemons$FinalizerDaemon.runInternal(Daemons.java:<span class="number">278</span>)</span><br></pre></td></tr></table></figure></p><p>单单从这段堆栈看的话，<code>BulkCursorToCursorAdaptor</code>执行<code>finalize</code>超过了10s，导致<code>FinalizerWatchdogDaemon</code>报错，<code>FinalizerWatchdogDaemon</code>字面上看像是监测回收超时的守护线程。<br>看下<code>FinalizerWatchdogDaemon</code>代码中的作用解释<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * The watchdog exits the VM if the finalizer ever gets stuck. We consider</span></span><br><span class="line"><span class="comment"> * the finalizer to be stuck if it spends more than MAX_FINALIZATION_MILLIS</span></span><br><span class="line"><span class="comment"> * on one instance.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">FinalizerWatchdogDaemon</span> <span class="keyword">extends</span> <span class="title">Daemon</span> </span>&#123;</span><br><span class="line">    <span class="meta">@UnsupportedAppUsage</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> FinalizerWatchdogDaemon INSTANCE = <span class="keyword">new</span> FinalizerWatchdogDaemon();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">boolean</span> needToWork = <span class="keyword">true</span>;  <span class="comment">// Only accessed in synchronized methods.</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">long</span> finalizerTimeoutNs = <span class="number">0</span>;  <span class="comment">// Lazily initialized.</span></span><br><span class="line"></span><br><span class="line">    FinalizerWatchdogDaemon() &#123;</span><br><span class="line">        <span class="keyword">super</span>(<span class="string">"FinalizerWatchdogDaemon"</span>);</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure></p><p>简单解释下就是：如果对象的<code>finalize</code>出现阻塞超时了会导致进程退出</p><p>这个问题中对应的是数据库的关闭，当然也可以发生在其它场景下，只要重写了成员函数<code>finalize</code>的对象都有可能会遇到这个问题，所以如果再遇到GC超时的报错，报错堆栈<code>AndroidRuntime:at java.lang.Daemons$</code>上面的内容可能会不一样。<br><strong>那么对于重写了成员函数<code>finalize</code>的对象，当它们被GC决定要被回收时，会立刻回收吗？</strong><br>其实不会马上被回收，而是被放入到一个队列中，等待<code>FinalizerDaemon</code>守护线程去调用它们的成员函数<code>finalize</code>后再被回收。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * This heap management thread moves elements from the garbage collector's</span></span><br><span class="line"><span class="comment"> * pending list to the managed reference queue.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">ReferenceQueueDaemon</span> <span class="keyword">extends</span> <span class="title">Daemon</span> </span>&#123;</span><br><span class="line">    <span class="meta">@UnsupportedAppUsage</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> ReferenceQueueDaemon INSTANCE = <span class="keyword">new</span> ReferenceQueueDaemon();</span><br><span class="line"></span><br><span class="line">    ReferenceQueueDaemon() &#123;</span><br><span class="line">        <span class="keyword">super</span>(<span class="string">"ReferenceQueueDaemon"</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span> <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">runInternal</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">while</span> (isRunning()) &#123;</span><br><span class="line">            Reference&lt;?&gt; list;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                <span class="keyword">synchronized</span> (ReferenceQueue.class) &#123;</span><br><span class="line">                    <span class="keyword">while</span> (ReferenceQueue.unenqueued == <span class="keyword">null</span>) &#123;</span><br><span class="line">                        ReferenceQueue.class.wait();</span><br><span class="line">                    &#125;</span><br><span class="line">                    list = ReferenceQueue.unenqueued;</span><br><span class="line">                    ReferenceQueue.unenqueued = <span class="keyword">null</span>;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">                <span class="keyword">continue</span>;</span><br><span class="line">            &#125; <span class="keyword">catch</span> (OutOfMemoryError e) &#123;</span><br><span class="line">                <span class="keyword">continue</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            ReferenceQueue.enqueuePending(list);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="超时阈值"><a href="#超时阈值" class="headerlink" title="超时阈值"></a>超时阈值</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// This used to be final. IT IS NOW ONLY WRITTEN. We now update it when we look at the command</span></span><br><span class="line"><span class="comment">// line argument, for the benefit of mis-behaved apps that might read it.  SLATED FOR REMOVAL.</span></span><br><span class="line"><span class="comment">// There is no reason to use this: Finalizers should not rely on the value. If a finalizer takes</span></span><br><span class="line"><span class="comment">// appreciable time, the work should be done elsewhere.  Based on disassembly of Daemons.class,</span></span><br><span class="line"><span class="comment">// the value is effectively inlined, so changing the field never did have an effect.</span></span><br><span class="line"><span class="comment">// DO NOT USE. FOR ANYTHING. THIS WILL BE REMOVED SHORTLY.</span></span><br><span class="line"><span class="meta">@UnsupportedAppUsage</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">long</span> MAX_FINALIZE_NANOS = <span class="number">10L</span> * <span class="number">1000</span> * NANOS_PER_MILLI;</span><br></pre></td></tr></table></figure><p>注释中对于该值的说明是它很快将被移除，实际这个值在代码中并没有起到真正的作用了，更新它的值是为了方便在外边读取到。<br>真正的超时阈值是通过<code>VMRuntime.getFinalizerTimeoutMs</code>获取，默认值是10s.<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">finalizer_timeout_ms_ = runtime_options.GetOrDefault(Opt::FinalizerTimeoutMs);</span><br><span class="line">RUNTIME_OPTIONS_KEY (unsigned <span class="keyword">int</span>, FinalizerTimeoutMs, <span class="number">10000</span>u)</span><br></pre></td></tr></table></figure></p><h3 id="超时检测"><a href="#超时检测" class="headerlink" title="超时检测"></a>超时检测</h3><p>通过watchdog机制检测<code>finalizer</code>在超时时间内有没有成功析构回收对象<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"> * The watchdog exits the VM <span class="keyword">if</span> the finalizer ever gets stuck. We consider</span><br><span class="line"> * the finalizer to be stuck <span class="keyword">if</span> it spends more than MAX_FINALIZATION_MILLIS</span><br><span class="line"> * on one instance.</span><br><span class="line"> */</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">FinalizerWatchdogDaemon</span> <span class="keyword">extends</span> <span class="title">Daemon</span> </span>&#123;</span><br><span class="line">    <span class="meta">@UnsupportedAppUsage</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> FinalizerWatchdogDaemon INSTANCE = <span class="keyword">new</span> FinalizerWatchdogDaemon();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">boolean</span> needToWork = <span class="keyword">true</span>;  <span class="comment">// Only accessed in synchronized methods.</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">long</span> finalizerTimeoutNs = <span class="number">0</span>;  <span class="comment">// Lazily initialized.</span></span><br><span class="line"></span><br><span class="line">    FinalizerWatchdogDaemon() &#123;</span><br><span class="line">        <span class="keyword">super</span>(<span class="string">"FinalizerWatchdogDaemon"</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span> <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">runInternal</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">while</span> (isRunning()) &#123;</span><br><span class="line">            <span class="keyword">if</span> (!sleepUntilNeeded()) &#123; (<span class="number">1</span>)</span><br><span class="line">                <span class="comment">// We have been interrupted, need to see if this daemon has been stopped.</span></span><br><span class="line">                <span class="keyword">continue</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">final</span> Object finalizing = waitForFinalization();(<span class="number">2</span>)</span><br><span class="line">            <span class="keyword">if</span> (finalizing != <span class="keyword">null</span> &amp;&amp; !VMDebug.isDebuggerConnected()) &#123;</span><br><span class="line">                finalizerTimedOut(finalizing);(<span class="number">3</span>)</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure></p><h4 id="Step1-GC前的检查"><a href="#Step1-GC前的检查" class="headerlink" title="Step1 GC前的检查"></a>Step1 GC前的检查</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">        * Notify daemon that it's OK to sleep until notified that something is ready to be</span></span><br><span class="line"><span class="comment">        * finalized.</span></span><br><span class="line"><span class="comment">        */</span></span><br><span class="line">       <span class="function"><span class="keyword">private</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">goToSleep</span><span class="params">()</span> </span>&#123;</span><br><span class="line">           needToWork = <span class="keyword">false</span>;</span><br><span class="line">       &#125;</span><br><span class="line"></span><br><span class="line">       <span class="comment">/**</span></span><br><span class="line"><span class="comment">        * Notify daemon that there is something ready to be finalized.</span></span><br><span class="line"><span class="comment">        */</span></span><br><span class="line">       <span class="function"><span class="keyword">private</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">wakeUp</span><span class="params">()</span> </span>&#123;</span><br><span class="line">           needToWork = <span class="keyword">true</span>;</span><br><span class="line">           notify();</span><br><span class="line">       &#125;</span><br></pre></td></tr></table></figure><p>开启回收之前，<code>needToWork</code>会被置为true，此时<code>sleepUntilNeeded</code>返回的是true，所以线程不会<code>wait</code><br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Override</span> <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">runInternal</span><span class="params">()</span> </span>&#123;</span><br><span class="line">           <span class="comment">// This loop may be performance critical, since we need to keep up with mutator</span></span><br><span class="line">           <span class="comment">// generation of finalizable objects.</span></span><br><span class="line">           <span class="comment">// We minimize the amount of work we do per finalizable object. For example, we avoid</span></span><br><span class="line">           <span class="comment">// reading the current time here, since that involves a kernel call per object.  We</span></span><br><span class="line">           <span class="comment">// limit fast path communication with FinalizerWatchDogDaemon to what's unavoidable: A</span></span><br><span class="line">           <span class="comment">// non-volatile store to communicate the current finalizable object, e.g. for</span></span><br><span class="line">           <span class="comment">// reporting, and a release store (lazySet) to a counter.</span></span><br><span class="line">           <span class="comment">// We do stop the  FinalizerWatchDogDaemon if we have nothing to do for a</span></span><br><span class="line">           <span class="comment">// potentially extended period.  This prevents the device from waking up regularly</span></span><br><span class="line">           <span class="comment">// during idle times.</span></span><br><span class="line"></span><br><span class="line">           <span class="comment">// Local copy of progressCounter; saves a fence per increment on ARM and MIPS.</span></span><br><span class="line">           <span class="keyword">int</span> localProgressCounter = progressCounter.get();</span><br><span class="line"></span><br><span class="line">           <span class="keyword">while</span> (isRunning()) &#123;</span><br><span class="line">               <span class="keyword">try</span> &#123;</span><br><span class="line">                   <span class="comment">// Use non-blocking poll to avoid FinalizerWatchdogDaemon communication</span></span><br><span class="line">                   <span class="comment">// when busy.</span></span><br><span class="line">                   FinalizerReference&lt;?&gt; finalizingReference = (FinalizerReference&lt;?&gt;)queue.poll();</span><br><span class="line">                   <span class="keyword">if</span> (finalizingReference != <span class="keyword">null</span>) &#123;</span><br><span class="line">                       finalizingObject = finalizingReference.get();</span><br><span class="line">                       progressCounter.lazySet(++localProgressCounter);</span><br><span class="line">                   &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                       finalizingObject = <span class="keyword">null</span>;</span><br><span class="line">                       progressCounter.lazySet(++localProgressCounter);</span><br><span class="line">                       <span class="comment">// Slow path; block.</span></span><br><span class="line">                       FinalizerWatchdogDaemon.INSTANCE.goToSleep();</span><br><span class="line">                       finalizingReference = (FinalizerReference&lt;?&gt;)queue.remove();</span><br><span class="line">                       finalizingObject = finalizingReference.get();</span><br><span class="line">                       progressCounter.set(++localProgressCounter);</span><br><span class="line">                       <span class="comment">//回收之前先唤醒看门狗线程</span></span><br><span class="line">                       FinalizerWatchdogDaemon.INSTANCE.wakeUp();</span><br><span class="line">                   &#125;</span><br><span class="line">                   <span class="comment">//开始回收的流程</span></span><br><span class="line">                   doFinalize(finalizingReference);</span><br><span class="line">               &#125; <span class="keyword">catch</span> (InterruptedException ignored) &#123;</span><br><span class="line">               &#125; <span class="keyword">catch</span> (OutOfMemoryError ignored) &#123;</span><br><span class="line">               &#125;</span><br><span class="line">           &#125;</span><br><span class="line">       &#125;</span><br></pre></td></tr></table></figure></p><p>如果此时线程处于<code>wait</code>，被中断了或者有<code>OOME</code>发生时，这个时候回到开头判断下<code>isRunning()</code>，也就是看下回收对象这个线程是否为空，如果该线程为空的话，这个循环体就没有必要再继续执行下去了。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">        * Wait until something is ready to be finalized.</span></span><br><span class="line"><span class="comment">        * Return false if we have been interrupted</span></span><br><span class="line"><span class="comment">        * See also http://code.google.com/p/android/issues/detail?id=22778.</span></span><br><span class="line"><span class="comment">        */</span></span><br><span class="line">       <span class="function"><span class="keyword">private</span> <span class="keyword">synchronized</span> <span class="keyword">boolean</span> <span class="title">sleepUntilNeeded</span><span class="params">()</span> </span>&#123;</span><br><span class="line">           <span class="keyword">while</span> (!needToWork) &#123;</span><br><span class="line">               <span class="keyword">try</span> &#123;</span><br><span class="line">                   wait();</span><br><span class="line">               &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">                   <span class="comment">// Daemon.stop may have interrupted us.</span></span><br><span class="line">                   <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">               &#125; <span class="keyword">catch</span> (OutOfMemoryError e) &#123;</span><br><span class="line">                   <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">               &#125;</span><br><span class="line">           &#125;</span><br><span class="line">           <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">       &#125;</span><br></pre></td></tr></table></figure></p><h4 id="Step2-等待GC完成"><a href="#Step2-等待GC完成" class="headerlink" title="Step2 等待GC完成"></a>Step2 等待GC完成</h4><p>这一步是等待回收结束的过程，这个睡眠过程中如果被中断，说明在这个周期内完成了析构，直接返回null<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">        * Return an object that took too long to finalize or return null.</span></span><br><span class="line"><span class="comment">        * Wait VMRuntime.getFinalizerTimeoutMs.  If the FinalizerDaemon took essentially the</span></span><br><span class="line"><span class="comment">        * whole time processing a single reference, return that reference.  Otherwise return</span></span><br><span class="line"><span class="comment">        * null.  Only called from a single thread.</span></span><br><span class="line"><span class="comment">        */</span></span><br><span class="line">       <span class="function"><span class="keyword">private</span> Object <span class="title">waitForFinalization</span><span class="params">()</span> </span>&#123;</span><br><span class="line">           <span class="keyword">if</span> (finalizerTimeoutNs == <span class="number">0</span>) &#123;</span><br><span class="line">               finalizerTimeoutNs =</span><br><span class="line">                       NANOS_PER_MILLI * VMRuntime.getRuntime().getFinalizerTimeoutMs();</span><br><span class="line">               <span class="comment">// Temporary app backward compatibility. Remove eventually.</span></span><br><span class="line">               MAX_FINALIZE_NANOS = finalizerTimeoutNs;</span><br><span class="line">           &#125;</span><br><span class="line">           <span class="keyword">long</span> startCount = FinalizerDaemon.INSTANCE.progressCounter.get();</span><br><span class="line">           <span class="comment">// Avoid remembering object being finalized, so as not to keep it alive.</span></span><br><span class="line">           <span class="comment">//如果回收对象没有超时的话，这里会返回null</span></span><br><span class="line">           <span class="keyword">if</span> (!sleepForNanos(finalizerTimeoutNs)) &#123;</span><br><span class="line">               <span class="comment">// Don't report possibly spurious timeout if we are interrupted.</span></span><br><span class="line">               <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">           &#125;</span><br><span class="line">           <span class="keyword">if</span> (getNeedToWork() &amp;&amp; FinalizerDaemon.INSTANCE.progressCounter.get() == startCount) &#123;</span><br><span class="line">               <span class="comment">// We assume that only remove() and doFinalize() may take time comparable to</span></span><br><span class="line">               <span class="comment">// the finalizer timeout.</span></span><br><span class="line">               <span class="comment">// We observed neither the effect of the gotoSleep() nor the increment preceding a</span></span><br><span class="line">               <span class="comment">// later wakeUp. Any remove() call by the FinalizerDaemon during our sleep</span></span><br><span class="line">               <span class="comment">// interval must have been followed by a wakeUp call before we checked needToWork.</span></span><br><span class="line">               <span class="comment">// But then we would have seen the counter increment.  Thus there cannot have</span></span><br><span class="line">               <span class="comment">// been such a remove() call.</span></span><br><span class="line">               <span class="comment">// The FinalizerDaemon must not have progressed (from either the beginning or the</span></span><br><span class="line">               <span class="comment">// last progressCounter increment) to either the next increment or gotoSleep()</span></span><br><span class="line">               <span class="comment">// call.  Thus we must have taken essentially the whole finalizerTimeoutMs in a</span></span><br><span class="line">               <span class="comment">// single doFinalize() call.  Thus it's OK to time out.  finalizingObject was set</span></span><br><span class="line">               <span class="comment">// just before the counter increment, which preceded the doFinalize call.  Thus we</span></span><br><span class="line">               <span class="comment">// are guaranteed to get the correct finalizing value below, unless doFinalize()</span></span><br><span class="line">               <span class="comment">// just finished as we were timing out, in which case we may get null or a later</span></span><br><span class="line">               <span class="comment">// one.  In this last case, we are very likely to discard it below.</span></span><br><span class="line">               Object finalizing = FinalizerDaemon.INSTANCE.finalizingObject;</span><br><span class="line">               sleepForNanos(<span class="number">500</span> * NANOS_PER_MILLI);</span><br><span class="line">               <span class="comment">// Recheck to make it even less likely we report the wrong finalizing object in</span></span><br><span class="line">               <span class="comment">// the case which a very slow finalization just finished as we were timing out.</span></span><br><span class="line">               <span class="keyword">if</span> (getNeedToWork()</span><br><span class="line">                       &amp;&amp; FinalizerDaemon.INSTANCE.progressCounter.get() == startCount) &#123;</span><br><span class="line">                   <span class="keyword">return</span> finalizing;</span><br><span class="line">               &#125;</span><br><span class="line">           &#125;</span><br><span class="line">           <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">       &#125;</span><br></pre></td></tr></table></figure></p><p><code>sleepForNanos</code>对应的函数很简单，如果在超时时间内完成GC，就会计算传进来的超时阈值减去当前已经睡眠的时间，如果这个差值小于0，说明睡眠的时间超过了阈值<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">        * Sleep for the given number of nanoseconds, or slightly longer.</span></span><br><span class="line"><span class="comment">        * <span class="doctag">@return</span> false if we were interrupted.</span></span><br><span class="line"><span class="comment">        */</span></span><br><span class="line">       <span class="function"><span class="keyword">private</span> <span class="keyword">boolean</span> <span class="title">sleepForNanos</span><span class="params">(<span class="keyword">long</span> durationNanos)</span> </span>&#123;</span><br><span class="line">           <span class="comment">// It's important to base this on nanoTime(), not currentTimeMillis(), since</span></span><br><span class="line">           <span class="comment">// the former stops counting when the processor isn't running.</span></span><br><span class="line">           <span class="keyword">long</span> startNanos = System.nanoTime();</span><br><span class="line">           <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">               <span class="keyword">long</span> elapsedNanos = System.nanoTime() - startNanos;</span><br><span class="line">               <span class="keyword">long</span> sleepNanos = durationNanos - elapsedNanos;</span><br><span class="line">               <span class="keyword">if</span> (sleepNanos &lt;= <span class="number">0</span>) &#123;</span><br><span class="line">                   <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">               &#125;</span><br><span class="line">               <span class="comment">// Ensure the nano time is always rounded up to the next whole millisecond,</span></span><br><span class="line">               <span class="comment">// ensuring the delay is &gt;= the requested delay.</span></span><br><span class="line">               <span class="keyword">long</span> sleepMillis = (sleepNanos + NANOS_PER_MILLI - <span class="number">1</span>) / NANOS_PER_MILLI;</span><br><span class="line">               <span class="keyword">try</span> &#123;</span><br><span class="line">                   Thread.sleep(sleepMillis);</span><br><span class="line">               &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">                   <span class="keyword">if</span> (!isRunning()) &#123;</span><br><span class="line">                       <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">                   &#125;</span><br><span class="line">               &#125; <span class="keyword">catch</span> (OutOfMemoryError ignored) &#123;</span><br><span class="line">                   <span class="keyword">if</span> (!isRunning()) &#123;</span><br><span class="line">                       <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">                   &#125;</span><br><span class="line">               &#125;</span><br><span class="line">           &#125;</span><br><span class="line">       &#125;</span><br></pre></td></tr></table></figure></p><h4 id="Step3-GC处理超时"><a href="#Step3-GC处理超时" class="headerlink" title="Step3 GC处理超时"></a>Step3 GC处理超时</h4><p>如果第二步中的超时时间内析构没有完成，则返回析构的对象，触发<code>finalizerTimedOut</code>。<br>到了这一步是最不希望看到的结局，此时系统会弹出应用停止运行的报错框。</p><p>注意这个时候并没有立刻杀死进程，杀死进程的选择权交给了用户，即通过弹窗展示给用户，但对于用户来说会一头雾水</p><p><img src="http://blog.lihaizhou.top/GC_crash/GC1.png" alt=""></p><h3 id="分析结论"><a href="#分析结论" class="headerlink" title="分析结论"></a>分析结论</h3><p>这种问题其实还是比较常见的，特别是低内存的机器上。<code>RootCasue</code>就是对象回收超时了，一般是由于队列中等待<code>FinalizerDaemon</code>线程回收的对象太多导致，或者此时系统资源异常紧张比如CPU负载过高或者低内存环境下。</p><h3 id="场景实测"><a href="#场景实测" class="headerlink" title="场景实测"></a>场景实测</h3><h4 id="模拟还原现场"><a href="#模拟还原现场" class="headerlink" title="模拟还原现场"></a>模拟还原现场</h4><p>通过模拟<code>GC</code>时耗时操作，应用退到后台后10s会弹出报错框，堆栈如下</p><p><img src="http://blog.lihaizhou.top/GC_crash/GC2.png" alt=""></p><p>验证了超时时间的确是10s，同时也验证了GC时耗时的操作确实会可能触发这个现象</p><h4 id="对比机情况"><a href="#对比机情况" class="headerlink" title="对比机情况"></a>对比机情况</h4><p>在手头的小米<code>note9 pro</code>上进行场景模拟测试，模拟GC耗时100s的情况<br><img src="http://blog.lihaizhou.top/GC_crash/GC3.png" alt=""></p><p>在小米的机器上，到了默认的10s后并不会有弹窗，说明小米肯定修改了超时时间，第一次是等待了全部的100s后竟然正常回收，说明超时时间设置的比较大。紧接着下一次在达到了近80s时，进程收到<code>signal 9</code>直接被kill了，此时再点击应用是冷启动。</p><p><strong>小米修改了超时阈值(超过100s)，通过直接sig 9杀掉了进程，没有报错弹窗，所以用户无感知</strong></p><h4 id="测试机情况"><a href="#测试机情况" class="headerlink" title="测试机情况"></a>测试机情况</h4><p>同样的在我们的机器上模拟GC耗时100s的情况<br><strong>退出应用到后台，此时系统触发GC回收，达到十秒钟时，界面上直接弹出停止运行的报错框，此时只有点击了关闭应用，才会去kill进程</strong></p><h4 id="修改策略"><a href="#修改策略" class="headerlink" title="修改策略"></a>修改策略</h4><p>在GC规定的超时时间内如果没有完成析构，直接<code>sig 9</code>给对应进程</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;写在前面&quot;&gt;&lt;a href=&quot;#写在前面&quot; class=&quot;headerlink&quot; title=&quot;写在前面&quot;&gt;&lt;/a&gt;写在前面&lt;/h3&gt;&lt;p&gt;这个问题之所以会拿出来仔细分析，一方面是因为这个问题不是简单的应用崩溃而是框架层的报错，另一方面是因为希望通过这个问题梳理下
      
    
    </summary>
    
      <category term="稳定性" scheme="http://lihaizhou.top/categories/%E7%A8%B3%E5%AE%9A%E6%80%A7/"/>
    
    
  </entry>
  
  <entry>
    <title>从tcpdump看miracast的play流程(工具篇)</title>
    <link href="http://lihaizhou.top/2020/11/30/%E4%BB%8Etcpdump%E7%9C%8Bmiracast%E7%9A%84play%E6%B5%81%E7%A8%8B/"/>
    <id>http://lihaizhou.top/2020/11/30/从tcpdump看miracast的play流程/</id>
    <published>2020-11-30T03:01:15.000Z</published>
    <updated>2021-10-16T06:00:43.000Z</updated>
    
    <content type="html"><![CDATA[<p>前言：<br>基于高通平台，其他平台都是类似的<br>本文作为工具篇，记录下来的目的是以便后续如再接触投屏工作能够快速对照上手</p><p>当我们开始准备连接sink设备时，开始的时候，source会创建一个socket监听着并等待sink端过来连接，sink端会触发”connect”的socket函数并开始tcp 握手之路，这个时候source接收到之后，它会触发”accept”的socket函数来处理sink发过俩的连接请求</p><p>开始是握手 Key Message #1~#4<br><img src="http://blog.lihaizhou.top/Miracast_play/miracast-play01.png" alt=""></p><p>RTSP connect M1~M8:<br><img src="http://blog.lihaizhou.top/Miracast_play/miracast-play02.png" alt=""></p><p>DHCP ACK<br><img src="http://blog.lihaizhou.top/Miracast_play/miracast-play03.png" alt=""></p><p>如果这里DHCP Discover -&gt; DHCP ACK耗时超过 5s, 对于一些sink设备来说它就不会继续发 SYN 消息了 ，因此连接会阻塞在这里<br>所以如果遇到sink没有发送SYN的话就要看看这里的DHCP是否耗时太久了</p><p>SYN handshake Sink should send SYN message to 7236 port at this step:<br><img src="http://blog.lihaizhou.top/Miracast_play/miracast-play04.png" alt=""></p><p>Get/Set parameter<br><img src="http://blog.lihaizhou.top/Miracast_play/miracast-play05.png" alt=""></p><p>Play<br><img src="http://blog.lihaizhou.top/Miracast_play/miracast-play06.png" alt=""></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;前言：&lt;br&gt;基于高通平台，其他平台都是类似的&lt;br&gt;本文作为工具篇，记录下来的目的是以便后续如再接触投屏工作能够快速对照上手&lt;/p&gt;
&lt;p&gt;当我们开始准备连接sink设备时，开始的时候，source会创建一个socket监听着并等待sink端过来连接，sink端会触发”c
      
    
    </summary>
    
      <category term="网络" scheme="http://lihaizhou.top/categories/%E7%BD%91%E7%BB%9C/"/>
    
    
  </entry>
  
  <entry>
    <title>一次SystemServer OOM导致的系统重启分析之路</title>
    <link href="http://lihaizhou.top/2020/11/25/%E4%B8%80%E6%AC%A1SystemServer-OOM%E5%AF%BC%E8%87%B4%E7%9A%84%E7%B3%BB%E7%BB%9F%E9%87%8D%E5%90%AF%E5%88%86%E6%9E%90%E4%B9%8B%E8%B7%AF/"/>
    <id>http://lihaizhou.top/2020/11/25/一次SystemServer-OOM导致的系统重启分析之路/</id>
    <published>2020-11-25T00:59:48.000Z</published>
    <updated>2021-10-16T06:14:02.000Z</updated>
    
    <content type="html"><![CDATA[<p><strong>测试步骤</strong><br>MTBF测试跑出来的机器重启，先解释下何为MTBF？<br><code>MTBF测试(Mean Time Between Failure)</code><br>主要测试终端在连续工作状态下，出现死机、重启、冻屏、应用强制关闭等严重故障的概率。通过在一个周期内以自动化方式反复执行规定用例，记录测试过程中被测终端出现的故障数</p><p><strong>复现概率</strong><br>1/200</p><p><strong>问题现象</strong><br>机器出现重启，并自动给出源头是OOM导致的结论</p><h1 id="初步分析"><a href="#初步分析" class="headerlink" title="初步分析"></a>初步分析</h1><p>正常步骤先看bugreport确定下是否是OOM导致的重启，搜索关键字”system_server_crash”或”am_crash”<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">2020</span>-<span class="number">12</span>-<span class="number">07</span> <span class="number">10</span>:<span class="number">56</span>:<span class="number">18</span> system_server_crash (text, <span class="number">346</span> bytes)</span><br><span class="line">Process: system_server</span><br><span class="line">java.lang.OutOfMemoryError: Heap of System_Server has allocated <span class="number">666</span>MB , So trigger OutOfMemoryError crash</span><br><span class="line">at com.android.server.WatchdogInjector.checkOOMState(WatchdogInjector.java:<span class="number">98</span>)</span><br><span class="line">at com.android.server.Watchdog.run(Watchdog.java:<span class="number">776</span>)</span><br><span class="line"></span><br><span class="line"><span class="number">12</span>-<span class="number">07</span> <span class="number">10</span>:<span class="number">56</span>:<span class="number">18.313</span>  <span class="number">1000</span>  <span class="number">1614</span>  <span class="number">1703</span> I am_crash: [<span class="number">1614</span>,<span class="number">0</span>,system_server,-<span class="number">1</span>,java.lang.OutOfMemoryError,Heap of System_Server has allocated <span class="number">666</span>MB , So trigger OutOfMemoryError crash,WatchdogInjector.java,<span class="number">98</span>]</span><br><span class="line"></span><br><span class="line"><span class="number">12</span>-<span class="number">07</span> <span class="number">10</span>:<span class="number">56</span>:<span class="number">18.312</span>  <span class="number">1000</span>  <span class="number">1614</span>  <span class="number">1703</span> D OOMEventManagerFK: dumpheap success : /data/anr/system_server_1614.hprof</span><br></pre></td></tr></table></figure></p><p>上面片段中可以看出当时SystemServer确实发生了OOM，日志中没有打出具体堆栈，这个时候去看下system_server_1614.hprof，这个应该是厂商定制化输出的，比如监测到SystemServer占据内存超过一定的阀值，就dump出这个hprof文件以便于分析<br><img src="http://blog.lihaizhou.top/SystemServerOOM/SystemServerOOM1.png" alt=""><br>这个文件打开后，最大的一块是有五百多个android.app.assist.AssistStructure实例</p><p><img src="http://blog.lihaizhou.top/SystemServerOOM/SystemServerOOM2.png" alt=""></p><p>接下来顺理成章的就看下android.app.assist.AssistStructure单个实例中的引用链关系了<br>直接点击Histogram搜索android.app.assist.AssistStructure即可<br><img src="http://blog.lihaizhou.top/SystemServerOOM/SystemServerOOM3.png" alt=""><br>选择outgoing reference后如下，可以看到有529个<br><img src="http://blog.lihaizhou.top/SystemServerOOM/SystemServerOOM4.png" alt=""><br>随便点击一个右键同样的选outgoing<br><img src="http://blog.lihaizhou.top/SystemServerOOM/SystemServerOOM5.png" alt=""></p><p>每个AssistStructure实例中都包含WifiConfigActivity，WifiConfigActivity是一个什么样的界面呢？<br>是一个对话框样式的Activity，包含了可以填充数据的编辑框。<br>其实我们到这里已经大致明白了，罪魁祸首基本可以认定是WifiConfigActivity了</p><p>从bugreport中寻找关于WifiConfigActivity的线索，查找system_server OOM之前的片段<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">12</span>-<span class="number">07</span> <span class="number">10</span>:<span class="number">56</span>:<span class="number">04.383</span>  <span class="number">1000</span>  <span class="number">1614</span>  <span class="number">2419</span> I WindowManager: Input event dispatching timed out sending to com.android.settings/com.android.settings.wifi.WifiConfigActivity.  Reason: e4a42fb com.android.settings/com.android.settings.wifi.WifiConfigActivity (server) is not responding. Waited <span class="number">8001</span><span class="function">ms <span class="keyword">for</span> <span class="title">FocusEvent</span><span class="params">(hasFocus=<span class="keyword">true</span>)</span></span></span><br></pre></td></tr></table></figure></p><p>可以看到当时的WifiConfigActivity界面是卡住了，无法响应事件，可能当时系统在不停的GC，再看下WifiConfigActivity的调起记录<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">12</span>-<span class="number">07</span> <span class="number">10</span>:<span class="number">55</span>:<span class="number">09.375</span>  <span class="number">1000</span>  <span class="number">1614</span> <span class="number">12880</span> I ActivityTaskManager: START u0 &#123;flg=<span class="number">0x10000000</span> cmp=com.android.settings/.wifi.WifiConfigActivity (has extras)&#125; from uid <span class="number">1000</span></span><br><span class="line"><span class="number">12</span>-<span class="number">07</span> <span class="number">10</span>:<span class="number">55</span>:<span class="number">18.151</span>  <span class="number">1000</span>  <span class="number">1614</span>  <span class="number">4490</span> I ActivityTaskManager: START u0 &#123;flg=<span class="number">0x10000000</span> cmp=com.android.settings/.wifi.WifiConfigActivity (has extras)&#125; from uid <span class="number">1000</span></span><br><span class="line"><span class="number">12</span>-<span class="number">07</span> <span class="number">10</span>:<span class="number">55</span>:<span class="number">21.185</span>  <span class="number">1000</span>  <span class="number">1614</span> <span class="number">12880</span> I ActivityTaskManager: START u0 &#123;flg=<span class="number">0x10000000</span> cmp=com.android.settings/.wifi.WifiConfigActivity (has extras)&#125; from uid <span class="number">1000</span></span><br><span class="line"><span class="number">12</span>-<span class="number">07</span> <span class="number">10</span>:<span class="number">55</span>:<span class="number">32.439</span>  <span class="number">1000</span>  <span class="number">1614</span>  <span class="number">5665</span> I ActivityTaskManager: START u0 &#123;flg=<span class="number">0x10000000</span> cmp=com.android.settings/.wifi.WifiConfigActivity (has extras)&#125; from uid <span class="number">1000</span></span><br><span class="line"><span class="number">12</span>-<span class="number">07</span> <span class="number">10</span>:<span class="number">55</span>:<span class="number">42.120</span>  <span class="number">1000</span>  <span class="number">1614</span>  <span class="number">8959</span> I ActivityTaskManager: START u0 &#123;flg=<span class="number">0x10000000</span> cmp=com.android.settings/.wifi.WifiConfigActivity (has extras)&#125; from uid <span class="number">1000</span></span><br><span class="line"><span class="number">12</span>-<span class="number">07</span> <span class="number">10</span>:<span class="number">55</span>:<span class="number">50.421</span>  <span class="number">1000</span>  <span class="number">1614</span>  <span class="number">4063</span> I ActivityTaskManager: START u0 &#123;flg=<span class="number">0x10000000</span> cmp=com.android.settings/.wifi.WifiConfigActivity (has extras)&#125; from uid <span class="number">1000</span></span><br><span class="line"><span class="number">12</span>-<span class="number">07</span> <span class="number">10</span>:<span class="number">56</span>:<span class="number">03.812</span>  <span class="number">1000</span>  <span class="number">1614</span> <span class="number">14712</span> I ActivityTaskManager: START u0 &#123;flg=<span class="number">0x10000000</span> cmp=com.android.settings/.wifi.WifiConfigActivity (has extras)&#125; from uid <span class="number">1000</span></span><br></pre></td></tr></table></figure></p><p>WifiConfigActivity什么时候会被调起呢，是在收到一个广播后，鉴于其启动模式是singleInstance<br>查阅代码发现这个文件有重写onNewIntent，所以再多次调用的情况下，onNewIntent会被多次触发<br>该函数里有一处代码<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">new</span> AccessPoint(<span class="keyword">this</span>, wifiConfiguration);</span><br></pre></td></tr></table></figure></p><p>这里直接传入了this且该类是singleInstance，所以这个对象是无法被GC的，会导致内存持续增加，其实日志中也有Settings OOM的片段打出来  </p><h1 id="修改方案"><a href="#修改方案" class="headerlink" title="修改方案"></a>修改方案</h1><p>修改方案如下：<br>传入this的地方改为弱引用，这样在该界面退出时activity可以正常被回收掉，另外新增一个文件继承自DialogInterface.OnDismissListener<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DetachWifiDialogListener</span> <span class="keyword">implements</span> <span class="title">DialogInterface</span>.<span class="title">OnDismissListener</span></span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">static</span> String TAG = DetachWifiDialogListener.class.getSimpleName();</span><br><span class="line">    <span class="keyword">private</span> Activity mActivity;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">DetachWifiDialogListener</span><span class="params">(Activity activity)</span> </span>&#123;</span><br><span class="line">        mActivity = activity;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onDismiss</span><span class="params">(DialogInterface dialog)</span> </span>&#123;</span><br><span class="line">       Log.d(TAG,<span class="string">"Dialog onDismiss"</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">clearOnDetach</span><span class="params">(Dialog dialog)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (dialog.getWindow() == <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        dialog.getWindow()</span><br><span class="line">                .getDecorView()</span><br><span class="line">                .getViewTreeObserver()</span><br><span class="line">                .addOnWindowAttachListener(<span class="keyword">new</span> ViewTreeObserver.OnWindowAttachListener() &#123;</span><br><span class="line">                    <span class="meta">@Override</span></span><br><span class="line">                    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onWindowAttached</span><span class="params">()</span> </span>&#123;</span><br><span class="line">                       Log.d(TAG, <span class="string">"dialog Attached to Window"</span>);</span><br><span class="line">                    &#125;</span><br><span class="line">                    <span class="meta">@Override</span></span><br><span class="line">                    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onWindowDetached</span><span class="params">()</span> </span>&#123;</span><br><span class="line">                        Log.d(TAG,<span class="string">"dialog Detached to Window"</span>);</span><br><span class="line">                        <span class="keyword">if</span>(mActivity != <span class="keyword">null</span>) &#123;</span><br><span class="line">                           mActivity.finish();</span><br><span class="line">                           mActivity = <span class="keyword">null</span>;</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>在弹出Dialog后执行clearOnDetach，及时的将Activity finish掉，并且在onPause中(这里因为此处场景特殊，一般在onDestory中)将Listener置空<br>目的是剪断这个引用链<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">dismissListener = <span class="keyword">new</span> DetachWifiDialogListener(mWifiConfigActivity.get());</span><br><span class="line"><span class="comment">//....</span></span><br><span class="line">mDialog.show();</span><br><span class="line">dismissListener.clearOnDetach(mDialog);</span><br></pre></td></tr></table></figure></p><p>本地测试下来，<code>dumpsys meminfo</code>出的Activity实例个数在Dialog消失后会减少，说明不存在内存泄露了</p><h1 id="常见示例"><a href="#常见示例" class="headerlink" title="常见示例"></a>常见示例</h1><p>再例举一个最常见的非静态内部类Handler泄漏例子，延迟发送一个消息，此时在消息处理之前退出该界面，就会存在该Activity泄漏的情形</p><p>此时在onDestory内执行<code>removeCallbacksAndMessages</code>，这样的话每次退出界面后就会清空该handler上所有的callback和消息，这样就不会存在<code>MessageQueue-&gt;Handler-&gt;Activity</code>这个引用链</p><p><img src="http://blog.lihaizhou.top/SystemServerOOM/SystemServerOOM6.png" alt=""></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;strong&gt;测试步骤&lt;/strong&gt;&lt;br&gt;MTBF测试跑出来的机器重启，先解释下何为MTBF？&lt;br&gt;&lt;code&gt;MTBF测试(Mean Time Between Failure)&lt;/code&gt;&lt;br&gt;主要测试终端在连续工作状态下，出现死机、重启、冻屏、应用强制关闭
      
    
    </summary>
    
      <category term="稳定性" scheme="http://lihaizhou.top/categories/%E7%A8%B3%E5%AE%9A%E6%80%A7/"/>
    
    
  </entry>
  
  <entry>
    <title>内存屏障</title>
    <link href="http://lihaizhou.top/2020/06/20/Memory-Barrier%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    <id>http://lihaizhou.top/2020/06/20/Memory-Barrier读书笔记/</id>
    <published>2020-06-20T07:56:03.000Z</published>
    <updated>2022-04-10T14:09:54.960Z</updated>
    
    <content type="html"><![CDATA[<p>本篇文章开始之前需要了解一些背景知识</p><h1 id="Cache-Memory"><a href="#Cache-Memory" class="headerlink" title="Cache Memory"></a>Cache Memory</h1><p>我们都知道程序是运行在 RAM之中，RAM 就是我们常说的DDR（例如 DDR3、DDR4等），我们称之为main memory（主存）当我们需要运行一个进程的时候，首先会从Flash设备（例如，eMMC、UFS等）中将可执行程序load到main memory中，然后开始执行。</p><p>在CPU内部存在一堆的通用寄存器（register），如果CPU需要将一个变量（假设地址是A）加1，一般分为以下3个步骤</p><ol><li>CPU 从主存中读取地址A的数据到内部通用寄存器 x0（ARM64架构的通用寄存器之一）</li><li>通用寄存器 x0 加1</li><li>CPU 将通用寄存器 x0 的值写入主存</li></ol><p>但是存在一个问题，CPU通用寄存器的速度和主存之间存在着太大的差异<br>从这个网址<a href="https://gist.github.com/jboner/2841832" target="_blank" rel="noopener">https://gist.github.com/jboner/2841832</a> 摘了一段数据<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">Latency Comparison <span class="title">Numbers</span> <span class="params">(~<span class="number">2012</span>)</span></span></span><br><span class="line"><span class="function">----------------------------------</span></span><br><span class="line"><span class="function">L1 cache reference                           0.5 ns</span></span><br><span class="line"><span class="function">Branch mispredict                            5   ns</span></span><br><span class="line"><span class="function">L2 cache reference                           7   ns                      14x L1 cache</span></span><br><span class="line"><span class="function">Mutex lock/unlock                           25   ns</span></span><br><span class="line"><span class="function">Main memory reference                      100   ns                      20x L2 cache, 200x L1 cache</span></span><br><span class="line"><span class="function">Compress 1K bytes with Zippy             3,000   ns        3 us</span></span><br><span class="line"><span class="function">Send 1K bytes over 1 Gbps network       10,000   ns       10 us</span></span><br><span class="line"><span class="function">Read 4K randomly from SSD*             150,000   ns      150 us          ~1GB/sec SSD</span></span><br><span class="line"><span class="function">Read 1 MB sequentially from memory     250,000   ns      250 us</span></span><br><span class="line"><span class="function">Round trip within same datacenter      500,000   ns      500 us</span></span><br><span class="line"><span class="function">Read 1 MB sequentially from SSD*     1,000,000   ns    1,000 us    1 ms  ~1GB/sec SSD, 4X memory</span></span><br><span class="line"><span class="function">Disk seek                           10,000,000   ns   10,000 us   10 ms  20x datacenter roundtrip</span></span><br><span class="line"><span class="function">Read 1 MB sequentially from disk    20,000,000   ns   20,000 us   20 ms  80x memory, 20X SSD</span></span><br><span class="line"><span class="function">Send packet CA-&gt;Netherlands-&gt;CA    150,000,000   ns  150,000 us  150 ms</span></span><br></pre></td></tr></table></figure></p><p>这里没有列出寄存器速度，看到L1 cache是0.5ns，可以肯定的是寄存器一定是低于1ns，Main memory是100ns，这里的数据仅供参考<br>所以上面的从主存读取数值三个步骤中的第一和第三步实际上速度很慢相对于寄存器而言</p><p>当CPU试图从主存中load/store 操作时，由于主存的速度限制，CPU不得不等待这漫长的65ns时间。如果我们可以提升主存的速度，那么系统将会获得很大的性能提升。如今的DDR存储设备，动不动就是几个GB，容量很大。如果我们采用更快材料制作更快速度的主存，并且拥有几乎差不多的容量。其成本将会大幅度上升。<br>我们试图提升主存的速度和容量，又期望其成本很低，这就有点难为人了。因此，我们有一种折中的方法，那就是制作一块速度极快但是容量极小的存储设备。那么其成本也不会太高。这块存储设备我们称之为cache memory。在硬件上，我们将cache放置在CPU和主存之间，作为主存数据的缓存。当CPU试图从主存中load/store数据的时候， CPU会首先从cache中查找对应地址的数据是否缓存在cache 中。如果其数据缓存在cache中，直接从cache中拿到数据并返回给CPU。<br><strong>CPU和主存之间直接数据传输的方式转变成CPU和cache之间直接数据传输。cache负责和主存之间数据传输。</strong></p><p>当存在cache的时候，以上程序如何运行的例子的流程将会变成如下：<br><img src="http://blog.lihaizhou.top/MemBarrier/memory-barrier01.png" alt=""></p><p>cahe的速度在一定程度上同样影响着系统的性能。一般情况cache的速度可以达到1ns，几乎可以和CPU寄存器速度媲美。但是，这就满足人们对性能的追求了吗？并没有。当cache中没有缓存我们想要的数据的时候，依然需要漫长的等待从主存中load数据。为了进一步提升性能，引入多级cache。前面提到的cache，称之为L1 cache（第一级cache）。<br>我们在L1 cache 后面连接L2 cache，在L2 cache 和主存之间连接L3 cache。等级越高，速度越慢，容量越大。但是速度相比较主存而言，依然很快</p><p>多级cache不是本文重点，详细可参考如下两篇文章，写的比较详细<br><a href="http://www.wowotech.net/memory_management/458.html" target="_blank" rel="noopener">浅谈Cache Memory</a><br><a href="https://zhuanlan.zhihu.com/cpu-cache" target="_blank" rel="noopener">高速缓存与一致性</a></p><h2 id="Cacheline"><a href="#Cacheline" class="headerlink" title="Cacheline"></a>Cacheline</h2><p>本文后续会涉及到一个名词Cacheline，cache的大小称之为cahe size，代表cache可以缓存最大数据的大小。<br>我们将cache平均分成相等的很多块，每一个块大小称之为cache line，其大小是cache line size。例如一个64 Bytes大小的cache<br>如果我们将64 Bytes平均分成64块，那么cache line就是1字节，总共64行cache line。如果我们将64 Bytes平均分成8块，那么cache line就是8字节，总共8行cache line<br>有一点需要注意，cache line是cache和主存之间数据传输的最小单位。什么意思呢？当CPU试图load一个字节数据的时候，如果cache缺失，那么cache控制器会从主存中一次性的load cache line大小的数据到cache中。</p><p>例如，cache line大小是8字节。CPU即使读取一个byte，在cache缺失后，cache会从主存中load 8字节填充整个cache line，至于原因可以参见这篇文章:<br><a href="http://www.wowotech.net/memory_management/458.html" target="_blank" rel="noopener">浅谈Cache Memory</a></p><p>有了前面的基础知识的认知，不难理解下面这个极简的抽象CPU架构图<br><img src="http://blog.lihaizhou.top/MemBarrier/memory-barrier02.gif" alt=""></p><h1 id="缓存一致性"><a href="#缓存一致性" class="headerlink" title="缓存一致性"></a>缓存一致性</h1><p>考虑到多线程读写环境中，不免会有个疑问，如果一个数据是多个cpu都共享，其中一个修改了是不是要想办法使得其他cpu也能更新<br>一个cpu去读取一个数值时，怎么确定是最新的呢？说到底就是要保证在使用cache后如何确保各 CPU 看到的数据是一致的<br>这个就引出另外一个名词“cache-coherence protocol”即缓存一致性协议<br>其中，MESI protocol 是一个基本版，从 MESI protocol 可以了解 CPU 之间如何维持看到一致的资料，可以参见MESI的维基定义:   <a href="https://zh.wikipedia.org/wiki/MESI%E5%8D%8F%E8%AE%AE" target="_blank" rel="noopener">MESI协议</a></p><p>这里摘取英文文档中的对于MESI拆解开来的四种状态的解释<br><code>A line in the “modified” state has been subject to a recent memory store from the corresponding CPU, and the corresponding memory is guaranteed not to appear in any other CPU’s cache. Cache lines in the “modified”state can thus be said to be “owned” by the CPU. Because this cache holds the only up-to-date copy of the data, thiscache is ultimately responsible for either writing it back to memory or handing it off to some other cache, and must do so before reusing this line to hold other data.</code><br>处于modified状态的cacheline说明近期有过来自对应cpu的写操作，同时也说明该该数据不会存在其他cpu对应的cache中。因此，处于modified状态的cacheline也可以说是被该CPU独占。而又因为只有该CPU的cache保存了最新的数据（最终的memory中都没有更新），所以，该cache需要对该数据负责到底。例如根据请求，该cache将数据及其控制权传递到其他cache中，或者cache需要负责将数据写回到memory中，而这些操作都需要在reuse该cache line之前完成。<br><code>The “exclusive” state is very similar to the “modified”state, the single exception being that the cache line has not yet been modified by the corresponding CPU, which in turn means that the copy of the cache line’s data that resides in memory is up-to-date. However, since the CPU can store to this line at any time, without consulting other CPUs, a line in the “exclusive” state can still be said to be owned by the corresponding CPU. That said, because the corresponding value in memory is up to date, this cache can discard this data without writing it back to memory or handing it off to some other CPU.</code><br>exclusive状态和modified状态非常类似，唯一的区别是对应CPU还没有修改cacheline中的数据，也正因为还没有修改数据，因此memory中对应的data也是最新的。在exclusive状态下，cpu也可以不通知其他CPU cache而直接对cacheline进行操作，因此，exclusive状态也可以被认为是被该CPU独占。由于memory中的数据和cacheline中的数据都是最新的，因此，cpu不需对exclusive状态的cacheline执行写回的操作或者将数据以及归属权转交其他cpu cache，而直接reuse该cacheline（将cacheine中的数据丢弃，用作他用）<br><code>A line in the “shared” state might be replicated in at least one other CPU’s cache, so that this CPU is not permitted to store to the line without first consulting with other CPUs. As with the “exclusive” state, because thecorresponding value in memory is up to date, this cache can discard this data without writing it back to memory or handing it off to some other CPU.</code><br>处于share状态的cacheline，其数据可能在一个或者多个CPU cache中，因此，处于这种状态的cache line，CPU不能直接修改cacheline的数据，而是需要首先和其他CPU cache进行沟通。和exclusive状态类似，处于share状态的cacheline对应的memory中的数据也是最新的，因此，cpu也可以直接丢弃cacheline中的数据而不必将其转交给其他CPU cache或者写回到memory中。<br><code>A line in the “invalid” state is empty, in other words, it holds no data. When new data enters the cache, it is placed into a cache line that was in the “invalid” state if possible. This approach is preferred because replacing a line in any other state could result in an expensive cache miss should the replaced line be referenced in the future.</code><br>处于invalid状态的cacheline是空的，没有数据。当新的数据要进入cache的时候，优选状态是invalid的cacheline，之所以如此是因为如果选中其他状态的cacheline，则说明需要替换cacheline数据，而未来如果再次访问这个被替换掉的cacheline数据的时候将遇到开销非常大的cache miss  </p><font color="red"> 个人理解:<br>1. 对于modified状态的cacheline，别的cpu如果需要其中的数据，必须要写回到memory或者转移<br>2. exclusive可以理解为是modified的轻量版，exclusive状态的cacheline数据此时还没有被cpu修改，也就是说它的数据和memory中是一致的，当别的cpu需要状态是exclusive的cacheline数据时，可以直接提供数据不需要写回到memory<br>3. share状态的cacheline不能直接被修改，如果一个cpu需要对这个cacheline进行修改了，需要先通知其他cpu让他们将各自对应的cacheline置为invalid，然后再切换cacheline的状态到exclusive，再然后就是M状态<br>4. invalid状态的cacheline之前可能是有数据的，比如之前是shared状态，后来其他cpu要修改这个cacheline了，就发通知过来了要求置为invalid的，不然读取出来的就是错误的<br><br> </font><p>有一个MESI动画的网址，可以模拟各个cacheline的状态切换，比起文字描述来讲更好理解，可以不断的模拟测试，对理解MESI很有帮助<br><a href="https://www.scss.tcd.ie/Jeremy.Jones/VivioJS/caches/MESIHelp.htm" target="_blank" rel="noopener">VivioJS - Interactive Reversible E-Learning Animations for the WWW</a></p><p>比如当前状态<br><img src="http://blog.lihaizhou.top/MemBarrier/memory-barrier03.png" alt=""></p><font color="red"><br>个人理解添加<br>此时CPU0上a1数据对应的cacheline此时的状态是M状态，可以看到此时的数值是11，比memory要新，其他两个cpu1，cpu2上的a1对应的cacheline是invalid状态。如果此时cpu2上对a1进行写值加1，会是什么样子的呢？<br>根据上面的理论知识，此时应该会通过总线通知cpu0让其写入到memory中，然后cpu2才能读取到最新的值此时再进行修改此时数值应该是12并将状态置为E并且写回memory，此时CPU0上的a1对应cacheline状态理论上应该是invalid。<br></font><br>实际的cpu2对a1加1后效果图如下：<br><img src="http://blog.lihaizhou.top/MemBarrier/memory-barrier04.png" alt=""><br><font color="red"> 个人理解添加<br>此时如果对cpu2的cacheline进行写加1，cacheline状态会切换到M状态，如果一直写，数值一直增加一直是M状态，其他cpu无变化。因为此时M是最新的，只有其他cpu比如此时cpu1需要读取a1的值，这个时候cpu2会将这个值写回到memory并且此时cpu1和cpu2上a1对应的cacheline状态都是S。<br>如果这个时候，对cpu2的a1进行写操作呢？其状态会切换到E，其他cpu对应的a1-cacheline都切到invalid<br>介绍完MESI后，我们知道有了MESI protocol，任何一个CPU 要写入资料前，都要先确保其它CPU 已invalid 同一位置的cache 后(希望写入的CPU 广播invalidate，其它CPU 回invalidate ack)， 才能写资料到自己的cache，并在稍后补写回memory。<br></font><br>这个设计确保资料的一致性，不用担心同一时间同一个位置的资料会有不同的值，但是代价是写入 cache 的速度会有点慢，让 CPU 闲置，下图中的stall就是cpu等待的时长<br><img src="http://blog.lihaizhou.top/MemBarrier/memory-barrier05.png" alt=""><br><br><font color="red">  个人理解添加<br>想象一下这个场景：<br><em> CPU 0 打算写入值到位置 X，CPU 1 的 cache 有 X 的值。因为缓存一致性的缘故，这个时候CPU0给CPU1发送一个invalid的广播告知其需要将其对应数值置于无效</em> 这个时候呢cpu0就开始傻乎乎的等 CPU 1 回 invalidate ack，但是此时CPU 1 的 cache 可能太忙而拖慢了回覆时间 (比方同时从 cache 大量的读写资料，或是短时间收到大量 invalidate ack)。<br>这样就导致了CPU0白白耗费时间在等待上，这对于宝贵的cpu资源是一种很大的浪费，其实没必要等待这么长的时间，毕竟物理CPU 1中的cacheline保存有什么样子的数据，其实都没有意义，这个值都会被CPU 0新写入的值覆盖的，所以能不能不等呢？这也就引出了另外一个名词StoreBuffer，还有另外一个名词对应刷新的Invalidate Queue<br></font> <h2 id="Store-Buffer-amp-Invalidate-Queue"><a href="#Store-Buffer-amp-Invalidate-Queue" class="headerlink" title="Store Buffer &amp; Invalidate Queue"></a>Store Buffer &amp; Invalidate Queue</h2><p>在CPU和cache之间增加store buffer这个HW block</p><font color="red">  个人理解添加<br>1. CPU 0 不等 invalidate ack：先写入 store buffer，然后继续作事。之后收到 invalidate ack 再更新 cache 的状态。因为最新的资料可能存在 store buffer，CPU 读资料的顺序变成 store buffer → cache → memory。<br>2. CPU 1 立即回 invalidate ack：收到 invalidate 时，记录到 invalidate queue 里，先回 invalidate ack，稍后再处理 invalidate。<br>3. 为啥有了store buffer后还会冒出来一个invalidate queue，因为 store buffer 很小，store buffer 满的时候，CPU 0 还是得等 invalidate ack，所以加上 invalidate queue，双管齐下减少 CPU 0 等待时间<br>这里还有一个细节后面会提到，如果有数据加了写内存屏障的话，加入storebuffer，其后面的写操作不管有没有写屏障都要加到storebuffer中，这就造成了storebuffer更容易满了，一旦满了又要开始等ack了，这就引入了<br>invalidate queue，后面还会继续讲它的作用<br>其实这里出现了一个重排序的“现象”，就是一旦某一条写指令放到storebuffer中了继续后面的指令操作，这就造成了下一条指令跑到这条指令前面执行的”假象”，这种重排序就是为了充分利用cpu的性能避免白白的浪费等待<br>CPU 为了提升效率而出现的这种”改指令”执行的顺序，只要最后結果和 single thread 预期的結果一样即可。这句话可以细品下，所以多线程的情况下需要我们研发人员自己控制<br></font>  <p>有了StoreBuffer以及Invalidate Queue之后的cpu cache架构如下<br><img src="http://blog.lihaizhou.top/MemBarrier/memory-barrier06.png" alt=""></p><p>下面摘自perfbook文档关于StoreBuffer以及Invalidate Queue的解释</p><p><code>These store buffers are local to a given CPU or, on systems with hardware multithreading, local to a given core. Either way, a given CPU is permitted to access only the store buffer assigned to it. For example, in Figure C.5, CPU 0 cannot access CPU 1’s store buffer and vice versa. This restriction simplifies the hardware by separating concerns: The store buffer improves performance for consecutive writes, while the responsibility for communicating among CPUs (or cores, as the case may be) is fully shouldered by the cache-coherence protocol. However, even given this restriction, there are complications that must be addressed, which are covered in the next two sections.</code></p><p>这些store buffer对于cpu而言是local的，如果系统是硬件多线程， 那么每一个cpu core拥有自己私有的stroe buffer，一个cpu只能访问自己私有的那个store buffer。在上图中，cpu 0不能访问cpu1的store buffer，反之亦然。之所以做这样的限制是为了模块划分（各个cpu core模块关心自己的事情，让cache系统维护自己的操作），让硬件设计变得简单一些。store buffer增加了CPU连续写的性能，同时把各个CPU之间的通信的任务交给维护cache一致性的协议。即便给每个CPU分配私有的store buffer，仍然引入了一些复杂性，我们会在下面两个小节中描述。</p><p><code>Unfortunately, each store buffer must be relatively small, which means that a CPU executing a modest sequence of stores can fill its store buffer (for example, if all of them result in cache misses). At that point, the CPU must once again wait for invalidations to complete in order to drain its store buffer before it can continue executing. This same situation can arise immediately after a memory barrier, when all subsequent store instructions must wait for invalidations to complete, regardless of whether or not these stores result in cache misses.</code></p><p>不幸的是：每个cpu的store buffer不能实现的太大，其entry的数目不会太多。当cpu以中等的频率执行store操作的时候（假设所有的store操作导致了cache miss），store buffer会很快的被填满。在这种状况下，CPU只能又进入等待状态，直到cache line完成invalidation和ack的交互之后，可以将store buffer的entry写入cacheline，从而为新的store让出空间之后，CPU才可以继续执行。这种状况也可能发生在调用了memory barrier指令之后，因为一旦store buffer中的某个entry被标记了，那么随后的store都必须等待invalidation完成，因此不管是否cache miss，这些store都必须进入store buffer。</p><p><code>This situation can be improved by making invalidate acknowledge messages arrive more quickly. One way of accomplishing this is to use per-CPU queues of invalidate messages, or “invalidate queues”.</code></p><p>引入invalidate queues可以缓解这个状况。store buffer之所以很容易被填充满，主要是其他CPU回应invalidate acknowledge比较慢，如果能够加快这个过程，让store buffer尽快进入cacheline，那么也就不会那么容易填满了。</p><p><code>Invalidate QueuesOne reason that invalidate acknowledge messages can take so long is that they must ensure that the correspondingcache line is actually invalidated, and this invalidation can be delayed if the cache is busy, for example, if the CPU is intensively loading and storing data, all of which resides in the cache. In addition, if a large number of invalidate messages arrive in a short time period, a given CPU might fall behind in processing them, thus possibly stalling all the other CPUs.</code></p><p>invalidate acknowledge不能尽快回复的主要原因是invalidate cacheline的操作没有那么快完成，特别是cache比较繁忙的时候，这时，CPU往往进行密集的loading和storing的操作，而来自其他CPU的，对本CPU local cacheline的操作需要和本CPU的密集的cache操作进行竞争，只要完成了invalidate操作之后，本CPU才会发生invalidate acknowledge。此外，如果短时间内收到大量的invalidate消息，CPU有可能跟不上处理，从而导致其他CPU不断的等待。</p><p><code>However, the CPU need not actually invalidate the cache line before sending the acknowledgement. It could instead queue the invalidate message with the understanding that the message will be processed before the CPU sends any further messages regarding that cache line.</code></p><p>然而，CPU其实不需要完成invalidate操作就可以回送acknowledgement消息，这样，就不会阻止发生invalidate请求的那个CPU进入无聊的等待状态。CPU可以buffer这些invalidate message（放入Invalidate Queues），然后直接回应acknowledgement，表示自己已经收到请求，随后会慢慢处理。当然，再慢也要有一个度，例如对a变量cacheline的invalidate处理必须在该CPU发送任何关于a变量对应cacheline的操作到bus之前完成。</p><p>有了Invalidate Queue的CPU，在收到invalidate消息的时候首先把它放入Invalidate Queue，同时立刻回送acknowledge 消息，无需等到该cacheline被真正invalidate之后再回应。当然，如果本CPU想要针对某个cacheline向总线发送invalidate消息的时候，那么CPU必须首先去Invalidate Queue中看看是否有相关的cacheline，如果有，那么不能立刻发送，需要等到Invalidate Queue中的cacheline被处理完之后再发送。</p><p><code>Placing an entry into the invalidate queue is essentially a promise by the CPU to process that entry before transmitting any MESI protocol messages regarding that cache line. As long as the corresponding data structures are not highly contended, the CPU will rarely be inconvenienced by such a promise.</code></p><p>一旦将一个invalidate（例如针对变量a的cacheline）消息放入CPU的Invalidate Queue，实际上该CPU就等于作出这样的承诺：在处理完该invalidate消息之前，不会发送任何相关（即针对变量a的cacheline）的MESI协议消息。只要是对该cacheline的竞争不是那么剧烈，CPU还是对这样的承诺很有信心的</p><p>因为多了 store buffer 和 invalidate queue，cache 之间的资料就没有完全一致了</p><h2 id="一个小案例"><a href="#一个小案例" class="headerlink" title="一个小案例"></a>一个小案例</h2><p>有了上面一连串理论知识的铺垫，下面看一个小例子，这个例子是老演员了，其实也是摘自perfbook中的，在查阅资料过程中发现很多博客都是用的这个图</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> a = b = <span class="number">0</span>;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">foo</span><span class="params">(<span class="keyword">void</span>)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  a = <span class="number">1</span>;</span><br><span class="line">  b = <span class="number">1</span>;</span><br><span class="line">&#125;</span><br><span class="line">  </span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">bar</span><span class="params">(<span class="keyword">void</span>)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="keyword">while</span> (b == <span class="number">0</span>) <span class="keyword">continue</span>;</span><br><span class="line">  <span class="keyword">assert</span>(a == <span class="number">1</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>考虑 CPU 0 执行 foo()， CPU 1 执行 bar()，也就是我们常说的多线程环境，假设 cache 的状态如下:<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">        a       b</span><br><span class="line">------------------------</span><br><span class="line">CPU <span class="number">0</span>:  Shared  Modified</span><br><span class="line">CPU <span class="number">1</span>:  Shared  Invalid</span><br></pre></td></tr></table></figure></p><p>其实可以理解为假设 a,b 初始值为 0 ，a 被 CPU0 和 CPU1 共同持有，b 被 CPU0 独占</p><p>试想，即便在多线程环境下，foo 和 bar 如若严格按照理想的顺序执行，是无论如何都不会出现 assert failed 的情况的。但往往事与愿违，这种看似很诡异的且有一定几率发生的 assert failed ，结合上面所说的 Store Buffer 就一点都不难理解了<br>我们来还原 assert failed 的整个过程</p><ol><li>CPU0 处理 a=1 之前发送 Invalidate 消息给 CPU1 ，并将其放入 Store Buffer ，尚未及时刷入缓存，所以这时候 cache 里a的值仍是 0；</li><li>CPU 0 转而处理 b=1 ，注意这里我们上面假设的是此时b 的状态已是 Modified，所以 b=1 直接被刷入缓存；</li><li>CPU 1 发出 Read 消息读取 b 的值，CPU 1 从 CPU 0 的 cache 读到 b = 1 ，跳出 while 语句；</li><li>CPU 1 发出 Read 消息读取 a 的值，发现 a 却为旧值 0，assert failed，然后收到 CPU 0 送来 “invalidate a” 的讯息，但已太迟了</li></ol><p>上面这个还原过程摘自一个台湾人写的博客&lt;從硬體觀點了解 memory barrier 的實作和效果&gt;<br>个人感觉这个描述过程不完全准确，既然已经有了Invalidate Queue，这个时候cpu1理论上是立刻给cpu0发ack的，可能由于当前要回复的ack很多，导致发送给cpu0的ack并没有达到”立刻”的效果<br>所以出现上面描述的过程也是有可能的，但是其实还有一种可能，就是读取a的时候最新值Invalidate Queue中，详细在下面的个人理解环节中  </p><font color="red"><br>个人理解如下<br>1. 大致流程是CPU0这个时候想要对a进行写值，发现a对应的cacheline对应的状态是S，也就是这里的cpu1上也有a的值，所以需要通知cpu1，通过总线发个消息告知cpu1进行invalid，因为有storebuffer这玩意所以直接放到storebuffer，又因为有invalidate queue的存在<br>2. 所以CPU1立刻回复了“已更新”的ack回去了，其实并没有实际更新，只是先放在了invalidate queue中待更改标记为invalid，CPU0收到这个ack后将数据回写到内存中<br>3. 此时CPU0开始了执行下一条对b写值，因为b是M状态也是说是cpu0独占的，所以直接写到缓存就完事了<br>4. 再来到cpu1这边看看，此时cpu1读取b的值，因为cpu1上没有对应的cacheline，cpu0上b对应的cacheline是M状态，所以此时cpu0会将b的值写回到memory,并且这个时候cpu1读取到的值是最新的和memory一样，此时cpu1和cpu0上b对于的cacheline状态变为S<br>5. 这个时候再看assert(a == 1);  此时CPU1读取到的数值a仍然是S状态，所以直接读取了，读取出来自然是0，因为此时并没有去invalidate queue看看有没有值，所以看到的值不是最新的，出现assert fail<br><br>如何解决这个问题呢？可以在foo函数a=1下面加一个写内存屏障，这样的话当a=1的值放到storebuffer中后，发现后面有一个写内存屏障指令，这个时候就会把后面的写指令都会顺序放到storebuffer中。另外在bar函数第二行读取a的时候需要看下invalidqueue中有没有值，有的话一定要将对应值得cacheline标记为无效，然后去读取最新值，这就引入了读内存屏障，强制标记队列中所有的值对应cacheline为无效<br></font> <p>上面的这个程序在实际开发中也是有可能会遇到的，于是 CPU提供了write memory barrier 以及 read memory barrier，让软件有机会避免这个问题</p><h2 id="write-memory-barrier"><a href="#write-memory-barrier" class="headerlink" title="write memory barrier"></a>write memory barrier</h2><p>比如在上面的 foo 方法中，a 的赋值和 b 的赋值之间加上这个write memory barrier<br>会使得 CPU 在后续变量变更写入之前，把 Store Buffer 的变更写入 flush 到缓存；CPU 要么就等待 flush 完成后写入，要么就把后续的写入变更放到 Store Buffer 中，直到 Store Buffer 数据顺序刷到缓存。<br><strong>write memory barrier 确保之前在 store buffer 里的资料会先更新到 cache，然后才能写入 barrier 之后的资料到 cache。</strong></p><p>假设我们在 foo() 的 a=1 和 b=1 之间插一个 write memory barrier，过程变为</p><ol><li>write memory barrier 先设 store buffer 里的资料为 “marked” (即 a=1)</li><li>写入 b 的时候，因为发现 store buffer 里有 marked 的栏位，所以即使 b 已处于 Modified，仍需写入 b=1 到 store buffer，不过状态是 “unmarked”</li><li>待收到 a 的 invalidate ack 后，cache 中 a 的状态改为 Modified，然后先写入有 marked 栏位的值到 cache，再写入 unmarked 栏位的值到 cache。</li></ol><p>这样其它 CPU 就会依序看到 a、b 更新的值了</p><h2 id="read-memory-barrier"><a href="#read-memory-barrier" class="headerlink" title="read memory barrier"></a>read memory barrier</h2><p>还是以上面的例子说明，假设 CPU 1 的 cache 里 a 处于 Shared。 CPU 0 已更新 a、b 到它的 cache，CPU 1 的 invalidate queue 里有 “invalidate a”，但还没处理。<br>这时 CPU 1 依序读 b、a 的值，会从 CPU 0 的 cache 读到 b=1，然后从自己的 cache 读到 a=0 (因为还没 invalidate a)。和上面的写入情况本质一样的，invalidate queue破坏了缓存一致性<br>invalidate queue是最新的，但是 a 处于 Shared，所以会从cache中直接拿，拿得是0，不是最新的<br>所以即便在foo函数给a,b分别赋值中间加上写栅栏，还是不能完全保证得到的结果是我们想要的，其实这个时候，可以猜到需要在assert之前也就是读取a之前加上一个读栅栏read memory barrier<br>目的很明确确保先清空 invalidate queue 再继续读资料。<br>在 assert(a==1) 之前插入 read memory barrier，执行顺序变成这样:</p><ol><li>CPU 1 执行 read memory barrier 时会设 invalidate queue 里的资料为 “marked”</li><li>CPU 1 读 cache 里 a 的值时，发现 invalidate queue 里有标记 a，于是会先执行 invalidate a 再继续读 a 的值</li><li>执行 invalidate a 后，就不会读自己 cache 的值，而改从 CPU 0 的 cache 读到最新的值，达到「依序读 b、a 的值」的效果</li></ol><h2 id="第二个小案例"><a href="#第二个小案例" class="headerlink" title="第二个小案例"></a>第二个小案例</h2><p>再摘一句perfbook的话，说的有点意思</p><p><code>Since the standard synchronization primitives preserve the illusion of ordering, your path of least resistance is to stop reading this section and simply use these primitives.However, if you need to implement the synchronization primitives themselves, or if you are simply interested in understanding how memory ordering and memory barriers work, read on!</code></p><p>你也许面对CPU的这种out of order的行为有本能的抵抗，没有关系，放轻松，你的抵抗之路可以到此结束，只要你愿意使用各种同步原语来保护你程序中的共享资源，因为透过这些标准的同步原语，你看到的是一个顺序执行的世界。当然，这会引入一些小小的遗憾：你不知道底层到底是如何把“乱序”变成“有序”的。不过，实现同步原语的那些软件工程师没有这个豁免权，他们必须要深入理解memory order和memory barrier。此外，那些想要“打破沙锅问到底”以及想要“知其然知其所以然”的工程师也可以跟随我们继续。</p><p>再举一个例子，摘自 perfbook memory barrier（14.2章节）<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1</span> thread0(<span class="keyword">void</span>)</span><br><span class="line"><span class="number">2</span> &#123;</span><br><span class="line"><span class="number">3</span> A = <span class="number">1</span>;</span><br><span class="line"><span class="number">4</span> smp_wmb();</span><br><span class="line"><span class="number">5</span> B = <span class="number">1</span>;</span><br><span class="line"><span class="number">6</span> &#125;</span><br><span class="line"><span class="number">7</span></span><br><span class="line"><span class="number">8</span> thread1(<span class="keyword">void</span>)</span><br><span class="line"><span class="number">9</span> &#123;</span><br><span class="line"><span class="number">10</span> <span class="keyword">while</span> (B != <span class="number">1</span>)</span><br><span class="line"><span class="number">11</span> <span class="keyword">continue</span>;</span><br><span class="line"><span class="number">12</span> barrier();</span><br><span class="line"><span class="number">13</span> C = <span class="number">1</span>;</span><br><span class="line"><span class="number">14</span> &#125;</span><br><span class="line"><span class="number">15</span></span><br><span class="line"><span class="number">16</span> thread2(<span class="keyword">void</span>)</span><br><span class="line"><span class="number">17</span> &#123;</span><br><span class="line"><span class="number">18</span> <span class="keyword">while</span> (C != <span class="number">1</span>)</span><br><span class="line"><span class="number">19</span> <span class="keyword">continue</span>;</span><br><span class="line"><span class="number">20</span> barrier();</span><br><span class="line"><span class="number">21</span> <span class="keyword">assert</span>(A != <span class="number">0</span>);</span><br><span class="line"><span class="number">22</span> &#125;</span><br></pre></td></tr></table></figure></p><p>开始，变量A，B，C的初始值都是0。根据程序逻辑：thread0中，A先于B赋值，thread1中，程序逻辑是一直等到B变量被赋值为1之后，再给C赋值。这里，人类的直觉告诉我们，如果变量C已经被赋值为1的时候（第13行程序），A一定已经被赋值为1了。同样的，在thread2中，第21行程序的assert一定是不会被触发的。</p><p><code>This line of reasoning, intuitively obvious though it may be, is completely and utterly incorrect. Please note that this is not a theoretical assertion: actually running this code on real-world weakly-ordered hardware (a 1.5GHz 16-CPU POWER 5 system) resulted in the assertion firing 16 times out of 10 million runs. Clearly, anyone who produces code with explicit memory barriers should do some extreme testing – although a proof of correctness might be helpful, the strongly counter-intuitive nature of the behavior of memory barriers should in turn strongly limit one’s trust in such proofs. The requirement for extreme testing should not be taken lightly, given that a number of dirty hardware-dependent tricks were used to greatly increase the probability of failure in this run.</code></p><p>上一节的推理从直觉上看是对的，但是在实际的CPU上运行的结果确是完全错误的。特别需要指出的是这个结果不是理论推导得出来的，是在真实的1.5GHz 16核的POWER 5系统（该cpu的内存模型属于weakly order）上观测得到的，平均每1千万次执行会有16次在21行代码处出现assert失败。很显然，当我们撰写显式调用memory barrier的代码的时候，必须进行非常大量的实际测试。在理论上进行正确性的推导是否有意义呢？也许有帮助，但是，你知道的，在使用memory barrier的时候会发生很多和你的直觉相悖的东西，这让理论的推导变得不那么确定。别小看那些看起来愚蠢的、非常重复性的大量测试，要知道不同的CPU会使用不同的硬件设计方法，因此在memory order和memory barrier方面表现各不相同，你的程序想要在各种硬件上，每次都运行成功不是一件容易的事情。</p><font color="red"><br>个人理解:<br>到底发生了什么让程序在21行的assert上失败？我们一起分析一下。我们假设CPU0、CPU1和CPU2分别执行thread0、thread1和thread2<br>1. 对于thread 0，我们假设A在CPU0的local cache中，但是状态是shared，因此当执行A=1的语句的时候，不能立刻执行，需要和其他CPU cache进行沟通（发送invalidate message去其他CPU），当然，cpu不会停下其脚步，将A的新值1放入store buffer，继续执行。<br>2. smp_wmb可以mark store buffer中A值，并且阻止后续的store操作进入cache，这时候，即便B在CPU0的local cache中，B=1的赋值也不能操作到cache，而是要进入store buffer，当然状态是unmarked。前面说过，后面进cache的话是marked先进然后unmarked进，由于存在Invalidate Queue这中东西，因此，CPU 0很快就可以收到来自其他CPU的响应，这时候，CPU0可以越过write memory barrier，完成对B的赋值。此时A的状态切到M，回写到cache中，B也跟着回写到cache中了。<br>3. 因此，对于thread1，很快可以感知B的新值“1”并执行了对C变量的赋值。来到thread2，同样的，对C变量的load操作也可以感知到thread1中的赋值因此跳出while循环。<br>4. 最关键的来了，第20行的barrier这个优化屏障不能阻止CPU对A变量的访问，但是，可能由于这时CPU cache操作非常繁忙，A变量的invalidate message还在其invalidate queue中，因此load A得到了旧的值0。<br><br>当然，要修正这个问题非常简单，修改20行代码为smp_rmb即可。一旦执行了smp_rmb，就会mark invalidate queue中的entry，这时候，CPU执行后续的load操作都必须要等到Invalidate queue中的所有缓存的invalidate message（当然，状态必须是marked）被处理并体现到cache中。因此，使用smp_rmb即可以在21行的load A操作中总是获取A的新值“1”从而避免了assert fail。<br>这里有个疑问就是例子中的barrier();这玩意到底到底代表啥意思，按照作者想要表达的意思是barrier()起不到读屏障的功能，要改为smp_rmb<br></font> <h2 id="简要归纳"><a href="#简要归纳" class="headerlink" title="简要归纳"></a>简要归纳</h2><p>硬件为了减少读写 memory 而有 cache。有 cache 就要确保 cache 之间的资料一致 (同一时间同一位置只有一个值)。但确保 cache 资料完全一致容易让 CPU 闲置，于是有了 store buffer 和 invalidate queue 降少 CPU 闲置。代价是只保证 CPU 自己会读到自己写入的最新数据，但其它 CPU 不一定。<br><strong>为了让其它 CPU 有需要的时候也能读到最新的资料，针对 store buffer 和 invalidate queue 的副作用设计了 write/read memory barrier</strong><br>于是写程序的人在需要的时候可以用 memory barrier 确保关键的数据有依正确的顺序更新 (没保证更新的时间)。 CPU 在多数情况下仍能避免闲置。<br>到此可以了解为什么这两种操作合在一起比较符合 CPU 架构：</p><ul><li>一个 thread 「先 write X 后执行 write memory barrier」</li><li>另一个 thread 「先执行 read memory barrier 后 read X」</li></ul><h1 id="java内存模型"><a href="#java内存模型" class="headerlink" title="java内存模型"></a>java内存模型</h1><p>这里再谈一下java的内存模型，这个模型是抽象出来的，下面这个图网上找的也是老演员了，最初来自深入理解虚拟机一书<br><img src="http://blog.lihaizhou.top/MemBarrier/memory-barrier07.png" alt=""></p><font color="red"><br>个人理解:<br>这里的java线程对应着cpu，工作内存其实是不存在的，可以简单的理解为是cpu的cache，save和load其实对应的是缓存一致性协议<br></font> <h2 id="JVM-barrier"><a href="#JVM-barrier" class="headerlink" title="JVM barrier"></a>JVM barrier</h2><ul><li>LoadLoad：两个 Load 操作之间内存屏障，smp_rmb 就是典型实现；</li><li>StoreStore：两个Store 操作之间的内存屏障，smp_wmb 典型实现；</li><li>LoadStore：在 Load 操作和 Store 操作之间的内存屏障；</li><li>StoreLoad：在 Store 操作和  Load 操作之间的内存屏障</li></ul><font color="red"><br>个人理解添加<br>以StoreLoad为例，这个是上面四个中最重的，最耗性能的，storeload其实能涵盖上面三个，因为它既保证了写也保证了读，它和loadstore的侧重点不一样，loadstore对于后面的那个写什么时候能写进去不是非常要求，更侧重的是前面的写。前一个是写后一个是读，后一个读取不能重排到这个写操作之前，也就是load时要看到前面写的值，这也就要保证前一个写的内容如果在storebuffer中就一定要写到cache中.<br>然后load的时候不能直接去读cache的值，要将invalidqueue中的值处理掉，该标记无效的都要进行标记，确保读取出来的是最新的。<br></font>   <p>对于java中的volatile防止重排网上博客一大堆，有些文章从汇编角度来分析加了volatile前后的对比，本地测试过hsdis可以用来将java转换为对应的汇编，这里就不展开了     </p><p><font color="red"> 个人理解<br>volatile最重要的使命是为了可见性，为了达到可见性这个目的不得不设计出防止指令重排，因为如果不限制重排，就达不到可见性这个目的<br>所以可以理解防止重排只是达到可见性的一个不得已手段<br></font><br><br>   </p><p><strong>参考文章</strong><br><a href="https://www.infoq.com/articles/memory_barriers_jvm_concurrency/" target="_blank" rel="noopener">Memory Barriers and JVM Concurrency</a><br><a href="http://www.wowotech.net/kernel_synchronization/memory-barrier.html" target="_blank" rel="noopener">Linux内核同步机制之（三）：memory barrier</a><br><a href="https://medium.com/fcamels-notes/%E5%BE%9E%E7%A1%AC%E9%AB%94%E8%A7%80%E9%BB%9E%E4%BA%86%E8%A7%A3-memry-barrier-%E7%9A%84%E5%AF%A6%E4%BD%9C%E5%92%8C%E6%95%88%E6%9E%9C-416ff0a64fc1" target="_blank" rel="noopener">從硬體觀點了解 memory barrier 的實作和效果</a><br><a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2015/p0098r0.pdf" target="_blank" rel="noopener">P0098R0: Towards Implementation and Use ofmemoryorderconsume</a><br><a href="https://createpoint.qti.qualcomm.com/search/contentdocument/stream/35553?refererRoute=search%2FsearchArgs%2Fq%7C%7CMemory%20Barriers%7C%7Crows%7C%7C10%7C%7CsortField%7C%7Cscore%7C%7CsortOrder%7C%7Cdesc&amp;dcn=80-N5603-1&amp;currentPage=1&amp;itemTotalIndex=1" target="_blank" rel="noopener">LINUX MEMORY ORDERING ON SCORPION-MP AND KRAIT APPLICATION PROCESSORS</a><br><a href="https://preshing.com/20120710/memory-barriers-are-like-source-control-operations/" target="_blank" rel="noopener">Memory Barriers Are Like Source Control Operations</a><br><a href="https://mp.weixin.qq.com/s?__biz=MzUzMDk3NjM3Mg==&amp;mid=2247483755&amp;idx=1&amp;sn=50f80e73f46fab04d8a799e8731432c6&amp;chksm=fa48da70cd3f5366d9658277cccd9e36fca540276f580822d41aef7d8af4dda480fc85e3bde4&amp;token=630636109&amp;lang=zh_CN#rd" target="_blank" rel="noopener">从 Java 内存模型看内部细节</a><br><a href="http://www.4e00.com/blog/java/2018/10/21/inside-java-memory-model.html" target="_blank" rel="noopener">深入理解 java 内存模型</a><br><a href="http://www.wowotech.net/memory_management/458.html" target="_blank" rel="noopener">浅谈Cache Memory</a><br><a href="http://www.wowotech.net/kernel_synchronization/Why-Memory-Barriers.html" target="_blank" rel="noopener">Why Memory Barriers</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;本篇文章开始之前需要了解一些背景知识&lt;/p&gt;
&lt;h1 id=&quot;Cache-Memory&quot;&gt;&lt;a href=&quot;#Cache-Memory&quot; class=&quot;headerlink&quot; title=&quot;Cache Memory&quot;&gt;&lt;/a&gt;Cache Memory&lt;/h1&gt;&lt;p&gt;我们都知
      
    
    </summary>
    
      <category term="Linux" scheme="http://lihaizhou.top/categories/Linux/"/>
    
    
  </entry>
  
  <entry>
    <title>谁拖慢了列表的滑动速度</title>
    <link href="http://lihaizhou.top/2020/03/04/%E8%B0%81%E6%8B%96%E6%85%A2%E4%BA%86%E5%88%97%E8%A1%A8%E7%9A%84%E6%BB%91%E5%8A%A8%E9%80%9F%E5%BA%A6/"/>
    <id>http://lihaizhou.top/2020/03/04/谁拖慢了列表的滑动速度/</id>
    <published>2020-03-04T13:59:04.000Z</published>
    <updated>2021-10-16T07:14:28.000Z</updated>
    
    <content type="html"><![CDATA[<p><strong>问题描述</strong><br>在开机向导界面滑动wifi列表界面时比较卡顿，概率为必现</p><p>抓一份systrace，红色帧有多处，总体上看有不少处发生掉帧<br><img src="http://blog.lihaizhou.top/List_kadun/wifi%E5%88%97%E8%A1%A8%E5%8D%A1%E9%A1%BF1.jpg" alt=""></p><p>挑其中一处红色帧放大看下<br><img src="http://blog.lihaizhou.top/List_kadun/wifi%E5%88%97%E8%A1%A8%E5%8D%A1%E9%A1%BF2.png" alt=""><br>耗时中的measure是大头，其中一次measure有数十次obtainview，对比其他绿色正常帧，发现正常的时候没有measure的过程<br>放大一次obtainview的过程，做的其实是inflate一项item的过程，红圈处对应了wifi一个item的布局<br><img src="http://blog.lihaizhou.top/List_kadun/wifi%E5%88%97%E8%A1%A8%E5%8D%A1%E9%A1%BF3.png" alt=""><br>我们都知道，ViewRootImpl的performTraversals方法会经过measure、layout和draw三个流程才能将一帧View需要显示的内容绘制到屏幕上</p><ul><li>performMeasure: 从根节点向下遍历View树，完成所有ViewGroup和View的测量工作，计算出所有ViewGroup和View显示出来需要的高度和宽度</li><li>performLayout()：从根节点向下遍历View树，完成所有ViewGroup和View的布局计算工作，根据测量出来的宽高及自身属性，计算出所有ViewGroup和View显示在屏幕上的区域；</li><li>performDraw()：从根节点向下遍历View树，完成所有ViewGroup和View的绘制工作，根据布局过程计算出的显示区域，将所有View的当前需显示的内容画到屏幕上</li></ul><p>对应到我们这个问题，此时大概心里有数了，一帧的耗时并不是计算显示在哪个区域以及本身的内容绘制耗时，而是计算需要显示的高度或宽度耗时，注意这里是计算这个列表的高度或宽度耗时了，因为每次measure都对应了数十次的加载item的过程，很显然需要依据item的高度或宽度来最终确定列表的高度或宽度</p><p>故真相只有一个，就是列表很可能使用了自适应的高度或宽度</p><p>看下代码<br><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">&lt;LinearLayout</span><br><span class="line">     android:id=<span class="string">"@+id/provision_lyt_content"</span></span><br><span class="line">     android:layout_width=<span class="string">"match_parent"</span></span><br><span class="line">     android:layout_height=<span class="string">"0dip"</span></span><br><span class="line">     android:layout_weight=<span class="string">"1"</span></span><br><span class="line">     android:layout_marginTop=<span class="string">"@dimen/provision_content_top_padding"</span></span><br><span class="line">     android:paddingStart=<span class="string">"@dimen/provision_list_left_padding"</span></span><br><span class="line">     android:paddingEnd=<span class="string">"@dimen/provision_list_right_padding"</span></span><br><span class="line">     android:orientation=<span class="string">"vertical"</span>&gt;</span><br><span class="line">     &lt;ListView</span><br><span class="line">         android:id=<span class="string">"@android:id/list"</span></span><br><span class="line">         android:layout_width=<span class="string">"match_parent"</span></span><br><span class="line">         android:layout_height=<span class="string">"wrap_content"</span> /&gt;</span><br><span class="line"> &lt;/LinearLayout&gt;</span><br></pre></td></tr></table></figure></p><p> 果不其然，这里设置了自适应的高度，修改为match_parent后再次测试发现卡顿消失<br>抓取改后的systrace<br><img src="http://blog.lihaizhou.top/List_kadun/wifi%E5%88%97%E8%A1%A8%E5%8D%A1%E9%A1%BF4.png" alt=""></p><p>基本上没有了红色帧，每一帧的绘制不再有measure的过程<br>其实这个问题不抓systrace，看traceview同样能够定位，只是没有systrace直观</p><p>到这里，还有一个疑问，当view设置了自适应高度后，它的高度由其子view的高度决定，故需要计算它的所有子view高度后才能确定自身的显示高度<br>这一点容易理解，但是具体到onMeasure的代码里是如何实现的呢？<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">frameworks/base/core/java/android/view/ViewRootImpl.java</span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">performMeasure</span><span class="params">(<span class="keyword">int</span> childWidthMeasureSpec, <span class="keyword">int</span> childHeightMeasureSpec)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (mView == <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line">     <span class="comment">//这里对应了systrace中measure tag</span></span><br><span class="line">        Trace.traceBegin(Trace.TRACE_TAG_VIEW, <span class="string">"measure"</span>);</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            mView.measure(childWidthMeasureSpec, childHeightMeasureSpec);</span><br><span class="line">        &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">            Trace.traceEnd(Trace.TRACE_TAG_VIEW);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure></p><p>其中的mView.measure(childWidthMeasureSpec, childHeightMeasureSpec);通过参数可以看到，view的显示宽高用到了其子view的宽高作为约束条件<br>listview必定会重写onMeasure，直接跟到其源码中<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">frameworks/base/core/java/android/widget/ListView.java</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">onMeasure</span><span class="params">(<span class="keyword">int</span> widthMeasureSpec, <span class="keyword">int</span> heightMeasureSpec)</span> </span>&#123;</span><br><span class="line">        <span class="comment">// Sets up mListPadding</span></span><br><span class="line">        <span class="keyword">super</span>.onMeasure(widthMeasureSpec, heightMeasureSpec);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">final</span> <span class="keyword">int</span> widthMode = MeasureSpec.getMode(widthMeasureSpec);</span><br><span class="line">        <span class="keyword">final</span> <span class="keyword">int</span> heightMode = MeasureSpec.getMode(heightMeasureSpec);</span><br><span class="line">        <span class="keyword">int</span> widthSize = MeasureSpec.getSize(widthMeasureSpec);</span><br><span class="line">        <span class="keyword">int</span> heightSize = MeasureSpec.getSize(heightMeasureSpec);</span><br><span class="line">          <span class="comment">//....</span></span><br><span class="line">          </span><br><span class="line">          <span class="keyword">if</span> (heightMode == MeasureSpec.AT_MOST) &#123;</span><br><span class="line">              <span class="comment">// <span class="doctag">TODO:</span> after first layout we should maybe start at the first visible position, not 0</span></span><br><span class="line">              heightSize = measureHeightOfChildren(widthMeasureSpec, <span class="number">0</span>, NO_POSITION, heightSize, -<span class="number">1</span>);</span><br><span class="line">          &#125;</span><br><span class="line">            <span class="comment">//...</span></span><br><span class="line">         &#125;</span><br></pre></td></tr></table></figure></p><p>我们都知道wrap_content对应的mode为<code>MeasureSpec.AT_MOST</code>,这时候调用到measureHeightOfChildren开始计算其子view的宽高</p><p>这里看注释描述，如果指定了高度，则measure会停止<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">     * Measures the height of the given range of children (inclusive) and</span></span><br><span class="line"><span class="comment">     * returns the height with this ListView's padding and divider heights</span></span><br><span class="line"><span class="comment">     * included. If maxHeight is provided, the measuring will stop when the</span></span><br><span class="line"><span class="comment">     * current height reaches maxHeight.</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> widthMeasureSpec The width measure spec to be given to a child's</span></span><br><span class="line"><span class="comment">     *            &#123;<span class="doctag">@link</span> View#measure(int, int)&#125;.</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> startPosition The position of the first child to be shown.</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> endPosition The (inclusive) position of the last child to be</span></span><br><span class="line"><span class="comment">     *            shown. Specify &#123;<span class="doctag">@link</span> #NO_POSITION&#125; if the last child should be</span></span><br><span class="line"><span class="comment">     *            the last available child from the adapter.</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> maxHeight The maximum height that will be returned (if all the</span></span><br><span class="line"><span class="comment">     *            children don't fit in this value, this value will be</span></span><br><span class="line"><span class="comment">     *            returned).</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> disallowPartialChildPosition In general, whether the returned</span></span><br><span class="line"><span class="comment">     *            height should only contain entire children. This is more</span></span><br><span class="line"><span class="comment">     *            powerful--it is the first inclusive position at which partial</span></span><br><span class="line"><span class="comment">     *            children will not be allowed. Example: it looks nice to have</span></span><br><span class="line"><span class="comment">     *            at least 3 completely visible children, and in portrait this</span></span><br><span class="line"><span class="comment">     *            will most likely fit; but in landscape there could be times</span></span><br><span class="line"><span class="comment">     *            when even 2 children can not be completely shown, so a value</span></span><br><span class="line"><span class="comment">     *            of 2 (remember, inclusive) would be good (assuming</span></span><br><span class="line"><span class="comment">     *            startPosition is 0).</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span> The height of this ListView with the given children.</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@UnsupportedAppUsage</span>(maxTargetSdk = Build.VERSION_CODES.P, trackingBug = <span class="number">115609023</span>)</span><br><span class="line">    <span class="function"><span class="keyword">final</span> <span class="keyword">int</span> <span class="title">measureHeightOfChildren</span><span class="params">(<span class="keyword">int</span> widthMeasureSpec, <span class="keyword">int</span> startPosition, <span class="keyword">int</span> endPosition,</span></span></span><br><span class="line"><span class="function"><span class="params">            <span class="keyword">int</span> maxHeight, <span class="keyword">int</span> disallowPartialChildPosition)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">final</span> ListAdapter adapter = mAdapter;</span><br><span class="line">        <span class="keyword">if</span> (adapter == <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span> mListPadding.top + mListPadding.bottom;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// Include the padding of the list</span></span><br><span class="line">        <span class="keyword">int</span> returnedHeight = mListPadding.top + mListPadding.bottom;</span><br><span class="line">        <span class="keyword">final</span> <span class="keyword">int</span> dividerHeight = mDividerHeight;</span><br><span class="line">        <span class="comment">// The previous height value that was less than maxHeight and contained</span></span><br><span class="line">        <span class="comment">// no partial children</span></span><br><span class="line">        <span class="keyword">int</span> prevHeightWithoutPartialChild = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">int</span> i;</span><br><span class="line">        View child;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// mItemCount - 1 since endPosition parameter is inclusive</span></span><br><span class="line">        endPosition = (endPosition == NO_POSITION) ? adapter.getCount() - <span class="number">1</span> : endPosition;</span><br><span class="line">        <span class="keyword">final</span> AbsListView.RecycleBin recycleBin = mRecycler;</span><br><span class="line">        <span class="keyword">final</span> <span class="keyword">boolean</span> recyle = recycleOnMeasure();</span><br><span class="line">        <span class="keyword">final</span> <span class="keyword">boolean</span>[] isScrap = mIsScrap;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (i = startPosition; i &lt;= endPosition; ++i) &#123;</span><br><span class="line">            child = obtainView(i, isScrap);</span><br><span class="line"></span><br><span class="line">            measureScrapChild(child, i, widthMeasureSpec, maxHeight);</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> (i &gt; <span class="number">0</span>) &#123;</span><br><span class="line">                <span class="comment">// Count the divider for all but one child</span></span><br><span class="line">                returnedHeight += dividerHeight;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="comment">// Recycle the view before we possibly return from the method</span></span><br><span class="line">            <span class="keyword">if</span> (recyle &amp;&amp; recycleBin.shouldRecycleViewType(</span><br><span class="line">                    ((LayoutParams) child.getLayoutParams()).viewType)) &#123;</span><br><span class="line">                recycleBin.addScrapView(child, -<span class="number">1</span>);</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            returnedHeight += child.getMeasuredHeight();</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> (returnedHeight &gt;= maxHeight) &#123;</span><br><span class="line">                <span class="comment">// We went over, figure out which height to return.  If returnedHeight &gt; maxHeight,</span></span><br><span class="line">                <span class="comment">// then the i'th position did not fit completely.</span></span><br><span class="line">                <span class="keyword">return</span> (disallowPartialChildPosition &gt;= <span class="number">0</span>) <span class="comment">// Disallowing is enabled (&gt; -1)</span></span><br><span class="line">                            &amp;&amp; (i &gt; disallowPartialChildPosition) <span class="comment">// We've past the min pos</span></span><br><span class="line">                            &amp;&amp; (prevHeightWithoutPartialChild &gt; <span class="number">0</span>) <span class="comment">// We have a prev height</span></span><br><span class="line">                            &amp;&amp; (returnedHeight != maxHeight) <span class="comment">// i'th child did not fit completely</span></span><br><span class="line">                        ? prevHeightWithoutPartialChild</span><br><span class="line">                        : maxHeight;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> ((disallowPartialChildPosition &gt;= <span class="number">0</span>) &amp;&amp; (i &gt;= disallowPartialChildPosition)) &#123;</span><br><span class="line">                prevHeightWithoutPartialChild = returnedHeight;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// At this point, we went through the range of children, and they each</span></span><br><span class="line">        <span class="comment">// completely fit, so return the returnedHeight</span></span><br><span class="line">        <span class="keyword">return</span> returnedHeight;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure></p><p>这里最关键的代码: <code>child = obtainView(i, isScrap);</code></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">    * Gets a view and have it show the data associated with the specified</span></span><br><span class="line"><span class="comment">    * position. This is called when we have already discovered that the view</span></span><br><span class="line"><span class="comment">    * is not available for reuse in the recycle bin. The only choices left are</span></span><br><span class="line"><span class="comment">    * converting an old view or making a new one.</span></span><br><span class="line"><span class="comment">    *</span></span><br><span class="line"><span class="comment">    * <span class="doctag">@param</span> position the position to display</span></span><br><span class="line"><span class="comment">    * <span class="doctag">@param</span> outMetadata an array of at least 1 boolean where the first entry</span></span><br><span class="line"><span class="comment">    *                    will be set &#123;<span class="doctag">@code</span> true&#125; if the view is currently</span></span><br><span class="line"><span class="comment">    *                    attached to the window, &#123;<span class="doctag">@code</span> false&#125; otherwise (e.g.</span></span><br><span class="line"><span class="comment">    *                    newly-inflated or remained scrap for multiple layout</span></span><br><span class="line"><span class="comment">    *                    passes)</span></span><br><span class="line"><span class="comment">    *</span></span><br><span class="line"><span class="comment">    * <span class="doctag">@return</span> A view displaying the data associated with the specified position</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">   <span class="function">View <span class="title">obtainView</span><span class="params">(<span class="keyword">int</span> position, <span class="keyword">boolean</span>[] outMetadata)</span> </span>&#123;</span><br><span class="line">       Trace.traceBegin(Trace.TRACE_TAG_VIEW, <span class="string">"obtainView"</span>);</span><br><span class="line">       <span class="comment">//...</span></span><br><span class="line">       <span class="comment">//obtainView方法里面核心的代码其实就两行，首先从复用缓存中取出一个可以复用的View，然后作为参传入getView中，</span></span><br><span class="line"><span class="comment">//也就是convertView。这里会走到obtainview，子View实例都是由obtainView方法返回的，然后再调用具体measureScrapChild</span></span><br><span class="line"><span class="comment">//来具体测量子View的高度.</span></span><br><span class="line">        <span class="comment">//正常情况下这里for循环的次数就等于所有子项的个数，不过特殊的是已测量的子View高度之和大于maxHeight</span></span><br><span class="line"> <span class="comment">//就直接return出循环了。这种做法其实很好理解，ListView能显示的最大高度就是屏幕的高度，如果有1000个子项</span></span><br><span class="line"> <span class="comment">//前面10项已经占满了一屏幕了，那后面的990项就没必要继续测量高度了，这样可以大大提高性能</span></span><br><span class="line">      <span class="keyword">final</span> View scrapView = mRecycler.getScrapView(position);</span><br><span class="line">       <span class="keyword">final</span> View child = mAdapter.getView(position, scrapView, <span class="keyword">this</span>);</span><br><span class="line">       <span class="keyword">if</span> (scrapView != <span class="keyword">null</span>) &#123;</span><br><span class="line">           <span class="keyword">if</span> (child != scrapView) &#123;</span><br><span class="line">               <span class="comment">// Failed to re-bind the data, return scrap to the heap.</span></span><br><span class="line">               mRecycler.addScrapView(scrapView, position);</span><br><span class="line">           &#125; <span class="keyword">else</span> <span class="keyword">if</span> (child.isTemporarilyDetached()) &#123;</span><br><span class="line">               outMetadata[<span class="number">0</span>] = <span class="keyword">true</span>;</span><br><span class="line"></span><br><span class="line">               <span class="comment">// Finish the temporary detach started in addScrapView().</span></span><br><span class="line">               child.dispatchFinishTemporaryDetach();</span><br><span class="line">           &#125;</span><br><span class="line">       &#125;</span><br><span class="line">       <span class="comment">//....</span></span><br><span class="line">       setItemViewLayoutParams(child, position);</span><br><span class="line">       Trace.traceEnd(Trace.TRACE_TAG_VIEW);</span><br><span class="line">       <span class="keyword">return</span> child;</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure><p>出现问题时正是触发了onMeasure，导致遍历可见范围内的数十个wifi item并计算他们的高度</p><hr><p><strong>一点小结</strong></p><p>一个View最终显示到屏幕上一共分为三个阶段：Measure、Layout、Draw，而使用不当会造成其重复调用，尤其是Measure过程最为敏感。<br>因为当根布局做measure的时候，需要逐级measure子View和子布局，当所有子View或子布局measure完成的时候才能最终确定根部局的大小，<br>所以子布局的measure调用时机是由父布局来决定的。而像ListView这种在其onMeasure中直接调用getView的情况，<br>如果onMeasure被调用次数过多，将严重影响性能。</p><p>这里的listview还好外边没有裹着RelativeLayout，不然会导致子View的onMeasure重复调用，卡顿也会更加明显，假设RelativeLayout嵌套层数为n，子View的onMeasure次数为2^（n+1）</p><p>使用ListView的时候注意尽量使用layout_height=”match_parent”，如果无法避免，外边也不能裹着RelativeLayout</p><p>总而言之: 写代码三思而后行，谨慎再谨慎</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;strong&gt;问题描述&lt;/strong&gt;&lt;br&gt;在开机向导界面滑动wifi列表界面时比较卡顿，概率为必现&lt;/p&gt;
&lt;p&gt;抓一份systrace，红色帧有多处，总体上看有不少处发生掉帧&lt;br&gt;&lt;img src=&quot;http://blog.lihaizhou.top/List_
      
    
    </summary>
    
      <category term="性能" scheme="http://lihaizhou.top/categories/%E6%80%A7%E8%83%BD/"/>
    
    
  </entry>
  
  <entry>
    <title>一个SharedPreferences写操作导致的ANR问题分析</title>
    <link href="http://lihaizhou.top/2019/06/23/%E4%B8%80%E4%B8%AASharedPreferences%E5%86%99%E6%93%8D%E4%BD%9C%E5%AF%BC%E8%87%B4%E7%9A%84ANR%E9%97%AE%E9%A2%98%E5%88%86%E6%9E%90/"/>
    <id>http://lihaizhou.top/2019/06/23/一个SharedPreferences写操作导致的ANR问题分析/</id>
    <published>2019-06-23T12:11:32.000Z</published>
    <updated>2021-09-08T12:31:40.000Z</updated>
    
    <content type="html"><![CDATA[<p><code>问题现象</code><br>手机连接WIFI后出现设置弹出无响应的弹框<br><code>问题概率</code><br>仅出现一次<br><code>问题平台</code><br>Andorid P  高通平台</p><p><strong>日志分析</strong><br>拿到bugreport，使用chkbugreport解析下(开源工具，将bugreport庞大的日志进行分门别类，并以网页形式展现出来)，打开浏览器看下event日志中的时间点</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">06</span><span class="number">-19</span> <span class="number">17</span>:<span class="number">53</span>:<span class="number">42.307</span>  <span class="number">1000</span>  <span class="number">1820</span>  <span class="number">1959</span> I am_anr  : [<span class="number">0</span>,<span class="number">3861</span>,com.android.settings,<span class="number">952745541</span>,Input dispatching timed out (com.android.settings/com.android.settings.MainSettings</span><br></pre></td></tr></table></figure><p>解压后的bugreport中有一份ANR文件，查看其中的trace<br><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"main"</span> prio=<span class="number">5</span> tid=<span class="number">1</span> Blocked</span><br><span class="line">  | group=<span class="string">"main"</span> sCount=<span class="number">1</span> dsCount=<span class="number">0</span> flags=<span class="number">1</span> obj=<span class="number">0x7923e118</span> self=<span class="number">0x763be14c00</span></span><br><span class="line">  | sysTid=<span class="number">3861</span> nice=<span class="number">-10</span> cgrp=<span class="keyword">default</span> sched=<span class="number">0</span>/<span class="number">0</span> handle=<span class="number">0x76c1e12548</span></span><br><span class="line">  | state=S schedstat=( <span class="number">4685634510</span> <span class="number">1791639950</span> <span class="number">6133</span> ) utm=<span class="number">380</span> stm=<span class="number">88</span> core=<span class="number">3</span> HZ=<span class="number">100</span></span><br><span class="line">  | stack=<span class="number">0x7fe6270000</span><span class="number">-0x7fe6272000</span> stackSize=<span class="number">8</span>MB</span><br><span class="line">  | held mutexes=</span><br><span class="line">  at android.app.QueuedWork.processPendingWork(QueuedWork.java:<span class="number">273</span>)</span><br><span class="line">  - waiting to lock &lt;<span class="number">0x00210110</span>&gt; (a java.lang.Object) held by thread <span class="number">19</span></span><br><span class="line">  at android.app.QueuedWork.waitToFinish(QueuedWork.java:<span class="number">184</span>)</span><br><span class="line">  at android.app.ActivityThread.handleStopActivity(ActivityThread.java:<span class="number">4305</span>)</span><br></pre></td></tr></table></figure></p><p>可以看出主线程在等锁0x00210110，该锁被thread 19持有，这里看堆栈可以看出卡在了waitToFinish上，界面回调了onStop的生命函数，<br>是不是可以理解为当时界面走了onStop准备退出，发现有任务没有完成，需要等待，猜测如此，继续看thread 19</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"queued-work-looper"</span> prio=<span class="number">5</span> tid=<span class="number">19</span> Native</span><br><span class="line">  | group=<span class="string">"main"</span> sCount=<span class="number">1</span> dsCount=<span class="number">0</span> flags=<span class="number">1</span> obj=<span class="number">0x130c0958</span> self=<span class="number">0x762df62800</span></span><br><span class="line">  | sysTid=<span class="number">3892</span> nice=<span class="number">-2</span> cgrp=<span class="keyword">default</span> sched=<span class="number">0</span>/<span class="number">0</span> handle=<span class="number">0x76223ff4f0</span></span><br><span class="line">  | state=D schedstat=( <span class="number">8250990</span> <span class="number">10651510</span> <span class="number">31</span> ) utm=<span class="number">0</span> stm=<span class="number">0</span> core=<span class="number">1</span> HZ=<span class="number">100</span></span><br><span class="line">  | stack=<span class="number">0x76222fc000</span><span class="number">-0x76222fe000</span> stackSize=<span class="number">1041</span>KB</span><br><span class="line">  | held mutexes=</span><br><span class="line">  kernel: (couldn<span class="string">'t read /proc/self/task/3892/stack)</span></span><br><span class="line"><span class="string">  native: #00 pc 000000000007b070  /system/lib64/libc.so (fsync+8)</span></span><br><span class="line"><span class="string">  native: #01 pc 0000000000003670  /system/lib64/libopenjdkjvm.so (JVM_Sync+20)</span></span><br><span class="line"><span class="string">  native: #02 pc 000000000001cd54  /system/lib64/libopenjdk.so (FileDescriptor_sync+40)</span></span><br><span class="line"><span class="string">  at java.io.FileDescriptor.sync(Native method)</span></span><br><span class="line"><span class="string">  at android.os.FileUtils.sync(FileUtils.java:197)</span></span><br><span class="line"><span class="string">  at android.app.SharedPreferencesImpl.writeToFile(SharedPreferencesImpl.java:777)</span></span><br><span class="line"><span class="string">  at android.app.SharedPreferencesImpl.access$900(SharedPreferencesImpl.java:54)</span></span><br><span class="line"><span class="string">  at android.app.SharedPreferencesImpl$2.run(SharedPreferencesImpl.java:642)</span></span><br><span class="line"><span class="string">  - locked &lt;0x08e457c5&gt; (a java.lang.Object)</span></span><br><span class="line"><span class="string">  at android.app.QueuedWork.processPendingWork(QueuedWork.java:286)</span></span><br><span class="line"><span class="string">  - locked &lt;0x00210110&gt; (a java.lang.Object)</span></span><br></pre></td></tr></table></figure><p>这里的堆栈可以看出，当时在做SharedPreference的IO操作，锁的持有对象当时在做processPendingWork，可是为什么Activity的onStop要等SharedPreference写完呢？</p><p>再来看下主线程中的堆栈</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">at android.app.QueuedWork.waitToFinish(QueuedWork.java:<span class="number">184</span>)</span><br><span class="line">at android.app.ActivityThread.handleStopActivity(ActivityThread.java:<span class="number">4305</span>)</span><br></pre></td></tr></table></figure><p>看下ActivityThread.java中的handleStopActivity</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">handleStopActivity</span><span class="params">(IBinder token, <span class="keyword">boolean</span> show, <span class="keyword">int</span> configChanges,</span></span></span><br><span class="line"><span class="function"><span class="params">            PendingTransactionActions pendingActions, <span class="keyword">boolean</span> finalStateRequest, String reason)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">final</span> ActivityClientRecord r = mActivities.get(token);</span><br><span class="line">        r.activity.mConfigChangeFlags |= configChanges;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">final</span> StopInfo stopInfo = <span class="keyword">new</span> StopInfo();</span><br><span class="line">        performStopActivityInner(r, stopInfo, show, <span class="keyword">true</span> <span class="comment">/* saveState */</span>, finalStateRequest,</span><br><span class="line">                reason);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (localLOGV) Slog.v(</span><br><span class="line">            TAG, <span class="string">"Finishing stop of "</span> + r + <span class="string">": show="</span> + show</span><br><span class="line">            + <span class="string">" win="</span> + r.window);</span><br><span class="line"></span><br><span class="line">        updateVisibility(r, show);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// Make sure any pending writes are now committed.</span></span><br><span class="line">        <span class="keyword">if</span> (!r.isPreHoneycomb()) &#123;</span><br><span class="line">            QueuedWork.waitToFinish();</span><br><span class="line">        &#125;</span><br><span class="line">    <span class="comment">//...</span></span><br><span class="line">     &#125;</span><br></pre></td></tr></table></figure><p>重点关注其中的waitToFinish()函数</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">     * Trigger queued work to be processed immediately. The queued work is processed on a separate</span></span><br><span class="line"><span class="comment">     * thread asynchronous. While doing that run and process all finishers on this thread. The</span></span><br><span class="line"><span class="comment">     * finishers can be implemented in a way to check weather the queued work is finished.</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * Is called from the Activity base class's onPause(), after BroadcastReceiver's onReceive,</span></span><br><span class="line"><span class="comment">     * after Service command handling, etc. (so async work is never lost)</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">waitToFinish</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="comment">// xxx ADD</span></span><br><span class="line">        <span class="keyword">boolean</span> interrupt = <span class="keyword">false</span>;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">long</span> startTime = System.currentTimeMillis();</span><br><span class="line">        <span class="keyword">boolean</span> hadMessages = <span class="keyword">false</span>;</span><br><span class="line"></span><br><span class="line">        Handler handler = getHandler();</span><br><span class="line"></span><br><span class="line">        <span class="keyword">synchronized</span> (sLock) &#123;</span><br><span class="line">            <span class="keyword">if</span> (handler.hasMessages(QueuedWorkHandler.MSG_RUN)) &#123;</span><br><span class="line">                <span class="comment">// Delayed work will be processed at processPendingWork() below</span></span><br><span class="line">                handler.removeMessages(QueuedWorkHandler.MSG_RUN);</span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> (DEBUG) &#123;</span><br><span class="line">                    hadMessages = <span class="keyword">true</span>;</span><br><span class="line">                    Log.d(LOG_TAG, <span class="string">"waiting"</span>);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="comment">// We should not delay any work as this might delay the finishers</span></span><br><span class="line">            sCanDelay = <span class="keyword">false</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        StrictMode.ThreadPolicy oldPolicy = StrictMode.allowThreadDiskWrites();</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">// xxx MOD</span></span><br><span class="line">            <span class="comment">// processPendingWork();</span></span><br><span class="line">            interrupt = processPendingWork(<span class="keyword">false</span>);</span><br><span class="line">        &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">            StrictMode.setThreadPolicy(oldPolicy);</span><br><span class="line">        &#125;</span><br></pre></td></tr></table></figure><p>依据trace，接着看processPendingWork</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">boolean</span> <span class="title">processPendingWork</span><span class="params">(<span class="keyword">boolean</span> fromMsg)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">long</span> startTime = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">int</span> workNdx = <span class="number">0</span>;</span><br><span class="line">        <span class="comment">// if (DEBUG) &#123;</span></span><br><span class="line">        startTime = System.currentTimeMillis();</span><br><span class="line">        <span class="comment">// &#125;</span></span><br><span class="line">    <span class="comment">// END</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">synchronized</span> (sProcessingWork) &#123; <span class="comment">//#273 主线程卡在这里等锁</span></span><br><span class="line">            LinkedList&lt;Runnable&gt; work;</span><br><span class="line"></span><br><span class="line">            <span class="keyword">synchronized</span> (sLock) &#123;</span><br><span class="line">                work = (LinkedList&lt;Runnable&gt;) sWork.clone();</span><br><span class="line">                sWork.clear();     </span><br><span class="line">            <span class="comment">// Remove all msg-s as all work will be processed now</span></span><br><span class="line">           getHandler().removeMessages(QueuedWorkHandler.MSG_RUN);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span> (work.size() &gt; <span class="number">0</span>) &#123;</span><br><span class="line">                <span class="keyword">for</span> (Runnable w : work) &#123;</span><br><span class="line">                    w.run(); <span class="comment">//#286 tid19 一直在运行该处</span></span><br><span class="line">                    .....</span><br><span class="line">                    &#125;</span><br><span class="line">            &#125;</span><br></pre></td></tr></table></figure><p>到这里基本明白了是怎么回事了，主线程在等的SharedPreference的写操作writeToFile完成，如果这个队列中的任务没有完成，SharedPreference就会一直持有这个锁，主线程拿不到这个锁，<br>一直等待，超过五秒后触发ANR，这点在日志中也得到了印证，ANR时间点前后有不少的SharedPreferencesImpl相关的日志输出，往上看大概能看出当时是在做同步数据之类</p><p>其实SharedPreference时不论是apply还是commit都会有出现写入磁盘慢的情况发生，特别是数据量大，或者多线程同时访问同一份xml，又或者连续多次commit，都会有可能造成waitToFinish函数耗时变长。虽然apply是异步执行的，主线程依旧需要等它执行结束。这点其实不好规避，所以尽可能的少使用SharedPreference，特别是可能存在多线程操作同一份数据这种情况，毕竟有了加锁，会可能出现排队的情况。</p><p><code>优化方式</code><br>尽可能传输的数据量轻量<br>尽可能减少commit次数<br>考虑新开线程，但是会有内存开销的存在，如果原本是apply，则在新开的线程改为commit</p><p>其实看公司内部代码，发现公司的framework同事有修改waitToFinish函数中调用的processPendingWork函数内容，增加了记录时间，<br>超过10s直接return false，这是个不错的想法，但是10s对于广播中的情况或许可以cover，对应Activity中超时5秒就ANR的这种情况不能cover</p><p>鉴于该问题只出现一次，不做修改</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;code&gt;问题现象&lt;/code&gt;&lt;br&gt;手机连接WIFI后出现设置弹出无响应的弹框&lt;br&gt;&lt;code&gt;问题概率&lt;/code&gt;&lt;br&gt;仅出现一次&lt;br&gt;&lt;code&gt;问题平台&lt;/code&gt;&lt;br&gt;Andorid P  高通平台&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;日志分析&lt;/str
      
    
    </summary>
    
      <category term="性能" scheme="http://lihaizhou.top/categories/%E6%80%A7%E8%83%BD/"/>
    
    
  </entry>
  
  <entry>
    <title>Launcher应用的重构之路</title>
    <link href="http://lihaizhou.top/2019/04/12/Launcher%E5%BA%94%E7%94%A8%E7%9A%84%E9%87%8D%E6%9E%84%E4%B9%8B%E8%B7%AF/"/>
    <id>http://lihaizhou.top/2019/04/12/Launcher应用的重构之路/</id>
    <published>2019-04-12T12:19:11.000Z</published>
    <updated>2021-09-08T12:28:54.000Z</updated>
    
    <content type="html"><![CDATA[<p><strong>当前需求</strong><br>新项目遵循竞品的Launcher样式设计<br><strong>当前计划</strong><br>重新编写Launcher，并尽可能的弥补老框架的不足</p><p><strong>为什么需要重写Launcher？</strong><br>从样式上来看<br>新版Launcher的UI显示上与老版本差异较大，左右滑动的菜单页变化最大<br>从代码结构上看<br>一. 不符合单一原则:  视图层承担过重的业务数据处理逻辑, 老版本的视图层代码量比较大，主Activity及LauncherService均近两千行，承担的任务过重。其中包含了View的显示逻辑，也有数据处理的逻辑，也有接收广播相关，也有与Fwk的网络接口交互处理的逻辑，还有一些其他应用需要在返回Launcher后对自身的一些判断逻辑等。<br>二. 从整个应用的角度来看，很多界面存在重复的冗余工作，比如判断接收login广播，判断电量，判断是否高温，json报文的解析等，需要抽取公共的行为封装并下沉，尽可能的使上层的处理优雅且简单<br>三. 页面间的耦合严重，彼此相互持有，难以剥离开来，且项目代码中大多缺少注释，理解上存在难度</p><p>综合考虑觉得采取重写或许会合适些</p><p><strong>前期研究</strong><br>当前市面上存在MVP,MVVM等等架构，先对这些架构做简单介绍</p><label style="color:red">一. MVC</label><br>MVC全名是<code>Model View Controller</code>，是模型(<code>model</code>)－视图(<code>view</code>)－控制器(<code>controller</code>)的缩写<br>其中M层处理数据，业务逻辑等；V层处理界面的显示结果；C层起到桥梁的作用，来控制V层和M层通信以此来达到分离视图显示和业务逻辑层<br><img src="https://github.com/hellolihaizhou/saveImg/blob/master/1_MVC.png?raw=true" align="left" style=" width:300px;height:100 px"><br><br><br><br><br><br><br><br>视图层(<code>View</code>)<br>一般采用<code>XML</code>文件进行界面的描述<br>控制层(<code>Controller</code>)<br>Android的Controller层的重任通常落在了众多的Activity的肩上，这也是MVC架构的一大弊病<br>模型层(<code>Model</code>)<br>Model是与View无关，与业务相关的，对数据库的操作、对网络等的操作都应该在Model里面处理，对业务计算等操作也是必须放在的该层的。<br>1. View接受用户的交互请求；<br>2. View将请求转交给Controller；<br>3. Controller（用户做的动作比如：update数据，删除指定名字的学生等等）操作Model进行数据更新（根据用户指示，执行底层的数据动作等等）；<br>4. 数据更新之后，Model通知View数据变化；<br>5. View显示更新之后的数据；<br><br>举个例子: Launcher中下拉状态栏显示天气的动作，如果是用<code>MVC</code>的架构，则大概是这样的一个过程:<br>View即状态栏接收到用户下拉的动作，此时C层即Activity向M层请求天气的数据，M层获取天气的方法被调用后，获取天气无论成功或失败，都会将状态通知给监听者这里即C层进行视图更新，这里的通知通过接口回调方式，即C层需要实现天气是否成功的接口比如onError, onSuccess<br><br>弊端:<br>第一，View层和Controller层没有分离，逻辑比较混乱；<br>第二，同样因为 View和 Controller层的耦合，导致Activity或者Fragment很臃肿，代码量很大。如果Activity 中的业务量很大，就像我们的老版Launcher，那么问题就会体现出来，一个Activity的代码行数高达近2000行<br><br><label style="color:red">二.MVP(对MVC的改进版)</label><br><code>Presenter</code>负责逻辑的处理，Model提供数据，View负责显示<br><img src="https://github.com/hellolihaizhou/saveImg/blob/master/2_MVP.png?raw=true" align="left" style=" width:300px;height:100 px"><br><br><br><br><br><br><br><br><code>MVP</code>框架由3部分组成：<code>View</code>负责显示，<code>Presenter</code>负责逻辑处理，<code>Model</code>提供数据。在MVP模式里通常包含3个要素（加上View interface是4个）：<br>View:负责绘制UI元素、与用户进行交互(在Android中体现为Activity)<br><code>Model</code>:负责存储、检索、操纵数据(有时也实现一个Model interface用来降低耦合)<br><code>Presenter</code>:作为View与Model交互的中间纽带，处理与用户交互的负责逻辑。<br><code>View interface</code>:需要View实现的接口，View通过View interface与Presenter进行交互，降低耦合，方便进行单元测试<br><br>显而易见的变化时引入了P层，来承担之前C层的工作，而Activity的角色变成了仅仅显示的V层，但是考虑到V层需要和P层交互，所以这里增加了一层接口层View interface<br>概述下来就是:<br>当 View 需要更新数据时，首先去找 Presenter，然后 Presenter 去找 Model 请求数据，Model 获取到数据之后通知 Presenter，Presenter 再通知 View 更新数据，这样 Model 和 View 就不会直接交互了，所有的交互都由 Presenter 进行，Presenter 充当了桥梁的角色。很显然，Presenter 必须同时持有 View 和 Model 的对象的引用，才能在它们之间进行通信<br>好处很明显: view与model完全解耦，它们的通信都要经过presenter<br>弊端也显而易见: presenter会过于复杂庞大 ,  view与presenter交互频繁，耦合度高 , presenter持有activity引用，可能引起内存泄露，需要在Activity退出时做额外处理<br>还以我们的Launcher下拉状态栏为例，如果是用MVP的架构，则大概是这样的一个过程:<br>下拉状态栏动作触发后，调用Presenter中请求天气的接口，将自身传进去，Presenter的请求方法拿到Activity的引用，并在该请求方法中调用Model的请求数据方法，同样将自身传进去，Model层获取数据后无论失败与否都会回调Presenter的处理结果方法，Presenter的处理结果方法会回调View的处理结果方法，这样View层拿到数据并做视图更新<br>这里的实现常用做法一般会将Presenter和Model层的接口抽取出来，写对应的实现类，层次上看的更分明些<br><br><label style="color:red">三.MVVM</label><br><code>MVVM</code>可以算是<code>MVP</code>的升级版，其中的VM是<code>ViewModel</code>的缩写，ViewModel可以理解成是View的数据模型和Presenter的合体，ViewModel和View之间的交互通过Data Binding完成，而Data Binding可以实现双向的交互，这就使得视图和控制层之间的耦合程度进一步降低，关注点分离更为彻底，同时减轻了Activity的压力。<br><img src="https://github.com/hellolihaizhou/saveImg/blob/master/3_MVVM.png?raw=true" align="left" style=" width:600px;height:200 px"><br><br><br><br><br><br><br>MVVM架构通过<code>ViewModel</code>隔离了UI层和业务逻辑层，降低程序的耦合度。通过<code>DataBinding</code>实现<code>View</code>和<code>ViewModel</code>之间的绑定。<br>好处:<br>在MVVM中，这些都是通过数据驱动来自动完成的，数据变化后会自动更新UI，UI的改变也能自动反馈到数据层，数据成为主导因素。这样MVVM层在业务逻辑处理中只要关心数据，不需要直接和UI打交道，在业务处理过程中简单方便很多<br>MVVM模式中，数据是独立于UI的<br>在MVVM中，数据发生变化后，我们在工作线程直接修改（在数据是线程安全的情况下）ViewModel的数据即可，不用再考虑要切到主线程更新UI了，这些事情相关框架都帮我们做了<br>关于MVVM不做多介绍，最大的变化无非就是引入了<code>Data Binding</code>，使得数据成为核心驱动<br><br><code>MVC</code> -&gt; <code>MVP</code> -&gt; <code>MVVM</code> 这几个软件设计模式是一步步演化发展的，<code>MVVM</code>是从 <code>MVP</code>的进一步发展与规范，<code>MVP</code> 隔离了<code>MVC</code>中的 M 与 V 的直接联系后，靠 Presenter 来中转，所以使用<code>MVP</code> 时 P 是直接调用 View 的接口来实现对视图的操作的，这个 View 接口的东西一般来说是<code>showData</code>、<code>showprogress</code>等。M 与 V已经隔离了，方便测试了，但代码还不够优雅简洁，所以 <code>MVVM</code>就弥补了这些缺陷。在 MVVM 中就出现的 <code>Data Binding</code> 这个概念，意思就是 View 接口的 showData 这些实现方法可以不写了，通过Data Binding 来自动实现<br><br>老版launcher的可以认为是VC结构，M的数据处理内容多放在C层或者util包中，utils包下还是直接持有引用调用，所以只有两层V和C<br><br>研究下来，觉得如上的三种模式都不太适合我们的项目，理由如下<br>1. MVC到改进版MVP再到后期的MVVM架构，MVC本质上是MC架构，Model与Control层耦合严重，MVP在MVC的基础上增加一层接口解耦，MVVM在MVP的基础上又增加了一层接口，虽耦合性进一步降低，但是存在很多的接口定义导致代码的可读性降低<br>2. 可切入性不强: 不利于团队同事快速加入适应，存在学习成本<br>3. 如上的三种模式本质其实是思想的演变，边界并不是很明显，只要能够很好地解耦就是最好的解决方法<br><br><label style="color:red">综合比较下来，决定根据我们自身业务定制，采用Model+View+事件总线的方式</label><p><strong>Step1: 分层结构</strong><br><img src="https://github.com/hellolihaizhou/saveImg/blob/master/4_%E5%88%86%E5%B1%82%E7%BB%93%E6%9E%84.png?raw=true" align="left" style=" width:700px;height:200 px"><br><br><br><br><br><br><br><br><br><br>这是我们Launcher的分层结构<br>业务逻辑层：<br>由业务需求来决定，如二维码展示，通知，SOS，绑定解绑等模块。通用功能抽取成独立于具体业务需求的模块，在模块内部实现通用的业务逻辑，同时对外暴露调用接口，不同的业务只需调用通用模块即可<br>基础框架层：<br>往往是根据功能来划分，可细分为网络支持功能、图片库、日志系统、数据库支持等模块<br>这一层目标是与具体业务解耦并对外提供良好的交互接口，后续的修改尽可能不在原来基础上修改而是采用扩展的方式，遵循开闭原则<br>lib库层：主要是三方的lib库，这些库为上层功能支持，如我们项目当前使用到的Glide,二维码等</p><p><strong>Step2: 分层结构基础上进一步细化</strong><br>为解决层与层以及同层之间的页面通信问题，引入数据处理框架<br>数据处理框架示意图:<br><img src="https://github.com/hellolihaizhou/saveImg/blob/master/5_%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%A1%86%E6%9E%B6.png?raw=true" align="left" style=" width:550px;height:600 px"><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br></p><p><label style="color:red">Step2.1 为什么要引入数据处理模块？</label></p><ol><li>我们当前的项目中请求服务端数据比较直接，直接调用Fwk的接口，虽然该接口是我们自己实现做在Fwk中并已经做了封装，不过因接收到返回数据的处理逻辑很多都是做在视图层，     且页面间的数据交互是通过相互持有实例调用，页面间耦合严重</li><li>视图层收到报文后直接显示，缺少校验的过程，这部分逻辑若做在视图层，会增加代码量且不符合单一职责</li><li>因联网后有多处需要调用Fwk接口获取网络数据，比较分散，且开多个线程占用内存较多且和UI线程抢占CPU资源，有概率影响UI线程视图的刷新速度</li><li>将处理数据均放置在数据处理模块，便于后续问题定位，数据定位模块细分为网络数据上传，网络数据拉取，持久化数据存储，报文的解析校验等</li></ol><p>数据处理模块在这里起到了一个加工数据并中转的角色，这样视图层和网络层就解耦了，避免了视图层直接和网络层交互，后续所有视图层需要和网络数据交互，视图界面之间的数据交互均通过数据处理模块，这样一来还有个好处就是视图层的代码量将大幅减少，视图页面间的耦合性消除，代码的可读性增</p><p><label style="color:red">Step2.2 数据处理模块承担哪些工作？</label><br>将所有需要和网络交互的数据获取和上传，以及数据库读写，File文件的读写，网络JSON数据的解析提取关键信息等数据处理相关的代码均放置在数据处理模块中</p><p><label style="color:red">一. 并发多任务执行同步操作</label><br>考虑到我们的Launcher需要在联网后做很多同步服务端的操作，比如同步时间，同步功能控制，同步天气等，这些操作实时性要求较高，需要当请求到达时，工作线程已经存在。故采取开启线程池以支持这些同步操作能够并发进行，节省了创建线程的过程，并能保证任务超过核心线程数时能得到复用，一定程度上节省了内存开销，另外一个好处是最大程度上加快联网数据获取，同时线程池默认background优先级，尽可能的保证UI线程的视图绘制优先进行，这样开机后Launcher加载时就不可能出现视图卡顿的现象。<br>线程池的理想大小取决于被提交任务的类型以及机器的处理器数量，线程池的大小需要避免“过大”和“过小”这两种极端情况</p><ol><li>如果线程池过大，那么大量的线程将在相对很少的CPU和内存资源上发生竞争，这不仅会导致更高的内存使用量，而且还可能耗尽资源。</li><li>如果线程池过小，那么将导致许多空闲的处理器无法执行工作，从而降低吞吐率<br>一般来说，核心线程数设置为2N+1(N为核数)</li></ol><p><label style="color:red">为什么要自定义线程池而不采用自带线程池？</label><br>阿里java开发手册中有如下解释:<br>【强制】}新建线程时，必须通过线程池提供（AsyncTask 或者 ThreadPoolExecutor 或者其他形式自定义的线程池），不允许在应用中自行显式创建线程。 说明： 使用线程池的好处是减少在创建和销毁线程上所花的时间以及系统资源的开销，解 决资源不足的问题。如果不使用线程池，有可能造成系统创建大量同类线程而导致 消耗完内存或者“过度切换”的问题。另外创建匿名线程不便于后续的资源使用分析， 对性能分析等会造成困扰。<br>【强制】}线程池不允许使用 Executors 去创建，而是通过 ThreadPoolExecutor 的方式，这样的处理方式让写的同学更加明确线程池的运行规则，规避资源耗尽的风险。 说明： Executors 返回的线程池对象的弊端如下：<br><code>FixedThreadPool</code>和 <code>SingleThreadPool</code>： 允 许 的 请 求 队 列 长 度 为 <code>Integer.MAX_VALUE</code>，可能会堆积大量的请求，从而导致 OOM；<br><code>CachedThreadPool</code> 和 <code>ScheduledThreadPool</code>： 允 许 的 创 建 线 程 数 量 为 <code>Integer.MAX_VALUE</code>，可能会创建大量的线程，从而导致 OOM。<br>当前的自定义线程池设置了核心线程数为5，当请求任务到达时，若池中暂无可用线程，则会走到拒绝策略中，将请求存在BlockingQueue中，待有闲置线程后，则继续执行<br>当前封装的线程池暴露出一个接口供Launcher中所有需要异步的地方使用，减少了内存的开销并且统一管理所有异步操作</p><p><label style="color:red">二.  合法性校验</label><br>考虑到任何数据源都无法保证能够返回合法的数据，如果不对数据错误进行容错处理，直接返回给视图层的话，会导致视图层无数据甚至异常。之前存在功能控制收到的报文中存在key对应的value是空的情况，Launcher直接<code>Crash</code>，这样很不友好，所以容错处理还是需要的，在数据处理模块中做数据的校验处理，确保返回给视图层的数据是否有效不知道，起码是合法的，不会出现空数据的情况，以保证视图层不会崩溃或显示异常。</p><p><strong>Step2.3 如何和视图层通信？</strong><br>前期研究<br>当前市面比较流行的是LiveData以及较早的EventBus,Otto等，其中基于LiveData的事件总线最为轻量且是谷歌官方支持，支持感知组件生命周期，且不需要解注册，对内存泄露都做了防控<br>为何不采用市面成熟的事件总线？</p><ol><li>我们的工程是源码工程不是gradle工程，无法通过依赖添加，只有通过jar包引入，弊端是不方便升级</li><li>项目需要向下兼容，低版本上如4.4存在注解不能使用的情况</li><li><code>LiveData</code>需要依赖Android官方<code>Android Architecture Components</code>组件的<code>LiveData</code>，在<code>gradle</code>工程下比较方便，对于我们的源码工程且需要支持多平台，需要引入较多的依赖文件，且存在一定的学习成本</li><li>基于<code>LiveData</code>的事件总线框架成熟且功能强大，功能较多，引入需投入时间成本进行研究，不然后续若出问题排查会无从下手<br><strong>自行设计事件总线的原理</strong><br>对市面主流的<code>eventbus</code>做了研究，考虑到eventbus文件数多达近二十个，考虑后续方便移植且方便定位问题，考虑设计一个满足我们业务需求的简化版事件总线<br>当前设计的事件总线采用类似订阅发布机制，支持一对一以及一对多通信，传递的消息实体支持泛型，核心当前只有两支文件，当前测试下来基本满足需求为方便应用使用，暴露的接口很简单，只有一个发送以及订阅接口，后续根据业务需要再看是否需要扩展</li></ol><p><strong>Step2.4 视图框架设计</strong></p><ol><li>主界面:<br>考虑使用<code>Fragment+ViewPager</code>，<code>Fragment</code>用来承载视图，优势在于轻量，加载速度快<br>菜单页均是<code>RecyclerView</code>或<code>ListView</code>展示数据，考虑到这些ListView均需要<code>ViewHolder</code>来填充视图，需要Adapter来填充数据，如果每个需要ListView的界面都维护各自的一套ViewHolder及Adapter，那么页面逻辑变得臃肿，整个Launcher的代码量也会比较大，所以这里考虑采用如下方式:<br>封装一个Adapter公共处理类，提供多种构造函数，其中有一个type参数，用来标明使用哪个ViewHolder，在Adapter的getView方法中，根据type参数，获取具体的ViewHolder实现<br>经过封装之后，视图层菜单页只需要向Adapter公共处理类传入一个type参数即可得到对应的Adapter，等数据返回到视图层后，再将数据传给Adapter公共处理类，其他什么都不用管，就可以展示列表数据了。这样设计的目的是将公共的行为抽取出来，大幅度减少菜单页的代码量，后续增加菜单页也会变得很简单。</li><li>下拉栏界面<br>分为<code>statusbar</code>以及通知栏，这里的诸多数据均需要调用系统的接口，比如电量，信号格，数据类型，将这些接口单独放在公共模块中，便于其他页面也能调用到</li><li>表盘界面<br>即待机界面，包括长按后进入表盘样式选择界面，这里已经做好了基类封装公共行为的操作，使得表盘样式的扩展变得很容易，只需要继承基类，改下布局文件即可</li></ol><p><strong>Step2.5 代码结构划分</strong><br>当前代码结构划分如下:<br><img src="https://github.com/hellolihaizhou/saveImg/blob/master/6_1_%E4%BB%A3%E7%A0%81%E7%BB%93%E6%9E%84.png?raw=true" align="left" style=" width:600px;height:600 px"><br><br><br><br><br><br><img src="https://github.com/hellolihaizhou/saveImg/blob/master/6_2_%E4%BB%A3%E7%A0%81%E7%BB%93%E6%9E%84.png?raw=true" align="left" style=" width:600px;height:600 px"><br><br><br><br><br><br><img src="https://github.com/hellolihaizhou/saveImg/blob/master/6_3_%E4%BB%A3%E7%A0%81%E7%BB%93%E6%9E%84.png?raw=true" align="left" style=" width:600px;height:100 px"><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br></p><p><strong>老项目上上存在的代码问题</strong></p><ol><li>存在不再使用的库文件但是并未移除，对库文件拿来直接用，对于所需功能过大过全，缺少裁剪过程，使用直接调用，与本身应用代码耦合度高，建议二次封装；</li><li>重复性代码较多，如接收心跳，监测电量，熄灭屏等</li><li>变量名和方法名很随意，建议驼峰命名，缺少注释，可读性差，添加类文件和文件夹，后面因为种种原因废弃，由于缺少注释且代码可读性差，导致成为僵尸代码，不利于后续接手人员维护。</li><li>逻辑过于冗长的方法，一大堆的if else，建议拆分优化；</li><li>没有考虑一些边界条件，比如请求失败，没有数据的情况，缺少容错处理；</li><li>代码存在很多容易造成空指针代码，最常见调用equals方法时，未遵循 “常量”.equals(变量) </li><li>static滥用，为内存泄露埋下伏笔</li><li>异步线程的滥用，使用new Thread方式过于简单粗暴，一个线程占用约1M内存，过多的开启会耗用不少内存</li><li>调用大多通过直接new对象方式持有引用，占用内存且强耦合，针对不同场景考虑单例或消息总线通信</li><li>代码美观方面，缺少缩进对齐随意空行，代码不规整</li><li>新加图片未进行压缩，建议png 图片使用 tinypng 或者类似工具压缩处理，减少包体积</li><li>对主线程子线程运行环境存在使用不当，Activity的生命周期方法中，广播的onreceive方法以及普通service中，存在耗时操作</li><li>修改已有稳定方法比较随意，往往塞进一大堆代码，带来隐患，建议进行扩展而不是修改原有设计，或者新增单独接口</li><li>对异步任务被中断情况，缺少资源清理，如AsyncTask或Handler异步更新UI，对任务未完成界面被退出情况，需要在ondestory或onPause中进行任务清理</li><li>过度的try catch，特别是catch了Exception这种基类，导致存在异常都被catch掉，将bug隐蔽起来，导致后期排查比较困难</li><li>界面间随意传递上下文context，为内存泄漏埋下伏笔</li></ol><hr><font color="#000000" size="2" face="楷体">good night！</font>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;strong&gt;当前需求&lt;/strong&gt;&lt;br&gt;新项目遵循竞品的Launcher样式设计&lt;br&gt;&lt;strong&gt;当前计划&lt;/strong&gt;&lt;br&gt;重新编写Launcher，并尽可能的弥补老框架的不足&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;为什么需要重写Launcher？&lt;/str
      
    
    </summary>
    
      <category term="Android" scheme="http://lihaizhou.top/categories/Android/"/>
    
    
  </entry>
  
  <entry>
    <title>Android 系统层捕捉所有应用崩溃情况推送到钉钉实践之路</title>
    <link href="http://lihaizhou.top/2019/03/11/Android-%E7%B3%BB%E7%BB%9F%E5%B1%82%E6%8D%95%E6%8D%89%E6%89%80%E6%9C%89%E5%BA%94%E7%94%A8%E5%B4%A9%E6%BA%83%E6%83%85%E5%86%B5%E6%8E%A8%E9%80%81%E5%88%B0%E9%92%89%E9%92%89%E5%AE%9E%E8%B7%B5%E4%B9%8B%E8%B7%AF/"/>
    <id>http://lihaizhou.top/2019/03/11/Android-系统层捕捉所有应用崩溃情况推送到钉钉实践之路/</id>
    <published>2019-03-11T14:19:11.000Z</published>
    <updated>2019-12-28T07:02:08.000Z</updated>
    
    <content type="html"><![CDATA[<p><strong>项目痛点</strong><br>出现偶现崩溃或<code>ANR</code>，因为没有开启日志开关，后面尝试复现又比较困难，研发同事比较苦恼，无从下手<br>还有一个测试同事抓取日志后还要记录时间点，再上传到JIRA上，研发同事下载日志还需要搜索报错点，整个流程比较费时</p><p><strong>初步想法</strong><br>可不可以将所有<code>ANR</code>,<code>Crash</code>等出错信息的关键日志片段直接传给服务器，在后面的摸索过程中发现钉钉可以提供对外的URL接口，这样的话直接传给钉钉就很方便了，正好平时的办公用的也是这个软件，这样一来就省去了很多的步骤，一步到位</p><p>以下是实做的步骤记录，只是实现了一个初稿，后面还需要不断优化完善</p><p><strong>Step1： 获取钉钉的<code>Webhook</code>地址</strong><br>这个地址后面作为推送的目标地址</p><p>在钉钉中添加机器人接口的步骤参见官网文档<br><a href="https://open-doc.dingtalk.com/docs/doc.htm?spm=a219a.7629140.0.0.XJQ2yZ&amp;treeId=257&amp;articleId=105735&amp;docType=1" target="_blank" rel="noopener">https://open-doc.dingtalk.com/docs/doc.htm?spm=a219a.7629140.0.0.XJQ2yZ&amp;treeId=257&amp;articleId=105735&amp;docType=1</a></p><p>通过以上步骤拿到了Laucnher的Webhook地址，如下:<br><a href="https://oapi.dingtalk.com/robot/send?access_token=a937a86122149aa52a694dd79fae2cdec1c7e448c62bff31471088ec13e941" target="_blank" rel="noopener">https://oapi.dingtalk.com/robot/send?access_token=a937a86122149aa52a694dd79fae2cdec1c7e448c62bff31471088ec13e941</a></p><p><strong>Step2：源码层增加上报机制</strong><br>之所以考虑在源码层中修改，是因为我们需要监测系统中所有应用的出错情况，想到<code>AMS</code>中的<code>Crash</code>弹框，猜想其中一定有相关的写入报错日志的操作</p><p><img src="https://github.com/hellolihaizhou/FrescoDemo/blob/master/handleApplicationCrash.png?raw=true" align="left" style=" width:700px;height:300 px"><br><br><br><br><br><br><br><br></p><p>这里调用了<code>handleApplicationCrashInner</code>这个函数，接着看这个函数<br><img src="https://github.com/hellolihaizhou/FrescoDemo/blob/master/handleApplicationCrashInner.png?raw=true" align="left" style=" width:700px;height:300 px"><br><br><br><br><br><br><br><br><br><br></p><p>这里追加了一行日志，在应用层添加会造成<code>crash</code>的代码片段，看看这行日志打出的信息</p><p><img src="https://github.com/hellolihaizhou/FrescoDemo/blob/master/crashLog.png?raw=true" align="left" style=" width:700px;height:300 px"><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br>这里会打出<code>eventtype</code>类型，报错进程，以及关键的堆栈信息，其中的<code>eventtype</code>包括了<code>watchdog</code>、<code>anr</code>、<code>wtf</code>、<code>lowmem</code>、<code>native_crash</code>、<code>crash</code><br>完全满足我们的要求，接下来就是如何把这段发给钉钉了<br>在<code>handleApplicationCrashInner</code>中增加接口<code>reportAllErrorToXunDingTalk</code></p><p><img src="https://github.com/hellolihaizhou/FrescoDemo/blob/master/AddReportFunction.png?raw=true" align="left" style=" width:700px;height:300 px"><br><br><br><br><br><br><br></p><p><code>reportAllErrorToXunDingTalk</code>接口如下：<br><img src="https://github.com/hellolihaizhou/FrescoDemo/blob/master/report1.png?raw=true" align="left" style=" width:700px;height:300 px"><br><img src="https://github.com/hellolihaizhou/FrescoDemo/blob/master/report2.png?raw=true" align="left" style=" width:700px;height:300 px"><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br></p><p>这个时候应用端报错的话话，钉钉群会收到消息<br><img src="https://github.com/hellolihaizhou/FrescoDemo/blob/master/dingding.png?raw=true" align="left" style=" width:700px;height:300 px"><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br></p><hr><font color="#000000" size="2" face="楷体">good night!</font>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;strong&gt;项目痛点&lt;/strong&gt;&lt;br&gt;出现偶现崩溃或&lt;code&gt;ANR&lt;/code&gt;，因为没有开启日志开关，后面尝试复现又比较困难，研发同事比较苦恼，无从下手&lt;br&gt;还有一个测试同事抓取日志后还要记录时间点，再上传到JIRA上，研发同事下载日志还需要搜索报错点，
      
    
    </summary>
    
      <category term="Android" scheme="http://lihaizhou.top/categories/Android/"/>
    
    
  </entry>
  
</feed>
