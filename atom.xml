<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>李海洲</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://lihaizhou.top/"/>
  <updated>2023-05-15T06:30:18.611Z</updated>
  <id>http://lihaizhou.top/</id>
  
  <author>
    <name>Steven Li</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>BPF | CPU scheduler 可行性调研</title>
    <link href="http://lihaizhou.top/2023/05/08/BPF-CPU-scheduler-%E5%8F%AF%E8%A1%8C%E6%80%A7%E8%B0%83%E7%A0%94/"/>
    <id>http://lihaizhou.top/2023/05/08/BPF-CPU-scheduler-可行性调研/</id>
    <published>2023-05-08T09:41:33.000Z</published>
    <updated>2023-05-15T06:30:18.611Z</updated>
    
    <content type="html"><![CDATA[<p>本文将主要涉及如下内容</p><p>1.解读<bpf scheduler=""> 邮件内容<br>  摘取其中的关键内容，尽量将围绕这个话题的关键讨论以时间线展示。</bpf></p><p>2.介绍Google 的GhOSt 开源框架</p><p>同时会穿插一些额外的内容(比如GKI 的基础介绍、OEM 的定制修改) 以便于更好的理解</p><p>备注：一笔关于BPF 实现的<a href="https://lkml.org/lkml/2023/1/27/1550" target="_blank" rel="noopener">sched_ext</a> 调度类去年11月底推到社区，引起了不少的讨论，由于代码量较大，相信会持续讨论较长时间，后面会新开一篇文章分析 </p><h3 id="关于BPF-scheduler-的邮件讨论"><a href="#关于BPF-scheduler-的邮件讨论" class="headerlink" title="关于BPF scheduler 的邮件讨论"></a>关于BPF scheduler <strong>的邮件讨论</strong></h3><p>将BPF 引入<code>CPU  scheduler</code>，业内有过一些讨论，涉及到的主要人物</p><ul><li><code>Roman Gushchin</code>  Facebook ，内核调度策略中加入BPF 基础设施的owner</li><li><code>Hao Luo</code>         Google，开源框架ghOSt 的owner，还有一个owner <code>Barret Rhoden</code></li><li><code>Qais Yousef</code>     ARM，针对Roman 的patchSet 提出一系列关于移动端的疑问</li><li><code>Ren Zhijie</code>      华为，  在<code>Roman</code> 的PatchSet 基础上做了二次开发</li></ul><p>故事的开始是Facebook 的<code>Roman Gushchin</code> 致力于想要将这笔<a href="https://lwn.net/ml/linux-kernel/20210916162451.709260-1-guro@fb.com/" target="_blank" rel="noopener">Scheduler BPF</a> 合入到内核主线中 ，对于该PatchSet 的目的他本人给出的理由：</p><blockquote><p>This patchset aims to start a discussion about potential applications of BPF to the scheduler. <strong>It also aims to land some very basic BPF infrastructure necessary to add new BPF hooks to the scheduler</strong>, a minimal set of useful helpers, corresponding libbpf changes, etc.</p></blockquote><p>本补丁集旨在启动关于将 BPF 应用于调度器的潜在应用讨论，它还旨在实现一些非常基本的 BPF 基础设施，以添加新的 BPF 钩子到调度器，提供一组最小的实用程序，对应的 libbpf 更改等。</p><p>同时<code>Roman Gushchin</code> 提到了目前这笔PatchSet 实测效果以及谷歌也正在做类似的事情</p><blockquote><p>Our very first experiments with using BPF in CFS look very promising. We’re at a very early stage, however already have seen a nice latency and ~1% RPS wins for our (Facebook’s) main web workload.</p><p>As I know, Google is working on a more radical approach [2]: they aim to move the scheduling code into userspace. It seems that their core motivation is somewhat similar: to make the scheduler changes easier to develop, validate and deploy. Even though their approach is different, they also use BPF for speeding up some hot paths. I think the suggested infrastructure can serve their purpose too.</p></blockquote><p>我们在 CFS 中使用 BPF 的第一个实验看起来非常有前途。虽然还处于早期阶段，但已经看到了对我们（Facebook）的主要 Web 工作负载产生的良好延迟和约 1% 的请求秒数优化。</p><p>据我所知，谷歌正在进行一种更激进的方法[2]：<strong>他们的目标是将调度代码移动到用户空间</strong>，看起来他们的核心动机也有些类似：</p><p><strong>使调度器的更改更易于开发，验证和部署。即使他们的方法不同，他们也使用 BPF 来加速一些热点路径，我认为所提供的基础设施也可以为他们的目的服务。</strong></p><p>额外补充：</p><p>这里<code>Roman Gushchin</code> 说的“他们的目标是将调度代码移动到用户空间”，容易让人误解，应该指的是调度的决策代码挪到了用户空间。事实上Google 的GhOSt 实际调度运行代码是在BPF 中实现的，运行在内核中，如果真的将调度代码挪到用户空间，那将引起大量的用户/内核之间的切换。</p><p>对于<code>Roman Gushchin</code> 上面邮件的内容</p><p>Google GhOSt  Owner <code>Hao Luo</code>  于15 Sep 2021 在邮件中回复到：</p><blockquote><p>Yes. Barret can talk more about this, but I think it summarized the work of ghOSt [3] and the use of BPF in ghOSt well. Looking forward, I agree that BPF has a great potential in customizing policies in the scheduler. It has the advantage of quick experimentation and deployment. One of the use cases I’m thinking of is to customize load balancing policies. For example, allow using BPF to influence whether a task can migrate (can_migrate_task). This is currently only an idea.</p></blockquote><p>没错，谷歌的开源框架ghOSt (<a href="https://lpc.events/event/11/contributions/954/" target="_blank" rel="noopener">Use of eBPF in cpu scheduler</a>) 正是利用BPF 实现了定制调度策略。</p><p>展望未来，我同意 BPF 对于定制化调度器策略有着巨大的潜力，它具有快速实验和部署的优势。我正在考虑其中一种用例，那就是定制负载平衡策略。</p><p>例如，可以使用 BPF 来影响一个任务是否可以迁移（can_migrate_task），这目前只是一个想法。</p><p>当天(15 Sep 2021) 晚些时候，<code>Roman Gushchin</code> 邮件回复了<code>Hao Luo</code></p><blockquote><p>I took a brief look over how you use BPF in ghOSt and I think what I suggest will work for you as well. I’d appreciate any comments/feedback whether it’s definitely true.</p></blockquote><p>我大致看了下你们用BPF 实现的ghOSt 框架，相信我的这笔patchSet 同样能够达到你们的目的。</p><p><code>Roman Gushchin</code> 和 <code>Hao Luo</code> 的邮件讨论，引起了来自ARM 的<code>Qais Yousef</code> 的注意</p><p><code>Yousef</code>于06 Oct 2021 回复了该主题的邮件，并提出了自己担忧</p><blockquote><p>I am (very) wary of these hooks. Scheduler (in mobile at least) is an area that gets heavily modified by vendors and OEMs. We try very hard to understand the problems they face and get the right set of solutions in mainline. Which would ultimately help towards the goal of having a single Generic kernel Image [1] that gives you what you’d expect out of the platform without any need for additional cherries on top. So my worry is that this will open the gate for these hooks to get more than just micro-optimization done in a platform specific way. And that it will discourage having the right discussion to fix real problems in the scheduler because the easy path is to do whatever you want in userspace. I am not sure we can control how these hooks are used.</p><p>The question is: why can’t we fix any issues in the scheduler/make it better and must have these hooks instead?</p></blockquote><p>我对这些钩子的引入非常担忧，调度器（至少在移动端）是一个被供应商和OEM大量客制化的领域。</p><p>我们非常努力地了解他们面临的问题，并在主线中获得正确的解决方案。这最终将有助于实现GKI 目标。所以，我担心这笔patchSet 一旦引入，内核将无法控制用户空间的行为。</p><p>问题是：</p><p><strong>为什么我们不能在内核主线中解决调度器中遇到的问题并使其更好，而非要使用这些钩子？</strong></p><p>同时，<code>Yousef</code> 提出如果要用钩子的话，最好要合入内核，这将使大家都能用得上，也方便以后追溯合入的原因，以及方便在不需要的时候移除。</p><p>额外补充：</p><p>这里说下OEM 客制化调度器这件事，社区一直在尝试解读OEM 的补丁修改，试图理解他们修改背后的动机，以便后续在主线内核中修复这些问题，同时摘取了一些OEM 的修改进行了性能测试验证。</p><p>详细可以阅读这篇文章 &lt;<a href="https://lwn.net/Articles/820825/" target="_blank" rel="noopener">Evaluating vendor changes to the scheduler</a>&gt;</p><p>另外，既然这里Yousef  提到了Android 的GKI，我们再简单的介绍下Google 对于ACK 后续的规划</p><p><img src="http://blog.lihaizhou.top/BPF-scheduler/BPF-scheduler2.png" alt="Untitled"></p><p>从上图可以看出，谷歌的目标是Android 通用内核 (ACK) 尽量贴近上游，所以后续对于内核的修改，厂商必须优先使用 Linux 内核邮件列表 (LKML) 向上游提交代码更改，并且只有在有充分理由说明上游不可行时才将代码更改提交到 ACK <code>android-mainline</code>分支。</p><p>如因修改不通用无法被上游采纳，并且没有打算重构下再提交到上游的计划，同样不会被ACK 采纳。</p><p>合入到上游这点很难，因为需要明确的案例说明这个修改是有帮助的。尤其是调度以及内存相关的修改，社区态度一向十分谨慎，然而很多手机厂商的客制化修改其实并非通用且多是策略优化 + 性能数据采集。</p><p>GKI 相关资料：</p><ol><li><a href="https://source.android.com/devices/architecture/kernel/kernel-code?hl=zh-cn#changes-to-gki-defconfig" target="_blank" rel="noopener">为 GKI 开发内核代码</a></li><li><a href="https://android.googlesource.com/kernel/common/+/refs/heads/android-mainline/README.md" target="_blank" rel="noopener">如何向 Android 通用内核提交补丁</a></li><li><a href="https://source.android.com/docs/core/architecture/kernel/android-common?hl=zh-cn" target="_blank" rel="noopener">Android 通用内核</a></li></ol><p>再继续回到邮件讨论上，对于<code>Yousef</code>的担忧，<code>Roman Gushchin</code> 在隔了几天后(11 Oct 2021) 回复了邮件：</p><blockquote><p>I think a relatively small and stable set of hooks can cover a large percent of potential customization ideas.</p></blockquote><p><code>Roman</code>认为提供一套小的且稳定的hooks，可以满足大部分的定制需求</p><blockquote><p>Shipping a custom kernel (actually any kernel) at this scale isn’t easy or fast.<br>Just for example, imagine a process of rebooting of a 1000000 machines running<br>1000’s different workloads, each with their own redundancy and capacity requirements.</p></blockquote><p>同时<code>Roman</code>解释了如果在内核主线上修改的话，修改以及重新部署内核的成本比较高，如果能够通过用户空间推送修改，这样可以节省不少的成本。</p><p>第二天(12 Oct 2021) <code>Yousef</code> 回复了<code>Roman Gushchin</code> 的邮件：</p><blockquote><p>I think you’re still referring to ghOSt here. I thought your 2 use cases are different as you mentioned they “completely move the scheduler code into userspace/bpf”; but it could be just me mis-interpreting what this means. That didn’t read to me they want to micro-optimize (few) certain decisions in the scheduler, rather replace it altogether, hence my question.</p></blockquote><blockquote><p>Anyway. My 2cents here is that we should be careful not to introduce something that encourages out-of-tree workarounds for real scheduler problems nor have it done in a way where we lose visibility over how these hooks are used and being able to share it with others who could benefit from the same mico-optimization too.</p></blockquote><p>这段不太好直接翻过来，根据个人理解下来<code>Yousef</code> 表达的大意是：</p><p>无论是优化还是移植，我们都需要小心，以免引入一些可能导致未来出现真正调度问题却绕过内核的解决方案。同时，我们还需要确保我们在使用调度钩子时具有完整的可见性和透明性，以便将这些经验分享给其他人，让更多人从这些优化中受益。如果我们失去了这些调度钩子的可见性和透明性，可能会导致很多人错过这些优化，或者可能会出现一些我们无法预知的复杂调度问题。</p><p>至此，关于该主题的邮件讨论平息了一段时间</p><p><code>Yafang Shao</code> 在一个月后(25 Nov 2021) 回复<code>Roman</code></p><blockquote><p>Scheduler BPF is a great idea. Thanks for the work.<br>Scheduler BPF won’t be a small feature,  I think we’d better give a summary of possible hooks it may add first.<br>We must have a <em>basic rule</em> to control what it will tend to be to avoid adding BPF hooks here and there.<br>I haven’t found a clear rule yet, but maybe we can learn it from netfilter, which has 5 basic hooks.<br>Regarding the scheduler BPF hooks, some possible basic hooks may be:</p><ul><li>Hook for Enqueue</li><li>Hook for Dequeue</li><li>Hook for Put Prev Task</li><li>Hook for Set Next Task</li></ul></blockquote><p>BPF 调度是一个不错的想法，并且不是一个小功能，建议先想下都有哪些地方需要加钩子，可以学习下netfilter 模块(有5个基本的钩子)，而调度这块可能会涉及到的钩子如Enqueue、Dequeue、Put Prev Task、Set Next Task等。</p><p><code>Roman</code> 次日(26 Nov 2021 )回复了<code>Yafang Shao</code>：</p><blockquote><p>I think it depends on what we want to achieve. There are several options:<br>we might aim to implement the whole scheduler logic in bpf, we might aim<br>to do some adjustments to the existing scheduler behavior or a mix of those<br>approaches.</p></blockquote><p>对于<code>Yafang Shao</code> 前面提到的这个功能不是一个小功能，<code>Roman</code> 认为这取决于我们想要达到什么样的效果</p><p>目前有如下几种选择</p><ol><li>在BPF中实现整个调度逻辑</li><li>对现有的调度基础上进行一些调整</li><li>混合使用这些方法</li></ol><p><code>Roman</code> 接着说到：</p><blockquote><p>Bpf as now is now is not capable enough to implement a new scheduler class without a substantial amount of new c code (in form of helpers, maybe custom maps, some verifier changes etc). In particular, it’s a challenging to provide strong safety guarantees: any scheduler bpf program loaded shouldn’t crash or deadlock the system (otherwise bpf isn’t any better than a kernel module). Also performance margins are quite tight.</p></blockquote><p>在当前的情况下，BPF现在还不足以在不添加大量新的C代码（比如帮助程序、自定义映射、一些验证程序的更改等）的情况下实现一个完全新的调度类。</p><p>特别是，要提供强有力的安全保障是一项挑战性的任务：任何加载的调度BPF程序都不应该使系统崩溃或死锁（否则BPF与内核模块的效果就没什么区别了），此外，性能表现非常重要。</p><blockquote><p>I’m not saying that providing such generic hooks is impossible or useless, but it requires a lot of changes and support code and I’m not sure that we have a good justification for them right now.<br>I think instead we might want to see bpf hooks as a better form of (sysctl) tunables, which are more flexible (e.g. can be used for specific processes, cgroups, cpus, being enabled depending on load, weather, etc) and do not create an ABI (so are easier to maintain).</p></blockquote><p>我们可能希望将bpf hooks 视为更好的（sysctl）可调参数的形式，这些参数更加灵活（例如可以用于特定进程、cgroup、CPU，根据负载、weather 等情况启用），并且不会创建ABI（因此更易于维护）。</p><p>再过去了大半年后(19 Jul 2022)，华为的的<code>Ren Zhijie</code> 回复了该主题邮件</p><blockquote><p>We want to implement a programmable scheduler to meet the schedule requirements of different workloads.<br>Using BPF, we can easily deploy schedule policies for specific workloads, quickly verifying without modifying the kernel code.<br>This greatly reduces the cost of deploying new schedule policies in the production environment.<br>Therefore, we want to continue to develop based on your patch. <strong>We plan to merge it into the openeuler open-source community and use the community to continuously evolve and maintain it</strong>.(link: <a href="https://www.openeuler.org/en/" target="_blank" rel="noopener">https://www.openeuler.org/en/</a>)</p></blockquote><p><code>Ren Zhijie</code> 开头先说了下BPF 定制调度能够快速部署，修改便利等，相比之前节省了成本，同时提出了他们正打算利用BPF 实现一个可编程调度器以应对不同的负载情况。</p><p>并打算在<code>Roman</code> 的patchSet 基础上进行修改，后面会贡献给openeuler  开源社区。</p><p>同时，<code>Ren Zhijie</code> 说明了他们做了哪些额外的修改</p><blockquote><p>We made some changes to your patch:</p><ol><li>Adapt to the openeuler-OLK-5.10 branch, which mostly base on linux<br>longterm branch 5.10.</li><li>Introduce the Kconfig CONFIG_BPF_SCHED to isolate related code at<br>compile time.</li><li>helpers bpf_sched_entity_to_cgrpid() and bpf_sched_entity_belongs_to_cgrp() are modified to obtain the task group to which the sched entity belongs through se-&gt;my_q-&gt;tg-&gt;css.cgroup.</li></ol><p>We have some ideas for the next iteration of Scheduler BPF that we would like to share with you:</p><ol><li>The tag field is added to struct task_struct and struct task_group. Users can use the file system interface to mark different tags for specific workloads. The bpf prog obtains the tags to detect different workloads.</li><li>Add BPF hook and helper to scheduling processes such as select_task_rq and pick_next_task to enable scalability.</li></ol><p><strong>It’s a new attempt, and there’s bound to be a lot of problems later, but it’s exciting that it makes the schduler programmable.</strong></p></blockquote><p>当天晚些时候，<code>Roman</code> 回复了<code>Ren Zhijie</code>：</p><blockquote><p>Great to hear my work is useful and thank you for describing your plans!<br>I’m not actively working on it right now, but I might start again in the future.<br>Let me know if I can help you with this effort.</p></blockquote><p>很高兴我的PatchSet 给你带来了帮助，不过我现在没在搞这个，后面可能会再捡起来继续搞。</p><p><code>Roman Gushchin</code> 的patchSet 内容比较多，可以从下面的PATCH rfc 1/6 慢慢看起</p><p><a href="https://lwn.net/ml/linux-kernel/20210916162451.709260-2-guro@fb.com/" target="_blank" rel="noopener">https://lwn.net/ml/linux-kernel/20210916162451.709260-2-guro@fb.com/</a></p><p>另外关于BPF 调度的一个示例简单 Demo ：<a href="https://github.com/rgushchin/atc" target="_blank" rel="noopener">https://github.com/rgushchin/atc</a></p><p>这个Demo 中包含三个hook 点，在<code>Roman Gushchin</code> 的patchSet 中同样涉及这三个</p><p><code>cfs_check_preempt_tic</code>、<code>cfs_check_preempt_wakeup</code>、<code>cfs_wakeup_preempt_entity</code></p><p>关于这三个hook 点的说明</p><ol><li><p>The first one allows to force or suppress a preemption from a tick context.<br>An obvious usage example is to minimize the number of non-voluntary context switches and decrease an associated latency penalty by (conditionally) providing tasks or task groups an extended execution slice.<br>It can be used instead of tweaking sysctl_sched_min_granularity.</p></li><li><p>The second one is called from the wakeup preemption code and allows to redefine whether a newly woken task should preempt the execution of the current task. This is useful to minimize a number of preemptions of latency sensitive tasks.<br>To some extent it’s a more flexible analog of a sysctl_sched_wakeup_granularity.</p></li><li><p>The third one is similar, but it tweaks the wakeup_preempt_entity() function, which is called not only from a wakeup context, but also from pick_next_task(), which allows to influence the decision on which task will be running next.</p></li></ol><h3 id="Google-开源框架ghOSt"><a href="#Google-开源框架ghOSt" class="headerlink" title="Google 开源框架ghOSt"></a>Google 开源框架ghOSt</h3><blockquote><p>ghOSt is a general-purpose delegation of scheduling policy implemented on top of the Linux kernel. The ghOSt framework provides a rich API that receives scheduling decisions for processes from userspace and actuates them as transactions. Programmers can use any language or tools to develop policies, which can be upgraded without a machine reboot. ghOSt supports policies for a range of scheduling objectives, from µs-scale latency, to throughput, to energy efficiency, and beyond, and incurs low overheads for scheduling actions. Many policies are just a few hundred lines of code. Overall, ghOSt provides a performant framework for delegation of thread scheduling policy to userspace processes that enables policy optimization, non-disruptive upgrades, and fault isolation.</p></blockquote><p>ghOSt 是一个通用的Linux内核调度策略委托工具，它提供了丰富的API，可以从用户空间接收进程调度决策并将它们作为交易来实施。</p><p>开发人员可以使用任何编程语言或工具来编写策略，并且可以在不重启机器的情况下进行升级。ghOSt支持多种调度目标，包括微秒级延迟、吞吐量、能源效率等，并且对调度操作的开销很小。</p><p>许多策略只需要几百行代码就可以实现。总的来说，ghOSt为将线程调度策略委托给用户空间进程提供了一个高性能的框架，可以实现策略优化、非破坏性升级和故障隔离。</p><p>如果说<code>Roman Gushchin</code> 的patchSet 是在内核中提供BPF 基础设施，那么Google 的ghOSt 则看起来是一整套框架(user + kernel)，一套完整的调度策略(和CFS 共存，优先级低于CFS)。</p><p>目前已在Google search 和snap 上落地，且有不错的性能测试数据，按paper 中的性能测试数据来看的话ghOSt 的调度开销只比现有的内核调度器略高。</p><p>Paper 中摘取一段Google 针对ghOSt  的性能测试图表</p><p>Linux 4.15 with our ghOSt patches applied.We run microbenchmarks on a 2-socket Intel Xeon Platinum 8173M @ 2GHz, 28 cores per socket, 2 logical cores each.</p><p><img src="http://blog.lihaizhou.top/BPF-scheduler/BPF-scheduler1.png" alt="Untitled"></p><p>关于ghOSt 的资料：</p><ol><li><a href="https://lpc.events/event/16/contributions/1365/attachments/986/1912/lpc22-ebpf-kernel-scheduling-with-ghost.pdf" target="_blank" rel="noopener">eBPF Kernel Scheduling with Ghost</a>  Google <code>Barret Rhoden</code> 2022.09.12 的PPT</li><li><a href="https://github.com/google/ghost-kernel" target="_blank" rel="noopener">https://github.com/google/ghost-kernel</a> kernel 源码，基于Linux 5.11</li><li><a href="https://github.com/google/ghost-userspace" target="_blank" rel="noopener">https://github.com/google/ghost-userspace</a> userspace 源码</li><li><a href="https://netdevconf.info/0x15/papers/25/ghOSt.pdf" target="_blank" rel="noopener">paper</a>  非常详细的技术细节解读，同时含有性能测试数据，看不动了内容太多</li><li><a href="https://www.youtube.com/watch?v=auen1MpxxGY&amp;list=PLrninrcyMo3L-hsJv23hFyDGRaeBY1EJO" target="_blank" rel="noopener">video</a>   可以结合着PPT 看</li></ol><h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><p>Google 的ghOSt  框架已经有实际落地项目(snap + search)，用户空间和内核代码都现成的，甚至测试工具都备好了，不过没看到有介绍说落地在Android 设备上，如果要用ghOSt  的话，不知道是否能够应用在移动端，需要阅读<a href="https://netdevconf.info/0x15/papers/25/ghOSt.pdf" target="_blank" rel="noopener">paper</a> 并结合源码。</p><p>而Roman 的patchSet 则是提供了一组内核的基础设施，个人理解以Roman 的patchSet 入手先进行微小的实践(比如结合前面提到的atc demo)或许是一个不错的开始。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;本文将主要涉及如下内容&lt;/p&gt;
&lt;p&gt;1.解读&lt;bpf scheduler=&quot;&quot;&gt; 邮件内容&lt;br&gt;  摘取其中的关键内容，尽量将围绕这个话题的关键讨论以时间线展示。&lt;/bpf&gt;&lt;/p&gt;
&lt;p&gt;2.介绍Google 的GhOSt 开源框架&lt;/p&gt;
&lt;p&gt;同时会穿插一些额外的
      
    
    </summary>
    
      <category term="ebpf" scheme="http://lihaizhou.top/categories/ebpf/"/>
    
    
  </entry>
  
  <entry>
    <title>Userfaultfd 在 ART GC 上的应用</title>
    <link href="http://lihaizhou.top/2023/04/25/Userfaultfd-%E5%9C%A8-ART-GC-%E4%B8%8A%E7%9A%84%E5%BA%94%E7%94%A8/"/>
    <id>http://lihaizhou.top/2023/04/25/Userfaultfd-在-ART-GC-上的应用/</id>
    <published>2023-04-25T01:15:41.000Z</published>
    <updated>2023-04-25T07:30:23.673Z</updated>
    
    <content type="html"><![CDATA[<h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>Google 自Android 12 开始将ART 模块mainline，对于Android 12 及其之后的设备而言，后续ART 性能优化补丁都可以通过Google play 在线升级ART 模块获得，不用再等每次的Android 大版本升级。</p><p>本文主要简单介绍为何在Android 12 上引入<code>userfaultfd</code> 这一kernel 特性，不会涉及到具体细节，只是先有个大概印象：userfaultfd 是什么，为何引入，有哪些优势，后面会另开笔记详细介绍。</p><h3 id="为何引入userfaultfd"><a href="#为何引入userfaultfd" class="headerlink" title="为何引入userfaultfd"></a>为何引入userfaultfd</h3><p>先说下为何引入userfaultfd ，其实就是为了解决现有的问题，主要有以下两个主要的问题</p><ol><li>读屏障(Read barrier) 的固定开销</li></ol><p>因为当前ART 为了保证数据的一致性，对每个对象的加载采用的读屏障(Read barrier) 是一种固定的开销，这种情况会一直存在，即使此时可能并没有进行GC，比如下面这个代码例子。</p><p><img src="http://blog.lihaizhou.top/Uffd/uffd0.png" alt="Untitled"></p><p>引入读屏障，不仅仅增加了代码的体积，还增长了编译时间，如果是在GC 运行的场景下，这种开销成本会更高。</p><ol start="2"><li>compact 策略导致的内存出现”先增后降”</li></ol><p>这种情形只在GC 场景下会发生，主要是由当前的compact 算法决定的，会先将这些零散的待迁移对象内容复制到另一块内存区域，然后再清空原先的零散对象所占的内存。</p><p>如下图所示</p><p><img src="http://blog.lihaizhou.top/Uffd/uffd1.png" alt="Untitled"></p><p>这就会导致一个现象，在GC 环节应用进程占据的物理内存(RSS) 会出现先增加，然后一个跳水式的下降现象，Google 的ART 大佬Lokesh Gidra 将这种跳水式的下降现象称之为”Rss cliff”（Rss 悬崖）。</p><p><img src="http://blog.lihaizhou.top/Uffd/uffd2.png" alt="Untitled"></p><p>进程RSS 占用先增加的过程，可能会导致内存压力，而内存压力一旦增大就可能导致后台杀进程。</p><h3 id="Userfaultfd-简介"><a href="#Userfaultfd-简介" class="headerlink" title="Userfaultfd 简介"></a><strong>Userfaultfd 简介</strong></h3><p>为了解决上面提到的这这两个问题，引入了Linux 的userfaultfd 这一特性，这里先简单介绍下userfaultfd。 </p><p>在Linux内核版本4.19 中引入了userfaultfd 这一系统调用，它允许用户空间可以处理已注册内存范围内的页面错误（例如page-missing 页错误）。</p><p>一旦一段内存区域向userfaultfd 注册成功，page-fault 的处理就会通过userfaultfd 通知委托给用户空间。用户空间可以通过SIGBUS（总线错误）故障处理程序或从向userfaultfd 注册的文件描述符中读取通知。如果用户空间应用程序收到page fault 通知，它会创建原本应映射到faulting address 对应page 的内容，解决page fault，然后将内容交给内核。</p><p>通过这种方式，用户空间可以有效地参与内存管理，提高系统的效率和稳定性。</p><p>那么利用userfaultfd 进行并发compact，可以带来哪些好处呢？</p><p>Google 的ART 大佬Lokesh Gidra 介绍有如下几种：</p><ol><li>可以执行与读屏障(Read barrier) 相同的功能，却没有读屏障(Read barrier) 的固定开销。</li><li>由于没有了读屏障(Read barrier)，编译代码将减少大约10%</li><li>随着compact 过程的进行同时进行释放页操作，而不是等compact 完成后再free，所以不会有”Rss cliff” 现象出现。</li></ol><p>手册上关于Userfaults  的优势介绍：</p><p><img src="http://blog.lihaizhou.top/Uffd/uffd3.png" alt="Untitled"></p><p>Userfaults 相对于常规的虚拟内存管理接口（如 mremap/mprotect）的真正优势在于，Userfaults 在所有操作中都不涉及像 vmas 这样的重量级数据结构（实际上，userfaultfd 运行期间的写操作从不会持有 mmap_lock 锁），另外对于大型虚拟地址空间时，使用VMA进行页面（或大页面）粒度的fault 跟踪并不适合，因为需要太多的VMA 数据结构才能达到这个目的。</p><p>userfaultfd 一旦创建，还可以通过 Unix 域套接字传递给管理进程，因此同一个管理进程可以处理多个不同进程的 userfaults，而这些进程不会意识到正在发生什么。</p><p>事实上，将原本内核处理pagefault 的活外包给用户空间这个想法，很久以前就有了，可以看下这个文章：<a href="https://lwn.net/Articles/550555/" target="_blank" rel="noopener">User-space page fault handling</a></p><p>除此之外，相比先前的算法还有一些其它的优势，不一一介绍了，详情参见：<strong><a href="https://www.youtube.com/watch?v=DYdHLqLVspY&amp;authuser=2&amp;hl=id" target="_blank" rel="noopener">What’s new in app performance - YouTube</a></strong></p><p>假设存在这样的场景:<br>GC 过程中正在将一个可达对象从一块内存区域拷贝到另一块内存区域 ，如果同一时间应用线程(也称“mutators”) 正尝试访问或修改这个对象，那么可能会出现数据不一致的情况。</p><p>这是因为拷贝过程中的某些变量或状态可能已经不同于正在访问的应用线程所期望的，这可能会导致意想不到的结果。因此，GC 过程中需要采取适当的同步措施，以确保数据的一致性和正确性。</p><p>那么采取的是什么措施呢？<br>GC 过程包括一个并发compact 阶段，该阶段GC 将保留在heap 中的object 进行compact（移动）。<br>为了实现这样的并发compact ，需要执行短暂的”stop-the-world”(STW) 暂停，其中所有GC-roots 都会更新到新位置(移动后的位置)。在这之后，应用程序线程将恢复，compact 过程将并发执行。</p><p>这样的并发compact 阶段允许将活动对象移动到被compact 的内存新位置，而不会有其他程序和应用程序试图访问或更新这些对象，否则会导致数据一致性问题。</p><p>GC 有不同的方法来避免compact 阶段期间可能出现的数据一致性问题，下面介绍两种：</p><ol><li>GC 在应用代码中插入读/写 屏障(barriers )，这样的话在GC 时，如果应用程序线程访问堆中GC 正在被复制和compact 的对象，本次访问将被读/写屏障截获并进行相应处理，这样就保证了并发垃圾回收(CC)的同时支持应用线程的读写，而不会破坏程序的数据一致性。</li><li><p>page 级别的内存保护拦截对堆的访问，例如，to-space 使用 mprotect 进行保护，这是一个内存保护的系统调用。当mprotect 被调用后，在复制和(或)移动对象之前，这些对象对应于堆中内存范围会被保护起来，以便保护对 to-space 的访问。</p><p> 此时当应用程序访问 to-space 时，它们会收到一个 SIGSEGV 信号（segmentation fault signal），并触发一个 fault handler（例如页面错误信号处理程序）。</p><p> fault handler 可以在 compact 之后复制 faulted page 中的所有对象，更新其中的所有引用，然后使页面可访问。</p></li></ol><p>除了上面介绍的两种方法，还有一种是基于Linux userfaultfd 系统调用的方法，可实现GC 过程与应用线程（mutators）并行进行。该过程包括多个不同阶段，可以与应用线程执行同时进行。</p><p>这些阶段包括并发标记阶段、并发计算阶段、STW 设置阶段和并发compact 阶段，如下图所示：</p><p><img src="http://blog.lihaizhou.top/Uffd/uffd4.png" alt="Untitled"></p><p>下面分别介绍这几个阶段</p><ol><li><p>并发标记阶段</p><p> GC算法会遍历堆中的对象，判断对象是否可达，以确定是否需要对其进行回收。如果对象可达，则被视为活动且有用，如果不可达，则被视为可回收的。在这个过程中，GC算法使用标记位来标记可达对象，以便后续的回收操作能够对其进行区分。例如，在Android中，可以使用并发标记清除（CMS）算法来并发标记死亡的对象。</p></li><li><p>并发计算阶段</p><p> 在并发标记阶段之后发生，这个阶段中，使用在并发标记阶段收集的信息（例如标记位）为每个对象预先计算信息，包括每个对象在compact 区域的新位置。</p><p> GC 遍历标记位(mark bitmap)并生成数据，从而实现一个函数，该函数可以在恒定时间内根据可达对象的旧地址，输出其新地址，新地址是将对象复制到后续compact 阶段的位置。</p><p> 并发计算阶段包括的两个步骤：</p><ol><li>为每个to-space页面计算from-space 偏移量，从而确定需要复制哪些存活对象。计算from-      space 偏移量可以确保在处理to-space 页面时，mutators和垃圾收集器线程都可以在O(1)时间内找到源偏移量。</li><li><p>确定偏移向量，该向量定义了旧地址和新地址之间的偏移量，这个偏移向量和标记位图(mark bitmap)一起，可以在O(1)时间内定义任何对象的to-space地址。</p><p>简单来说，这意味着并发计算阶段会计算需要复制哪些存活对象，并为这些对象确定新的地址，以便在后续的垃圾收集阶段进行复制和compact。</p></li></ol></li><li><p>STW 设置阶段</p><p> 在并发计算阶段之后，STW 设置阶段开始。</p><p> 发生 STW 暂停的过程中，当前映射到堆（例如：from-space）的物理页面被移动到一个临时位置（例如：temp-space），并且堆的新内存范围被注册到 userfaultfd。</p><p> 通过这样移动页面，堆的原始内存范围将会变为空。因此，一旦此时应用线程恢复执行并尝试访问这些缺失的页面，应用线程将收到一个page fault。</p><p> 将堆的物理页移动到临时位置的操作可以使用mremap 这一系统调用来执行，开销与要移动的页面数量成线性关系。如果设备对响应的灵敏度要求比较高的话，这种与堆大小成比例的SWT 可能会导致卡顿。</p><p> 为避免卡顿，mremap 可以通过将page-table entries 移动的粒度改为Page Middle Directory (PMD) ，而不是页Page Table Entry (PTE) 来进行优化 ，这样每次移动的是 2MB 而不是4KB，从而显著减少迭代所需的次数。如果目标是移动多 GB 或更大的堆，则可以进一步扩展至 Page Upper Directory (PUD) 或 Page Global Directory（PGD）级别。</p><p> 唯一要求是确保堆和临时内存范围适当对齐。</p><p> 与移动页面和注册堆内存范围并行的是，GC roots（如应用线程堆栈（mutator stacks），静态变量，image spaces, zygote space, runtime roots 等）将更新为相应的 to-space 地址。</p><p> 在 STW 暂停之后，垃圾回收进程将进入并发压缩阶段。</p></li><li><p>并发压缩阶段</p><p> 应用程序线程恢复运行，GC 线程开始逐个处理堆的to-space 页面。如果应用程序线程访问了GC 线程尚未处理完成（即没有分配页面）的堆中的某个区域（如 to-space page），则GC 线程 将接收到一个SIGBUS信号（bus error），表示出现page fault。</p><p> 收到page fault 后，会创建一个页面缓冲区（例如4KB的page buffer），根据并发计算阶段的计算结果，将原本应该位于缺失页面上的所有可达对象复制到page buffer，并将这些对象内部的引用更新为相应的新地址。</p><p> 最后，用户空间通过调用userfaultfd ioctl 接口将page buffer 交给内核，并指示要在faulting address 上显示的页面。作为回应，内核会将page buffer 内容复制到一个page 并映射该page。然后内核恢复应用线程的执行。</p></li></ol><p>简而言之，使用Linux中的userfaultfd 这一系统调用来进行垃圾回收，比前面提到两种方法更高效，并且能够提供更多数据一致性，从而实现更可靠的垃圾回收，同时减少了开销。</p><h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><p><a href="https://android-developers.googleblog.com/2022/08/android-13-is-in-aosp.html" target="_blank" rel="noopener">https://android-developers.googleblog.com/2022/08/android-13-is-in-aosp.html</a><br><a href="https://www.tdcommons.org/cgi/viewcontent.cgi?article=4751&amp;context=dpubs_series" target="_blank" rel="noopener">Utilizing the Linux Userfaultfd System Call in a Compaction Phase of a Garbage Collection Process</a><br><a href="https://docs.kernel.org/admin-guide/mm/userfaultfd.html" target="_blank" rel="noopener">https://docs.kernel.org/admin-guide/mm/userfaultfd.html</a><br><a href="https://lwn.net/Articles/787308/" target="_blank" rel="noopener">Write-protect for userfaultfd()</a><br><a href="https://news.ycombinator.com/item?id=35492307" target="_blank" rel="noopener">https://news.ycombinator.com/item?id=35492307</a><br><a href="https://www.tdcommons.org/cgi/viewcontent.cgi?article=4751&amp;context=dpubs_series" target="_blank" rel="noopener">https://www.tdcommons.org/cgi/viewcontent.cgi?article=4751&amp;context=dpubs_series</a><br><a href="https://blog.csdn.net/feelabclihu/article/details/120574383" target="_blank" rel="noopener">Android R常见GC类型与问题案例</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h3&gt;&lt;p&gt;Google 自Android 12 开始将ART 模块mainline，对于Android 12 及其之后的设备而言，后续ART 性能优化
      
    
    </summary>
    
      <category term="kernel，Android" scheme="http://lihaizhou.top/categories/kernel%EF%BC%8CAndroid/"/>
    
    
  </entry>
  
  <entry>
    <title>反碎片化 | Proactive compaction</title>
    <link href="http://lihaizhou.top/2023/04/20/%E5%8F%8D%E7%A2%8E%E7%89%87%E5%8C%96-Proactive-compaction/"/>
    <id>http://lihaizhou.top/2023/04/20/反碎片化-Proactive-compaction/</id>
    <published>2023-04-20T10:51:03.000Z</published>
    <updated>2023-04-21T01:20:38.670Z</updated>
    
    <content type="html"><![CDATA[<p>历年来内核中为反碎片化所做的努力，如下图所示：</p><table><thead><tr><th>Publish date</th><th>Articles on LWN.net</th></tr></thead><tbody><tr><td>2004-09-08</td><td><a href="https://lwn.net/Articles/101230/" target="_blank" rel="noopener">https://lwn.net/Articles/101230/</a></td></tr><tr><td>2004-05-10</td><td><a href="https://lwn.net/Articles/105021/" target="_blank" rel="noopener">https://lwn.net/Articles/105021/</a></td></tr><tr><td>2005-02-01</td><td><a href="https://lwn.net/Articles/121618/" target="_blank" rel="noopener">https://lwn.net/Articles/121618/</a></td></tr><tr><td>2005-11-02</td><td><a href="https://lwn.net/Articles/158211/" target="_blank" rel="noopener">https://lwn.net/Articles/158211/</a></td></tr><tr><td>2005-11-08</td><td><a href="https://lwn.net/Articles/159110/" target="_blank" rel="noopener">https://lwn.net/Articles/159110/</a></td></tr><tr><td>2006-11-28</td><td><a href="https://lwn.net/Articles/211505/" target="_blank" rel="noopener">https://lwn.net/Articles/211505/</a></td></tr><tr><td>2010-01-06</td><td><a href="https://lwn.net/Articles/368869/" target="_blank" rel="noopener">https://lwn.net/Articles/368869/</a></td></tr><tr><td>2014-03-26</td><td><a href="https://lwn.net/Articles/591998/" target="_blank" rel="noopener">https://lwn.net/Articles/591998/</a></td></tr><tr><td>2015-07-14</td><td><a href="https://lwn.net/Articles/650917/" target="_blank" rel="noopener">https://lwn.net/Articles/650917/</a></td></tr><tr><td>2016-04-23</td><td><a href="https://lwn.net/Articles/684611/" target="_blank" rel="noopener">https://lwn.net/Articles/684611/</a></td></tr><tr><td>2016-05-10</td><td><a href="https://lwn.net/Articles/686801/" target="_blank" rel="noopener">https://lwn.net/Articles/686801/</a></td></tr><tr><td>2017-03-21</td><td><a href="https://lwn.net/Articles/717656/" target="_blank" rel="noopener">https://lwn.net/Articles/717656/</a></td></tr><tr><td>2018-10-31</td><td><a href="https://lwn.net/Articles/770235/" target="_blank" rel="noopener">https://lwn.net/Articles/770235/</a></td></tr><tr><td>2020-04-21</td><td><a href="https://lwn.net/Articles/817905/" target="_blank" rel="noopener">https://lwn.net/Articles/817905/</a></td></tr></tbody></table><p>内存规整有几条不同的路径可以触发：</p><ol><li>直接规整，由<code>alloc_page</code> 进入到慢速回收阶段会触发</li><li>kcompactd </li><li>手动触发</li></ol><p>这三种情况都会走到<code>compact_zone</code> ，进而到最终的页面迁移函数<code>migrate_pages</code> 中</p><p>本文主要针对kcompactd 触发的情形进行讨论</p><h3 id="kcompactd-触发时机"><a href="#kcompactd-触发时机" class="headerlink" title="kcompactd 触发时机"></a>kcompactd 触发时机</h3><p>在正式介绍<code>Proactive compaction</code> 之前，先看下之前都有哪些情况下会触发kcompact 线程</p><p>唤醒kcompact 线程是通过wakeup_kcompactd 这一函数</p><ol><li>kswapd_try_to_sleep 即将进入睡眠时触发kcompact 线程</li><li>wakeup_kswapd 即唤醒kswapd 函数中，kswapd 回收失败超过16 次，触发direct reclaim 时</li></ol><p><img src="http://blog.lihaizhou.top/kcompact/1.png" alt="Untitled"></p><ol start="3"><li>开启了watermark_boost，在balance_pgdat 这一内存回收的核心函数中满足一定条件触发</li></ol><p>本文将着重解读Proactive compaction 这一功能</p><h3 id="可调节参数-proactiveness"><a href="#可调节参数-proactiveness" class="headerlink" title="可调节参数 proactiveness"></a>可调节参数 proactiveness</h3><p>引入了一个可调参数 sys/kernel/mm/compaction/proactiveness</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * Tunable for proactive compaction. It determines how</span></span><br><span class="line"><span class="comment"> * aggressively the kernel should compact memory in the</span></span><br><span class="line"><span class="comment"> * background. It takes values in the range [0, 100].</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">unsigned</span> <span class="keyword">int</span> __read_mostly sysctl_compaction_proactiveness = <span class="number">20</span>;</span><br></pre></td></tr></table></figure><p>接受 [0, 100] 范围内的值，默认值为 20，这个可调参数决定内核在后台压缩内存的积极程度。</p><h3 id="水位值的划定"><a href="#水位值的划定" class="headerlink" title="水位值的划定"></a>水位值的划定</h3><p><img src="http://blog.lihaizhou.top/kcompact/2.png" alt="Untitled"></p><p>如果当前节点的碎片得分高于高水位线，则启动主动内存碎片整理，这里还有一点值得注意的地方就是如果系统参数sysctl_compaction_proactiveness为0 或者当前节点正在运行kswapd，则不应该启动主动的内存碎片整理。</p><h3 id="计算碎片化得分"><a href="#计算碎片化得分" class="headerlink" title="计算碎片化得分"></a>计算碎片化得分</h3><p>下面拆解分析fragmentation_score_node</p><ol><li>node 的分数</li></ol><p><img src="http://blog.lihaizhou.top/kcompact/3.png" alt="Untitled"></p><ol start="2"><li>单个zone 的分数</li></ol><p><img src="http://blog.lihaizhou.top/kcompact/4.png" alt="Untitled"></p><p>这里的分母加1为了避免分母出现0的情况</p><ol start="3"><li>对于给定的zone以及order 计算出的分数</li></ol><p><img src="http://blog.lihaizhou.top/kcompact/5.png" alt="Untitled"></p><p>重点在extfrag_for_order 这个函数：计算碎片分值的核心函数</p><p><img src="http://blog.lihaizhou.top/kcompact/6.png" alt="Untitled"></p><p>这里的order 指定的是COMPACTION_HPAGE_ORDER，为何要限定这个order 呢？</p><p>fragmentation_score_zone_weighted 函数注释中给了解释</p><p><img src="http://blog.lihaizhou.top/kcompact/7.png" alt="Untitled"></p><p>为了避免浪费时间尝试压缩 ZONE_DMA32等特殊区域，而是专注于将主动内存规整应用在更大的zone 上比如ZONE_NORMAL等区域，另外对于小zone 的分数趋于 0，因此永远不会超过能够触发主动内存规整的low 阈值。</p><p>在kcompactd 函数中的循环中</p><p><img src="http://blog.lihaizhou.top/kcompact/8.png" alt="Untitled"></p><p>这里有一个疑问：</p><p>如果每次规整后的收益非常非常小，但是得分确实满足了比上次高，比如存在某些进程不断轻微的碎片化。<br>那是不是会存在在满足低于触发阈值之前，每间隔默认的timeout （500ms）就触发kcompact 线程。</p><p>如果改成比例的形式会不会更好点，比如本次分值比上次高2%，再进行规整。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * Fragmentation score check interval for proactive compaction purposes.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> HPAGE_FRAG_CHECK_INTERVAL_MSEC(500)</span></span><br></pre></td></tr></table></figure><p>接着看proactive_compact_node 函数</p><p><img src="http://blog.lihaizhou.top/kcompact/9.png" alt="Untitled"></p><p>这一函数负责压缩节点中的所有区域，直到每个区域的碎片得分低于主动压缩阈值，真正实际规整的动作是compact_zone 函数中完成的。</p><p>函数注释中提示由于各种退避条件（例如，对每个节点或每个区域锁的争用），该函数可能在达到得分目标之前返回。</p><p>大致包含如下几种退避条件：</p><p><img src="http://blog.lihaizhou.top/kcompact/10.png" alt="Untitled"></p><h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><p><a href="https://lwn.net/Articles/368869/" target="_blank" rel="noopener">https://lwn.net/Articles/368869/</a><br><a href="https://lwn.net/Articles/817905/" target="_blank" rel="noopener">https://lwn.net/Articles/817905/</a><br><a href="https://lwn.net/ml/linux-kernel/20200310222539.1981-1-nigupta%40nvidia.com/" target="_blank" rel="noopener">https://lwn.net/ml/linux-kernel/20200310222539.1981-1-nigupta%40nvidia.com/</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;历年来内核中为反碎片化所做的努力，如下图所示：&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Publish date&lt;/th&gt;
&lt;th&gt;Articles on LWN.net&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;2004-
      
    
    </summary>
    
    
      <category term="kernel" scheme="http://lihaizhou.top/tags/kernel/"/>
    
  </entry>
  
  <entry>
    <title>关于kswapd 并发的思考</title>
    <link href="http://lihaizhou.top/2023/04/17/%E5%85%B3%E4%BA%8Ekswapd-%E5%B9%B6%E5%8F%91%E7%9A%84%E6%80%9D%E8%80%83/"/>
    <id>http://lihaizhou.top/2023/04/17/关于kswapd-并发的思考/</id>
    <published>2023-04-17T08:04:02.000Z</published>
    <updated>2023-04-17T09:28:02.946Z</updated>
    
    <content type="html"><![CDATA[<h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>关于Kswapd 相信是比较熟悉了，如果经常分析Perfetto 的话，会经常看见这玩意的身影，尤其是内存紧张的场景下。</p><p>以前有过这样的一个想法，为何不将kswapd 改为并发呢？充分利用多核的优势，正好最近在Aosp 上看到一笔修改，觉得挺有意思，正是将kswapd 改为并发的方式，虽然不能在当前手机设备上应用(UMA 架构的缘故，下面会提到)，但是思路不错，也借此机会再熟悉下kswapd 的工作机制。</p><p>Linux内核中的页面置换有两种方式：</p><p>1）异步方式，通过kswapd 处理<br>2）同步方式，通过direct reclaim 处理</p><p>下面列举出几个关于Kswapd 场景的问题</p><h3 id="kswapd-QA问题"><a href="#kswapd-QA问题" class="headerlink" title="kswapd QA问题"></a>kswapd QA问题</h3><h4 id="Q：为何手机设备上只有一个Kswapd线程？"><a href="#Q：为何手机设备上只有一个Kswapd线程？" class="headerlink" title="Q：为何手机设备上只有一个Kswapd线程？"></a>Q：为何手机设备上只有一个Kswapd线程？</h4><p>A：现在主流的手机操作系统使用的是UMA结构，它是Uniform Memory Access的缩写。</p><p>在UMA模型下，所有的CPU都共享同一个内存节点，即所有的内存访问时间相同。</p><p>相比之下，NUMA非一致内存访问模型将内存分为多个节点，每个节点被绑定到一个或多个CPU上，内存访问时间因节点间的距离等因素而不同。</p><p>对于UMA架构，只需一个内存回收线程kswapd，且默认会绑定到所有的CPU上面。而对于NUMA架构，需要多个kswapd线程，并且每个线程只负责自己节点的内存回收，以减少内存访问的延迟和提高系统的性能。</p><p>我们抓取的perfetto 中显示的kswapd0，这里的0就是内存节点的node id。</p><h4 id="Q：kswapd-默认运行在大核还是小核？"><a href="#Q：kswapd-默认运行在大核还是小核？" class="headerlink" title="Q：kswapd 默认运行在大核还是小核？"></a>Q：kswapd 默认运行在大核还是小核？</h4><p>A: 原因同上，绑定到所有的CPU上面</p><p><img src="http://blog.lihaizhou.top/Kswapd/1.png" alt="Untitled"></p><h4 id="Q：什么情况下会触发kswapd？"><a href="#Q：什么情况下会触发kswapd？" class="headerlink" title="Q：什么情况下会触发kswapd？"></a>Q：什么情况下会触发kswapd？</h4><p>A: 在分配内存页面函数(__alloc_pages )中</p><p><img src="http://blog.lihaizhou.top/Kswapd/2.png" alt="Untitled"></p><p>alloc_pages_slowpath 这一函数中，检查下分配flag中是否包含ALLOC_KSWAPD，如果包含，则允许唤醒kswapd</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (alloc_flags &amp; ALLOC_KSWAPD)</span><br><span class="line">wake_all_kswapds(order, gfp_mask, ac);</span><br></pre></td></tr></table></figure><p>这里解释下ALLOC_KSWAPD 这一flag，并说明下有哪些场景下的分配flag 会包含ALLOC_KSWAPD </p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">define</span> ALLOC_KSWAPD0x800 <span class="comment">/* allow waking of kswapd, __GFP_KSWAPD_RECLAIM set */</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> __GFP_RECLAIM ((__force gfp_t)(___GFP_DIRECT_RECLAIM|___GFP_KSWAPD_RECLAIM))</span></span><br></pre></td></tr></table></figure><p>这几种场景下的内存分配包括进程内存分配都有资格触发kswapd</p><p><img src="http://blog.lihaizhou.top/Kswapd/3.png" alt="Untitled"></p><p>wake_all_kswapds 最终调用到wakeup_kswapd 这一唤醒kswapd 的函数。</p><p><img src="http://blog.lihaizhou.top/Kswapd/4.png" alt="Untitled"></p><p>这里如果kswapd 尝试超过MAX_RECLAIM_RETRIES(定义数值是16)都未能回收到申请的内存页，则本次不会再尝试唤醒kswapd，将回收的机会寄托在了direct reclaim上。</p><h4 id="Q：-什么情况下kswapd-会进入休眠？"><a href="#Q：-什么情况下kswapd-会进入休眠？" class="headerlink" title="Q： 什么情况下kswapd 会进入休眠？"></a>Q： 什么情况下kswapd 会进入休眠？</h4><p>A: 在kswapd 函数中有一个死循环，是kswapd 的主循环</p><p><img src="http://blog.lihaizhou.top/Kswapd/5.png" alt="Untitled"></p><p>此时我们来到kswapd_try_to_sleep 函数中</p><p><img src="http://blog.lihaizhou.top/Kswapd/6.png" alt="Untitled"></p><p>为什么这里要唤醒kcompactd 线程呢？</p><p>首先需要了解这两者的角色，kswapd 作用是为了回收页，kcompact 负责将散落在内存中的小块空余空间合并起来，为大块内存腾出空间。当 kswapd 需要睡眠时，它可能会发现一些内存页面无法被回收。因此，kswapd 会通知 kcompact 线程来进行内存紧凑工作，以尽可能释放更多的内存。</p><p>这种机制可以让内存的利用更加高效，避免了因内部碎片而浪费可用内存的情况。因此，kswapd 和 kcompact 之间有一种相互协作的关系，以保证内存的高效使用。</p><h4 id="Q-文件页和匿名页的回收关系？"><a href="#Q-文件页和匿名页的回收关系？" class="headerlink" title="Q: 文件页和匿名页的回收关系？"></a>Q: 文件页和匿名页的回收关系？</h4><p>A: </p><p>下面我们分几个步骤循序渐进的解释下</p><p>首先我们知道内核通常更倾向于换出 page cache 中的页面，至于这个具体的比例关系，则是由 swappiness 参数决定的。其值从 0 到 100 不等，通过如下命令可以查询</p><p><img src="http://blog.lihaizhou.top/Kswapd/7.png" alt="Untitled"></p><p>数值越高，则回收的时候越优先选择 anonymous pages。当它等于 100 的时候，anonymous pages 和 page cache 就具有相同的优先级。</p><p>好了。到这里我们知道了参数swappiness 大致作用，那么这个参数是在什么时候，又是如何影响匿名页和文件页的回收呢？</p><p>其实不管是 direct reclaim 的阻塞式同步回收，还是 kswapd 的异步回收，决定回收页面数量的一个核心函数都是 <em>get_scan_count，</em>swappiness 正是在这个函数中做的文章</p><p><strong>`shrink_node</strong>() <strong>–</strong>&gt; <strong>shrink_node_memcg</strong>(mem_cgroup_iter) <strong>–</strong>&gt; <strong>shrink_lruvec</strong>() <strong>–</strong>&gt; <strong>get_scan_count</strong>()`</p><p>下面我们开始拆分分析<em>get_scan_count 这一函数</em></p><p>1.开头首先判断下是否含有Swap分区，没有的话就不会扫描匿名页</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/* If we have no swap space, do not bother scanning anon folios. */</span></span><br><span class="line"><span class="keyword">if</span> (!sc-&gt;may_swap || !can_reclaim_anon_pages(memcg, pgdat-&gt;node_id, sc)) &#123;</span><br><span class="line">scan_balance = SCAN_FILE;</span><br><span class="line"><span class="keyword">goto</span> out;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>2.如果不是全局设置的swappiness 而是单独的group 中的参数，那么如果swappiness 为0，则会只扫描文件页。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * Global reclaim will swap to prevent OOM even with no</span></span><br><span class="line"><span class="comment"> * swappiness, but memcg users want to use this knob to</span></span><br><span class="line"><span class="comment"> * disable swapping for individual groups completely when</span></span><br><span class="line"><span class="comment"> * using the memory controller's swap limit feature would be</span></span><br><span class="line"><span class="comment"> * too expensive.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">if</span> (cgroup_reclaim(sc) &amp;&amp; !swappiness) &#123;</span><br><span class="line">scan_balance = SCAN_FILE;</span><br><span class="line"><span class="keyword">goto</span> out;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>3.sc-&gt;priority 变量用于在内存回收期间确定匿名和文件LRU列表的扫描程度，priority 的值等于 0 了，说明现在离 OOM 很可能不远了。所以如果sc-&gt;priority为零且swappiness为非零，则会平等扫描匿名和文件页面。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * Do not apply any pressure balancing cleverness when the</span></span><br><span class="line"><span class="comment"> * system is close to OOM, scan both anon and file equally</span></span><br><span class="line"><span class="comment"> * (unless the swappiness setting disagrees with swapping).</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">if</span> (!sc-&gt;priority &amp;&amp; swappiness) &#123;</span><br><span class="line">scan_balance = SCAN_EQUAL;</span><br><span class="line"><span class="keyword">goto</span> out;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>4.如果当前可回收文件页非常少，不管swappiness 设定值直接强制回收匿名页</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/* The file folios on the current node are dangerously low */</span></span><br><span class="line"><span class="keyword">unsigned</span> <span class="keyword">int</span> file_is_tiny:<span class="number">1</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * If the system is almost out of file pages, force-scan anon.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">if</span> (sc-&gt;file_is_tiny) &#123;</span><br><span class="line">scan_balance = SCAN_ANON;</span><br><span class="line"><span class="keyword">goto</span> out;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>5.如果此时inactive file 很充足，则只回收file 页，毕竟回收开销低</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * If there is enough inactive page cache, we do not reclaim</span></span><br><span class="line"><span class="comment"> * anything from the anonymous working right now.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">if</span> (sc-&gt;cache_trim_mode) &#123;</span><br><span class="line">scan_balance = SCAN_FILE;</span><br><span class="line"><span class="keyword">goto</span> out;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>6.这个时候，来到了根据swappiness 数值来平衡文件页和匿名页的地方了</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"> scan_balance = SCAN_FRACT;</span><br><span class="line"> <span class="comment">// With swappiness at 100, anon and file have equal IO cost.</span></span><br><span class="line"> total_cost = sc-&gt;anon_cost + sc-&gt;file_cost;</span><br><span class="line">anon_cost = total_cost + sc-&gt;anon_cost;</span><br><span class="line">file_cost = total_cost + sc-&gt;file_cost;</span><br><span class="line">total_cost = anon_cost + file_cost;</span><br><span class="line"></span><br><span class="line">ap = swappiness * (total_cost + <span class="number">1</span>);</span><br><span class="line">ap /= anon_cost + <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line">fp = (<span class="number">200</span> - swappiness) * (total_cost + <span class="number">1</span>);</span><br><span class="line">fp /= file_cost + <span class="number">1</span>;</span><br></pre></td></tr></table></figure><h4 id="并发patch-解析"><a href="#并发patch-解析" class="headerlink" title="并发patch 解析"></a>并发patch 解析</h4><p>有了前面的基础铺垫，接下来，来看下这个关于kswapd 的并发修改</p><p><a href="https://android-review.googlesource.com/c/kernel/common/+/1579505" target="_blank" rel="noopener">https://android-review.googlesource.com/c/kernel/common/+/1579505</a></p><p>先看下message，看下这笔修改的初衷</p><p><img src="http://blog.lihaizhou.top/Kswapd/8.png" alt="Untitled"></p><p>direct reclaim 的耗时长会带来性能问题，实际上，在Linux系统上并不需要kswapd，kswapd 存在的意义仅仅是为了通过防止触发direct reclaim 从而来优化性能。</p><p><img src="http://blog.lihaizhou.top/Kswapd/9.png" alt="Untitled"></p><p>如果理解这段话呢？</p><p>我们知道当系统内存不足时，kswapd会通过扫描页面缓存并交换出未使用的页面来释放内存页面。这个过程可能非常耗时，特别是在CPU时钟速度较慢的系统上。</p><p><strong>随着硬件的发展，存储速度显著提高，而CPU时钟速度相对稳定，此时单线程的kswapd 无法满足高性能存储硬件的需求，说白了就是速度不一致性，因此，支持多线程的kswapd是必要的，以提高其吞吐量并避免性能问题。</strong></p><p>这其实有点像网络拥塞算法，同样在历史的发展过程中出现了类似的中间路由设备硬件性能的提升，带来的转发越来越快最终带来的bufferbloat(缓冲区肿胀)问题。</p><p>归纳下来就是：</p><p>对kswapd 采用多线程可以利用额外的CPU资源来进行主动页面替换，以减少direct reclaim 次数，从而减少任务的延迟，但并不意味着不会发生direct reclaim，如果采用的并发线程数值较高的情况下仍然发生了direct reclaim，由于锁竞争的加剧，这种情况下如果出现direct reclaim的开销（延迟）可能更高。</p><p>下面将看下修改的具体内容</p><p>1.将传参字符串转换为整数，并将其存储在kswapd_threads 变量中，如转换失败或超出最大限制数值16 则返回0</p><p><img src="http://blog.lihaizhou.top/Kswapd/10.png" alt="Untitled"></p><p>2.在kswapd_run 函数中调用kswapd_per_node_run 函数(kswapd_threads &gt; 1情况下)，循环创建kswapd 线程，个数是kswapd_threads 个</p><p><img src="http://blog.lihaizhou.top/Kswapd/11.png" alt="Untitled"></p><p>但是没有地方调用kswapd_per_node_setup ，也就是这个修改目前只是集成了支持配置kswapd 线程数的功能，实际上在当前主流的手机设备上，是不适用这个修改的，原因在前面提到过，因为只有一个内存节点的缘故，即便真的在手机设备上改为了并发，相信会带来严重的锁竞争，反而得不偿失。</p><p>所以这个修改理解适用场景应该是NUMA 架构的设备上，多个node多CPU，这样才能在一定程度上提升kswapd 的吞吐量。</p><h3 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h3><ol><li><a href="https://mp.weixin.qq.com/s?search_click_id=16672924557035298023-1681529678112-9957738303&amp;__biz=MzAxMDM0NjExNA==&amp;mid=2247487168&amp;idx=1&amp;sn=b8ae6d5af2f28119fe9bdbcca8474582&amp;chksm=9b50852dac270c3be7e552aefe661448ca43dadf1df0bb1ec63f6192afd28e730cc2de80b6f7&amp;scene=7#rd" target="_blank" rel="noopener">kswapd介绍</a></li><li><a href="https://zhuanlan.zhihu.com/p/70964195" target="_blank" rel="noopener">Linux中的内存回收 [一]</a></li><li><a href="https://zhuanlan.zhihu.com/p/499738178" target="_blank" rel="noopener">Linux - 再议内存回收之 swappiness</a></li><li><a href="https://android-review.googlesource.com/c/kernel/common/+/1579505" target="_blank" rel="noopener">https://android-review.googlesource.com/c/kernel/common/+/1579505</a></li><li><a href="https://lore.kernel.org/lkml/1522661062-39745-1-git-send-email-buddy.lumpkin@oracle.com/" target="_blank" rel="noopener">https://lore.kernel.org/lkml/1522661062-39745-1-git-send-email-buddy.lumpkin@oracle.com/</a></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h3&gt;&lt;p&gt;关于Kswapd 相信是比较熟悉了，如果经常分析Perfetto 的话，会经常看见这玩意的身影，尤其是内存紧张的场景下。&lt;/p&gt;
&lt;p&gt;以前
      
    
    </summary>
    
      <category term="kernel" scheme="http://lihaizhou.top/categories/kernel/"/>
    
    
  </entry>
  
  <entry>
    <title>Android|图形栈疑问汇总(持续更新)</title>
    <link href="http://lihaizhou.top/2022/09/06/Android-%E5%9B%BE%E5%BD%A2%E6%A0%88%E7%96%91%E9%97%AE%E6%B1%87%E6%80%BB-%E6%8C%81%E7%BB%AD%E6%9B%B4%E6%96%B0/"/>
    <id>http://lihaizhou.top/2022/09/06/Android-图形栈疑问汇总-持续更新/</id>
    <published>2022-09-06T13:09:45.000Z</published>
    <updated>2022-09-06T14:05:30.249Z</updated>
    
    <content type="html"><![CDATA[<p>最近在看图形显示方面的内容，这块的知识点繁多且复杂，到了S以及T上有了较多的变化，单看理论源码的话，难以形成深刻的认知。<br>所以打算在最近的学习过程中列举出自己的一些疑问，后面会持续的更新疑问并补充个人的理解。</p><h4 id="1-onMeasure-onLayout-onDraw-分别做得事？"><a href="#1-onMeasure-onLayout-onDraw-分别做得事？" class="headerlink" title="1. onMeasure/ onLayout/ onDraw 分别做得事？"></a>1. onMeasure/ onLayout/ onDraw 分别做得事？</h4><h4 id="2-如何理解Window-ViewRootImpl-Surface-SurfaceTexture-TextureView-GLSurfaceview-概念及其相互的关系"><a href="#2-如何理解Window-ViewRootImpl-Surface-SurfaceTexture-TextureView-GLSurfaceview-概念及其相互的关系" class="headerlink" title="2. 如何理解Window/ ViewRootImpl/ Surface/ SurfaceTexture/ TextureView/ GLSurfaceview 概念及其相互的关系?"></a>2. 如何理解Window/ ViewRootImpl/ Surface/ SurfaceTexture/ TextureView/ GLSurfaceview 概念及其相互的关系?</h4><h4 id="3-如何理解硬件加速这一角色？"><a href="#3-如何理解硬件加速这一角色？" class="headerlink" title="3. 如何理解硬件加速这一角色？"></a>3. 如何理解硬件加速这一角色？</h4><ul><li>硬件加速引入的初衷？</li><li>会带来什么样的好处及对内存的影响？</li><li>如何强制让View/ Window/ Activity 开启硬件加速？</li><li>如何快速判断是否开了硬件加速？</li><li>什么情况下会依旧采用软件绘制？</li><li>如果是软件绘制的话，大概过程是怎么样的？</li><li>如果是硬件加速的话，大概过程是怎么样的？ </li></ul><h4 id="4-RenderThread-扮演的角色？"><a href="#4-RenderThread-扮演的角色？" class="headerlink" title="4. RenderThread 扮演的角色？"></a>4. RenderThread 扮演的角色？</h4><ul><li>为何要另起个线程？</li><li>queueBuffer 结束是否标志GPU 完成？</li><li>RenderThread是如何和MainThread 交互的？</li><li>RenderThread是如何和Sf 交互的？</li></ul><h4 id="5-游戏的绘制和普通App-应用有什么区别？"><a href="#5-游戏的绘制和普通App-应用有什么区别？" class="headerlink" title="5. 游戏的绘制和普通App 应用有什么区别？"></a>5. 游戏的绘制和普通App 应用有什么区别？</h4><ul><li>游戏的绘制阶段buffer 是自身控制还是受系统buffer count限制？</li><li>游戏会听Vsync吗？如果不受Vsync 控制，那么游戏绘制的节奏是如何把握的？</li></ul><h4 id="6-Choreographer-doframe-扮演的角色？"><a href="#6-Choreographer-doframe-扮演的角色？" class="headerlink" title="6. Choreographer#doframe 扮演的角色？"></a>6. Choreographer#doframe 扮演的角色？</h4><ul><li>触发的时机？</li></ul><h4 id="7-如何理解掉帧这个概念？"><a href="#7-如何理解掉帧这个概念？" class="headerlink" title="7. 如何理解掉帧这个概念？"></a>7. 如何理解掉帧这个概念？</h4><ul><li>市面统计掉帧工具如PerfDog 等测试原理？</li><li>如何根据Perfetto 快速统计出实际FPS？</li><li>为何掉帧要看Sf 而不是App 侧？</li><li>如果一帧在绘制阶段超出了一个Vsync，但是此时有其它layer 更新的buffer，此时Sf 拿到了并正常合成，那么这次究竟算不算掉帧？视觉上会不会感受到卡顿？</li></ul><h4 id="8-为何Google-声称三缓冲能够有效降低掉帧？"><a href="#8-为何Google-声称三缓冲能够有效降低掉帧？" class="headerlink" title="8. 为何Google 声称三缓冲能够有效降低掉帧？"></a>8. 为何Google 声称三缓冲能够有效降低掉帧？</h4><ul><li>如果是这样的话，那多增加一些buffer count 不是会更流畅？为何没有这么做？</li><li>对于常见的三级流水线而言，Triple buffer 会比double buffer 触控延时更好？</li><li>试想一下，如果在三级流水线上，分别有绘制稳定、绘制过快、绘制过慢这三种场景下，Triple buffer和double buffer 一帧从绘制到显示的延迟周期差异？</li></ul><h4 id="9-如何理解client-和device-合成？"><a href="#9-如何理解client-和device-合成？" class="headerlink" title="9. 如何理解client 和device 合成？"></a>9. 如何理解client 和device 合成？</h4><ul><li>发起GPU 合成动作是在哪个线程中？</li><li>device 合成是在哪里完成的？涉及到什么硬件？</li><li>如何判断本次合成是GPU合成还是硬件合成？</li></ul><h4 id="10-什么情况下layer-会采用GPU-合成"><a href="#10-什么情况下layer-会采用GPU-合成" class="headerlink" title="10. 什么情况下layer 会采用GPU 合成?"></a>10. 什么情况下layer 会采用GPU 合成?</h4><ul><li>举个例子，比如为何处于桌面静止下dump 出来显示是GPU 合成？</li></ul><h4 id="11-如何理解画面撕裂这个现象？"><a href="#11-如何理解画面撕裂这个现象？" class="headerlink" title="11. 如何理解画面撕裂这个现象？"></a>11. 如何理解画面撕裂这个现象？</h4><ul><li>什么情况下可能会出现画面撕裂？</li><li>如果出现了画面撕裂，有哪些分析排查的思路？</li></ul><h4 id="12-Vsync-offset-引入的目的是？"><a href="#12-Vsync-offset-引入的目的是？" class="headerlink" title="12. Vsync offset 引入的目的是？"></a>12. Vsync offset 引入的目的是？</h4><ul><li>其数值不同会有什么影响？</li><li>厂商一般是如何调校SF以及App的offset 数值的？</li><li>调整Sf offset后 对触控延时可能的影响？</li><li>offset 数值的改变对游戏应用有影响吗？</li><li>举个例子，对于60fps而言，如何调整Sf offset 数值并且要满足什么样的条件，会对触控延时有改善即能够省掉一个Vsync 周期时间？</li></ul><h4 id="13-图形系统中不同进程是如何操作同一块buffer的？"><a href="#13-图形系统中不同进程是如何操作同一块buffer的？" class="headerlink" title="13. 图形系统中不同进程是如何操作同一块buffer的？"></a>13. 图形系统中不同进程是如何操作同一块buffer的？</h4><h4 id="14-一个Vsync-周期内，绘制和合成用的是同一块buf-吗？"><a href="#14-一个Vsync-周期内，绘制和合成用的是同一块buf-吗？" class="headerlink" title="14. 一个Vsync 周期内，绘制和合成用的是同一块buf 吗？"></a>14. 一个Vsync 周期内，绘制和合成用的是同一块buf 吗？</h4><ul><li>举个例子，在offset为0的情况下，一个Vsync周期内绘制和Sf的合成用的是同一个buffer吗？</li><li>对于三级流水线而言，一帧最快要等几个Vsync周期才能显示？</li></ul><h4 id="15-如何快速找到同一块buffer-在绘制、合成、显示的位置-Perfetto"><a href="#15-如何快速找到同一块buffer-在绘制、合成、显示的位置-Perfetto" class="headerlink" title="15. 如何快速找到同一块buffer 在绘制、合成、显示的位置? (Perfetto)"></a>15. 如何快速找到同一块buffer 在绘制、合成、显示的位置? (Perfetto)</h4><ul><li>我们看perfetto 时，经常需要找到一块buffer 对应到App、Sf、HWC、presentFence的位置，这样可以分析waiting for GPU completion和waiting for HWC release 耗时长问题，该如何快速找到比如合成或显示用到的buffer 对应到绘制片段是哪一块？</li></ul><h4 id="16-不同级数的流水线所带来的影响？"><a href="#16-不同级数的流水线所带来的影响？" class="headerlink" title="16. 不同级数的流水线所带来的影响？"></a>16. 不同级数的流水线所带来的影响？</h4><ul><li>不同刷新率对应的流水线级数差异？比如高刷120hz下流水线级数？</li><li>如果将三级流水线改为两级或者四级会有什么影响？触控延时会降低吗？</li><li>不同级数对应的buffer数目要求？</li></ul><h4 id="17-如何快速厘清dequeue-buffer-以及queue-buffer-耗时长问题？"><a href="#17-如何快速厘清dequeue-buffer-以及queue-buffer-耗时长问题？" class="headerlink" title="17. 如何快速厘清dequeue buffer 以及queue buffer 耗时长问题？"></a>17. 如何快速厘清dequeue buffer 以及queue buffer 耗时长问题？</h4><h4 id="18-图形显示引入Fence-机制的根本缘由是？-宏观角度概述"><a href="#18-图形显示引入Fence-机制的根本缘由是？-宏观角度概述" class="headerlink" title="18. 图形显示引入Fence 机制的根本缘由是？(宏观角度概述)"></a>18. 图形显示引入Fence 机制的根本缘由是？(宏观角度概述)</h4><ul><li>Fence是如何跨进程跨硬件的？</li></ul><h4 id="19-Sf-侧的waiting-for-presentFence-结束点代表的含义？"><a href="#19-Sf-侧的waiting-for-presentFence-结束点代表的含义？" class="headerlink" title="19. Sf 侧的waiting for presentFence 结束点代表的含义？"></a>19. Sf 侧的waiting for presentFence 结束点代表的含义？</h4><h4 id="20-SurfaceFlinger-是如何和HWC-Service交互的？"><a href="#20-SurfaceFlinger-是如何和HWC-Service交互的？" class="headerlink" title="20. SurfaceFlinger 是如何和HWC Service交互的？"></a>20. SurfaceFlinger 是如何和HWC Service交互的？</h4><h4 id="21-怎么理解Hwcomposer-扮演的角色？"><a href="#21-怎么理解Hwcomposer-扮演的角色？" class="headerlink" title="21. 怎么理解Hwcomposer 扮演的角色？"></a>21. 怎么理解Hwcomposer 扮演的角色？</h4><ul><li>为什么不放在Sf 主线程中做？这样似乎可以省去很多的binder交互开销？</li></ul><h4 id="22-HWC-侧的OverlayEngin扮演的角色是？"><a href="#22-HWC-侧的OverlayEngin扮演的角色是？" class="headerlink" title="22. HWC 侧的OverlayEngin扮演的角色是？"></a>22. HWC 侧的OverlayEngin扮演的角色是？</h4><h4 id="23-HWC-下到kernel-的过程？"><a href="#23-HWC-下到kernel-的过程？" class="headerlink" title="23. HWC 下到kernel 的过程？"></a>23. HWC 下到kernel 的过程？</h4><h4 id="24-如何排查Resync问题？"><a href="#24-如何排查Resync问题？" class="headerlink" title="24. 如何排查Resync问题？"></a>24. 如何排查Resync问题？</h4><ul><li>哪些场景可能会触发Resync？</li></ul><h4 id="25-如何排查应用自身不出帧的原因？-Perfetto"><a href="#25-如何排查应用自身不出帧的原因？-Perfetto" class="headerlink" title="25. 如何排查应用自身不出帧的原因？(Perfetto)"></a>25. 如何排查应用自身不出帧的原因？(Perfetto)</h4><h4 id="26-Sf-默认是跑在什么大核还是小核，什么进程组？"><a href="#26-Sf-默认是跑在什么大核还是小核，什么进程组？" class="headerlink" title="26. Sf 默认是跑在什么大核还是小核，什么进程组？"></a>26. Sf 默认是跑在什么大核还是小核，什么进程组？</h4><ul><li>如果想让其有机会进大核，如何修改？</li><li>如果想在loading轻的时候让其有机会跑大核，最安全的改法？</li></ul><h4 id="27-如何排查Sf-挤压问题？"><a href="#27-如何排查Sf-挤压问题？" class="headerlink" title="27. 如何排查Sf 挤压问题？"></a>27. 如何排查Sf 挤压问题？</h4><ul><li>一般如何排查以及优化策略？这种情况下还会对齐Vsync-sf吗？</li></ul><h4 id="28-如何Sf-侧有空白或pending-现象？"><a href="#28-如何Sf-侧有空白或pending-现象？" class="headerlink" title="28. 如何Sf 侧有空白或pending 现象？"></a>28. 如何Sf 侧有空白或pending 现象？</h4><h4 id="29-哪种合成会走Drawlayers？"><a href="#29-哪种合成会走Drawlayers？" class="headerlink" title="29. 哪种合成会走Drawlayers？"></a>29. 哪种合成会走Drawlayers？</h4><h4 id="30-如何排查Drawlayers-耗时长？和GPU有关系吗？"><a href="#30-如何排查Drawlayers-耗时长？和GPU有关系吗？" class="headerlink" title="30. 如何排查Drawlayers 耗时长？和GPU有关系吗？"></a>30. 如何排查Drawlayers 耗时长？和GPU有关系吗？</h4><h4 id="31-acquireFence以及releaseFence之间的关系？"><a href="#31-acquireFence以及releaseFence之间的关系？" class="headerlink" title="31. acquireFence以及releaseFence之间的关系？"></a>31. acquireFence以及releaseFence之间的关系？</h4><h4 id="32-acquireFence放的慢或releaseFence放的慢分别意味着什么？"><a href="#32-acquireFence放的慢或releaseFence放的慢分别意味着什么？" class="headerlink" title="32. acquireFence放的慢或releaseFence放的慢分别意味着什么？"></a>32. acquireFence放的慢或releaseFence放的慢分别意味着什么？</h4><h4 id="33-什么情况会出现waiting-for-HWC-release-Tag-或waiting-for-GPU-completion？"><a href="#33-什么情况会出现waiting-for-HWC-release-Tag-或waiting-for-GPU-completion？" class="headerlink" title="33. 什么情况会出现waiting for HWC release Tag 或waiting for GPU completion？"></a>33. 什么情况会出现waiting for HWC release Tag 或waiting for GPU completion？</h4><h4 id="34-如果快速排查waiting-for-GPU-completion-耗时长问题？"><a href="#34-如果快速排查waiting-for-GPU-completion-耗时长问题？" class="headerlink" title="34. 如果快速排查waiting for GPU completion 耗时长问题？"></a>34. 如果快速排查waiting for GPU completion 耗时长问题？</h4><ul><li>如何快速排查是GPU问题还是releaseFence放的慢了？</li><li>如果是releaseFence放慢了影响到下一帧的合成，那么Systrace侧如何看waiting for GPU completion耗时中GPU空等时长？</li></ul><h4 id="34-如Sf-未及时拿走buf-合成，可能是什么原因？"><a href="#34-如Sf-未及时拿走buf-合成，可能是什么原因？" class="headerlink" title="34. 如Sf 未及时拿走buf 合成，可能是什么原因？"></a>34. 如Sf 未及时拿走buf 合成，可能是什么原因？</h4><ul><li>Sf bufferTX中有buffer进来，Sf在接到Vsync-sf没有去拿buffer合成，一般是什么原因导致？</li></ul><h4 id="35-如何从Systrace侧看是否存在buffer-轮转压力？"><a href="#35-如何从Systrace侧看是否存在buffer-轮转压力？" class="headerlink" title="35. 如何从Systrace侧看是否存在buffer 轮转压力？"></a>35. 如何从Systrace侧看是否存在buffer 轮转压力？</h4><ul><li>当出现buffer轮转压力时，为何waiting for HWC release 后往往会伴随着waiting for GPU completion</li><li>如果waiting for GPU completion在waiting for HWC release之前出现，意味着什么？</li></ul><h4 id="37-buffer-count数量由什么因素决定？-Android-S及以上"><a href="#37-buffer-count数量由什么因素决定？-Android-S及以上" class="headerlink" title="37. buffer count数量由什么因素决定？(Android S及以上)"></a>37. buffer count数量由什么因素决定？(Android S及以上)</h4><h4 id="38-如何知道一段时间内buffer-count-Android-S及以上-？"><a href="#38-如何知道一段时间内buffer-count-Android-S及以上-？" class="headerlink" title="38. 如何知道一段时间内buffer count(Android S及以上)？"></a>38. 如何知道一段时间内buffer count(Android S及以上)？</h4><h4 id="39-如何理解BBQ机制？-Android-S及以上"><a href="#39-如何理解BBQ机制？-Android-S及以上" class="headerlink" title="39. 如何理解BBQ机制？(Android S及以上)"></a>39. 如何理解BBQ机制？(Android S及以上)</h4><h4 id="40-如何理解S上的Duration架构？"><a href="#40-如何理解S上的Duration架构？" class="headerlink" title="40. 如何理解S上的Duration架构？"></a>40. 如何理解S上的Duration架构？</h4><ul><li>数值设置的依据是？是一个动态的数值吗？不同的数值会有什么影响？会影响跟手性吗？</li></ul><h4 id="41-如何理解S上的-Latch-signaled-buffer？"><a href="#41-如何理解S上的-Latch-signaled-buffer？" class="headerlink" title="41. 如何理解S上的 Latch signaled buffer？"></a>41. 如何理解S上的 Latch signaled buffer？</h4><h4 id="42-如何理解S上的Sf-Backpressure？"><a href="#42-如何理解S上的Sf-Backpressure？" class="headerlink" title="42. 如何理解S上的Sf Backpressure？"></a>42. 如何理解S上的Sf Backpressure？</h4>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;最近在看图形显示方面的内容，这块的知识点繁多且复杂，到了S以及T上有了较多的变化，单看理论源码的话，难以形成深刻的认知。&lt;br&gt;所以打算在最近的学习过程中列举出自己的一些疑问，后面会持续的更新疑问并补充个人的理解。&lt;/p&gt;
&lt;h4 id=&quot;1-onMeasure-onLay
      
    
    </summary>
    
      <category term="性能" scheme="http://lihaizhou.top/categories/%E6%80%A7%E8%83%BD/"/>
    
    
  </entry>
  
  <entry>
    <title>Android S Doze模式</title>
    <link href="http://lihaizhou.top/2022/04/19/Android-S-Doze%E6%A8%A1%E5%BC%8F/"/>
    <id>http://lihaizhou.top/2022/04/19/Android-S-Doze模式/</id>
    <published>2022-04-19T06:19:53.000Z</published>
    <updated>2022-04-19T07:10:17.063Z</updated>
    
    <content type="html"><![CDATA[<h4 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h4><p>基于<code>Android S</code>梳理下Doze 机制</p><h4 id="认识-Doze"><a href="#认识-Doze" class="headerlink" title="认识 Doze"></a>认识 Doze</h4><blockquote><p>如果用户未插接设备的电源，在屏幕关闭的情况下，让设备在一段时间内保持不活动状态，那么设备就会进入Doze 模式。<br>在Doze 模式下，系统会尝试通过限制应用访问占用大量网络和 CPU 资源的服务来节省电量。它还会阻止应用访问网络，并延迟其作业、同步和标准闹钟。<br>系统会定期退出Doze 模式一小段时间，让应用完成其延迟的活动。在此维护期内，系统会运行所有待处理的同步、作业和闹钟，并允许应用访问网络。</p></blockquote><p><img src="http://blog.lihaizhou.top/Doze/doze_1.png" alt=""><br>(摘自 <a href="https://developer.android.google.cn/training/monitoring-device-state/doze-standby" target="_blank" rel="noopener">https://developer.android.google.cn/training/monitoring-device-state/doze-standby</a>)</p><p>关于上面这张图的理解：</p><ol><li>当设备灭屏且未充电下，一段时间后会先进入图中的第一个Doze 即light doze 状态。</li><li>light doze 阶段对应用限制措施相比deep doze 会少一些，light doze阶段同样有窗口期，窗口期内会解除对应用的限制措施。</li><li>一段时间后，如设备处于静止状态，会进入到deep doze，从图中可以看到deep doze 阶段对应用的限制措施会有所增加，比如增加了Alarm、Wifi扫描等限制。</li><li>在deep doze 阶段，如没有外在条件改变比如位置移动、亮屏等，会在deep doze 和窗口期之间循环切换。</li></ol><h4 id="应用行为限制"><a href="#应用行为限制" class="headerlink" title="应用行为限制"></a>应用行为限制</h4><p>deep doze 阶段对应用的行为限制如下：</p><blockquote><p>暂停访问网络。<br>系统忽略唤醒锁定。<br>标准 AlarmManager 闹钟（包括 setExact() 和 setWindow()）推迟到下一个维护期。<br>如果您需要设置在设备处于低电耗模式时触发的闹钟，请使用 setAndAllowWhileIdle() 或 setExactAndAllowWhileIdle()。<br>使用 setAlarmClock() 设置的闹钟将继续正常触发，系统会在这些闹钟触发之前不久退出低电耗模式。<br>系统不执行 WLAN 扫描。<br>系统不允许运行同步适配器。<br>系统不允许运行 JobScheduler。</p></blockquote><p>(引用自 <a href="https://developer.android.google.cn/training/monitoring-device-state/doze-standby" target="_blank" rel="noopener">https://developer.android.google.cn/training/monitoring-device-state/doze-standby</a>)<br>而对于应用进入light doze状态的话，应用限制会减少很多，只有网络限制、不允许运行同步适配器、不允许运行 JobScheduler这三种类型的限制措施，同时窗口间隔会更短。</p><h4 id="Doze-状态集"><a href="#Doze-状态集" class="headerlink" title="Doze 状态集"></a>Doze 状态集</h4><p>deep doze 和light doze 的关系</p><ul><li>进入deep doze 状态前提之一是设备已经静止了一段时间，而进入light doze 则不需要这个条件。</li><li>deep doze 和light doze 可以在设备中同时运行，简单来说就是在进入deep之前，两个状态机的代码都会执行。</li><li>设备进入deep doze 状态之前必须先经过light doze。</li><li>如果设备进入了deep doze，那么light doze 的状态机代码就不会跑了。</li></ul><p>下面介绍下deep doze 和light doze 的状态集<br><strong>Deep doze</strong><br><img src="http://blog.lihaizhou.top/Doze/doze_2.png" alt="enter description here"><br><strong>Light doze</strong><br><img src="http://blog.lihaizhou.top/Doze/doze_3.png" alt="enter description here"></p><h4 id="Doze-状态机"><a href="#Doze-状态机" class="headerlink" title="Doze 状态机"></a>Doze 状态机</h4><h5 id="Light-Doze-状态机"><a href="#Light-Doze-状态机" class="headerlink" title="Light Doze 状态机"></a>Light Doze 状态机</h5><p>light doze 的代码状态机<br><img src="http://blog.lihaizhou.top/Doze/doze_4.png" alt="enter description here"></p><p>Light doze 图形状态机<br><img src="http://blog.lihaizhou.top/Doze/doze_5.png" alt="enter description here"></p><p>下面我们将尽可能用通俗易懂的话来解释上面这张light doze 图形状态机</p><ol><li>假设用户正在使用手机，此时停留在Active 状态。</li><li>用户使用一段时间后，关闭了屏幕且未在充电，则进入LIGHT_STATE_INACTIVE 状态。</li><li>3 分钟之后进入到PRE_IDLE 状态，这个阶段处理未完成的事务。</li><li>5 分钟之后会进入到LIGHT_STATE_IDLE 状态，这个时候会根据当前设备是否联网而选择进入不同的状态，有网络的话则进入到MAINTANCE 状态，否则进入WAITING_FOR_NETWORK 状态。</li><li>设备有网络的情况下，状态会在IDLE 和 MAINTANCE 之间交替切换。</li></ol><p>PS：停留在light idle 时长并不会随着转换次数N的增加而无限增长，会受到最大值<code>DEFAULT_LIGHT_MAX_IDLE_TIMEOUT = 15 min</code>的限制</p><h5 id="Deep-Doze-状态机"><a href="#Deep-Doze-状态机" class="headerlink" title="Deep Doze 状态机"></a>Deep Doze 状态机</h5><p>Deep doze 的状态机相较于light doze 而言稍显复杂一些<br><img src="http://blog.lihaizhou.top/Doze/doze_6.png" alt="enter description here"></p><p>Deep doze 图形状态机<br><img src="http://blog.lihaizhou.top/Doze/doze_7.png" alt="enter description here"></p><p>下面我们将尽可能用通俗易懂的话来解释上面这张deep doze 图形状态机</p><ol><li>假设用户正在使用手机，此时停留在Active 状态。</li><li>用户使用一段时间后，关闭了屏幕且未在充电，设备将很快进入InActive 状态。</li><li>过了30 min之后，进入Idle_pending状态并停留5 min。</li><li>5 min后进入Sensing 状态，这个阶段会检测设备是否有转向变化。</li><li>没有转向变化的话，会进入到Locating 状态并停留30s，这个阶段会检测位置是否变化。</li><li>位置没有变化的话，30s 后将进入Idle 状态即deep doze。</li><li>Idle 状态停留60乘以2的N次方时间后(N是Idle 和窗口期转换的次数，初始值0)，会进入到窗口期，窗口期内应用的限制措施会被解除。<br>在窗口期停留5乘以2的N次方时间(N是Idle 和窗口期转换的次数，初始值0)后，会再次进入Idle，此后如没有外在条件变化的话，则会在idle 和窗口期之间交替切换。</li></ol><p>PS：停留在deep idle 时长并不会随着转换次数N的增加而无限增长，会受到最大值<code>DEFAULT_MAX_IDLE_TIMEOUT = 6 h</code>的限制</p><p><strong>Q：进入到deep Idle 状态后，是如何限制应用行为的？</strong><br>A：<code>stepIdleStateLocked</code>函数扮演了重要的角色，主要用于切换状态机，<br>当<code>STATE_IDLE_MAINTENANCE</code> 切换到<code>STATE_IDLE</code> 后，会发一个<code>MSG_REPORT_IDLE_ON</code>消息</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@VisibleForTesting</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">stepIdleStateLocked</span><span class="params">(String reason)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (DEBUG) Slog.d(TAG, <span class="string">"stepIdleStateLocked: mState="</span> + mState);</span><br><span class="line">    EventLogTags.writeDeviceIdleStep();</span><br><span class="line">            <span class="comment">//....</span></span><br><span class="line">            <span class="keyword">switch</span> (mState) &#123;</span><br><span class="line">            <span class="comment">//....</span></span><br><span class="line">            <span class="keyword">case</span> STATE_IDLE_MAINTENANCE:</span><br><span class="line">            <span class="comment">//Doze 相关状态的停留时间都是通过Alarm 的超时来实现的</span></span><br><span class="line">            <span class="comment">//超出mNextIdleDelay时间后，检测条件满足的话会再次进入STATE_IDLE_MAINTENANCE</span></span><br><span class="line">            scheduleAlarmLocked(mNextIdleDelay, <span class="keyword">true</span>);</span><br><span class="line">            <span class="keyword">if</span> (DEBUG) Slog.d(TAG, <span class="string">"Moved to STATE_IDLE. Next alarm in "</span> + mNextIdleDelay +<span class="string">" ms."</span>);</span><br><span class="line">            <span class="comment">//Idle 状态停留的时间, IDLE_FACTO为2，所以是2的N次方</span></span><br><span class="line">            mNextIdleDelay = (<span class="keyword">long</span>)(mNextIdleDelay * mConstants.IDLE_FACTOR);</span><br><span class="line">            <span class="keyword">if</span> (DEBUG) Slog.d(TAG, <span class="string">"Setting mNextIdleDelay = "</span> + mNextIdleDelay);</span><br><span class="line">            mIdleStartTime = SystemClock.elapsedRealtime();</span><br><span class="line">            mNextIdleDelay = Math.min(mNextIdleDelay, mConstants.MAX_IDLE_TIMEOUT);</span><br><span class="line">            <span class="comment">//首次的话mNextIdleDelay是0，所以首次Idle 停留时间就是IDLE_TIMEOUT</span></span><br><span class="line">            <span class="comment">//即60 * 60 * 1000L(60min)</span></span><br><span class="line">            <span class="keyword">if</span> (mNextIdleDelay &lt; mConstants.IDLE_TIMEOUT) &#123;</span><br><span class="line">                mNextIdleDelay = mConstants.IDLE_TIMEOUT;</span><br><span class="line">            &#125;</span><br><span class="line">            moveToStateLocked(STATE_IDLE, reason);</span><br><span class="line">            <span class="comment">//进入到Idle 状态后，light 状态就不会运行了并取消light相关的alram超时</span></span><br><span class="line">            <span class="keyword">if</span> (mLightState != LIGHT_STATE_OVERRIDE) &#123;</span><br><span class="line">                mLightState = LIGHT_STATE_OVERRIDE;</span><br><span class="line">                cancelLightAlarmLocked();</span><br><span class="line">            &#125;</span><br><span class="line">            addEvent(EVENT_DEEP_IDLE, <span class="keyword">null</span>);</span><br><span class="line">            mGoingIdleWakeLock.acquire();</span><br><span class="line">            <span class="comment">//发送 REPORT_IDLE_ON消息</span></span><br><span class="line">            mHandler.sendEmptyMessage(MSG_REPORT_IDLE_ON);</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">            <span class="comment">//...</span></span><br><span class="line">            &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>进入到处理<code>MSG_REPORT_IDLE_ON</code> 消息环节，这个环节主要是通知其它模块起来做限制措施。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">handleMessage</span><span class="params">(Message msg)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (DEBUG) Slog.d(TAG, <span class="string">"handleMessage("</span> + msg.what + <span class="string">")"</span>);</span><br><span class="line">        <span class="keyword">switch</span> (msg.what) &#123;</span><br><span class="line">            <span class="comment">//....</span></span><br><span class="line">            <span class="keyword">case</span> MSG_REPORT_IDLE_ON:</span><br><span class="line">            <span class="keyword">case</span> MSG_REPORT_IDLE_ON_LIGHT: &#123;</span><br><span class="line">                <span class="comment">// mGoingIdleWakeLock is held at this point</span></span><br><span class="line">                EventLogTags.writeDeviceIdleOnStart();</span><br><span class="line">                <span class="keyword">final</span> <span class="keyword">boolean</span> deepChanged;</span><br><span class="line">                <span class="keyword">final</span> <span class="keyword">boolean</span> lightChanged;</span><br><span class="line">                <span class="keyword">if</span> (msg.what == MSG_REPORT_IDLE_ON) &#123;</span><br><span class="line">                    deepChanged = mLocalPowerManager.setDeviceIdleMode(<span class="keyword">true</span>);</span><br><span class="line">                    lightChanged = mLocalPowerManager.setLightDeviceIdleMode(<span class="keyword">false</span>);</span><br><span class="line">                &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                    <span class="comment">//触发powerManager模块调用setDeviceIdleMode做wakelock的释放</span></span><br><span class="line">                    deepChanged = mLocalPowerManager.setDeviceIdleMode(<span class="keyword">false</span>);</span><br><span class="line">                    lightChanged = mLocalPowerManager.setLightDeviceIdleMode(<span class="keyword">true</span>);</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">try</span> &#123;</span><br><span class="line">                    <span class="comment">//触发NetworkPolicy模块调用setDeviceIdleMode做应用的网络限制</span></span><br><span class="line">                    mNetworkPolicyManager.setDeviceIdleMode(<span class="keyword">true</span>);</span><br><span class="line">                    mBatteryStats.noteDeviceIdleMode(msg.what == MSG_REPORT_IDLE_ON</span><br><span class="line">                            ? BatteryStats.DEVICE_IDLE_MODE_DEEP</span><br><span class="line">                            : BatteryStats.DEVICE_IDLE_MODE_LIGHT, <span class="keyword">null</span>, Process.myUid());</span><br><span class="line">                &#125; <span class="keyword">catch</span> (RemoteException e) &#123;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="comment">//....</span></span><br><span class="line">            &#125; <span class="keyword">break</span>;</span><br><span class="line">                    <span class="comment">//....</span></span><br><span class="line">            &#125;</span><br></pre></td></tr></table></figure><p>同样的，当切换到窗口期后会发一个<code>MSG_REPORT_IDLE_OFF</code> 消息，并通知PowerMS、Network等模块解除对应用的限制措施。</p><h4 id="Doze-白名单"><a href="#Doze-白名单" class="headerlink" title="Doze 白名单"></a>Doze 白名单</h4><p>当设备处于Idle 状态下的时候，位于白名单下的应用行为不受doze 机制限制。<br>当前系统维护了三种类型的白名单<br><strong>1.system-excidle(System app)</strong><br>这种名单只针对doze 模式起作用，对于应用处于idle情况下不会生效。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">* Package names the system has white-listed to opt out of power save restrictios, * except for device idle mode.</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> ArrayMap&lt;String, Integer&gt; mPowerSaveWhitelistAppsExceptIdle = <span class="keyword">new</span> ArrayMap&lt;&gt;();</span><br></pre></td></tr></table></figure><p><strong>2.system(System app)</strong><br>这种类型的名单对doze 和App standby模式均会起效，用户无法在电池优化界面手动修改其状态。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">* Package names the system has white-listed to opt out of power save restriction   * s for all modes.</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> ArrayMap&lt;String, Integer&gt; mPowerSaveWhitelistApps = <span class="keyword">new</span> ArrayMap&lt;&gt;();</span><br></pre></td></tr></table></figure></p><p><strong>3.user</strong><br>这种类型的名单对doze 和App standby模式均会起效<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Package names the user has white-listed to opt out of power save restrictions.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> ArrayMap&lt;String, Integer&gt; mPowerSaveWhitelistUserApps = <span class="keyword">new</span> ArrayMap&lt;&gt;();</span><br></pre></td></tr></table></figure></p><p>User 这种白名单通常可以用户自行设置，设置中的电池优化选项对应的正是这种类型，如果希望某个应用不走doze，则将该应用的电池优化关闭即可。</p><p>上面三种类型可以通过<code>dumpsys deviceidle whitelist</code> 命令查询<br><img src="http://blog.lihaizhou.top/Doze/doze_8.png" alt="enter description here"><br>上图可以看到微信和飞书在user 白名单中，也就说doze 下不会对这两个应用的行为比如联网进行限制。至于为何这两个三方应用会加到白名单中，是因为它们没有使用任何系统级推送通道，但是由于它们的用户群体比较庞大，最好是加入到白名单，以免出现灭屏后收不到消息引起客诉。</p><p>加到白名单中的应用会通过层层调用到PMS、Network、Alarm等模块中，这些模块中对白名单应用会正常放行，不会做特殊的限制措施。</p><p>调用<code>addPowerSaveWhitelistApps</code> 后的时序如下：<br><img src="http://blog.lihaizhou.top/Doze/doze_9.png" alt="enter description here"></p><h4 id="常见问题-Q-amp-A"><a href="#常见问题-Q-amp-A" class="headerlink" title="常见问题 Q&amp;A"></a>常见问题 Q&amp;A</h4><p><strong>Q：Doze 和省电模式(Battery saver) 差异？</strong><br>A:省电模式是Google 自<code>Android L</code>版本引入的省电策略<br>省电模式的限制措施以及触发条件：<br>1.应用处于后台且不在白名单中的话，禁止联网。<br>2.电量低于一定阈值(默认15%)且未充电情况下则自动触发，高于一定阈值或充上电后会自动关闭，用户可以通过设置中的开关项主动打开，另外省电模式的触发阈值也可手动调整.</p><p>归纳下来:<br>1.两者触发机制不同<br>2.限制措施有部分重叠，比如都会限制应用联网<br>3.共用白名单<code>deviceidle.xml</code>，所以应用是否进入省电模式同样可以在电池优化界面设置。</p><p><strong>Q：Doze 和应用待机(App standby) 差异?</strong><br>A:<code>App Standby</code>是一种电池管理技术，根据应用最近使用时间和使用频率分为不同的组，开发者选项中的待机应用菜单，对应用使用jobs，alarm，network进行不同程度限制，达到省电的目的。<br>当用户不触摸使用应用程序一段时间时，该应用程序处于App Standby状态，系统将把该App标志为空闲状态。除非触发以下任意条件，应用程序将退出App Standby状态：</p><blockquote><p>The user explicitly launches the app.<br>The app has a process currently in the foreground (either as an activity or foreground service, or in use by another activity or foreground service).<br>The app generates a notification that users see on the lock screen or in the notification tray.<br>The app is an active device admin app (for example, a device policy controller). Although they generally run in the background, device admin apps never enter App Standby because they must remain available to receive policy from a server at any time.<br>(引用自 <a href="https://developer.android.com/training/monitoring-device-state/doze-standby" target="_blank" rel="noopener">https://developer.android.com/training/monitoring-device-state/doze-standby</a>)<br>归纳：<br>1.两者进入条件不同，比如Doze 前提条件之一是灭屏，而App standby 则不需要灭屏。<br>2.共用白名单deviceidle.xml，除了system-excidle，因为system-excidle是只限制doze。</p></blockquote><p><strong>Q：Doze 和深度睡眠差异?</strong><br>A：Doze 在sleep 之前，doze 阶段会解除应用的wakelock，限制联网，但是程序还是可以运行的。<br>但是设备一旦进入深度睡眠，进程会被冻结，CPU挂起。<br>还有一点差异是进入doze 状态不受wakelock 影响，也就是是不管当前是否存在wakelock 没有释放都不会影响设备进doze，doze 状态的进入只取决于超时阈值以及一堆传感器判断。但是进入深度睡眠之前，如果应用持有wakelock 则不会进入到深度睡眠模式。</p><p><strong>Q：如何调试模拟Doze？</strong><br>A: 本地可以通过如下命令进行调试验证</p><ol><li>开启Doze<br>adb shell dumpsys deviceidle enable<br>或者在MTK平台上执行 adb shell setprop persist.config.AutoPowerModes 1 </li><li>模拟移除电源<br>adb shell dumpsys battery unplug </li><li>调试Doze状态<br>adb shell dumpsys deviceidle step 每执行一次就切换一次状态</li><li>Dump Doze 状态分析<br>查询白名单情况：adb shell dumpsys deviceidle </li><li>开启Doze dubug 调试开关<br>如需要本地调试验证问题的话，可以将DeviceIdleController.java文件中的<br>private static final boolean DEBUG = false;</li></ol><h4 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h4><p>关于Android S上的Doze 机制介绍到这里。</p><h4 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h4><p><a href="https://developer.android.google.cn/training/monitoring-device-state/doze-standby?hl=en" target="_blank" rel="noopener">https://developer.android.google.cn/training/monitoring-device-state/doze-standby?hl=en</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h4&gt;&lt;p&gt;基于&lt;code&gt;Android S&lt;/code&gt;梳理下Doze 机制&lt;/p&gt;
&lt;h4 id=&quot;认识-Doze&quot;&gt;&lt;a href=&quot;#认识-D
      
    
    </summary>
    
      <category term="Android" scheme="http://lihaizhou.top/categories/Android/"/>
    
    
  </entry>
  
  <entry>
    <title>ART 虚拟机｜Dex2oat 调优实践之路</title>
    <link href="http://lihaizhou.top/2022/03/20/ART-%E8%99%9A%E6%8B%9F%E6%9C%BA%EF%BD%9CDex2oat-%E8%B0%83%E4%BC%98%E5%AE%9E%E8%B7%B5%E4%B9%8B%E8%B7%AF/"/>
    <id>http://lihaizhou.top/2022/03/20/ART-虚拟机｜Dex2oat-调优实践之路/</id>
    <published>2022-03-20T14:45:02.000Z</published>
    <updated>2022-04-10T14:45:56.837Z</updated>
    
    <content type="html"><![CDATA[<h4 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h4><p>我们都知道Dex2oat对应用的启动速度、以及日常使用的流畅度起到了重要作用，不过Google现有的dex2oat机制存在着明显的局限性。</p><ol><li>开机/OTA等场景，容易整机卡顿及开机时间长。</li><li>Idle下的触发条件苛刻，发挥空间有限。</li></ol><p>前段时间研究了下dex2oat的原理机制，并且对一些场景下的dex2oat行为做了客制化，打算做下小结，以便后续回顾完善。</p><p>涉及代码均基于Android S</p><h4 id="基本概述"><a href="#基本概述" class="headerlink" title="基本概述"></a>基本概述</h4><p>一个App经过优化dex2oat的大致流程如下<br><img src="http://blog.lihaizhou.top/ART_dex2oat/dex2oat_1.png" alt="摘自谷歌开发者网站"><br>(图片来源：谷歌开发者网站)</p><p>简单的理解就是优化是以dex文件中的method为单位，dex2oat在优化时，会根据需要优化一定量的method，也就是说并不是优化的method都会被翻译成oat模式。</p><p>根据优化的method的量的多少，分为如下几种：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">enum</span> Filter &#123;</span><br><span class="line">    kAssumeVerified,      <span class="comment">// Skip verification but mark all classes as verified anyway.</span></span><br><span class="line">    kExtract,             <span class="comment">// Delay verication to runtime, do not compile anything.</span></span><br><span class="line">    kVerify,              <span class="comment">// Only verify classes.</span></span><br><span class="line">    kSpaceProfile,        <span class="comment">// Maximize space savings based on profile.</span></span><br><span class="line">    kSpace,               <span class="comment">// Maximize space savings.</span></span><br><span class="line">    kSpeedProfile,        <span class="comment">// Maximize runtime performance based on profile.</span></span><br><span class="line">    kSpeed,               <span class="comment">// Maximize runtime performance.</span></span><br><span class="line">    kEverythingProfile,   <span class="comment">// Compile everything capable of being compiled based on profile.</span></span><br><span class="line">    kEverything,          <span class="comment">// Compile everything capable of being compiled.</span></span><br><span class="line">  &#125;;</span><br></pre></td></tr></table></figure><p>上面列举出的这些模式，简单理解就是越往下的模式，优化的程度越深，自然而然性能会越加流畅，不过耗费的时间以及空间也会随之增长。</p><h4 id="触发时机"><a href="#触发时机" class="headerlink" title="触发时机"></a>触发时机</h4><p><img src="http://blog.lihaizhou.top/ART_dex2oat/dex2oat_2.png" alt=""><br>(图片来源：谷歌开发者网站)</p><ol><li>首次开机<br>开机过程中PMS扫描手机中的各个目录，安装的时候，会对这些App进行dex2oat。如果说App比较多，或者dex2oat比较慢，那么开机时间就会比较长。</li><li>应用安装/启动<br>其实流程还是会走PMS流程，由PMS执行安装的运行，并发起dex2oat的动作。</li><li>系统空闲时<br>系统处于空闲时，且满足一系列的条件比如充电等，会对应用进行dex2oat，在正式dex2oat之前同样会进行一系列的判断，比如根据profile的更新量决定是否进行本次优化，这部分也是我们客制化的重点。<br>对应到源码中，触发的原因会更加丰富一些</li></ol><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Compilation reasons.</span></span><br><span class="line">   <span class="keyword">public</span> <span class="keyword">static</span> final <span class="keyword">int</span> REASON_UNKNOWN = <span class="number">-1</span>;</span><br><span class="line">   <span class="keyword">public</span> <span class="keyword">static</span> final <span class="keyword">int</span> REASON_FIRST_BOOT = <span class="number">0</span>;</span><br><span class="line">   <span class="keyword">public</span> <span class="keyword">static</span> final <span class="keyword">int</span> REASON_BOOT = <span class="number">1</span>;</span><br><span class="line">   <span class="keyword">public</span> <span class="keyword">static</span> final <span class="keyword">int</span> REASON_INSTALL = <span class="number">2</span>;</span><br><span class="line">   <span class="keyword">public</span> <span class="keyword">static</span> final <span class="keyword">int</span> REASON_BACKGROUND_DEXOPT = <span class="number">3</span>;</span><br><span class="line">   <span class="keyword">public</span> <span class="keyword">static</span> final <span class="keyword">int</span> REASON_AB_OTA = <span class="number">4</span>;</span><br><span class="line">   <span class="keyword">public</span> <span class="keyword">static</span> final <span class="keyword">int</span> REASON_INACTIVE_PACKAGE_DOWNGRADE = <span class="number">5</span>;</span><br><span class="line">   <span class="keyword">public</span> <span class="keyword">static</span> final <span class="keyword">int</span> REASON_SHARED = <span class="number">6</span>;</span><br><span class="line">   <span class="keyword">public</span> <span class="keyword">static</span> final <span class="keyword">int</span> REASON_AGRESSIVE = <span class="number">10000</span>;</span><br><span class="line"></span><br><span class="line">   <span class="keyword">public</span> <span class="keyword">static</span> final <span class="keyword">int</span> REASON_LAST = REASON_SHARED;</span><br></pre></td></tr></table></figure><p>我们可以通过命令查询项目上的配置情况<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">lihaizhou@lihaizhou:~$ adb shell getprop |grep pm.dex</span><br><span class="line">[pm.dexopt.ab-ota]: [speed-profile]</span><br><span class="line">[pm.dexopt.bg-dexopt]: [speed-profile]</span><br><span class="line">[pm.dexopt.boot]: [verify]</span><br><span class="line">[pm.dexopt.first-boot]: [quicken]</span><br><span class="line">[pm.dexopt.inactive]: [verify]</span><br><span class="line">[pm.dexopt.install]: [speed-profile]</span><br><span class="line">[pm.dexopt.shared]: [speed]</span><br></pre></td></tr></table></figure></p><p>这里顺便提一下，从前面的描述，我们知道系统处于idle且满足充电条件下，才会触发后台dex2oat。那么这里的idle是如何定义的，需要等多长时间呢？<br><code>frameworks/base/core/res/res/values/config.xml</code><br><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">integer</span> <span class="attr">name</span>=<span class="string">"config_jobSchedulerInactivityIdleThreshold"</span>&gt;</span>1860000<span class="tag">&lt;/<span class="name">integer</span>&gt;</span></span><br></pre></td></tr></table></figure></p><p>对于jobscheduler而言，这个阈值设定的是31min，当用户没有交互超过31min后会认为当前设备处于idle状态。</p><h4 id="原理机制"><a href="#原理机制" class="headerlink" title="原理机制"></a>原理机制</h4><p>本文只讨论idle下的dex2oat，其它场景下如install、开机后的dex2oat等，流程几乎是一致的。<br><code>BackgroundDexOptService @schedule</code></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Schedule a daily job which scans installed packages and compiles</span></span><br><span class="line"><span class="comment">// those with fresh profiling data.</span></span><br><span class="line">js.schedule(<span class="keyword">new</span> JobInfo.Builder(JOB_IDLE_OPTIMIZE, sDexoptServiceName)</span><br><span class="line">            .setRequiresDeviceIdle(<span class="keyword">true</span>)</span><br><span class="line">            .setRequiresCharging(<span class="keyword">true</span>)</span><br><span class="line">            .setPeriodic(IDLE_OPTIMIZATION_PERIOD)</span><br><span class="line">            .build());</span><br></pre></td></tr></table></figure><p>可以看到需要满足的条件还是比较苛刻的，需要满足idle状态，且处于充电条件下，检测周期为一天，均满足的情况下才会触发dex2oat。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">onStartJob</span><span class="params">(JobParameters params)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (DEBUG) &#123;</span><br><span class="line">            Slog.i(TAG, <span class="string">"onStartJob"</span>);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// <span class="doctag">NOTE:</span> PackageManagerService.isStorageLow uses a different set of criteria from</span></span><br><span class="line">        <span class="comment">// the checks above. This check is not "live" - the value is determined by a background</span></span><br><span class="line">        <span class="comment">// restart with a period of ~1 minute.</span></span><br><span class="line">        PackageManagerService pm = (PackageManagerService)ServiceManager.getService(<span class="string">"package"</span>);</span><br><span class="line">        <span class="keyword">if</span> (pm.isStorageLow()) &#123;</span><br><span class="line">            Slog.i(TAG, <span class="string">"Low storage, skipping this run"</span>);</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">final</span> ArraySet&lt;String&gt; pkgs = pm.getOptimizablePackages();</span><br><span class="line">        <span class="keyword">if</span> (pkgs.isEmpty()) &#123;</span><br><span class="line">            Slog.i(TAG, <span class="string">"No packages to optimize"</span>);</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        mThermalStatusCutoff =</span><br><span class="line">            SystemProperties.getInt(<span class="string">"dalvik.vm.dexopt.thermal-cutoff"</span>, THERMAL_CUTOFF_DEFAULT);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">boolean</span> result;</span><br><span class="line">        <span class="keyword">if</span> (params.getJobId() == JOB_POST_BOOT_UPDATE) &#123;</span><br><span class="line">            result = runPostBootUpdate(params, pm, pkgs);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            result = runIdleOptimization(params, pm, pkgs);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> result;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>主要关注runIdleOptimization，略过部分流程。<br><code>BackgroundDexOptService @optimizePackage</code> <code>frameworks/base/services/core/java/com/android/server/pm/BackgroundDexOptService.java</code></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">    *</span></span><br><span class="line"><span class="comment">    * Optimize package if needed. Note that there can be no race between</span></span><br><span class="line"><span class="comment">    * concurrent jobs because PackageDexOptimizer.performDexOpt is synchronized.</span></span><br><span class="line"><span class="comment">    * <span class="doctag">@param</span> pm An instance of PackageManagerService</span></span><br><span class="line"><span class="comment">    * <span class="doctag">@param</span> pkg The package to be downgraded.</span></span><br><span class="line"><span class="comment">    * <span class="doctag">@param</span> isForPrimaryDex. Apps can have several dex file, primary and secondary.</span></span><br><span class="line"><span class="comment">    * <span class="doctag">@return</span> true if the package was downgraded.</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">   <span class="function"><span class="keyword">private</span> <span class="keyword">boolean</span> <span class="title">optimizePackage</span><span class="params">(PackageManagerService pm, String pkg,</span></span></span><br><span class="line"><span class="function"><span class="params">           <span class="keyword">boolean</span> isForPrimaryDex)</span> </span>&#123;</span><br><span class="line">       <span class="keyword">int</span> reason = PackageManagerService.REASON_BACKGROUND_DEXOPT;</span><br><span class="line">       <span class="keyword">int</span> dexoptFlags = DexoptOptions.DEXOPT_CHECK_FOR_PROFILES_UPDATES</span><br><span class="line">               | DexoptOptions.DEXOPT_BOOT_COMPLETE</span><br><span class="line">               | DexoptOptions.DEXOPT_IDLE_BACKGROUND_JOB;</span><br><span class="line"></span><br><span class="line">       <span class="comment">// System server share the same code path as primary dex files.</span></span><br><span class="line">       <span class="comment">// PackageManagerService will select the right optimization path for it.</span></span><br><span class="line">       <span class="keyword">return</span> (isForPrimaryDex || PLATFORM_PACKAGE_NAME.equals(pkg))</span><br><span class="line">           ? performDexOptPrimary(pm, pkg, reason, dexoptFlags)</span><br><span class="line">           : performDexOptSecondary(pm, pkg, reason, dexoptFlags);</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure><p>我们以<code>performDexOptPrimary</code>为例，继续往下看</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">boolean</span> <span class="title">performDexOptPrimary</span><span class="params">(PackageManagerService pm, String pkg, <span class="keyword">int</span> reason,</span></span></span><br><span class="line"><span class="function"><span class="params">           <span class="keyword">int</span> dexoptFlags)</span> </span>&#123;</span><br><span class="line">       <span class="keyword">int</span> result = trackPerformDexOpt(pkg, <span class="comment">/*isForPrimaryDex=*/</span> <span class="keyword">false</span>,</span><br><span class="line">               () -&gt; pm.performDexOptWithStatus(<span class="keyword">new</span> DexoptOptions(pkg, reason, dexoptFlags)));</span><br><span class="line">       <span class="keyword">return</span> result == PackageDexOptimizer.DEX_OPT_PERFORMED;</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure><p><code>frameworks/base/services/core/java/com/android/server/pm/PackageManagerService.java</code></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Perform dexopt on the given package and return one of following result:</span></span><br><span class="line"><span class="comment"> *  &#123;<span class="doctag">@link</span> PackageDexOptimizer#DEX_OPT_SKIPPED&#125;</span></span><br><span class="line"><span class="comment"> *  &#123;<span class="doctag">@link</span> PackageDexOptimizer#DEX_OPT_PERFORMED&#125;</span></span><br><span class="line"><span class="comment"> *  &#123;<span class="doctag">@link</span> PackageDexOptimizer#DEX_OPT_FAILED&#125;</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="comment">/* package */</span> <span class="function"><span class="keyword">int</span> <span class="title">performDexOptWithStatus</span><span class="params">(DexoptOptions options)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> performDexOptTraced(options);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>省略部分中间调用过程<br><code>PackageDexOptimizer.java@ performDexOptLI</code><br>frameworks/base/services/core/java/com/android/server/pm/PackageDexOptimizer.java</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">    * Performs dexopt on all code paths of the given package.</span></span><br><span class="line"><span class="comment">    * It assumes the install lock is held.</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">   <span class="meta">@GuardedBy</span>(<span class="string">"mInstallLock"</span>)</span><br><span class="line">   <span class="function"><span class="keyword">private</span> <span class="keyword">int</span> <span class="title">performDexOptLI</span><span class="params">(AndroidPackage pkg, @NonNull PackageSetting pkgSetting,</span></span></span><br><span class="line"><span class="function"><span class="params">           String[] targetInstructionSets, CompilerStats.PackageStats packageStats,</span></span></span><br><span class="line"><span class="function"><span class="params">           PackageDexUsage.PackageUseInfo packageUseInfo, DexoptOptions options)</span> </span>&#123;</span><br><span class="line">           <span class="comment">//....</span></span><br><span class="line">           <span class="keyword">final</span> String compilerFilter = getRealCompilerFilter(pkg,</span><br><span class="line">               options.getCompilerFilter(), isUsedByOtherApps);</span><br><span class="line">           <span class="comment">// If we don't have to check for profiles updates assume</span></span><br><span class="line">           <span class="comment">// PROFILE_ANALYSIS_DONT_OPTIMIZE_SMALL_DELTA which will be a no-op with respect to</span></span><br><span class="line">           <span class="comment">// profiles.</span></span><br><span class="line">           <span class="keyword">final</span> <span class="keyword">int</span> profileAnalysisResult = options.isCheckForProfileUpdates()</span><br><span class="line">                   ? analyseProfiles(pkg, sharedGid, profileName, compilerFilter)</span><br><span class="line">                   : PROFILE_ANALYSIS_DONT_OPTIMIZE_SMALL_DELTA;    </span><br><span class="line">           <span class="comment">// Get the dexopt flags after getRealCompilerFilter to make sure we get the correct</span></span><br><span class="line">           <span class="comment">// flags.</span></span><br><span class="line">           <span class="keyword">final</span> <span class="keyword">int</span> dexoptFlags = getDexFlags(pkg, pkgSetting, compilerFilter, options);</span><br><span class="line"></span><br><span class="line">           <span class="keyword">for</span> (String dexCodeIsa : dexCodeInstructionSets) &#123;</span><br><span class="line">               <span class="keyword">int</span> newResult = dexOptPath(pkg, pkgSetting, path, dexCodeIsa, compilerFilter,</span><br><span class="line">                       profileAnalysisResult, classLoaderContexts[i], dexoptFlags, sharedGid,</span><br><span class="line">                       packageStats, options.isDowngrade(), profileName, dexMetadataPath,</span><br><span class="line">                       options.getCompilationReason());</span><br><span class="line">                <span class="comment">//....</span></span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">//....</span></span><br><span class="line">      &#125;</span><br></pre></td></tr></table></figure><ol><li>getRealCompilerFilter：获取该pkg实际的编译模式</li><li>analyseProfiles：检测profile是否更新，并确定是否需要优化。</li><li>dexOptPath：实际的优化工作</li></ol><p>略过部分中间调用流程，dexOptPath函数经过层层调用，最终会通过跨进程来到<br><code>frameworks/native/cmds/installd/dexopt.cpp @ dexopt</code><br>该函数内容较长，拆分开来</p><ol><li>根据应用的路径解析其dex文件</li></ol><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">UniqueFile in_dex(open(dex_path, O_RDONLY, 0), dex_path);</span><br><span class="line">    <span class="keyword">if</span> (in_dex.fd() &lt; <span class="number">0</span>) &#123;</span><br><span class="line">        *error_msg = StringPrintf(<span class="string">"installd cannot open '%s' for input during dexopt"</span>, dex_path);</span><br><span class="line">        LOG(ERROR) &lt;&lt; *error_msg;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol start="2"><li>生成对应的oat文件</li></ol><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">RestorableFile out_oat =</span><br><span class="line">            open_oat_out_file(dex_path, oat_dir, is_public, uid, instruction_set, is_secondary_dex);</span><br><span class="line"><span class="keyword">if</span> (out_oat.fd() &lt; <span class="number">0</span>) &#123;</span><br><span class="line">    *error_msg = <span class="string">"Could not open out oat file."</span>;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol start="3"><li>调用dex2oat 二进制文件去做实际的oat工作</li></ol><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">bool</span> use_dex2oat64 = <span class="literal">false</span>;</span><br><span class="line">    <span class="comment">// Check whether the device even supports 64-bit ABIs.</span></span><br><span class="line">    <span class="keyword">if</span> (!GetProperty(<span class="string">"ro.product.cpu.abilist64"</span>, <span class="string">""</span>).empty()) &#123;</span><br><span class="line">      use_dex2oat64 = GetBoolProperty(<span class="string">"dalvik.vm.dex2oat64.enabled"</span>, <span class="literal">false</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">const</span> <span class="keyword">char</span>* dex2oat_bin = select_execution_binary(</span><br><span class="line">        (use_dex2oat64 ? kDex2oat64Path : kDex2oat32Path),</span><br><span class="line">        (use_dex2oat64 ? kDex2oatDebug64Path : kDex2oatDebug32Path),</span><br><span class="line">        background_job_compile);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">auto</span> execv_helper = <span class="built_in">std</span>::make_unique&lt;ExecVHelper&gt;();</span><br><span class="line"></span><br><span class="line">    LOG(VERBOSE) &lt;&lt; <span class="string">"DexInv: --- BEGIN '"</span> &lt;&lt; dex_path &lt;&lt; <span class="string">"' ---"</span>;</span><br><span class="line"></span><br><span class="line">    RunDex2Oat runner(dex2oat_bin, execv_helper.get());</span><br><span class="line">    runner.Initialize(out_oat.GetUniqueFile(), out_vdex.GetUniqueFile(), out_image.GetUniqueFile(),</span><br><span class="line">                      in_dex, in_vdex, dex_metadata, reference_profile, class_loader_context,</span><br><span class="line">                      join_fds(context_input_fds), swap_fd.get(), instruction_set, compiler_filter,</span><br><span class="line">                      debuggable, boot_complete, for_restore, target_sdk_version,</span><br><span class="line">                      enable_hidden_api_checks, generate_compact_dex, use_jitzygote_image,</span><br><span class="line">                      compilation_reason);</span><br></pre></td></tr></table></figure><p>至此，idle下的dex2oat流程梳理完毕。</p><p>画了一个核心的调用过程<br><img src="http://blog.lihaizhou.top/ART_dex2oat/dex2oat_3.png" alt=""></p><h4 id="影响因素"><a href="#影响因素" class="headerlink" title="影响因素"></a>影响因素</h4><p>dex2oat 优化后虽然能够增加应用运行的流畅度， 但是如果在短时间内大量发起则会影响用户界面操作， 造成整机性能问题，所以我们对dex2oat的预期效果就是尽可能的快完成，尽可能不影响用户。<br>那么有哪些因素会影响dex2oat的执行时长呢？</p><ol><li>工作量<br>dex2oat发生的时候，会将原文件中的dex文件抽出来，逐个指令的判断，然后进行翻译，并生成大量的中间内容。并占用所有有CPU（目前的策略是有多少个核，就启动多少个线程）。<br>对于单个应用而言，选择不同的模式该应用优化的耗时也会不一样，比如选择everything和interpret-only这两种不同的模式，耗时可能会悬殊几倍。</li><li>线程数<br>启动的线程数越多，dex2oat就会在越短的时间内完成<br>启动的线程数以及耗时时长可以通过日志打印查看</li></ol><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">LogCompletionTime</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="comment">// Note: when creation of a runtime fails, e.g., when trying to compile an app but when there</span></span><br><span class="line">    <span class="comment">//       is no image, there won't be a Runtime::Current().</span></span><br><span class="line">    <span class="comment">// Note: driver creation can fail when loading an invalid dex file.</span></span><br><span class="line">    LOG(INFO) &lt;&lt; <span class="string">"dex2oat took "</span></span><br><span class="line">              &lt;&lt; PrettyDuration(NanoTime() - start_ns_)</span><br><span class="line">              &lt;&lt; <span class="string">" ("</span> &lt;&lt; PrettyDuration(ProcessCpuNanoTime() - start_cputime_ns_) &lt;&lt; <span class="string">" cpu)"</span></span><br><span class="line">              &lt;&lt; <span class="string">" (threads: "</span> &lt;&lt; thread_count_ &lt;&lt; <span class="string">") "</span></span><br><span class="line">              &lt;&lt; ((Runtime::Current() != <span class="literal">nullptr</span> &amp;&amp; driver_ != <span class="literal">nullptr</span>) ?</span><br><span class="line">                  driver_-&gt;GetMemoryUsageString(kIsDebugBuild || VLOG_IS_ON(compiler)) :</span><br><span class="line">                  <span class="string">""</span>);</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><ol start="3"><li>EMMC性能<br>如果dex文件比较大，会产生大量的中间内容，这些在memory当中是保存不下的，所以采用了swap机制，会将一些内容交换到EMMC当中，而且有大量的读操作，同时会将结果保存至emmc当中，所以emmc的性能也是非常关键的。</li><li>负载：整机负载较高的话，dex2oat容易拿不到足够的cpu资源，也会造成耗时变长。</li><li>内存：如果处于低内存情况下的话，容易引起IO拉升，可能会导致dex2oat遇到IO上的瓶颈。 </li></ol><h4 id="优化方案"><a href="#优化方案" class="headerlink" title="优化方案"></a>优化方案</h4><p>我们对dex2oat的客制化优化方案如下图所示:<br><img src="http://blog.lihaizhou.top/ART_dex2oat/dex2oat_4.png" alt=""></p><p>基本思路：</p><ol><li>增加周期性后台优化策略，同样需要满足一定的条件如idle下且Charge情况下，对于热点应用以及小的dex文件进行优化。</li><li>为了避免开机时间过长，系统启动过程中不再对所有应用进行dex2oat，开机后接收到开机广播delay十分钟，对热点应用进行dex2oat优化。</li><li>根据系统负载的情况，动态调整dex2oat使用的线程数以及编译模式。</li></ol><p>为了测试应用在优化后的性能表现，通过高速相机测试做完dex2oat后应用启动速度均值提升15%左右，掉帧情况也得到了大幅缓解。</p><h4 id="拓展"><a href="#拓展" class="headerlink" title="拓展"></a>拓展</h4><p>我们顺便介绍下谷歌的Baseline profile<br>Android 9 (API 级别 28) 在 Play Cloud 中引入了 ART 优化配置文件，以缩短应用启动时间。<br>基准配置文件在构建时创建，作为 APK 的一部分发送到 Play 中，然后在下载应用时，从 Play 发送至用户。<br><img src="http://blog.lihaizhou.top/ART_dex2oat/dex2oat_5.png" alt=""><br>(图片摘自开发者网站)<br>从上面的描述我们可以得知，profile文件由应用开发者按照谷歌提供的规则，在构建时就创建好，然后通过play商店上架。当用户下载该应用时，profile连同apk会一起安装，这样就可以确保用户在首次安装时便能享受到性能的提升。<br>这种做法相对于系统现有的dex2oat机制来说，所做的事情显得轻量很多，对系统负担也会大幅降低。<br>因为profile由应用开发者提供，这就使得profile变得不再神秘。因为开发者有源代码，并且熟悉自己的业务流程，这样的话开发者本地构建profile后可以不断的调试并测试性能的数据，最终提供一份最优的基准profile。</p><h4 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h4><p>至此，关于dex2oat原理及客制化修改介绍到这里。<br>其实不管是谷歌的dex2oat策略，还是厂商的客制化方案，其目的都是明确的：<br>尽可能在用户的使用过程中，能够享受到直接运行机器码所带来的性能提升，同时避免dex2oat本身的工作对系统带来的负面影响。</p><h4 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h4><p><a href="https://blog.csdn.net/feelabclihu/article/details/105502166" target="_blank" rel="noopener">https://blog.csdn.net/feelabclihu/article/details/105502166</a><br><a href="https://developer.android.google.cn/" target="_blank" rel="noopener">https://developer.android.google.cn/</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;写在前面&quot;&gt;&lt;a href=&quot;#写在前面&quot; class=&quot;headerlink&quot; title=&quot;写在前面&quot;&gt;&lt;/a&gt;写在前面&lt;/h4&gt;&lt;p&gt;我们都知道Dex2oat对应用的启动速度、以及日常使用的流畅度起到了重要作用，不过Google现有的dex2oat机制存在着
      
    
    </summary>
    
      <category term="ART" scheme="http://lihaizhou.top/categories/ART/"/>
    
    
  </entry>
  
  <entry>
    <title>网络 | 拥塞控制算法之BBR</title>
    <link href="http://lihaizhou.top/2022/03/01/%E7%BD%91%E7%BB%9C-%E6%8B%A5%E5%A1%9E%E6%8E%A7%E5%88%B6%E7%AE%97%E6%B3%95%E4%B9%8BBBR/"/>
    <id>http://lihaizhou.top/2022/03/01/网络-拥塞控制算法之BBR/</id>
    <published>2022-03-01T14:50:11.000Z</published>
    <updated>2022-05-22T06:56:23.843Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>TCP BBR（Bottleneck Bandwidth and Round-trip propagation time）是由Google 设计，于2016年发布的拥塞算法。<br>以往的大部分拥塞控制算法都是基于丢包来作为降低传输速率的信号，而BBR 则基于模型主动探测。<br>目前已经在Google 内部大范围使用并随着linux 4.9 版本正式发布。</p></blockquote><h4 id="Bufferbloat"><a href="#Bufferbloat" class="headerlink" title="Bufferbloat"></a>Bufferbloat</h4><p>在讨论BBR 之前不得不先说下Bufferbloat，在BBR 出来之前的拥塞控制算法无一例外都和网络缓存耦合在了一起，所以都会存在发生Bufferbloat 的情况。</p><p><strong>关于bufferbloat的定义</strong></p><blockquote><p>Bufferbloat is a cause of high latency and jitter in packet-switched networks caused by excess buffering of packets. Bufferbloat can also cause packet delay variation (also known as jitter), as well as reduce the overall network throughput. When a router or switch is configured to use excessively large buffers, even very high-speed networks can become practically unusable for many interactive applications like voice over IP (VoIP), audio streaming, online gaming, and even ordinary web browsing.<br>Some communications equipment manufacturers designed unnecessarily large buffers into some of their network products. In such equipment, bufferbloat occurs when a network link becomes congested, causing packets to become queued for long periods in these oversized buffers. In a first-in first-out queuing system, overly large buffers result in longer queues and higher latency, and do not improve network throughput. It can also be induced by specific slow-speed connections hindering the ontime delivery of other packets.</p></blockquote><p>大多数的拥塞控制算法都是基于丢包来测算带宽，有丢包发生便会降低传输速率。<br>中间网络设备引入大的缓冲区虽然可以降低丢包的发生，但是会导致TCP 对网络阻塞敏感度的降低，直到缓冲区满了并开始出现丢包，TCP 才开始降窗。</p><p>另外，由于缓冲区的增大，会导致延迟增加。试着想象一下如果这个缓冲区是一个非常大的的数据池，那么延迟将会上升到一个非常糟糕的地步。</p><p>你可能会觉得Bufferbloat 的产生似乎是一个错误。</p><p>那么它的产生历史缘由是什么呢？</p><blockquote><p>在以前的互联网上，交换机可能总是拥有比服务器更快的网卡，所以这些位于互联网中间层的服务器也可能比客户端更快，并且并不能对客户端发送信息包的速率有多大影响。<br>很显然今天已经不是这样的了！众所周知，今天的计算机相比于 5 年前的计算机在速度上并没有多大的提升（我们遇到了某些有关光速的问题）。所以我想路由器上的大型交换机并不会在速度上大幅领先于数据中心里服务器上的网卡。</p></blockquote><p>(摘自Van Jacobson的netdev演讲)</p><p><strong>如何理解这段话呢？</strong><br>早期终端设备和网络核心交换设备性能上存在明显的悬殊，像思科这类厂商，他们的中间路由设备的处理能力是能够甩开一众终端设备的。<br>在这个时期，中间设备的缓存就显得不那么重要了，可能只需很少的缓存就够用了，对于终端设备而言，只需要考虑发送的尽可能的快就行！<br>随着时代的发展，终端处理器以及网卡性能的不断提升，不断缩小了和中间转发设备性能上的差距。</p><p>这个时候问题就出现了:<br>中间转发设备似乎不太来得及处理数据包了!</p><p>这就需要想办法尽快解决没有来得及处理的数据包，提升处理器性能或增加处理器都是办法，但这些方法都没有直接搞一个大缓存来的简单又有性价比。<br>这样一来，引入Buffer 其实违背了中间转发设备本身的角色定位，它的角色应该只是转发，而不应该成为一个缓存设备。</p><p>对于Bufferbloat，你可以鄙视它，甚至厌恶它，但它却是时代变迁下的产物。</p><h4 id="BBR-原理"><a href="#BBR-原理" class="headerlink" title="BBR 原理"></a>BBR 原理</h4><p>BBR 的诞生解决了Bufferbloat 问题，关于它的诞生缘由，BBR 论文[3]是这样描述的：</p><blockquote><p>These problems result from a design choice made when TCP congestion control was created in the 1980s—interpreting packet loss as “congestion.”13 This equivalence was true at the time but was because of technology limitations, not first principles. As NICs (network interface controllers) evolved from Mbps to Gbps and memory chips from KB to GB, the relationship between packet loss and congestion became more tenuous.<br>Today TCP’s loss-based congestion control—even with the current best of breed, CUBIC11—is the primary cause of these problems. When bottleneck buffers are large, loss-based congestion control keeps them full, causing bufferbloat. When bottleneck buffers are small, loss-based congestion control misinterprets loss as a signal of congestion, leading to low throughput. Fixing these problems requires an alternative to loss-based congestion control. Finding this alternative requires an understanding of where and how network congestion originates.</p></blockquote><p>(摘自BBR论文&lt;BBR: Congestion-Based Congestion Control&gt;)</p><p>简单的理解就是基于丢包的拥塞控制算法，在缓冲区缓存比较大的时候，会使得缓冲区被填满最终造成bufferbloat。而当缓冲区缓存较小时，基于丢包的拥塞算法可能会误判为此时网络拥塞，并降低吞吐量，所以要想解决这种问题，就需要找到一种不是基于丢包的拥塞控制算法。<br>于是，BBR 诞生了。</p><p>在讲解BBR之前，先了解几个参数名词，这几个名词会贯穿本文</p><ol><li>RTprop（Round-trippropagation time）：最小时延，一个来回所以其实是两倍时延</li><li>BtlBw（bottleneck bandwidth）：瓶颈带宽</li><li>BDP = BtlBw * RTprop：整条链路所能存储的数据值(不含路由缓存)</li><li>BtlBufSize ：链路上所有的中间路由缓存之和<br>BBR论文中对两者关系用了一个比喻来说明<br>If the network path were a physical pipe, RTprop would be its length and BtlBw its minimum diameter.<br>其实根据这个定义，我们很容易想到：<br>如果当前的实际发送速率乘以延迟得到的值越接近 BDP 说明算法的效率越高。</li></ol><p>下图是这几个参数之间的关系<br><img src="http://blog.lihaizhou.top/BBR/BBR_1.png" alt=""><br>(这张图原图摘自BBR论文，笔者加了一些自己的理解在上面)</p><p>个人理解</p><ol><li>数据刚开始传输时，这个时候显然数据量未填充满也就是未达到BDP，此时传输速率持续上升，RTT处于最优状态也就是最小时延，这是一个传输通畅的阶段。</li><li>当数据填充超过BDP时，数据会使用到路由的缓存区，这个时候RTT会开始上升，但是发送速率还维持不变，这个阶段处于一个缓冲阶段，一旦越过BDP分界线就说明拥塞开始出现了。</li><li>当数据填充超过（BDP+BtlBufSize）大小后，此时没有地方能够存储下没有来得及发送的数据，丢包开始产生！关于图中笔者标记出来的丢包临界点，基于丢包的拥塞算法几乎都是以此为收敛点，尽可能的填充满网络和缓存，认为此举是可以提高网络利用率和减少丢包，一旦出现丢包，就开始降低数据的发送量并再次向这个错误的收敛靠近。<br>BBR的目标收敛点都是围绕着图中理想收敛点位置，而基于丢包的cubic/Reno等算法都是围绕着如何收敛到丢包临界点上，因为它们总是将缓存考虑在内，这其实是一个错误的做法。BBR</li></ol><p>关于图中的斜率，个人理解如下：<br>假设某一时刻实际发送数据大小为S，实际带宽为R，R必定是 &lt;= BtlBw，实际时延设为<code>T&gt;=RTprop</code>。<br>这一时刻的数据量 S=T*R， 所以这里<code>T/S = 1/R &gt;= 1/BtlBw</code>，所以实际情况下斜率往往是比上半图中的更陡峭，同理下半图的斜率 R/S = 1/T &lt;= 1/RTprop，所以实际情况下下半图的斜率往往会更平缓些，图中的阴影部分是不可达的。</p><p>关于发送速率的计算方式，BBR论文中是这样解释的</p><blockquote><p>Unlike RTT, nothing in the TCP spec requires implementations to track bottleneck bandwidth, but a good estimate results from tracking delivery rate. When the ack for some packet arrives back at the sender, it conveys that packet’s RTT and announces the delivery of data inflight when that packet departed. Average delivery rate between send and ack is the ratio of data delivered to time elapsed: deliveryRate = Δdelivered/Δt. This rate must be ≤ the bottleneck rate (the arrival amount is known exactly so all the uncertainty is in the Δt, which must be ≥ the true arrival interval; thus, the ratio must be ≤ the true delivery rate, which is, in turn, upper-bounded by the bottleneck capacity). </p></blockquote><p>简单理解为</p><ol><li>应答了多少数据，记为delivered；</li><li>应答delivered这么多数据所用时间，记为interval_us。<br>将上述二者相除，就能得到带宽：bw = delivered/interval_us</li></ol><p>从前面那张图我们可以发现，如果测量BtlBw则需要填满buffer，测量RTprop 需要排空buffer也就是不能使用buffer，所以BBR的BtlBw和RTprop无法同时测量的。<br>那么BBR是怎么做得呢？下面会结合源码分别进行分析</p><h5 id="Startup"><a href="#Startup" class="headerlink" title="Startup"></a>Startup</h5><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/* We use a high_gain value of 2/ln(2) because it's the smallest pacing gain</span></span><br><span class="line"><span class="comment"> * that will allow a smoothly increasing pacing rate that will double each RTT</span></span><br><span class="line"><span class="comment"> * and send the same number of packets per RTT that an un-paced, slow-starting</span></span><br><span class="line"><span class="comment"> * Reno or CUBIC flow would:</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">const</span> <span class="keyword">int</span> bbr_high_gain  = BBR_UNIT * <span class="number">2885</span> / <span class="number">1000</span> + <span class="number">1</span>;</span><br></pre></td></tr></table></figure><p>这个值主要用于计算<code>pacing_rate</code>，至于这个初始值为何是2/ln(2)这样一个写死的值，笔者翻阅了BBR论文并找到没有提及原因的地方，猜测可能是实测算出的最优值。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/* Initialize pacing rate to: high_gain * init_cwnd / RTT. */</span></span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">bbr_init_pacing_rate_from_rtt</span><span class="params">(struct sock *sk)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">        <span class="class"><span class="keyword">struct</span> <span class="title">tcp_sock</span> *<span class="title">tp</span> = <span class="title">tcp_sk</span>(<span class="title">sk</span>);</span></span><br><span class="line">        <span class="class"><span class="keyword">struct</span> <span class="title">bbr</span> *<span class="title">bbr</span> = <span class="title">inet_csk_ca</span>(<span class="title">sk</span>);</span></span><br><span class="line">        u64 bw;</span><br><span class="line">        u32 rtt_us;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (tp-&gt;srtt_us) &#123;                <span class="comment">/* any RTT sample yet? */</span></span><br><span class="line">                rtt_us = max(tp-&gt;srtt_us &gt;&gt; <span class="number">3</span>, <span class="number">1U</span>);</span><br><span class="line">                bbr-&gt;has_seen_rtt = <span class="number">1</span>;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;                         <span class="comment">/* no RTT sample yet */</span></span><br><span class="line">                rtt_us = USEC_PER_MSEC;         <span class="comment">/* use nominal default RTT */</span></span><br><span class="line">        &#125;</span><br><span class="line">        bw = (u64)tp-&gt;snd_cwnd * BW_UNIT;</span><br><span class="line">        do_div(bw, rtt_us);</span><br><span class="line">        sk-&gt;sk_pacing_rate = bbr_bw_to_pacing_rate(sk, bw, bbr_high_gain);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在Startup阶段，pacing_rate在每次收到一个ACK后，都会提高bbr_high_gain的值。<br>BBR计算拥塞窗口是用“当前采集到的速率”乘以“当前采集到的最小RTT”来计算的，这就造成了“当前发送窗口”和“当前已经提高的速率”之间的不匹配，所以，计算拥塞窗口的时候，gain因子也必须是bbr_high_gain，从而可以吸收掉速率的实际提升.</p><h5 id="ProbeRTT"><a href="#ProbeRTT" class="headerlink" title="ProbeRTT"></a>ProbeRTT</h5><p>到这里，我们知道要想达到理想收敛点，就需要找到最小时延和瓶颈带宽<br>我们先来讨论下BBR是如何找到最小RTT的<br>如果了解过Vegas算法原理的人，应该知道Vegas对时延的波动比较敏感，即便一次不是真的拥塞导致的RTT增加都会导致其降窗。<br>那么BBR是基于时延找最小RTT的吗？并不是，下面会讲述</p><p>最小RTT的有效时间是10s<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/* Window length of min_rtt filter (in sec): */</span></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">const</span> u32 bbr_min_rtt_win_sec = <span class="number">10</span>;</span><br><span class="line"><span class="comment">/* Minimum time (in ms) spent at bbr_cwnd_min_target in BBR_PROBE_RTT mode: */</span></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">const</span> u32 bbr_probe_rtt_mode_ms = <span class="number">200</span>;</span><br></pre></td></tr></table></figure></p><p>探测最小RTT需要最少4个数据包，这是为了兼顾延迟ACK。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/* Try to keep at least this many packets in flight, if things go smoothly. For</span></span><br><span class="line"><span class="comment"> * smooth functioning, a sliding window protocol ACKing every other packet</span></span><br><span class="line"><span class="comment"> * needs at least 4 packets in flight:</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">const</span> u32 bbr_cwnd_min_target = <span class="number">4</span>;</span><br></pre></td></tr></table></figure><p>更新最小RTT核心函数 bbr_update_min_rtt，这个函数较长，我们将其拆分开来进行讨论</p><p>1.如果本次RTT时间小于最小RTT时间值或者最小RTT时间有效时间到了，则更新最小RTT值</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/* Track min RTT seen in the min_rtt_win_sec filter window: */</span></span><br><span class="line">  filter_expired = after(tcp_jiffies32,</span><br><span class="line">                         bbr-&gt;min_rtt_stamp + bbr_min_rtt_win_sec * HZ);</span><br><span class="line">  <span class="keyword">if</span> (rs-&gt;rtt_us &gt;= <span class="number">0</span> &amp;&amp;</span><br><span class="line">      (rs-&gt;rtt_us &lt; bbr-&gt;min_rtt_us ||</span><br><span class="line">       (filter_expired &amp;&amp; !rs-&gt;is_ack_delayed))) &#123;</span><br><span class="line">          bbr-&gt;min_rtt_us = rs-&gt;rtt_us;</span><br><span class="line">          bbr-&gt;min_rtt_stamp = tcp_jiffies32;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><p>2.最小RTT时间过期了且当前未处于PROBE_RTT模式，则切换模式到RTT，降低发送速率<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (bbr_probe_rtt_mode_ms &gt; <span class="number">0</span> &amp;&amp; filter_expired &amp;&amp;</span><br><span class="line">       !bbr-&gt;idle_restart &amp;&amp; bbr-&gt;mode != BBR_PROBE_RTT) &#123;</span><br><span class="line">           bbr-&gt;mode = BBR_PROBE_RTT;  <span class="comment">/* dip, drain queue */</span></span><br><span class="line">           bbr_save_cwnd(sk);  <span class="comment">/* note cwnd so we can restore it */</span></span><br><span class="line">           bbr-&gt;probe_rtt_done_stamp = <span class="number">0</span>;</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure></p><p>3.如果此时处于<code>PROBE_RTT</code>模式下，首先设置app_limited 是为了表面这个时间区域内BW参与最大值计算。inflight数据包小于等于<code>bbr_cwnd_min_target</code>即四个数据包时，同时满足一些其它条件后，开始更新本次最小RTT侦测结束时间戳，也就是当前时间加上200ms，并将本次已delivered数据赋值给下个RTT。   </p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (bbr-&gt;mode == BBR_PROBE_RTT) &#123;</span><br><span class="line">               <span class="comment">/* Ignore low rate samples during this mode. */</span></span><br><span class="line">               tp-&gt;app_limited =</span><br><span class="line">                       (tp-&gt;delivered + tcp_packets_in_flight(tp)) ? : <span class="number">1</span>;</span><br><span class="line">               <span class="comment">/* Maintain min packets in flight for max(200 ms, 1 round). */</span></span><br><span class="line">               <span class="keyword">if</span> (!bbr-&gt;probe_rtt_done_stamp &amp;&amp;</span><br><span class="line">                   tcp_packets_in_flight(tp) &lt;= bbr_cwnd_min_target) &#123;</span><br><span class="line">                       bbr-&gt;probe_rtt_done_stamp = tcp_jiffies32 +</span><br><span class="line">                               msecs_to_jiffies(bbr_probe_rtt_mode_ms);</span><br><span class="line">                       bbr-&gt;probe_rtt_round_done = <span class="number">0</span>;</span><br><span class="line">                       bbr-&gt;next_rtt_delivered = tp-&gt;delivered;</span><br><span class="line">               &#125; <span class="keyword">else</span> <span class="keyword">if</span> (bbr-&gt;probe_rtt_done_stamp) &#123;</span><br><span class="line">                       <span class="keyword">if</span> (bbr-&gt;round_start)</span><br><span class="line">                               bbr-&gt;probe_rtt_round_done = <span class="number">1</span>;</span><br><span class="line">                       <span class="keyword">if</span> (bbr-&gt;probe_rtt_round_done)</span><br><span class="line">                               bbr_check_probe_rtt_done(sk);</span><br><span class="line">               &#125;</span><br><span class="line">       &#125;</span><br></pre></td></tr></table></figure><h5 id="ProbeBW"><a href="#ProbeBW" class="headerlink" title="ProbeBW"></a>ProbeBW</h5><p>增益系数数组</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/* The pacing_gain values for the PROBE_BW gain cycle, to discover/share bw: */</span></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">const</span> <span class="keyword">int</span> bbr_pacing_gain[] = &#123;</span><br><span class="line">        BBR_UNIT * <span class="number">5</span> / <span class="number">4</span>,        <span class="comment">/* probe for more available bw */</span></span><br><span class="line">        BBR_UNIT * <span class="number">3</span> / <span class="number">4</span>,        <span class="comment">/* drain queue and/or yield bw to other flows */</span></span><br><span class="line">        BBR_UNIT, BBR_UNIT, BBR_UNIT, <span class="comment">/* cruise at 1.0*bw to utilize pipe, */</span></span><br><span class="line">        BBR_UNIT, BBR_UNIT, BBR_UNIT  <span class="comment">/* without creating excess queue... */</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><ol><li>bbr_pacing_gain[0]<br>这个阶段gain的值是1.25，也是BBR的初始值，这个阶段意味着BBR会试图增加发送量，尽可能多的占用带宽，占满新进的多余的带宽，目的是提升资源的利用率，不过这个阶段可能会出现队列的产生以及RTT变长的情况。<br>bbr_pacing_gain[0]退出条件时：<br>已经运行超过了一个最小RTT时间并且要么发生了丢包，要么本次ACK到来前的inflight的值已经等于窗口值了。[引用2]</li><li>bbr_pacing_gain[1]<br>bbr_pacing_gain[1] 这个阶段gain的值为0.75，假设此时正处于增益阶段，此时一个新的连接发起，可能会导致正处于增益阶段的连接的inflight满载，这个时候就需要切换到bbr_pacing_gain[1] 状态，在出让部分带宽后尽快进入平稳期，这个阶段体现了BBR的公平性。<br>这个阶段时间较短，一旦完成出让带宽就退出，最多停留不超过一个最短RTT时间。</li><li>bbr_pacing_gain[2]…. bbr_pacing_gain[7]<br>这个阶段代表的是平稳期，至少停留6个RTT</li></ol><p>进入<code>PROBE_BW</code>状态后会反复的在上面三个步骤之间循环：加速、减速、匀速。。。。<br><img src="http://blog.lihaizhou.top/BBR/BBR_2.png" alt=""><br>(图片摘自BBR论文，笔者加了些理解) </p><p>这个时候，设想下如果上面的数组中移除掉后面的六个元素，也就是移除平稳期，会出现什么样的情况呢？<br>因为一旦进入平稳期由于至少停留6个RTT的限制，导致在这期间如果有富余带宽，BBR是无法抢占的，所以如果一旦移除到平稳期，带来的就是更快的发现富余带宽，代价就是比较网络比较颠簸，对于一些如下载类的业务有益，不适用于如直播类业务。</p><p>关于bbr_pacing_gain增益数组的作用，归纳下来就是：<br><code>BBR会尽可能的抢占更多带宽，一旦有了新的连接之后，如果出现本次窗口估值等于上次的inflight值，说明这个时候带宽被填满了。此时旧连接的gain值下降进而让出部分带宽给新连接，在至少6个RTT周期内也就是平稳期，这个阶段旧连接不会抢占更多带宽，直到6个RTT后，旧连接会试图抢占更多带宽，周而复始。</code></p><p>bbr_update_bw 函数</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/* Estimate the bandwidth based on how fast packets are delivered */</span></span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">bbr_update_bw</span><span class="params">(struct sock *sk, <span class="keyword">const</span> struct rate_sample *rs)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">        <span class="class"><span class="keyword">struct</span> <span class="title">tcp_sock</span> *<span class="title">tp</span> = <span class="title">tcp_sk</span>(<span class="title">sk</span>);</span></span><br><span class="line">        <span class="class"><span class="keyword">struct</span> <span class="title">bbr</span> *<span class="title">bbr</span> = <span class="title">inet_csk_ca</span>(<span class="title">sk</span>);</span></span><br><span class="line">        u64 bw;</span><br><span class="line"></span><br><span class="line">        bbr-&gt;round_start = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">if</span> (rs-&gt;delivered &lt; <span class="number">0</span> || rs-&gt;interval_us &lt;= <span class="number">0</span>)</span><br><span class="line">                <span class="keyword">return</span>; <span class="comment">/* Not a valid observation */</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">/* See if we've reached the next RTT */</span></span><br><span class="line">        <span class="keyword">if</span> (!before(rs-&gt;prior_delivered, bbr-&gt;next_rtt_delivered)) &#123;</span><br><span class="line">                bbr-&gt;next_rtt_delivered = tp-&gt;delivered;</span><br><span class="line">                bbr-&gt;rtt_cnt++;</span><br><span class="line">                bbr-&gt;round_start = <span class="number">1</span>;</span><br><span class="line">                bbr-&gt;packet_conservation = <span class="number">0</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        bbr_lt_bw_sampling(sk, rs);</span><br><span class="line"></span><br><span class="line">        <span class="comment">/* Divide delivered by the interval to find a (lower bound) bottleneck</span></span><br><span class="line"><span class="comment">         * bandwidth sample. Delivered is in packets and interval_us in uS and</span></span><br><span class="line"><span class="comment">         * ratio will be &lt;&lt;1 for most connections. So delivered is first scaled.</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        <span class="comment">//计算当前实际带宽</span></span><br><span class="line">        bw = div64_long((u64)rs-&gt;delivered * BW_UNIT, rs-&gt;interval_us);</span><br><span class="line"></span><br><span class="line">        <span class="comment">/* If this sample is application-limited, it is likely to have a very</span></span><br><span class="line"><span class="comment">         * low delivered count that represents application behavior rather than</span></span><br><span class="line"><span class="comment">         * the available network rate. Such a sample could drag down estimated</span></span><br><span class="line"><span class="comment">         * bw, causing needless slow-down. Thus, to continue to send at the</span></span><br><span class="line"><span class="comment">         * last measured network rate, we filter out app-limited samples unless</span></span><br><span class="line"><span class="comment">         * they describe the path bw at least as well as our bw model.</span></span><br><span class="line"><span class="comment">         *</span></span><br><span class="line"><span class="comment">         * So the goal during app-limited phase is to proceed with the best</span></span><br><span class="line"><span class="comment">         * network rate no matter how long. We automatically leave this</span></span><br><span class="line"><span class="comment">         * phase when app writes faster than the network can deliver :)</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        <span class="comment">//加入新的样本</span></span><br><span class="line">        <span class="keyword">if</span> (!rs-&gt;is_app_limited || bw &gt;= bbr_max_bw(sk)) &#123;</span><br><span class="line">                <span class="comment">/* Incorporate new sample into our max bw filter. */</span></span><br><span class="line">                minmax_running_max(&amp;bbr-&gt;bw, bbr_bw_rtts, bbr-&gt;rtt_cnt, bw);</span><br><span class="line">        &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这个函数主要做的事比较清晰，主要是更新RTT周期、通过已delivered数据 * BW_UNIT/采样时间得出带宽值，并将带宽和min rtt加入到新的RTT和BW样本。</p><p>通过对<code>ProbeRTT</code>和<code>ProbeBW</code>的分析，可以知道BBR其实大部分时候都是在ProbeBW和ProbeRTT状态之间切换，并且绝大部分时间是停留在ProbeBW上。<br>根据代码可以得到如下一个简要的图：<br><img src="http://blog.lihaizhou.top/BBR/BBR_3.png" alt=""></p><p>可以看出大部分时候都停留在<code>ProbeBW</code>上，在<code>ProbeRTT</code>停留的时间很短，这其实符合BBR的初衷：尽可能的多占用带宽并且尽量不占用缓存。</p><p>根据前面的代码梳理，画了一张状态机的流转图<br><img src="http://blog.lihaizhou.top/BBR/BBR_4.png" alt=""><br>如果我们用一个精简的图来看这个过程的话，大致如下<br><img src="http://blog.lihaizhou.top/BBR/BBR_5.png" alt=""></p><h4 id="BBR-优缺点"><a href="#BBR-优缺点" class="headerlink" title="BBR 优缺点"></a>BBR 优缺点</h4><p>从前面的讨论中，我们知道BBR的优势，也不难发现其劣势。</p><h5 id="BBR-优势"><a href="#BBR-优势" class="headerlink" title="BBR 优势"></a>BBR 优势</h5><p>1.在长传即大RTT场景下优势明显<br>有一种典型的场景便是”长肥管道”，在TCP连接中，较长的距离意味着RTT的增加，进而意味着窗口打开的更慢，对于像Cubic这类AIMD的拥塞算法而言，它们的慢启动过程会越长 ，这就是Reno家族算法的典型弊端。<br>另外，对于Cubic这类算法而言，更容易出现缓冲区被占满的情况，也就是我们前面提到的bufferbloat，这是为何呢？<br>一窗数据只有在得到ACK确认后才会清除，RTT越小意味着缓冲区能够越快腾出空间，发生bufferbloat概率也越低。反之RTT越大的话，越容易出现bufferbloat的情形<br>而BBR设计之初，就没有将中间缓存考虑在内，从本文前面的收敛图可以看出</p><ul><li>BBR的理想带宽收敛点是在缓冲区即将被填充的时候，此时BtlBW最大，RTT最小</li><li>而对于Reno家族算法而言，其收敛点是缓冲区被填满的时候，此时BtlBW最大，但RTT也最大。</li></ul><p>归纳下来：<br>对于长肥管道这种场景，Cubic这类传统算法表现会异常脆弱，一旦有丢包立马械 投降，执行MD     过程，这个过程是一个快速降窗的过程，前功尽弃。<br>而BBR的优势在于不会导致bufferbloat，且对丢包不敏感使得其不会出现激进降窗的行为。</p><p>2.抢占带宽能力强<br>BBR其实大部分时候都是在ProbeBW和ProbeRTT状态之间切换，并且绝大部分时间是停留在ProbeBW上。ProbeBW阶段会不断的试探剩余可用带宽，短时间内占据更多的带宽。</p><p>3.平稳发送<br>由于其平稳期至少待够6个RTT周期才行，这使得该阶段的发送速率比较平稳，比较适合音视频领域比如视频直播这种对稳定性要求较高的场景。</p><h5 id="BBR-不足之处"><a href="#BBR-不足之处" class="headerlink" title="BBR 不足之处"></a>BBR 不足之处</h5><p>1.对带宽变化不敏感<br>从前面原理分析环节，我们知道BBR减损期会让出部分带宽，一旦这个时候被其它流占据了话，BBR要等到度过本地”漫长”的平稳期，等到下个增益周期才能发现。<br>也就是说BBR在ProbeBW状态下，只有在ProbeMore周期才能感受到带宽的变化，后面的ProbeDrain以及平稳期对于带宽的变化都无法感知，如果这个阶段实际带宽降低，BBR需要多个RTT周期才能收敛到实际的带宽位置。</p><p>2.ProbeRTT阶段导致发送速率下降太多<br>这个阶段由于只发四个包，导致发送速率迅速下降，虽然时间很短，但是如果应用在一些对实时性要求很高的音视频场景下，就会出现卡顿现象。<br>解决方案有多种，根据实际业务需要可以减少ProbeRTT时间甚至直接拿掉ProbeRTT阶段。</p><p>3.抗RTT抖动能力差<br>一个典型的场景便是BBR在WIFI弱网下表现不佳，这里的弱网不是指的是网络质量差，速度慢。<br>而是指的是WIFI场景下的稳定性相比于有线网络而言，逊色太多。由于无线网络是共享介质的，几乎无法在信号不冲突的前提下同时发送和接收。<br>所以在WIFI场景下，接入的终端设备一多，RTT抖动会越明显，这种情况下BBR测算出的BDP很可能就不准确了，可能会低于实际带宽数据。</p><p>综合来看：<br>个人理解目前为止并没有一种拥塞算法能够适应各种网络环境，是否选择BBR需要根据自己的业务场景需要。BBR存在不少优势的同时，也存在不少劣势。<br>应用BBR之后如存在问题，只要不是先天不足，都可以根据业务需要对BBR进行修改。<br>比如对于下载业务应用BBR的话是否可以将平稳期移除，这样虽然带来了网络颠簸，但是对于用户而言带来的变化时下载更快了。<br>再比如对于稳定性要求高的音视频业务，是否可以缩短ProbeRTT时间甚至直接拿掉ProbeRTT阶段，这样的话就不会存在ProbeRTT阶段发包速率掉下来导致的卡顿。</p><h4 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h4><p>至此，对于BBR的一个小结到此结束，由于理解水平有限，可能有不足或理解错误的地方，希望以后回顾时能够再完善下。</p><h4 id="参考文章"><a href="#参考文章" class="headerlink" title="参考文章"></a>参考文章</h4><ol><li>BBR论文 <a href="https://www.cis.upenn.edu/~cis553/files/BBR.pdf" target="_blank" rel="noopener">https://www.cis.upenn.edu/~cis553/files/BBR.pdf</a></li><li>[引用1] Startup阶段拥塞窗口计算的滞后性</li><li>[引用2] 从TCP拥塞本质看BBR算法及其收敛性</li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;TCP BBR（Bottleneck Bandwidth and Round-trip propagation time）是由Google 设计，于2016年发布的拥塞算法。&lt;br&gt;以往的大部分拥塞控制算法都是基于丢包来作为降低传输速率的信号，而B
      
    
    </summary>
    
      <category term="网络" scheme="http://lihaizhou.top/categories/%E7%BD%91%E7%BB%9C/"/>
    
    
  </entry>
  
  <entry>
    <title>ANR原理分析及常见案例</title>
    <link href="http://lihaizhou.top/2022/02/10/ANR%E5%8E%9F%E7%90%86%E5%88%86%E6%9E%90%E5%8F%8A%E5%B8%B8%E8%A7%81%E6%A1%88%E4%BE%8B/"/>
    <id>http://lihaizhou.top/2022/02/10/ANR原理分析及常见案例/</id>
    <published>2022-02-10T13:20:55.000Z</published>
    <updated>2022-04-11T01:16:26.193Z</updated>
    
    <content type="html"><![CDATA[<p>最近看了下ANR代码，结合之前项目上的一些ANR案例，打算对ANR的原理以及常见案例做下小结，涉及的代码均基于<code>Android S</code></p><p>画了一张图，列举了可能导致ANR的一些影响因素<br><img src="http://blog.lihaizhou.top/ANR/ANR_1.png" alt="ANR影响因素"></p><h4 id="原理机制"><a href="#原理机制" class="headerlink" title="原理机制"></a>原理机制</h4><p>我们平时遇到的ANR问题大部分都是input ANR类型，所以以input ANR为例进行梳理，这块机制并不复杂，只梳理埋计时和check超时的代码部分。<br>正常输入事件的分发流程如下<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">InputDispatcher::dispatchOnce() </span><br><span class="line">-&gt;InputDispatcher::dispatchOnceInnerLocked </span><br><span class="line">-&gt;InputDispatcher::dispatchKeyLocked </span><br><span class="line">-&gt;InputDispatcher::findFocusedWindowTargetsLocked</span><br><span class="line">       ......</span><br></pre></td></tr></table></figure></p><p><code>findFocusedWindowTargetsLocked</code>这个函数从字面很好理解: 查找有焦点window。<br>因函数较长，我们将其拆分开来进行梳理<br><strong>Step1: 未找到focused的window，也没有找到focused的application，drop该事件</strong></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// If there is no currently focused window and no focused application</span></span><br><span class="line"><span class="comment">// then drop the event.</span></span><br><span class="line"><span class="keyword">if</span> (focusedWindowHandle == <span class="literal">nullptr</span> &amp;&amp; focusedApplicationHandle == <span class="literal">nullptr</span>) &#123;</span><br><span class="line">    ALOGI(<span class="string">"Dropping %s event because there is no focused window or focused application in "</span></span><br><span class="line">          <span class="string">"display %"</span> PRId32 <span class="string">"."</span>,</span><br><span class="line">          NamedEnum::<span class="built_in">string</span>(entry.type).c_str(), displayId);</span><br><span class="line">    <span class="keyword">return</span> InputEventInjectionResult::FAILED;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>Step2: 未找到focused的window，有focused的application，这是最为常见的情况</strong></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (focusedWindowHandle == <span class="literal">nullptr</span> &amp;&amp; focusedApplicationHandle != <span class="literal">nullptr</span>) &#123;</span><br><span class="line">       <span class="keyword">if</span> (!mNoFocusedWindowTimeoutTime.has_value()) &#123;</span><br><span class="line">           <span class="comment">// We just discovered that there's no focused window. Start the ANR timer</span></span><br><span class="line">           <span class="built_in">std</span>::chrono::nanoseconds timeout = focusedApplicationHandle-&gt;getDispatchingTimeout(</span><br><span class="line">                   DEFAULT_INPUT_DISPATCHING_TIMEOUT);</span><br><span class="line">           <span class="comment">//更新超时时间，该focused事件开始进入计时</span></span><br><span class="line">           mNoFocusedWindowTimeoutTime = currentTime + timeout.count();</span><br><span class="line">           mAwaitedFocusedApplication = focusedApplicationHandle;</span><br><span class="line">           mAwaitedApplicationDisplayId = displayId;</span><br><span class="line">           ALOGW(<span class="string">"Waiting because no window has focus but %s may eventually add a "</span></span><br><span class="line">                 <span class="string">"window when it finishes starting up. Will wait for %"</span> PRId64 <span class="string">"ms"</span>,</span><br><span class="line">                 mAwaitedFocusedApplication-&gt;getName().c_str(), millis(timeout));</span><br><span class="line">           *nextWakeupTime = *mNoFocusedWindowTimeoutTime;</span><br><span class="line">           <span class="keyword">return</span> InputEventInjectionResult::PENDING;</span><br><span class="line">       &#125; <span class="keyword">else</span> <span class="keyword">if</span> (currentTime &gt; *mNoFocusedWindowTimeoutTime) &#123;</span><br><span class="line">           <span class="comment">// Already raised ANR. Drop the event</span></span><br><span class="line">           ALOGE(<span class="string">"Dropping %s event because there is no focused window"</span>,</span><br><span class="line">                 NamedEnum::<span class="built_in">string</span>(entry.type).c_str());</span><br><span class="line">           <span class="keyword">return</span> InputEventInjectionResult::FAILED;</span><br><span class="line">       &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">           <span class="comment">//说明之前已经埋过计时，此时还未到超时时间则继续等待</span></span><br><span class="line">           <span class="comment">// Still waiting for the focused window</span></span><br><span class="line">           <span class="keyword">return</span> InputEventInjectionResult::PENDING;</span><br><span class="line">       &#125;</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure><p><strong>Step3: 重置超时时间</strong></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// we have a valid, non-null focused window</span></span><br><span class="line">resetNoFocusedWindowTimeoutLocked();</span><br></pre></td></tr></table></figure><p>执行到这步，说明本次<code>findFocusedWindowTargetsLocked</code>找到了非空的window，这种情况下会<code>resetNoFocusedWindowTimeoutLocked。</code><br>除此之外，系统还有多个场景下也会触发该重置接口，比如</p><ol><li>setFocusedApplicationLocked  当前focused应用发生变化</li><li>setInputDispatchMode  调用了分发模式</li><li>resetAndDropEverythingLocked  这个接口存在多处会调用，比如stopFreezingDisplayLocked解冻屏幕、performEnableScreen亮屏等场景</li></ol><p><strong>Step4: 其它窗口异常情况</strong><br>如果当前window存在异常情况，也会做pending处理，同样可能会成为造成ANR的原因<br>比如窗口处于paused状态</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (focusedWindowHandle-&gt;getInfo()-&gt;paused) &#123;</span><br><span class="line">    ALOGI(<span class="string">"Waiting because %s is paused"</span>, focusedWindowHandle-&gt;getName().c_str());</span><br><span class="line">    <span class="keyword">return</span> InputEventInjectionResult::PENDING;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>还有其他情况也会导致pending，如窗口未连接、窗口连接已满、窗口连接已死亡等，不再一一列出。<br>这里提到了造成消息pending的情况，我们自然会想到那什么场景下消息会drop掉呢？<br><code>frameworks/native/services/inputflinger/dispatcher/InputDispatcher.cpp</code><br><img src="http://blog.lihaizhou.top/ANR/ANR_2.png" alt=""><br>大致有如上几种场景会造成消息drop，dropInboundEventLocked的触发时机是在<code>InputDispatcher::dispatchOnceInnerLocked</code>中。<br>到这里我们已经清楚了埋下超时时间的流程，那么什么时候会检查超时时间有没有到呢？<br><code>InputDispatcher.cpp@dispatchOnce-&gt; InputDispatcher.cpp@processAnrsLocked</code><br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Check if any of the connections' wait queues have events that are too old.</span></span><br><span class="line"><span class="comment"> * If we waited for events to be ack'ed for more than the window timeout, raise an ANR.</span></span><br><span class="line"><span class="comment"> * Return the time at which we should wake up next.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">nsecs_t</span> InputDispatcher::processAnrsLocked() &#123;</span><br><span class="line">    <span class="keyword">const</span> <span class="keyword">nsecs_t</span> currentTime = now();</span><br><span class="line">    <span class="keyword">nsecs_t</span> nextAnrCheck = LONG_LONG_MAX;</span><br><span class="line">    <span class="comment">// Check if we are waiting for a focused window to appear. Raise ANR if waited too long</span></span><br><span class="line">    <span class="keyword">if</span> (mNoFocusedWindowTimeoutTime.has_value() &amp;&amp; mAwaitedFocusedApplication != <span class="literal">nullptr</span>) &#123;</span><br><span class="line">        <span class="keyword">if</span> (currentTime &gt;= *mNoFocusedWindowTimeoutTime) &#123;</span><br><span class="line">            processNoFocusedWindowAnrLocked();</span><br><span class="line">            mAwaitedFocusedApplication.reset();</span><br><span class="line">            mNoFocusedWindowTimeoutTime = <span class="built_in">std</span>::nullopt;</span><br><span class="line">            <span class="keyword">return</span> LONG_LONG_MIN;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="comment">//mNoFocusedWindowTimeoutTime代表的是这个window超时的时间点</span></span><br><span class="line">            <span class="comment">// Keep waiting. We will drop the event when mNoFocusedWindowTimeoutTime comes.</span></span><br><span class="line">            nextAnrCheck = *mNoFocusedWindowTimeoutTime;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Check if any connection ANRs are due</span></span><br><span class="line">    nextAnrCheck = <span class="built_in">std</span>::min(nextAnrCheck, mAnrTracker.firstTimeout());</span><br><span class="line">    <span class="keyword">if</span> (currentTime &lt; nextAnrCheck) &#123; <span class="comment">// most likely scenario</span></span><br><span class="line">        <span class="keyword">return</span> nextAnrCheck;          <span class="comment">// everything is normal. Let's check again at nextAnrCheck</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// If we reached here, we have an unresponsive connection.</span></span><br><span class="line">    sp&lt;Connection&gt; connection = getConnectionLocked(mAnrTracker.firstToken());</span><br><span class="line">    <span class="keyword">if</span> (connection == <span class="literal">nullptr</span>) &#123;</span><br><span class="line">        ALOGE(<span class="string">"Could not find connection for entry %"</span> PRId64, mAnrTracker.firstTimeout());</span><br><span class="line">        <span class="keyword">return</span> nextAnrCheck;</span><br><span class="line">    &#125;</span><br><span class="line">    connection-&gt;responsive = <span class="literal">false</span>;</span><br><span class="line">    <span class="comment">// Stop waking up for this unresponsive connection</span></span><br><span class="line">    mAnrTracker.eraseToken(connection-&gt;inputChannel-&gt;getConnectionToken());</span><br><span class="line">    onAnrLocked(connection);</span><br><span class="line">    <span class="keyword">return</span> LONG_LONG_MIN;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>如果当前时间已经满足超时时间，则触发onAnrLocked</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">void</span> InputDispatcher::onAnrLocked(<span class="built_in">std</span>::<span class="built_in">shared_ptr</span>&lt;InputApplicationHandle&gt; application) &#123;</span><br><span class="line">    <span class="built_in">std</span>::<span class="built_in">string</span> reason =</span><br><span class="line">            StringPrintf(<span class="string">"%s does not have a focused window"</span>, application-&gt;getName().c_str());</span><br><span class="line">    updateLastAnrStateLocked(*application, reason);</span><br><span class="line"></span><br><span class="line">    <span class="built_in">std</span>::<span class="built_in">unique_ptr</span>&lt;CommandEntry&gt; commandEntry = <span class="built_in">std</span>::make_unique&lt;CommandEntry&gt;(</span><br><span class="line">            &amp;InputDispatcher::doNotifyNoFocusedWindowAnrLockedInterruptible);</span><br><span class="line">    commandEntry-&gt;inputApplicationHandle = <span class="built_in">std</span>::move(application);</span><br><span class="line">    postCommandLocked(<span class="built_in">std</span>::move(commandEntry));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>onAnrLocked函数的主要作用是将<code>doNotifyNoFocusedWindowAnrLockedInterruptible</code>通过<code>postCommandLocked</code>塞进队列中。<br>在下一次<code>InputDispatcher.dispatchOnce</code>中会执行<code>runCommandsLockedInterruptible</code><br><img src="http://blog.lihaizhou.top/ANR/ANR_3.png" alt=""></p><p><code>runCommandsLockedInterruptible</code>方法很简单，取出所有的Command执行一遍<br><img src="http://blog.lihaizhou.top/ANR/ANR_4.png" alt=""><br>这里顺便提一下，我们平时分析日志时经常会遇到类似这样的片段<br><img src="http://blog.lihaizhou.top/ANR/ANR_5.png" alt=""><br><img src="http://blog.lihaizhou.top/ANR/ANR_6.png" alt=""><br><img src="http://blog.lihaizhou.top/ANR/ANR_7.png" alt=""><br>上面的日志片段其实是在processAnrsLocked中打印的，这块日志打印在S上已经被谷歌移除了。</p><h4 id="分析步骤"><a href="#分析步骤" class="headerlink" title="分析步骤"></a>分析步骤</h4><p><strong>Step1：系统环境因素</strong><br>首先判断下是否受环境因素影响，这里所说的系统环境因素通常指的是整机负载/低内存/系统异常等，下面以高负载和低内存这两个场景为例进行说明<br>一. 受整机负载影响<br>搜索<code>ANR in</code>关键词<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">01</span><span class="number">-29</span> <span class="number">06</span>:<span class="number">24</span>:<span class="number">46.618452</span>  <span class="number">1210</span>  <span class="number">5962</span> I AnrManager: ANR in com.journeyui.calculator (com.journeyui.calculator/.Calculator), time=<span class="number">260439862</span></span><br><span class="line"><span class="number">01</span><span class="number">-29</span> <span class="number">06</span>:<span class="number">24</span>:<span class="number">46.618452</span>  <span class="number">1210</span>  <span class="number">5962</span> I AnrManager: Reason: Input dispatching timed out (ActivityRecord&#123;<span class="number">51e27</span>ca u0 com.journeyui.calculator/.Calculator t1837&#125; does <span class="keyword">not</span> have a focused window)</span><br><span class="line"><span class="number">01</span><span class="number">-29</span> <span class="number">06</span>:<span class="number">24</span>:<span class="number">46.618452</span>  <span class="number">1210</span>  <span class="number">5962</span> I AnrManager: Load: <span class="number">31.7</span> / <span class="number">33.43</span> / <span class="number">30.98</span></span><br><span class="line"><span class="number">01</span><span class="number">-29</span> <span class="number">06</span>:<span class="number">24</span>:<span class="number">46.618452</span>  <span class="number">1210</span>  <span class="number">5962</span> I AnrManager: Android time :[<span class="number">2022</span><span class="number">-01</span><span class="number">-29</span> <span class="number">06</span>:<span class="number">24</span>:<span class="number">46.60</span>] [<span class="number">260451.594</span>]</span><br><span class="line"><span class="number">01</span><span class="number">-29</span> <span class="number">06</span>:<span class="number">24</span>:<span class="number">46.618452</span>  <span class="number">1210</span>  <span class="number">5962</span> I AnrManager: CPU usage from <span class="number">167270</span>ms to <span class="number">0</span>ms ago (<span class="number">2022</span><span class="number">-01</span><span class="number">-29</span> <span class="number">06</span>:<span class="number">21</span>:<span class="number">47.589</span> to <span class="number">2022</span><span class="number">-01</span><span class="number">-29</span> <span class="number">06</span>:<span class="number">24</span>:<span class="number">34.860</span>) with <span class="number">99</span>% awake:</span><br><span class="line"><span class="number">01</span><span class="number">-29</span> <span class="number">06</span>:<span class="number">24</span>:<span class="number">46.618452</span>  <span class="number">1210</span>  <span class="number">5962</span> I AnrManager:   <span class="number">226</span>% <span class="number">1210</span>/system_server: <span class="number">173</span>% user + <span class="number">52</span>% kernel / faults: <span class="number">1026822</span> minor <span class="number">8</span> major</span><br><span class="line"><span class="number">01</span><span class="number">-29</span> <span class="number">06</span>:<span class="number">24</span>:<span class="number">46.618452</span>  <span class="number">1210</span>  <span class="number">5962</span> I AnrManager:   <span class="number">125</span>% <span class="number">459</span>/logd: <span class="number">16</span>% user + <span class="number">109</span>% kernel / faults: <span class="number">408</span> minor</span><br><span class="line"><span class="number">01</span><span class="number">-29</span> <span class="number">06</span>:<span class="number">24</span>:<span class="number">46.618452</span>  <span class="number">1210</span>  <span class="number">5962</span> I AnrManager:   <span class="number">29</span>% <span class="number">21567</span>/com.journeyui.globalsearch: <span class="number">18</span>% user + <span class="number">10</span>% kernel / faults: <span class="number">45071</span> minor <span class="number">25</span> major</span><br><span class="line"><span class="number">01</span><span class="number">-29</span> <span class="number">06</span>:<span class="number">24</span>:<span class="number">46.618452</span>  <span class="number">1210</span>  <span class="number">5962</span> I AnrManager:   <span class="number">26</span>% <span class="number">639</span>/surfaceflinger: <span class="number">18</span>% user + <span class="number">8.6</span>% kernel / faults: <span class="number">4704</span> minor</span><br><span class="line"><span class="number">01</span><span class="number">-29</span> <span class="number">06</span>:<span class="number">24</span>:<span class="number">46.618452</span>  <span class="number">1210</span>  <span class="number">5962</span> I AnrManager:   <span class="number">26</span>% <span class="number">20889</span>/com.yulong.android.gamecenter: <span class="number">16</span>% user + <span class="number">9.3</span>% kernel / faults: <span class="number">21143</span> minor</span><br><span class="line"><span class="number">01</span><span class="number">-29</span> <span class="number">06</span>:<span class="number">24</span>:<span class="number">46.618452</span>  <span class="number">1210</span>  <span class="number">5962</span> I AnrManager:   <span class="number">24</span>% <span class="number">29706</span>/com.sohu.inputmethod.sogou:home: <span class="number">16</span>% user + <span class="number">8.6</span>% kernel / faults: <span class="number">21832</span> minor</span><br><span class="line"><span class="number">01</span><span class="number">-29</span> <span class="number">06</span>:<span class="number">24</span>:<span class="number">46.618452</span>  <span class="number">1210</span>  <span class="number">5962</span> I AnrManager:   <span class="number">24</span>% <span class="number">545</span>/com.android.messaging: <span class="number">15</span>% user + <span class="number">9</span>% kernel / faults: <span class="number">26023</span> minor <span class="number">2</span> major</span><br><span class="line"><span class="number">01</span><span class="number">-29</span> <span class="number">06</span>:<span class="number">24</span>:<span class="number">46.618452</span>  <span class="number">1210</span>  <span class="number">5962</span> I AnrManager:   <span class="number">19</span>% <span class="number">803</span>/guardserver: <span class="number">3</span>% user + <span class="number">16</span>% kernel</span><br><span class="line"><span class="comment">//....</span></span><br><span class="line"><span class="number">01</span><span class="number">-29</span> <span class="number">06</span>:<span class="number">24</span>:<span class="number">46.618452</span>  <span class="number">1210</span>  <span class="number">5962</span> I AnrManager:   <span class="number">1.7</span>% <span class="number">3589</span>/com.journeyui.calculator: <span class="number">1</span>% user + <span class="number">0.6</span>% kernel / faults: <span class="number">3365</span> minor <span class="number">5</span> major</span><br><span class="line"><span class="comment">//.....</span></span><br><span class="line"><span class="number">01</span><span class="number">-29</span> <span class="number">06</span>:<span class="number">24</span>:<span class="number">46.618480</span>  <span class="number">1210</span>  <span class="number">5962</span> I AnrManager: <span class="number">85</span>% TOTAL: <span class="number">42</span>% user + <span class="number">33</span>% kernel + <span class="number">0</span>% iowait + <span class="number">0</span>% softirq</span><br></pre></td></tr></table></figure></p><ol><li><code>ANR in com.journeyui.calculator</code>  ANR进程名</li><li><code>Reason: Input dispatching timed out (ActivityRecord{51e27ca u0 com.journeyui.calculator/.Calculator t1837} does not have a focused window)</code><br>ANR原因，通俗的解释是：输入事件落到了<br>com.tencent.mm/.ui.LauncherUI这个窗口上，该窗口直到超时时间到了仍未响应输入事件，input超时时间系统默认是5s(我们客制化为8s)。</li><li>Load: 31.7 / 33.43 / 30.98  前 1，前 5，前 15 分钟的负载，我们通常看变化趋势。</li><li><code>2022-01-29 06:21:47.589 to 2022-01-29 06:24:34.860</code>  统计的时间区域</li><li><code>85% TOTAL: 42% user + 33% kernel + 0% iowait + 0% softirq</code><br>这行是我们通常比较关注的，代表了整体的负载情况，85% TOTAL说明整机负载很高。</li><li>图中(4)-(5)之间的片段则是各个进程占据的CPU情况, 发生ANR的进程<code>com.journeyui.calculator</code>的CPU占用只有1.7%<br>PS: 整机CPU loading很高转给系统同事分析 </li></ol><p>二. 整机内存<br>我们知道通常内存紧张的时候，kswapd线程会活跃起来进行回收内存<br>比如下面这个案例<br><img src="http://blog.lihaizhou.top/ANR/ANR_8.png" alt=""><br>通常认为kswapd的CPU占据排进top3的话，这个问题受系统低内存影响比较大。<br>为何低内存会可能和ANR扯上关系呢？<br>因为整机一旦陷入低内存，会表现的响应慢以及多场景下操作卡顿。<br>比如启动应用时间变长 、滑动列表会掉更多帧、LMKD活跃杀进程以释放更多内存。<br>PS: 这个时候如果现场还在的话，可以执行通过adb shell cat proc/meminfo查看下内存情况</p><p>低内存对整机性能的影响</p><ol><li>从过往分析的Systrace来看，低内存会出现大量的Uninterruptible Sleep | WakeKill - Block I/O block信息都是wait_on_page_bit_killable.<br>它的链路是do_page_fault —&gt; lock_page_or_retry -&gt; wait_on_page_bit_killable，由于低内存可能触发的fast path 回收 \ kswapd 回收 \ direct reclaim 回收 \ LMK杀进程回收等行为，造成do_page_fault 高频发生。<br>当出现大量的 IO 操作的时候，应用主线程的 Uninterruptible Sleep 也会变多，此时涉及到 io 操作（比如 view ，读文件，读配置文件、读 odex 文件），都会触发 Uninterruptible Sleep ， 导致整个操作的时间变长，这就解释了为何低内存下为何应用响应卡顿。</li><li>另外低内存的时候，kswapd0和HeapTaskDaemon线程会非常活跃，从我们过往的分析来看，低内存时kswapd0和HeapTaskDaemon线程会跑在大核，占据很多的CPU资源，并且会和前台应用争抢CPU资源，这就可能会出现前台进程得不到足够的CPU资源而出现响应卡顿。</li><li>低内存时查杀进程，有些进程被kill后会立刻restart，我们之前项目上遇到过低内存时，persistent服务进程被kill立马restart，陷入了一种”死循环”，导致整机严重卡顿以及发烫。<br>所以，如果分析ANR问题遇到这种kswapd占据很高(通常认为排到top3内)，基本可以认为该问题是由于系统环境因素导致。<br>另外这个时候，如果搜索”lowmemorykiller”关键词，可以看到问题时间区域会有较多的查杀进程行为，我们通常看”lowmemorykiller”这一行杀的进程adj值，adj值越低，说明当前系统内存越吃紧。</li></ol><p>小结：如果出现了整机高负载或者低内存的情况，ANR的进程可能只是充当了受害者的角色。</p><p><strong>Step2: 分析堆栈</strong><br>如果前面已经排除了系统环境影响因素的话，那么接下来就要分析具体的callstack了<br>搜索”am_anr”关键字<br><img src="http://blog.lihaizhou.top/ANR/ANR_9.png" alt=""><br>时间点: <code>01-25 14:40:44</code>，进程号是17728<br>根据时间戳找到anr文件下对应的trace文件<br><img src="http://blog.lihaizhou.top/ANR/ANR_10.png" alt=""><br>文件头部看下进程号再次确认下<br><img src="http://blog.lihaizhou.top/ANR/ANR_11.png" alt=""><br>搜索关键字”sysTid=17728”, 这里的17728就是上面”am_anr”中包含的进程号也是主线程号<br><img src="http://blog.lihaizhou.top/ANR/ANR_12.png" alt=""></p><ol><li>线程运行状态</li><li>nice值代表该线程优先级，nice的取值范围为-20到19，通常来说nice的值越大，进程的优先级就越低，获得CPU调用的机会越少，nice值越小，进程的优先级则越高，获得CPU调用的机会越多。</li><li>utm：该线程在用户态所执行的时间(单位是jiffies）<br>stm：该线程在内核态所执行的时间<br>该线程的cpu耗时是两者相加(utm+stm)，utm,stm 单位换算成时间单位为 1 比 10ms</li><li>core：跑在哪个核上，core=7表示打印这段日志时该线程跑在大核CPU7上</li><li>函数调用堆栈</li></ol><h4 id="典型案例"><a href="#典型案例" class="headerlink" title="典型案例"></a>典型案例</h4><h5 id="主线程耗时操作"><a href="#主线程耗时操作" class="headerlink" title="主线程耗时操作"></a>主线程耗时操作</h5><p>这种情况是最为常见一种类型<br>比如下面这个案例，是com.tencent.qqlive的ANR，callstack如下<br><img src="http://blog.lihaizhou.top/ANR/ANR_13.png" alt=""><br>通常来说，如果打印的堆栈是ANR进程的堆栈，业务验证证实这段代码确实存在耗时的可能，那么根据callstack位置找到代码修改即可。</p><h5 id="主线程-Blocked-waiting-Sleeping"><a href="#主线程-Blocked-waiting-Sleeping" class="headerlink" title="主线程 Blocked/waiting/Sleeping"></a>主线程 Blocked/waiting/Sleeping</h5><p>主线程当前的状态是(1)Blocked, 原因是它在等锁(2) 0x06573567，而0x06573567被(3)线程13所持有<br><img src="http://blog.lihaizhou.top/ANR/ANR_14.png" alt=""><br>看下tid=13线程 CallStack，在该份trace文件中搜索关键字”0x06573567”找到线程13的堆栈。<br><img src="http://blog.lihaizhou.top/ANR/ANR_15.png" alt=""><br>除了主线程陷入Blocked这种比较常见的情况之外，通常是由于真正持有锁的线程在做繁琐的事务或是发生了死锁，除此之外还有一些少见的情况</p><ol><li>主线程处于waiting状态，说明其正在等待其他线程来notify它，堆栈同样是等锁，分析思路一样。</li><li>主线程处于Sleeping状态，说明当前线程主动调用sleep，其堆栈通常是sleeping on &lt;锁ID&gt;。</li></ol><h5 id="Binder-block"><a href="#Binder-block" class="headerlink" title="Binder block"></a>Binder block</h5><p>这种情况比较常见，比如A进程在主线程中向B进程发起binder请求，B进程因为一些原因比如正在处理耗时消息或网络异常等原因，无法及时响应A进程的binder的请求，造成A进程一直阻塞等待binder的返回结果最终ANR。<br>比如下面这个案例<br><img src="http://blog.lihaizhou.top/ANR/ANR_16.png" alt=""><br>keyguard模块做native层的binder通信，阻塞等待对端结果返回。<br>涉及一个问题：我们该如何快速找到binder对端信息？<br>对于mtk平台而言，anr文件下的binderinfo会打印出binder交互的信息<br>搜索关键字”outgoing transaction” 表示的是当前线程扮演的是Client角色，向其它进程发起binder。<br><img src="http://blog.lihaizhou.top/ANR/ANR_17.png" alt=""><br>28444这个进程中28536这个线程向22767这个进程发起了binder请求。<br>需要注意一点的是：22767:0这里0代表的是server端当前没有可用binder线程。<br>如果binderinfo文件中没有找到的话，也可以在kernel日志中搜索”binder : release”关键词，这行日志通常是binder所在进程结束时会吐出来。</p><h5 id="Binder-池耗尽"><a href="#Binder-池耗尽" class="headerlink" title="Binder 池耗尽"></a>Binder 池耗尽</h5><p>应用的Binder池最多支持16个binder线程，SystemServer比较特殊支持最多32个binder线程。<br>那么什么样的场景下可能会出现Binder 池耗尽的情况呢？<br>比如进程A发送太多重复binder请求给进程B，那么就会导致短时间内接收端进程B的binder线程池被占满，从而处理不了A进程发过来的binder请求。<br>比如下面这段日志<br><img src="http://blog.lihaizhou.top/ANR/ANR_18.png" alt=""><br>和上面binder block同样的分析策略，找到对端是谁以及对端的callstack即可，不再详细展开。</p><h5 id="陷阱堆栈"><a href="#陷阱堆栈" class="headerlink" title="陷阱堆栈"></a>陷阱堆栈</h5><p>何为陷阱堆栈，即出现的callstack并非真正的凶手，比如我们最为常见的CallStack落在nativePollOnce上，这种情况说明当前主线程的消息队列是空闲的，在等待处理下一个msg，打印日志时真正的block消息已经走完了。<br>以下面这个计算器的anr案例<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">01</span><span class="number">-29</span> <span class="number">06</span>:<span class="number">24</span>:<span class="number">46.618452</span>  <span class="number">1210</span>  <span class="number">5962</span> I AnrManager: ANR in com.journeyui.calculator (com.journeyui.calculator/.Calculator), time=<span class="number">260439862</span></span><br><span class="line"><span class="number">01</span><span class="number">-29</span> <span class="number">06</span>:<span class="number">24</span>:<span class="number">46.618452</span>  <span class="number">1210</span>  <span class="number">5962</span> I AnrManager: Reason: Input dispatching timed out (ActivityRecord&#123;<span class="number">51e27</span>ca u0 com.journeyui.calculator/.Calculator t1837&#125; does <span class="keyword">not</span> have a focused window)</span><br><span class="line"><span class="number">01</span><span class="number">-29</span> <span class="number">06</span>:<span class="number">24</span>:<span class="number">46.618452</span>  <span class="number">1210</span>  <span class="number">5962</span> I AnrManager: Load: <span class="number">31.7</span> / <span class="number">33.43</span> / <span class="number">30.98</span></span><br><span class="line"><span class="number">01</span><span class="number">-29</span> <span class="number">06</span>:<span class="number">24</span>:<span class="number">46.618452</span>  <span class="number">1210</span>  <span class="number">5962</span> I AnrManager: Android time :[<span class="number">2022</span><span class="number">-01</span><span class="number">-29</span> <span class="number">06</span>:<span class="number">24</span>:<span class="number">46.60</span>] [<span class="number">260451.594</span>]</span><br><span class="line"><span class="number">01</span><span class="number">-29</span> <span class="number">06</span>:<span class="number">24</span>:<span class="number">46.618452</span>  <span class="number">1210</span>  <span class="number">5962</span> I AnrManager: CPU usage from <span class="number">167270</span>ms to <span class="number">0</span>ms ago (<span class="number">2022</span><span class="number">-01</span><span class="number">-29</span> <span class="number">06</span>:<span class="number">21</span>:<span class="number">47.589</span> to <span class="number">2022</span><span class="number">-01</span><span class="number">-29</span> <span class="number">06</span>:<span class="number">24</span>:<span class="number">34.860</span>) with <span class="number">99</span>% awake:</span><br><span class="line"><span class="number">01</span><span class="number">-29</span> <span class="number">06</span>:<span class="number">24</span>:<span class="number">46.618452</span>  <span class="number">1210</span>  <span class="number">5962</span> I AnrManager:   <span class="number">226</span>% <span class="number">1210</span>/system_server: <span class="number">173</span>% user + <span class="number">52</span>% kernel / faults: <span class="number">1026822</span> minor <span class="number">8</span> major</span><br><span class="line"><span class="number">01</span><span class="number">-29</span> <span class="number">06</span>:<span class="number">24</span>:<span class="number">46.618452</span>  <span class="number">1210</span>  <span class="number">5962</span> I AnrManager:   <span class="number">125</span>% <span class="number">459</span>/logd: <span class="number">16</span>% user + <span class="number">109</span>% kernel / faults: <span class="number">408</span> minor</span><br><span class="line"><span class="number">01</span><span class="number">-29</span> <span class="number">06</span>:<span class="number">24</span>:<span class="number">46.618452</span>  <span class="number">1210</span>  <span class="number">5962</span> I AnrManager:   <span class="number">29</span>% <span class="number">21567</span>/com.journeyui.globalsearch: <span class="number">18</span>% user + <span class="number">10</span>% kernel / faults: <span class="number">45071</span> minor <span class="number">25</span> major</span><br><span class="line"><span class="number">01</span><span class="number">-29</span> <span class="number">06</span>:<span class="number">24</span>:<span class="number">46.618452</span>  <span class="number">1210</span>  <span class="number">5962</span> I AnrManager:   <span class="number">26</span>% <span class="number">639</span>/surfaceflinger: <span class="number">18</span>% user + <span class="number">8.6</span>% kernel / faults: <span class="number">4704</span> minor</span><br><span class="line"><span class="number">01</span><span class="number">-29</span> <span class="number">06</span>:<span class="number">24</span>:<span class="number">46.618452</span>  <span class="number">1210</span>  <span class="number">5962</span> I AnrManager:   <span class="number">26</span>% <span class="number">20889</span>/com.yulong.android.gamecenter: <span class="number">16</span>% user + <span class="number">9.3</span>% kernel / faults: <span class="number">21143</span> minor</span><br><span class="line"><span class="number">01</span><span class="number">-29</span> <span class="number">06</span>:<span class="number">24</span>:<span class="number">46.618452</span>  <span class="number">1210</span>  <span class="number">5962</span> I AnrManager:   <span class="number">24</span>% <span class="number">29706</span>/com.sohu.inputmethod.sogou:home: <span class="number">16</span>% user + <span class="number">8.6</span>% kernel / faults: <span class="number">21832</span> minor</span><br><span class="line"><span class="number">01</span><span class="number">-29</span> <span class="number">06</span>:<span class="number">24</span>:<span class="number">46.618452</span>  <span class="number">1210</span>  <span class="number">5962</span> I AnrManager:   <span class="number">24</span>% <span class="number">545</span>/com.android.messaging: <span class="number">15</span>% user + <span class="number">9</span>% kernel / faults: <span class="number">26023</span> minor <span class="number">2</span> major</span><br><span class="line"><span class="comment">//...</span></span><br><span class="line"><span class="number">01</span><span class="number">-29</span> <span class="number">06</span>:<span class="number">24</span>:<span class="number">46.618452</span>  <span class="number">1210</span>  <span class="number">5962</span> I AnrManager:   <span class="number">1.7</span>% <span class="number">3589</span>/com.journeyui.calculator: <span class="number">1</span>% user + <span class="number">0.6</span>% kernel / faults: <span class="number">3365</span> minor <span class="number">5</span> major</span><br><span class="line"><span class="comment">//...</span></span><br><span class="line"><span class="number">01</span><span class="number">-29</span> <span class="number">06</span>:<span class="number">24</span>:<span class="number">46.618480</span>  <span class="number">1210</span>  <span class="number">5962</span> I AnrManager: <span class="number">75</span>% TOTAL: <span class="number">42</span>% user + <span class="number">33</span>% kernel + <span class="number">0</span>% iowait + <span class="number">0</span>% softirq</span><br></pre></td></tr></table></figure></p><p>整机负载很高，但是前台进程com.journeyui.calculator占用只有1.7%，top5中没有kswapd的身影，排除低内存的影响。<br>PS: SystemServer占据如果稍高可能是正常的，Dump Trace时需要获取系统整体及各进程 CPU 使用情况，短时间内会造成SystemServer升高。<br>接着event日志中搜索”am_anr”关键字<br><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">01-29 06:24:34.907471  1210  5962 I am_anr  : [0,3589,com.journeyui.calculator,684244549,Input dispatching timed out (ActivityRecord&#123;51e27ca u0 com.journeyui.calculator/.Calculator t1837&#125; does not have a focused window)]</span><br></pre></td></tr></table></figure></p><p>找到对应的anr文件<br><img src="http://blog.lihaizhou.top/ANR/ANR_19.png" alt=""><br>callstack落在了nativePollOnce上<br>我们前面说过落在nativePollOnce上，说明应用已经idle了<br>那么什么情况下会出现落在nativePollOnce上呢？</p><ol><li>应用主线程历史调度中存在严重耗时的消息</li><li>应用主线程历史调度中存在多个耗时的消息</li><li>应用主线程历史调度中存在大量消息比如高频发送消息</li><li>应用主线程本身并不耗时，而是受到系统环境因素影响(IO/低内存/高负载等)<br>那么历史调度中的耗时消息我们应该如何得知？<br>谷歌本身在系统多处都加有耗时消息打印，比如我们常见的日志Looper  : Slow dispatch等。</li></ol><p>通常手机厂商也会做日志增强，常见的思路如下:</p><ol><li>监控主线程的binder transaction的耗时情况， 超过阈值时输出相应的目标调用信息。</li><li>当某个线程等待lock的时间blocked超过阈值，则输出当前的持锁状态。</li><li>主线程的生命周期回调方法执行时间超过阈值，则输出相应信息。</li><li>当system_server等进程的线程池使用完, 无空闲线程时, 则binder通信都处于饥饿状态, 则饥饿状态超过一定阈值则输出信息。</li><li>当任意进程的非oneway的Binder调用耗时超过一定阈值的时候，输出Slow Binder信息。</li><li>当SystemServer进程响应其它任意Java进程的非oneway的Binder调用，耗时超过一定阈值的时候，输出Slow Binder信息</li></ol><p>一些头部应用厂商如字节跳动有自研的Raster消息监控平台，出现这种落在<code>nativePollOnce</code>上查找历史耗时消息即可。<br>除了落在<code>nativePollOnce</code>的情况，还有一种情况则更加隐蔽，也更容易将我们带偏分析的方向。<br>那就是callstack打印出来确实是应用自身的堆栈，但是根据callstack找到对应代码后发现根本不可能会出现耗时，说明真正的”凶手”藏身在历史消息中。</p><h5 id="应用内存问题"><a href="#应用内存问题" class="headerlink" title="应用内存问题"></a>应用内存问题</h5><p>我们平时也会经常遇到这样的情况：应用自身内存使用不当导致的ANR<br>比如下面的美团ANR案例<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">01</span><span class="number">-08</span> <span class="number">14</span>:<span class="number">53</span>:<span class="number">20.130</span>  <span class="number">1074</span> <span class="number">32039</span> I AnrManager: ANR in com.sankuai.meituan (com.sankuai.meituan/com.meituan.android.pt.homepage.activity.MainActivity), time=<span class="number">48329538</span></span><br><span class="line"><span class="number">01</span><span class="number">-08</span> <span class="number">14</span>:<span class="number">53</span>:<span class="number">20.130</span>  <span class="number">1074</span> <span class="number">32039</span> I AnrManager: Reason: Input dispatching timed out (c961943 com.sankuai.meituan/com.meituan.android.pt.homepage.activity.MainActivity (server) is <span class="keyword">not</span> responding. Waited <span class="number">8006</span>ms <span class="keyword">for</span> MotionEvent)</span><br><span class="line"><span class="number">01</span><span class="number">-08</span> <span class="number">14</span>:<span class="number">53</span>:<span class="number">20.130</span>  <span class="number">1074</span> <span class="number">32039</span> I AnrManager: Load: <span class="number">27.74</span> / <span class="number">27.04</span> / <span class="number">27.19</span></span><br><span class="line"><span class="number">01</span><span class="number">-08</span> <span class="number">14</span>:<span class="number">53</span>:<span class="number">20.130</span>  <span class="number">1074</span> <span class="number">32039</span> I AnrManager: Android time :[<span class="number">2022</span><span class="number">-01</span><span class="number">-08</span> <span class="number">14</span>:<span class="number">53</span>:<span class="number">20.10</span>] [<span class="number">48351.410</span>]</span><br><span class="line"><span class="number">01</span><span class="number">-08</span> <span class="number">14</span>:<span class="number">53</span>:<span class="number">20.130</span>  <span class="number">1074</span> <span class="number">32039</span> I AnrManager: CPU usage from <span class="number">9706</span>ms to <span class="number">0</span>ms ago (<span class="number">2022</span><span class="number">-01</span><span class="number">-08</span> <span class="number">14</span>:<span class="number">52</span>:<span class="number">48.524</span> to <span class="number">2022</span><span class="number">-01</span><span class="number">-08</span> <span class="number">14</span>:<span class="number">52</span>:<span class="number">58.230</span>):</span><br><span class="line"><span class="number">01</span><span class="number">-08</span> <span class="number">14</span>:<span class="number">53</span>:<span class="number">20.130</span>  <span class="number">1074</span> <span class="number">32039</span> I AnrManager:   <span class="number">100</span>% <span class="number">32613</span>/com.sankuai.meituan: <span class="number">99</span>% user + <span class="number">1.5</span>% kernel / faults: <span class="number">72075</span> minor</span><br><span class="line"><span class="number">01</span><span class="number">-08</span> <span class="number">14</span>:<span class="number">53</span>:<span class="number">20.130</span>  <span class="number">1074</span> <span class="number">32039</span> I AnrManager:   <span class="number">24</span>% <span class="number">16662</span>/com.ss.android.ugc.aweme:miniappX: <span class="number">17</span>% user + <span class="number">7.3</span>% kernel / faults: <span class="number">1762</span> minor</span><br><span class="line"><span class="number">01</span><span class="number">-08</span> <span class="number">14</span>:<span class="number">53</span>:<span class="number">20.130</span>  <span class="number">1074</span> <span class="number">32039</span> I AnrManager:   <span class="number">17</span>% <span class="number">4548</span>/com.ss.android.ugc.aweme: <span class="number">11</span>% user + <span class="number">5.9</span>% kernel / faults: <span class="number">2500</span> minor</span><br><span class="line"><span class="number">01</span><span class="number">-08</span> <span class="number">14</span>:<span class="number">53</span>:<span class="number">20.130</span>  <span class="number">1074</span> <span class="number">32039</span> I AnrManager:   <span class="number">11</span>% <span class="number">1074</span>/system_server: <span class="number">8</span>% user + <span class="number">3.6</span>% kernel / faults: <span class="number">6412</span> minor <span class="number">1</span> major</span><br><span class="line"><span class="comment">//...</span></span><br><span class="line"><span class="number">01</span><span class="number">-08</span> <span class="number">14</span>:<span class="number">53</span>:<span class="number">20.130</span>  <span class="number">1074</span> <span class="number">32039</span> I AnrManager: <span class="number">30</span>% TOTAL: <span class="number">21</span>% user + <span class="number">8.1</span>% kernel + <span class="number">0.1</span>% iowait + <span class="number">1</span>% softirq</span><br></pre></td></tr></table></figure></p><p>整机负载不高，且kswapd占比很低，基本可以排除系统环境影响<br><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">01-08 14:52:58.243  1074 32039 I am_anr  : [0,32613,com.sankuai.meituan,949501508,Input dispatching timed out (c961943 com.sankuai.meituan/com.meituan.android.pt.homepage.activity.MainActivity (server) is not responding. Waited 8006ms for MotionEvent)]</span><br></pre></td></tr></table></figure></p><p>时间点14:52:58，进程号32613<br>因为这份日志缺少anr文件，所以我们直接看系统日志<br>在案发时间点附近，我们发现出现有大量的GC片段<br><img src="http://blog.lihaizhou.top/ANR/ANR_20.png" alt=""><br>Clamp target GC heap from这行日志是在SetIdealFootprint即调整目标堆上限值时会打印，这块不太熟悉的话可以参见我们之前发表过的一篇文章<android s="" art="" gc基础篇="">。<br>日志说明当前应用堆使用已超出上限512M，为了分配新的对象，一直持续的阻塞GC再尝试分配。<br>通过日志我们可以发现，尽管应用持续的阻塞GC，但是内存依旧没有降下来。<br>对于应用内存使用问题，通常有如下几种情况</android></p><ol><li>频繁的生成临时对象导致堆内存增长迅速，达到下次堆GC触发阈值后便会触发Bg GC，进而导致回收线程跑大核和前台应用争抢CPU。<br>另外GC回收阶段会存在一次锁堆，应用的主线程会被pause，这种情况下势必会造成应用使用卡顿甚至ANR。</li><li>比较常见的一种情况是应用发生了较为严重的内存泄漏，导致GC一直无法回收足够的内存。</li><li>申请大内存触发阻塞GC以申请到足够的内存，这种情况一般会引起黑屏卡顿。</li><li>还有一种情况，我们知道系统低内存时会触发OnTrimMemory回调，如果应用在OnTrimMemory中并且是在主线程中直接调用显式GC接口即System.gc()，也容易引起应用卡顿。</li></ol><p>上面这些情况虽不一定会导致ANR，但是应用操作卡顿可能在所难免。</p><h4 id="写在最后"><a href="#写在最后" class="headerlink" title="写在最后"></a>写在最后</h4><p>通常ANR是卡顿的一种严重表现形式，所以遇到卡顿问题时应趁早解决，防患于未然。</p><h4 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h4><p><a href="https://www.androidperformance.com/" target="_blank" rel="noopener">https://www.androidperformance.com/</a><br><a href="https://blog.csdn.net/feelabclihu/article/details/120574383" target="_blank" rel="noopener">https://blog.csdn.net/feelabclihu/article/details/120574383</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;最近看了下ANR代码，结合之前项目上的一些ANR案例，打算对ANR的原理以及常见案例做下小结，涉及的代码均基于&lt;code&gt;Android S&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;画了一张图，列举了可能导致ANR的一些影响因素&lt;br&gt;&lt;img src=&quot;http://blog.lih
      
    
    </summary>
    
      <category term="ANR" scheme="http://lihaizhou.top/categories/ANR/"/>
    
    
  </entry>
  
  <entry>
    <title>优化实践: 高刷下列表滑动出现卡顿掉帧</title>
    <link href="http://lihaizhou.top/2021/11/27/%E4%BC%98%E5%8C%96%E5%AE%9E%E8%B7%B5-%E9%AB%98%E5%88%B7%E4%B8%8B%E5%88%97%E8%A1%A8%E6%BB%91%E5%8A%A8%E5%87%BA%E7%8E%B0%E5%8D%A1%E9%A1%BF%E6%8E%89%E5%B8%A7/"/>
    <id>http://lihaizhou.top/2021/11/27/优化实践-高刷下列表滑动出现卡顿掉帧/</id>
    <published>2021-11-27T04:08:46.000Z</published>
    <updated>2022-03-12T14:31:55.044Z</updated>
    
    <content type="html"><![CDATA[<h4 id="问题背景"><a href="#问题背景" class="headerlink" title="问题背景"></a>问题背景</h4><p>近期我们的测试同事，上报了一些操作掉帧的问题，对比机选取的是同配置的荣耀x20。<br>以微信为例，如下是测试提供的测试报告<br><img src="http://blog.lihaizhou.top/%E9%AB%98%E5%88%B7%E4%B8%8B%E6%BB%91%E5%8A%A8%E5%8D%A1%E9%A1%BF/gaoshua_kadun1.png" alt="图片"><br>这份perfdog报告的操作步骤对应的是上下滑动微信列表，数据上看，测试机表现似乎比对比机逊色一些。<br>打算实际对比体验下，在两台机器上安装同版本的微信，清理后台任务，并确保两台机器上的微信均已完成dex2oat且dex2oat模式一样。<br>实际对比测试下来的主观感受是: 在我们的测试机上，滑动松开手指后会概率性出现顿挫感，荣耀机器上滑动的fling阶段比较平滑，虽然偶尔也会有顿挫，对比体验上确实优于我们的测试机</p><p>基于数据报告以及主观测试感受，说明我们的机器在部分场景操作上可能确实存在性能问题，于是开始着手调查这个问题背后的原因。<br>PS: 本文深受<a href="https://www.androidperformance.com/" target="_blank" rel="noopener">androidperformance系列文章</a>启发</p><h4 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h4><p>我们的测试机和对比机均支持120hz高刷，实测在滑动场景下，两者屏幕的刷新率均为120hz，意味着都是8.3ms刷新一次屏幕，滑动松开手指后的fling阶段，两者软件上均为120fps。<br>需要注意一点的是: </p><blockquote><p>120hz指的是屏幕这个硬件刷新画面的频率，是一个硬件的概念。而软件的120fps则是一个软件的概念，表示1秒内生产120帧。<br>一般而言，屏幕刷新率和软件的fps是对应的，比如60hz对应60fps，120hz对应120fps，只有这样用户体验才是最佳的，两者是通过Vsync 机制做到同步，如果屏的刷新率和软件不匹配的话，效果上势必会打折扣，还可能造成无端的功耗开销。<br>比如屏幕刷新率是 60 hz，软件是 120 fps，那么软件每秒绘制的120次有一半是没有显示就被抛弃了的。</p></blockquote><p>以我们这个案例来说，滑动微信列表松开手指后，此时屏的刷新率是120hz，系统为了适配这个120hz，会将Vsync的周期设置为8.3ms，意味着每隔 8.3 ms，Vsync-app 信号就会到来唤醒 Choreographer 来做 App 的绘制渲染操作。<br>App绘制渲染完成后，会将buffer给SurfaceFlinger对应的App所在的bufferQueue队列中，SurfaceFlinger同样需要等Vsync-sf信号，等到信号后SurfaceFlinger开始合成工作并最终送给屏显示，这个过程中如果有一个步骤耗时长了都有可能导致最终一帧花费时间超出8.3ms。</p><h4 id="原因分析"><a href="#原因分析" class="headerlink" title="原因分析"></a>原因分析</h4><p>有了这些基础知识铺垫后，下面从系统全局来分析<br>先看下手指松开fling阶段的应用绘制片段<br><img src="http://blog.lihaizhou.top/%E9%AB%98%E5%88%B7%E4%B8%8B%E6%BB%91%E5%8A%A8%E5%8D%A1%E9%A1%BF/gaoshua_kadun2.png" alt="图片"><br>可以看到，在fling阶段，我们的测试机有很多黄帧，对比机上只有少数的几帧是黄色的<br>这里先解释下黄色帧的含义</p><blockquote><p>黄帧表示这一帧的耗时超过了1个 Vsync 周期，但是小于 2 个 Vsync 周期。<br>黄帧的出现表示这一帧可能存在性能问题，可能掉帧了，注意这里用了可能这个词，因为TripleBuffer机制，即便主线程这一帧超过一个Vsync周期，由于多buffer缓冲，这一帧不一定会掉帧，我们后面会单独成文介绍这块。<br>绿帧表示这一帧在规定时间内及时完成了，耗时不超过1个 Vsync 周期</p></blockquote><p>再看下Sf区域的情况<br><img src="http://blog.lihaizhou.top/%E9%AB%98%E5%88%B7%E4%B8%8B%E6%BB%91%E5%8A%A8%E5%8D%A1%E9%A1%BF/gaoshua_kadun3.png" alt="图片"><br>两者Vsync间隔都是8.3ms，对比机的Sf主线程在大部分时候，都能在Vsync-sf到来后的8.3ms内及时完成，画面上看有条不紊。</p><p>再看下我们的测试机情况，很容易发现由于单次处理比较耗时，出现了堆积延后的情况，这也导致了在屏幕上看到的画面不是很流畅的缘故。<br>通过对比应用fling阶段主线程区域，绘制区域，Sf区域，很快便发现了我们的测试机输在了CPU频率上<br><img src="http://blog.lihaizhou.top/%E9%AB%98%E5%88%B7%E4%B8%8B%E6%BB%91%E5%8A%A8%E5%8D%A1%E9%A1%BF/gaoshua_kadun4.png" alt="图片"><br>从上图可以看出，我们的测试机在应用主线程处理过程中，很多时候CPU频率会掉的很低。<br>比如图中圈出的红色位置，我们测试机在这一帧的应用主线程处理上耗时12ms，虽然是落在大核CPU6上，但是频率只有650Mkhz。<br>再看下竞品机的应用主线程处理阶段CPU情况，在手指触摸后，其频率迅速提升，并且在手指松开后的fling阶段，对比机仍然能够维持一两秒的CPU高频。</p><p>到这里，我们明白了差距在哪里，我们的测试机在手指松开后的fling阶段CPU落下来，而对比机能够在fling阶段维持高频。</p><h4 id="修改方案"><a href="#修改方案" class="headerlink" title="修改方案"></a>修改方案</h4><p>原因在于MTk的powerHal配置有误导致触摸提频未起效，将大核和小核的CPU频率分别限制为不低于1.75Ghz和2.2Ghz(天花板分别为2G和2.4G)<br>并且boost持续时间限定为2s<br><img src="http://blog.lihaizhou.top/%E9%AB%98%E5%88%B7%E4%B8%8B%E6%BB%91%E5%8A%A8%E5%8D%A1%E9%A1%BF/gaoshua_kadun5.png" alt="图片"><br>再次测试微信滑动列表的场景，可以看到修改后，处理堆积延后的现象消失</p><p>再看下应用区域的fling阶段<br><img src="http://blog.lihaizhou.top/%E9%AB%98%E5%88%B7%E4%B8%8B%E6%BB%91%E5%8A%A8%E5%8D%A1%E9%A1%BF/gaoshua_kadun6.png" alt="图片"><br>从图中可以看到修改后，fling阶段黄色帧大幅减少，基本达到了竞品机的表现</p><h4 id="写在最后"><a href="#写在最后" class="headerlink" title="写在最后"></a>写在最后</h4><p>120fps最大的挑战在于一帧的完成必须在8.3ms内完成，细化一点就是App 和 SurfaceFlinger 及其相关的进程端 (加上 crtc 和 hw service)花费的时间总和必须在 8.3ms 之内, 这就需要App侧和Sf侧都不能出现较长耗时，才可以保证不掉帧.<br>高刷下的掉帧原因可能有很多，就笔者遇到的场景有低内存下kswapd跑大核、同步GC、温升限频、IO、Vsync不均、GPU&amp;CPU性能不足等场景，当然最常见的场景还是应用自身绘制超时导致。<br>这个案例根因在于高刷场景下没有提供足够的CPU性能。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;问题背景&quot;&gt;&lt;a href=&quot;#问题背景&quot; class=&quot;headerlink&quot; title=&quot;问题背景&quot;&gt;&lt;/a&gt;问题背景&lt;/h4&gt;&lt;p&gt;近期我们的测试同事，上报了一些操作掉帧的问题，对比机选取的是同配置的荣耀x20。&lt;br&gt;以微信为例，如下是测试提供的测试报告
      
    
    </summary>
    
      <category term="性能" scheme="http://lihaizhou.top/categories/%E6%80%A7%E8%83%BD/"/>
    
    
  </entry>
  
  <entry>
    <title>优化实践:从系统层面优化应用启动速度</title>
    <link href="http://lihaizhou.top/2021/11/19/%E4%BC%98%E5%8C%96%E5%AE%9E%E8%B7%B5-%E4%BB%8E%E7%B3%BB%E7%BB%9F%E5%B1%82%E9%9D%A2%E4%BC%98%E5%8C%96%E5%BA%94%E7%94%A8%E5%90%AF%E5%8A%A8%E9%80%9F%E5%BA%A6/"/>
    <id>http://lihaizhou.top/2021/11/19/优化实践-从系统层面优化应用启动速度/</id>
    <published>2021-11-19T02:00:24.000Z</published>
    <updated>2022-03-12T14:31:44.408Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>应用的启动表现特别是冷启动的速度，是用户对App的第一印象。很多时候也会被评测机构用来测试一个手机性能的依据，所以对启动速度的优化一直以来是App和手机厂商发力的重点</p></blockquote><h4 id="故事背景"><a href="#故事背景" class="headerlink" title="故事背景"></a>故事背景</h4><p>最近，测试提了很多应用启动速度落后于竞品荣耀x20的问题单<br>以其中的支付宝为例, 如下是测试提供的支付宝冷启数据<br>(通过高速相机，以手指松开为起点，以首页内容加载出为结束点)<br><img style="margin: left;" src="http://blog.lihaizhou.top/startProcess/startProcess1.png"></p><p>从高速相机均值数据上，我们的机器上冷启支付宝比竞品机慢了29%，另外通过实测同时打开，直观感受上发现绝大部分时候确实慢于竞品机。<br>顺便说一句:<br><code>测试冷启速度最佳方式是通过高速相机，这种方式最贴近用户实际感受，其次便是通过Systrace，但是Systrace的结束帧的确定是个技术活(没有源码情况下)。</code></p><h4 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h4><p>本文将以支付宝为例进行讨论，对于支付宝这种体积的App，在启动过程中会起来上百个业务操作，但是其冷启耗时却能够控制在几百毫秒，我觉得已经是非常之优秀了。<br>其实这种头部App会有专门的性能团队进行优化，相信支付宝已经做了很多的优化工作。<br>PS: 本文深受<a href="https://www.androidperformance.com/" target="_blank" rel="noopener">androidperformance系列文章</a>启发</p><p>本文将致力于回答如下两个问题</p><ol><li>同样的App版本，同样的配置，为何我们的机器启动速度会比竞品机慢？</li><li>如何优化提升我们机器上的应用启动速度？</li></ol><h4 id="大纲"><a href="#大纲" class="headerlink" title="大纲"></a>大纲</h4><ol><li>App和系统角度分别看启动速度优化</li><li>CPU提频</li><li>Dex2oat策略优化</li><li>抑制GC次数</li><li>IO优化</li><li>优化后实测数据</li><li>写在最后</li><li>参考文献</li></ol><h4 id="App-amp-系统角度看启动速度优化"><a href="#App-amp-系统角度看启动速度优化" class="headerlink" title="App&amp;系统角度看启动速度优化"></a>App&amp;系统角度看启动速度优化</h4><h5 id="应用角度看启动优化"><a href="#应用角度看启动优化" class="headerlink" title="应用角度看启动优化"></a>应用角度看启动优化</h5><p>对于应用启动优化手段比较常规，主要有如下几种:</p><ol><li>启动页主题之类的替换，达到视觉上的速度加快，并非真的快了。</li><li>初始化的生命周期内一些繁重业务或者库加载尽可能的延迟加载，异步加载，用的时候再加载。</li><li>布局上的优化，尽可能降低布局的复杂度，在需要用的时再加载</li><li>主动dex2oat，需要注意的是在Android10+上谷歌限制了应用进程主动dex2oat，但是其实还是有办法触发，只是实现上会稍微麻烦一点，这里不展开讨论。</li></ol><p>这些常规的优化步骤是最基础的，但是实际优化起来并不一定容易，特别是一些庞大的团队合作App。<br>之前在小米做过启动优化的工作，由于项目业务代码实在太繁杂，初始化代码里充斥了各种回调各种插件，还有很多锁等待，文件读写，反射hook，网络操作等耗时的操作，梳理优化的过程需要有足够的耐心，需要不少的沟通成本。<br>对于应用开发人员而言，分析应用自身的耗时分析手段比较常规，最常见的手段就是Systrace，traceview，simpleperf等，实在不行代码里进行插桩埋点，因为有源代码，一切都好办。<br>而对于一些头部App比如抖音支付宝等，这类App往往有专门的性能团队，可能会涉及到GC优化，dex2oat优化，文件重排列降低IO次数等门槛较高的方向。</p><h5 id="系统全局角度看启动优化"><a href="#系统全局角度看启动优化" class="headerlink" title="系统全局角度看启动优化"></a>系统全局角度看启动优化</h5><p>对于系统工程师而言，需要关注从驱动上报input事件到首页第一帧画面合成的整个过程。<br>主要会涉及input事件传递，一帧的渲染，CPU&amp;GPU的调度频率，Surfaceflinger的合成等等。</p><h4 id="CPU提频"><a href="#CPU提频" class="headerlink" title="CPU提频"></a>CPU提频</h4><p>下图是启动过程中主线程的CPU频率<br><img src="http://blog.lihaizhou.top/startProcess/startProcess2.png" alt=""><br>mtk默认已有实现在进程创建后boost持续10s，从上面Systrace可以看到主线程绘制running的片段是跑在大核上且频率已是最高。<br>但是在对比竞品机Systrace时，笔者发现竞品机surfaceflinger很多时候会跑在大核上，而我们的机器没有跑在大核的时候，其单次onMessageReceived耗时很多时候只有我们的一半。<br>这里先解释下onMessageReceived的作用，主要是处理两个Message</p><ol><li>MessageQueue::INVALIDATE — 主要是执行 handleMessageTransaction&amp;handleMessageInvalidate</li><li>MessageQueue::REFRESH — 主要是执行 handleMessageRefresh 方法<br>可以简单的理解为这块的消息处理越快，合成的速度也会越快，画面能够提早显示出来，降低掉帧的概率。<br>这个时候，你可能会有疑问了，竞品机是做了绑大核处理了吗？</li></ol><p>下面我们看下两者cpuset的差异<br><img src="http://blog.lihaizhou.top/startProcess/startProcess3.png" alt=""><br>可以看到竞品机器对于surfaceflinger设置的是前台进程组，我们的机器遵循的是原生System-background，这也意味着我们机器上surfaceflinger只能跑在0-5核上。<br>那么谷歌设计限制在System-background上基于什么考虑呢？猜测是因为绝大部分时候，这个设计都可以满足需求，占用大核的话可能会导致某些情况下加剧大核队列的负载。</p><h4 id="Dex2oat策略优化"><a href="#Dex2oat策略优化" class="headerlink" title="Dex2oat策略优化"></a>Dex2oat策略优化</h4><p>我们知道dex2oat在优化时，会根据需要优化一定量的method。也就是说并不是优化的method都会被翻译成oat模式。根据优化的method的量的多少，可以分为几种常见的模式：<br><code>verify、quicken、space-profile、space、speed-profile、speed、everything</code><br>字面上比较好理解， 越后面的类型编译时间越长，占用的空间也越大，运行时打开速度也越快，典型空间换时间思路的体现。</p><p>下面是我们的机器和对比机上参数的对比<br><img src="http://blog.lihaizhou.top/startProcess/startProcess4.png" alt=""><br>参数是一致的，其实这也是平台默认的配置, 这些参数中有一项是install时的选择的模式: speed-profile.<br>这里说下speed和speed-profile的区别，speed-profile是对profile中的热点函数进行编译，可以简单理解为是局部编译，而speed是全编。<br>对于dex2oat的调优，其实策略比较常规，根据不同的场景和负载，选择不同的模式。除了原生的idle模式下优化，新增了热点应用的周期性dex2oat。</p><h4 id="降低GC的频率"><a href="#降低GC的频率" class="headerlink" title="降低GC的频率"></a>降低GC的频率</h4><p>之前处理过的性能案例中，有不少是GC引起的性能问题。<br>将友商oppo的修改合入：<br>大意是在进程状态变化触发的GC转换中，如果当前堆增长(自上次GC以来)大小未达到可增长的1/4，则跳过本次GC，这样可以降低启动过程中GC的频率。<br>另外，谷歌在Android R上的一笔GC优化修改，也是降低启动过程中的GC频率<br><img src="http://blog.lihaizhou.top/startProcess/startProcess5.png" alt=""><br>大意就是应用启动过程中等进程fork结束之后，将堆上限阈值调整到最大，因为我们知道GC的触发时机主要取决于堆实际增长是否触及上限值，这样一来的话，进程启动过程中GC的概率就会降低，等两秒钟过后，再将堆上限阈值恢复回来。<br>这些修改的目的都是为了降低GC对启动速度的影响，其实GC的影响不光光在启动上，对于整机的流畅度都起到了很重要影响。</p><h4 id="IO优化"><a href="#IO优化" class="headerlink" title="IO优化"></a>IO优化</h4><p>当内核发起一个读请求时（例如进程发起 read() 请求），首先会检查请求的数据是否缓存到了 pagecache 中。如果有，那么直接从内存中读取，不需要访问磁盘，这被称为 cache命中（cache hit）。如果 cache 中没有请求的数据，即 cache 未命中（cache miss），就必须从磁盘中读取数据。<br>然后内核将读取的数据缓存到 cache 中，这样后续的读请求就可以命中 cache 了。Page 可以只缓存一个文件部分的内容，不需要把整个文件都缓存进来。对磁盘的数据进行缓存从而提高性能主要是基于两个因素：</p><ol><li>磁盘访问的速度比内存慢好几个数量级（毫秒和纳秒的差距）。</li><li>被访问过的数据，有很大概率会被再次访问。</li></ol><p>对于一些头部App比如支付宝就对Apk中的文件进行了重排优化，大意就是:<br><code>通过文件重布局，将启动阶段需要用到的文件在 APK 文件中排布在一起，尽可能的利用 pagecache 机制，用最少的磁盘 IO 次数，读取尽可能多的启动阶段需要的文件，减少 IO 开销，从而达到提升启动性能的目的</code></p><p>上面是App中的IO优化策略，从系统角度的优化策略比较复杂，需要对文件系统比较熟悉, 后续会单独成文记录IO这块的内容</p><h4 id="最终优化效果"><a href="#最终优化效果" class="headerlink" title="最终优化效果"></a>最终优化效果</h4><p>当前采用了如下三种方式对启动性能进行了优化</p><ol><li>对SurfaceFlinger占据的CPU资源调整</li><li>针对不同场景下的dex2oat进行了编译模式调优</li><li>启动过程中降低GC次数<br>影响其实最大的是dex2oat</li></ol><p>在优化后的版本上，我们再次使用高速相机对支付宝进行测试<br><img src="http://blog.lihaizhou.top/startProcess/startProcess6.png" alt=""></p><h4 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h4><p><a href="https://developer.android.google.cn/topic/performance/vitals/launch-time" target="_blank" rel="noopener">https://developer.android.google.cn/topic/performance/vitals/launch-time</a><br><a href="https://source.android.com/devices/tech/dalvik/configure" target="_blank" rel="noopener">https://source.android.com/devices/tech/dalvik/configure</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;应用的启动表现特别是冷启动的速度，是用户对App的第一印象。很多时候也会被评测机构用来测试一个手机性能的依据，所以对启动速度的优化一直以来是App和手机厂商发力的重点&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id=&quot;故事背景&quot;&gt;&lt;a href=
      
    
    </summary>
    
      <category term="性能" scheme="http://lihaizhou.top/categories/%E6%80%A7%E8%83%BD/"/>
    
    
  </entry>
  
  <entry>
    <title>Systrace角度: 拆解分析应用的启动流程</title>
    <link href="http://lihaizhou.top/2021/11/11/Systrace%E8%A7%92%E5%BA%A6-%E6%8B%86%E8%A7%A3%E5%88%86%E6%9E%90%E5%BA%94%E7%94%A8%E7%9A%84%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B/"/>
    <id>http://lihaizhou.top/2021/11/11/Systrace角度-拆解分析应用的启动流程/</id>
    <published>2021-11-11T11:40:26.000Z</published>
    <updated>2022-03-12T14:33:11.630Z</updated>
    
    <content type="html"><![CDATA[<p>上周看了一个支付宝启动速度逊色于对比机的案例，花了些时间整理了下这个过程。<br>应用启动过程中牵扯的知识点较多，基本涵盖了Android几大重要的子系统，非一篇文章能够讲清。<br>本文将以支付宝为例，介绍下从input事件触发到首页帧显示完成的整个流程，后面会单独成文介绍与竞品的差异分析。</p><p>本文深受<a href="https://www.androidperformance.com/" target="_blank" rel="noopener">androidperformance系列文章</a>启发</p><h4 id="测试步骤"><a href="#测试步骤" class="headerlink" title="测试步骤"></a>测试步骤</h4><ol><li>使用user版本，开机后连接信号好的WIFI网络，清理后台所有程序。登录支付宝账号后先启动几次，最后再forceStop</li><li>手机放置五分钟后，确保机器未发热，此时打开Systrace录制，通过高速相机拍摄，点击icon冷启，再forceStop下，再次冷启，循环做五组<br>取耗时最长一次925ms为例进行分析，时间范围起始点:   以手指落下接触到icon为起点，以支付宝首页内容完全加载出为结束点</li></ol><h4 id="Input事件"><a href="#Input事件" class="headerlink" title="Input事件"></a>Input事件</h4><p><img src="http://blog.lihaizhou.top/Systrace_process_start/processStart1.png" alt="img"></p><p>关键时间点</p><ol><li>AppLaunch_dispatchPtr:Up:  5s 617ms</li><li>Launcher中接收到input事件:   5s 620ms<br>从up事件到Launcher接收到最早的input事件耗时约3ms</li></ol><p>这个过程大致就是：</p><ol><li>inputReader从Eventhub中获取到input事件后</li><li>inputReader将事件给inputDispatcher，inputDispatcher会将事件放到 “iq” 队列中(图中没有列出)</li><li>这个时候开始寻找处理这个input事件的目标窗口了，这个案例中对应的就是Launcher，找到后放在oq队列中，等着发送给Launcher</li><li>事件发送出去后，将事件放到图中的wq队列中，等Launcher消费过这个事件后，会通知inputDisp已经消费完成，图中的wq凸起点会消失</li></ol><p>这里顺便说下，我们平时经常会遇到input类型的ANR，对应的正是wq的等待时长。<br>简单理解就是事件发给应用窗口了，这个时候开始倒计时，如果5s内(我们项目上客制化为8s)应用窗口没有告知inputDispatcher这个事件消费完成，说明应用窗口无响应了，就会触发ANR。<br>如果5s内应用窗口处理完成了并告知inputDispatcher后，inputDispatcher就会从 “wq” 队列中及时移除待处理事件避免ANR。</p><h4 id="创建进程"><a href="#创建进程" class="headerlink" title="创建进程"></a>创建进程</h4><p><img src="http://blog.lihaizhou.top/Systrace_process_start/processStart2.png" alt="img"></p><p>时间关键点: </p><ol><li><p>fork进程起点 5s 652ms，耗时6ms<br>这里顺便介绍下关于fork进程花费时间的优化，Android R上新增了一个usap的机制，大意是会预先fork一些空进程放在池中，这样可以省去应用fork的时间。<br>有些厂商会定制化这块内容，将这些预先fork出来的空进程指定包名，比如用户感知较强的微信支付宝等，这样的在支付宝冷启时，这里就不会有fork的片段，其实就是空间换时间的做法。<br>但是这种做法不太适合小内存机器，相比内存的额外开销所带来的仅仅几毫秒的提速，似乎并不是特别划算。</p></li><li><p>Launcher将自身pause 5s 665ms<br>大概过程就是检测到前台此时resume状态的Activity是Launcher界面，就会通知桌面应用的 Activity 进入 Paused 状态，有些厂商会定制化桌面icon按压的效果，我手头的小米手机上按压会有一个置灰缩小的动画。</p></li></ol><p>Launcher onpause执行完成之后，便会开始启动动画，对应的会是一连串的帧。<br><img src="http://blog.lihaizhou.top/Systrace_process_start/processStart3.png" alt="img"></p><p>前面的内容大致对应了<br>点击icon-&gt;input事件的分发-&gt; fork进程 -&gt; Launcher onpause<br>launcher启动动画的过程中，支付宝开始同步执行生命周期，如果支付宝生命周期执行结束，则启动动画也会结束并切换到应用窗口</p><h4 id="应用初始化环节"><a href="#应用初始化环节" class="headerlink" title="应用初始化环节"></a>应用初始化环节</h4><p>这块大致的过程是:<br>ZygoteInit-&gt;ActivityThreadMain-&gt;BindApplication-&gt;StartActivity-&gt;onresume-&gt;doFrame-&gt;display</p><p>对于应用开发人员而言，关注点是从BindApplication开始，这个时间点是应用开发者最早能够控制的时间点。<br>ZygoteInit-&gt;ActivityThreadMain</p><ul><li>ZygoteInit -&gt; 5s 669ms   标识支付宝进程初始化开始，创建binder线程池之类的事务</li><li>ActivityThreadMain  -&gt; 5s 670ms  创建并启动主线程的 loop 消息循环；通过 binder 调用 AMS 的 attachApplication 接口将自己 attach 注册到 AMS 中。</li></ul><h5 id="bindApplication"><a href="#bindApplication" class="headerlink" title="bindApplication"></a>bindApplication</h5><p><img src="http://blog.lihaizhou.top/Systrace_process_start/processStart4.png" alt="img"><br>关键时间点<br>bindApplication 起始点5s 676ms，耗时112ms<br>bindApplication段CPU运行情况<br><img src="http://blog.lihaizhou.top/Systrace_process_start/processStart5.png" alt="img"></p><p>bindApplication耗时拆分<br><img src="http://blog.lihaizhou.top/Systrace_process_start/processStart6.png" alt="img"></p><h5 id="activityStart"><a href="#activityStart" class="headerlink" title="activityStart"></a>activityStart</h5><p><img src="http://blog.lihaizhou.top/Systrace_process_start/processStart7.png" alt="img"></p><p>这个过程简单概述下来就是</p><ol><li>创建 Activity 的 Context；</li><li>通过反射创建 Activity 对象；</li><li>执行 Activity 的 attach 动作，其中会创建应用窗口的 PhoneWindow 对象并设置 WindowManage；</li><li>执行应用 Activity 的 onCreate 生命周期函数，并在 setContentView 中创建窗口的 DecorView 对象；</li></ol><p>activityStart时间段CPU执行情况<br><img src="http://blog.lihaizhou.top/Systrace_process_start/processStart8.png" alt="img"><br>activityStart拆分耗时<br><img src="http://blog.lihaizhou.top/Systrace_process_start/processStart9.png" alt="img"></p><h5 id="activityResume"><a href="#activityResume" class="headerlink" title="activityResume"></a>activityResume</h5><p><img src="http://blog.lihaizhou.top/Systrace_process_start/processStart10.png" alt="img"></p><p>这个阶段主要对应的操作</p><ol><li>执行应用 Activity 的 onResume 生命周期函数；</li><li>执行 WindowManager 的 addView 动作开启视图绘制逻辑；</li><li>创建 Activity 的 ViewRootImpl 对象；</li><li>执行 ViewRootImpl 的 setView 函数开启 UI 界面绘制动作；</li></ol><p><img src="http://blog.lihaizhou.top/Systrace_process_start/processStart11.png" alt="img"></p><h4 id="SplashActivity首帧"><a href="#SplashActivity首帧" class="headerlink" title="SplashActivity首帧"></a>SplashActivity首帧</h4><p>市面上有很多应用打开后会有一个启动界面，这个界面叫做SplashActivity，一般会在这个页面可以做一些App数据初始化的工作。<br>如果应用没有SplashActivity的话，那这个环节可以直接跳过直接来到应用首页帧即可。</p><p><img src="http://blog.lihaizhou.top/Systrace_process_start/processStart12.png" alt="img"><br>关键时间点: 启动页首帧 5s 893ms ,耗时37ms</p><p>首帧绘制结束时间点 5s931ms<br><img src="http://blog.lihaizhou.top/Systrace_process_start/processStart13.png" alt="img"></p><p>注意一点的是: 这里的finish draw只有在mDrawsNeededToReport为0时才会打印</p><p>mDrawsNeededToReport的含义是<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">A count of the number of calls to pendingDrawFinished we require to notify the WM drawing is complete.</span><br></pre></td></tr></table></figure></p><p>简单的理解这次的绘制序列结束后会打印，所以我们在首页帧后面找不到finish draw是因为首页会加载很多内容，对应的是会有很多帧才能完成，所以首页帧的结束点用finish draw并不适用。</p><p>还有一点值得注意，因为我们这个案例中是以支付宝为例的，支付宝是有SplashActivity的 ，所以Systrace中你所看到的launching: com.eg.android.AlipayGphone耗时不能代表整个启动过程。<br>只能粗略的代表启动到SplashActivity首帧的耗时， 但是可以在和竞品数据对比时作为一个参考指标</p><p>可以看到launching: com.eg.android.AlipayGphone共计耗费了286.6ms<br><img src="http://blog.lihaizhou.top/Systrace_process_start/processStart14.png" alt="img"></p><p>到这里 , 从dispatchPtr:Up的5s 617ms到SplashActivity首帧绘制结束时间点5s931ms，共耗时314ms</p><h4 id="首页帧"><a href="#首页帧" class="headerlink" title="首页帧"></a>首页帧</h4><p><img src="http://blog.lihaizhou.top/Systrace_process_start/processStart15.png" alt="img"></p><p>这一帧的cpu运行情况<br><img src="http://blog.lihaizhou.top/Systrace_process_start/processStart16.png" alt="img"></p><p>cpu运行情况<br><img src="http://blog.lihaizhou.top/Systrace_process_start/processStart17.png" alt="img"></p><p>渲染结束后将buffer queue到SF的队列中<br><img src="http://blog.lihaizhou.top/Systrace_process_start/processStart18.png" alt="img"></p><h4 id="冷启动结束帧"><a href="#冷启动结束帧" class="headerlink" title="冷启动结束帧"></a>冷启动结束帧</h4><p>对于有源码的应用，定义结束帧会比较简单，加载哪个view或layout能够大致代表界面内容显示完全作为owner你是清楚的。<br>但是对于三方应用比如我们这个案例，没有其源代码，可以通过高速相机先大致确认下时间范围，然后在范围区域内的几帧逐一看。<br>可以先查看下支付宝首页的布局，比如这里home_advertisement.xml对应主界面上的中间广告页，这个布局的加载完成，其后面紧跟着的一帧我我们就认为是结束帧。<br>所以我们在对比竞品的Systrace时也要以home_advertisement.xml加载后的一帧为结束点。</p><p><img src="http://blog.lihaizhou.top/Systrace_process_start/processStart19.png" alt="img"></p><p>SF侧以及渲染线程侧</p><p><img src="http://blog.lihaizhou.top/Systrace_process_start/processStart20.png" alt="img"><br><img src="http://blog.lihaizhou.top/Systrace_process_start/processStart21.png" alt="img"></p><p>关键时间点:<br>SF中bufferQueue对应的支付宝这一帧的buffer被消费后的时间点是 6s554ms<br>这个时间点可以基本认为是冷启动最后的时间点</p><p>到这里我们计算下冷启的大概耗时</p><ul><li><p>inputReader中读取到up事件起始点 : 5s 617ms</p></li><li><p>首页内容完全加载第一帧时间点: 6s554ms</p></li></ul><p>整个冷启动过程共计耗时937ms，和我们高速相机测算的925ms比较接近</p><h4 id="写在最后"><a href="#写在最后" class="headerlink" title="写在最后"></a>写在最后</h4><p>到这里，对于支付宝的整个启动流程拆解结束，希望通过本文能够加深对应用启动流程的理解，后面会另行成文分析和竞品机的差异细节。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;上周看了一个支付宝启动速度逊色于对比机的案例，花了些时间整理了下这个过程。&lt;br&gt;应用启动过程中牵扯的知识点较多，基本涵盖了Android几大重要的子系统，非一篇文章能够讲清。&lt;br&gt;本文将以支付宝为例，介绍下从input事件触发到首页帧显示完成的整个流程，后面会单独成文介
      
    
    </summary>
    
      <category term="性能" scheme="http://lihaizhou.top/categories/%E6%80%A7%E8%83%BD/"/>
    
    
  </entry>
  
  <entry>
    <title>案例分析:打开应用后操作界面无响应(Systrace)</title>
    <link href="http://lihaizhou.top/2021/11/08/%E6%A1%88%E4%BE%8B%E5%88%86%E6%9E%90-%E5%88%87%E6%8D%A2%E5%BA%94%E7%94%A8%E5%90%8E%E9%AB%98%E6%A6%82%E7%8E%87%E6%93%8D%E4%BD%9C%E6%97%A0%E5%93%8D%E5%BA%94-Systrace/"/>
    <id>http://lihaizhou.top/2021/11/08/案例分析-切换应用后高概率操作无响应-Systrace/</id>
    <published>2021-11-08T02:34:51.000Z</published>
    <updated>2021-11-08T06:45:49.000Z</updated>
    
    <content type="html"><![CDATA[<h4 id="问题现象"><a href="#问题现象" class="headerlink" title="问题现象"></a>问题现象</h4><p>打开应用(热启动)后，概率性出现手指滑动界面无任何响应(界面控件支持上下滑动)</p><h4 id="Systrace角度分析"><a href="#Systrace角度分析" class="headerlink" title="Systrace角度分析"></a>Systrace角度分析</h4><p>先看下应用区域帧绘制的情况</p><p><img src="http://blog.lihaizhou.top/Systrace_cpmpact/Systrace_compact2.png" alt="图片"></p><p>这个时间段除了开头的几帧，后面几乎是空白的，复现时手指明明是一直滑动的。</p><p>先确认下input事件是否正常，在分析input事件流转是否正常之前</p><p>我们先简单的介绍下input事件大概的流转过程</p><blockquote><p>1.触摸屏每隔几毫秒扫描一次，如果有触摸事件，那么把事件上报到对应的驱动</p><p>2.InputReader 读取触摸事件交给 InputDispatcher 进行事件派发</p><p>3.InputDispatcher 将触摸事件发给注册了 Input 事件的 App</p><p>4.app 拿到事件之后，进行 Input 事件分发，如果此事件分发的过程中，App的</p><p>UI 发生变化，那么会请求 Vsync，则进行一帧的绘制</p></blockquote><p>先看下input down的时间点</p><p><img src="http://blog.lihaizhou.top/Systrace_cpmpact/Systrace_compact3.png" alt="图片"></p><p>后面的事件是连续且密集的，说明我们复现抓取的时候，报点是没有问题的。</p><p>这个时候我们注意到一个奇怪的现象，outBoundQueue和waitQueue是空的。</p><p>关于outBoundQueue和waitQueue简单介绍下</p><blockquote><p>1.当应用窗口准备就绪，将mPendingEvent转移到outBoundQueue队列，对应的是即将要被派发给对应 AppConnection 的事件。</p><p>2.当outBoundQueue不为空，且应用管道对端连接状态正常，则将数据从outboundQueue中取出事件，放入waitQueue队列，记录的是已经派发给 AppConnection 但是 App 还在处理没有返回处理成功的事件。</p></blockquote><p>如果outBoundQueue和waitQueue是空的话，说明此时应用窗口未就绪。我们操作时窗口明明可见的，难道应用D状态了？</p><p>带着这个疑问，我们再次回到应用所在区域</p><p><img src="http://blog.lihaizhou.top/Systrace_cpmpact/Systrace_compact4.png" alt="图片"></p><p>可以看到飞书热启后，多个运行线程处于非IO导致的D状态，另外结合基本没有占据CPU资源这一情况。</p><p>可以认定之所以应用没有响应down事件，正是由于其处于非IO导致的D状态。</p><p>下面就需要调查为何应用D状态了，很快在应用区域注意到一个现象</p><p><img src="http://blog.lihaizhou.top/Systrace_cpmpact/Systrace_compact5.png" alt="图片"></p><p>我们知道匿名页被压缩换到Zram通常出现在kswapd回收内存场景中。</p><p>但是还有一种场景我们可能会忽略，那就是adj变化触发的进程压缩同样会消费Zram。</p><p>为了验证是进程压缩导致，来到压缩线程所在区域。为了看起来更直观，将down事件和压缩线程放在一起</p><p><img src="http://blog.lihaizhou.top/Systrace_cpmpact/Systrace_compact6.png" alt="图片"></p><p>到这里我们可以确定飞书之所以没有响应到input down事件，正是由于其当时正在进行进程压缩从而导致其处于D状态。</p><h4 id="问题完整时间线"><a href="#问题完整时间线" class="headerlink" title="问题完整时间线"></a>问题完整时间线</h4><p>到这里我们将这个案例完整的故事情节还原出来</p><ol><li><p>在一次退出飞书后，此时引起adj变化，进入压缩判断环节，此时满足一系列条件(如匿名页大小, 前后时间差, adj值)后，压缩线程开始对飞书应用进行压缩。</p></li><li><p>很快再次打开飞书(29s793ms)</p></li><li><p>此时手指按下开始滑动(29s988ms)(不松手)，注意这个时候压缩还未完成，飞书仍处于进程压缩导致的D状态中，所以未能响应down事件。</p><p>我们知道一个事件序列是由down+若干move+up组成，由于down事件丢失以至于后面的move事件未能响应。</p></li><li><p>飞书压缩完成(30s598ms)，该主界面进程压缩过程持续约882.6ms，完成后飞书解除D状态。</p></li></ol><p>这个过程简单点说，在飞书可见后，如果上次压缩未完成，这时候手指按下的down事件都会被丢弃。</p><p>这也解释了为何该问题在快速切换场景下更容易出现</p><h4 id="压缩速度"><a href="#压缩速度" class="headerlink" title="压缩速度"></a>压缩速度</h4><p>这个时候，你可能会觉得疑惑，是不是压缩速度慢导致的这个问题?</p><p>下面我们将试着计算问题时的”压缩速度”, 这里对压缩速度之所以加引号后面会解释</p><p><img src="http://blog.lihaizhou.top/Systrace_cpmpact/Systrace_compact7.png" alt="图片"></p><p>从我们这次复现的Systrace来看，飞书压缩完成后，其Swap占据从118.8M增长到232.7M，共计压缩了约114M的匿名页，共计耗时882ms</p><p>用压缩量除以耗时时间得出”压缩速度”约129M/s。</p><p>影响压缩速度的因素可能有哪些呢？</p><p><strong>主要是压缩算法，CPU频率，DDR频率，内存读写性能这几方面因素</strong></p><p>我们从Systrace中再看下压缩期间的CPU运行情况</p><p><img src="http://blog.lihaizhou.top/Systrace_cpmpact/Systrace_compact8.png" alt="图片"></p><p>可以看到有较多的Runnable (Preempted)，说明该时间段内可能负载较重，存在CPU争抢的情况。</p><p>除了等CPU的片段外，还有很多片段跑在了小核上</p><p><img src="http://blog.lihaizhou.top/Systrace_cpmpact/Systrace_compact9.png" alt="图片"></p><p>这也是为何上面提到的”压缩速度”加引号的原因。正好压缩的耗时882ms并不是一直在running状态。</p><p>其实这点比较好理解，好比你开车上班，短短的五公里的车程却有二十个红绿灯，这个时候用路程除以耗时得出的”车速”，严格意义上说并不准确。</p><h4 id="测试实验"><a href="#测试实验" class="headerlink" title="测试实验"></a>测试实验</h4><p>我们前面已经发现压缩期间很多片段跑在了小核上，那么如果给压缩线程更高的CPU资源权重，是否能提升”压缩速度”呢？</p><p>于是，对压缩线程占据CPU的权重进行调整后，再次抓取了一份Systrace</p><p><img src="http://blog.lihaizhou.top/Systrace_cpmpact/Systrace_compact10.png" alt="图片"></p><p>从修改后抓取的Systrace可以看到，这次压缩线程确实大部分时候跑在了大核上。</p><p>从图中可以看到本次压缩了约144M匿名页，耗时约450ms，”压缩速度”约320M/s</p><p>相比修改前，”压缩速度”提升了近三倍，但是其实仍然不够快，还是会有一定概率发生手指按下时，正好落在压缩未完成的时间段内，只是相比之前大幅降低了该问题复现概率。</p><h4 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h4><p>如果压缩算法已经确认是最优的选择(平衡压缩率和解压缩速度)情况下，通过尽量赋予压缩线程更高的CPU优先级确实能够缩短耗时(假设压缩量固定)，但是最大的影响因素在于内存读写性能。</p><hr><p>愿你秃顶归来，内心依旧少年</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;问题现象&quot;&gt;&lt;a href=&quot;#问题现象&quot; class=&quot;headerlink&quot; title=&quot;问题现象&quot;&gt;&lt;/a&gt;问题现象&lt;/h4&gt;&lt;p&gt;打开应用(热启动)后，概率性出现手指滑动界面无任何响应(界面控件支持上下滑动)&lt;/p&gt;
&lt;h4 id=&quot;Systrace角度
      
    
    </summary>
    
      <category term="性能" scheme="http://lihaizhou.top/categories/%E6%80%A7%E8%83%BD/"/>
    
    
  </entry>
  
  <entry>
    <title>第三视角: 一个ART GC的优化故事</title>
    <link href="http://lihaizhou.top/2021/11/01/%E7%AC%AC%E4%B8%89%E8%A7%86%E8%A7%92-%E4%B8%80%E4%B8%AAART-GC%E7%9A%84%E4%BC%98%E5%8C%96%E6%95%85%E4%BA%8B/"/>
    <id>http://lihaizhou.top/2021/11/01/第三视角-一个ART-GC的优化故事/</id>
    <published>2021-11-01T08:54:55.000Z</published>
    <updated>2022-03-12T14:16:15.509Z</updated>
    
    <content type="html"><![CDATA[<h4 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h4><p>从事过整机性能优化的同事，在实际项目上相信都遇到过GC引起的性能问题。有了上一篇文章<android s="" art="" gc基础="">的铺垫，阅读本文将会比较轻松。<br>笔者在梳理GC这块的代码过程中，深感其复杂并非一蹴而就，如果你对其某处代码的设计缘由不甚理解，不妨试着去追踪它的提交记录。<br>通过其一系列的patch更新以及comment，跟着提交owner的思路历程，便可以了解这个”成品”是如何被加工出来的。</android></p><h4 id="故事的缘起"><a href="#故事的缘起" class="headerlink" title="故事的缘起"></a>故事的缘起</h4><p>笔者在梳理GC这块的代码时，偶然看到一处友商的提交，不禁有点好奇。为了探究其修改的缘由，仔细阅读了这笔修改的提交更新以及所有的comment之后，觉得其中一些思路对我们有启发作用，故而决定将这个思路过程尽可能的还原出来。<br>PS: 友商员工技术之扎实令人印象深刻，采用第三视角纯粹是为了提升趣味性，本文无任何戏谑意思</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">主角: 卢卡斯(谷歌员工)，大壮(友商员工)    </span><br><span class="line">配角: 汉斯(谷歌员工)   </span><br><span class="line">旁白: 笔者</span><br></pre></td></tr></table></figure><h4 id="故事开始"><a href="#故事开始" class="headerlink" title="故事开始"></a>故事开始</h4><p>大壮在国内一家手机厂商搬砖，负责整机性能方面的研究。最近大壮有点闷闷不乐，项目上一些GC相关的性能问题困扰了他许久，具体是什么GC问题呢？<br>大壮通过不限于Systrace等手段，发现在一些场景下比如后台运行较多应用时，GC会消耗较多CPU资源，加剧系统负担，表现出的现象就是更加卡顿了。<br>于是，自信上进的大壮开始着手调研该如何解决这个问题，最终有了一个方案：<br>既然GC会在后台运行较多应用时争抢CPU，那么在CPU负载高的时候降低GC的触发，CPU负载低的时候再恢复，这不就可以了吗？</p><ol><li>怎么降低GC频率呢？Multiplier机制。</li><li>怎么统计CPU负载呢？大壮看了下代码中原本就有GC期间占据的CPU数据。</li></ol><p>看起来小菜一碟嘛，熟悉GC流程代码的大壮很快就做出了第一笔修改。</p><h5 id="修改Multiplier"><a href="#修改Multiplier" class="headerlink" title="修改Multiplier"></a>修改Multiplier</h5><p>考虑到HeapGrowthMultiplier这个接口是谷歌原有的，存在多处会调用，为了不影响其他调用,贴心的大壮加了一个单独的接口HeapGrowthMultiplierExt,  这个接口最终会调用HeapGrowthMultiplier，只是在此之前会有一些判断条件。比如是否处于亮屏，不同的radio下返回不同的Multiplier值。<br>通过前一篇文章的分析，我们知道Multiplier的改变会引起下次GC水位的提升，总的而言，值越高GC的触发频率就会更低。<br>runtime/gc/collector/garbage_collector.cc<br><img src="http://blog.lihaizhou.top/ART_story/GC_story1.png" alt="图片"><br>runtime/gc/heap.cc</p><p><img src="http://blog.lihaizhou.top/ART_story/GC_story2.png" alt="图片"></p><h5 id="降低GC转换的次数"><a href="#降低GC转换的次数" class="headerlink" title="降低GC转换的次数"></a>降低GC转换的次数</h5><p><img src="http://blog.lihaizhou.top/ART_story/GC_story3.png" alt="图片"><br>前后台切换会导致GC转换，大壮心想有一些本身占据堆内存就比较小的进程，他们很多时候的GC转换带来的收益并不明显。<br>特别是内存比较充足的项目这种GC转换似乎有点多余，那么通过判断堆使用大小，去掉一些”不必要”的GC转换，这样就可以降低系统负担。</p><p>旁白:<br>为了可拓展性，尽可能的不要引入硬编码，即便你是通过大量数据实测出来的最优值，除非是一些约定俗成的值。提到硬编码这种情况，在实际项目上经常出现，很多时候这种代码的引入，是由于Reviewer的疏忽没有发现或者说默许了。</p><h4 id="谷歌Review"><a href="#谷歌Review" class="headerlink" title="谷歌Review"></a>谷歌Review</h4><p>很快，大壮的提交修改引起了卢卡斯的注意，看完了大壮的修改后，卢卡斯脑袋上顶着大大的问号。<br>对于如下大壮添加的计算gc期间CPU负载的做法。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">uint64_t gc_cpu_time = thread_cpu_end_time - thread_cpu_start_time;  </span><br><span class="line">float ratio = static_cast&lt;float&gt;(gc_cpu_time) / duration_ns;</span><br></pre></td></tr></table></figure></p><p>卢卡斯认为这只是本次GC周期内的CPU负载情况，且这个值在绝大部分时候都应该是接近1的，并不能说明未来一段时间的CPU情况。<br>另外，GC等待checkpoint或者其他原因都可能会导致GC等待，但是这些等待的时间不会计入gc_cpu_time中，所以这种计算方式只能说一定程度上可能暗示了当前的负载情况，但是远远达不到可靠的地步。</p><p>旁白：<br>注意这里谷歌提到了未来的CPU使用情况，是因为这个比例值是本次GC周期计算的，你可以理解为是一个瞬时值，但是抑制GC的情况是需要等到<br>下次GC触发才会发生的，是一个未来发生的事情，那么等到下次GC的时候，本次GC算出的负载可能就不适用了。</p><p>大壮：<br>大壮看完大G的回复之后，虎躯一震，这修改。。怕是要凉啊！于是大壮赶紧回复到：<br>在一些性能较差设备上，如果后台开启很多应用，很多时候这个比例值会低于0.5甚至触及0.2。<br>另外，我们做过功耗测试，这修改后的效果杠杠的，改善很明显(使用时间增加了18分钟)。</p><p>卢卡斯：<br>看完大壮理直气壮的回复后，卢卡斯回复到：这里亮屏的判断，并根据不同的radio返回不同的Multiplier，这个修改同样会作用到所有系统进程(如system_server、systemui等)，作用于<br>系统进程是一种错误的行为。还有根据不同的radio即你认为的代表负载情况，返回不同的Multiplier值。这些Multiplier值你是怎么得出来的？<br>比如你上面写的当ratio &lt; 0.3时，返回Multiplier 6，这个值6怎么来的？为何不是返回8？为啥不是9？为啥不是一个10000000000？(谷歌没说这句话)。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (screenOn) &#123;</span><br><span class="line">    <span class="keyword">float</span> ratio = current_gc_iteration_.GetRunningRatio();</span><br><span class="line">    <span class="keyword">if</span> (!CareAboutPauseTimes()) &#123;</span><br><span class="line">      <span class="keyword">if</span> (ratio &lt; <span class="number">0.3</span>) <span class="keyword">return</span> <span class="number">6.0</span>;</span><br><span class="line">      <span class="keyword">if</span> (ratio &lt; <span class="number">0.5</span>) <span class="keyword">return</span> <span class="number">4.0</span>;</span><br><span class="line">      <span class="keyword">if</span> (ratio &lt; <span class="number">0.7</span>) <span class="keyword">return</span> <span class="number">2.0</span>;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="keyword">if</span> (ratio &lt; <span class="number">0.3</span>) <span class="keyword">return</span> <span class="number">7.0</span>;</span><br><span class="line">      <span class="keyword">if</span> (ratio &lt; <span class="number">0.6</span>) <span class="keyword">return</span> <span class="number">5.0</span>;</span><br><span class="line">    &#125;</span><br><span class="line"><span class="comment">//....</span></span><br></pre></td></tr></table></figure><p>旁白：给谷歌提代码一定要避免提交这种硬编码</p><p>大壮：<br>此时的大壮，刚从食堂吃完午饭回来的路上，一路上大壮都在和同事吐槽食堂的饭菜又贵又难吃。<br>坐到座位上，看到卢卡斯的连环追问，大壮有点发蒙。这些数据我经过一些性能和功耗测试，是有帮助的，既然你们提出来这样的修改不合理，那么请告诉我,还有没有其它办法可以降低高负载情况下GC的频率。</p><p>卢卡斯:<br>此时的卢卡斯正喝着咖啡，窗外阳光正明媚，卢卡斯回过头和旁边的汉斯说到，这天气不去钓鱼真是浪费生命啊，汉斯点头如蒜捣，没错没错。<br>这个时候，卢卡斯看了下时间快4点了，准备收拾下班，这个时候看到了大壮的comment，回复到:<br>在堆使用较少的情况下不进行GC我觉得有意义，这种情况下我认为是可以直接跳过GC转换的，而不是引入进程状态切换次数这个变量。</p><p>旁白：谷歌的这句话，在一些场景下跳过GC更有意义，正是这句话改变了修改的方向</p><p>卢卡斯旁边的汉斯看到了大壮的这段回复，心里OS: 上一次这么无语还是在上一次, 忍不住回复到：<br>卢卡斯，大壮的这种改法让我感觉也很不舒服，也许我们在一些场景下GC的次数有点多了，但是能不能用更合理的方式来解决这个问题呢？比如依据自上次GC以来分配的字节数作为依据, 对于某些应用程序来说，转换可能会频繁发生，并且每次执行GC并不总是可取的。<br>用比例值或许更合理？例如:“如果我们已经消耗了超过30%的free heap，我们将在转换时GC”。</p><p>旁白：汉斯的这句话奠定了这个修改的基本方向，依据自上次GC以来的分配数值作为依据，采用比例的方式，不用管这个进程的大小。</p><p>大壮：<br>此时的大壮正在工位上，跟旁边的测试妹纸炫耀自己昨天一口气钓了十几斤的鲫鱼，妹纸看大壮的眼神满是崇拜。大壮说的有点渴了，坐下来喝口水时，看到了卢卡斯的回复，思考片刻后，觉得谷歌提出的修改建议确实更加合理。<br>于是讲起了之前遇到的案例:<br>最早是我们遇到的一个Launcher的卡顿例子，同一uid下的5个进程同时在后台执行collectorTransionGc，导致系统负载过高。四个子进程的堆大小都小于5MB，不信我给你们看Systrace。对于这种内存消耗很小的进程，真的大可不必每次都GC，所以我们希望能够限制这种类型的collectortransiongc。因为从实际用户的GC数据中可以发现，这种类型的CollectorTransitionGC的总量非常大。</p><p>卢卡斯:<br>卢卡斯觉得不应该仅限于小内存进程，应该一视同仁，所以卢卡斯觉得基于堆的大小进行限制不是太好。卢卡斯想起了汉斯提出的建议: 根据自上次GC以来分配的大小作为跳过GC转换的条件。<br>汉斯的这个建议确实更加合理一些，这样的话，所有的应用都有机会跳过一些”不必要”的GC。卢卡斯想了下，与其跳过一些转换GC，不如让它更简单，比如: 如果自上次GC以来的分配小于3MB，GC转换时跳过GC。</p><p>旁白:<br>卢卡斯认同汉斯的通过自上次GC以来分配的大小作为依据，但是忽略了汉斯提出另一个意见，那就是通过堆空闲内存的使用率来作为触发条件，这里卢卡斯提出的小于3M就不进行GC，也正是这句话给了大壮一些误导。</p><p>大壮:<br>听完卢卡斯说的堆使用小于3M就不进行GC转换后，大壮进行了一次修改，加了一个阈值<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="keyword">constexpr</span> <span class="keyword">size_t</span> kDefaultTransitionThreshold = <span class="number">5</span> * MB;</span><br></pre></td></tr></table></figure></p><p>并且在GC转换的地方加了一个判断，如果低于这个阈值，就跳过本次的GC转换<br><img src="http://blog.lihaizhou.top/ART_story/GC_story4.png" alt="图片"></p><p>卢卡斯:<br>看完大壮的修改后，卢卡斯后悔了，这里搞个固定的阈值看起来并不合适。因为如果这个进程是一个占用内存比较小的进程，那么5M对于这个进程来说并不容易达到，这会导致GC的触发频率被大幅降低，导致这个进程的堆大小”不合适”的增大。<br>这个时候卢卡斯想起了汉斯的通过比例的建议，没错，通过比例更合理一些，于是卢卡斯提出了: 上次GC后新增大小如果小于<br>UnignedDifference(target_footprint_.load(std::memory_order_relaxed)- num_bytes_alive_after_gc_)/4 话，则跳过本次GC转换，并且对于LowMemoryMode设备避免跳过GC</p><p>旁白：卢卡斯的这番话基本成形了这个修改，即消耗没有达到堆空闲的1/4，此时有GC转换请求的话，则直接丢弃。</p><p>大壮：<br>看完卢卡斯的建议后，大壮开始着手进行了修改，关于如何计算GC后新分配的值。<br>大壮想到了在GC后算出已分配的减去GC前计算出的已分配大小，修改完之后再次更新了patch，很快卢卡斯在大壮的修改下加了comment<br><img src="http://blog.lihaizhou.top/ART_story/GC_story5.png" alt="图片"></p><p>旁白：这是并发GC的特色所在，分配的同时可能伴随着GC，所以需要考虑GC期间释放的空间大小。</p><h4 id="最终修改思想"><a href="#最终修改思想" class="headerlink" title="最终修改思想"></a>最终修改思想</h4><ol><li>进程状态变化触发GC转换</li><li>计算出自上次GC后新分配字节大小，由于并发缘故，需考虑GC期间释放字节数。</li><li>堆可增长上限减去自上次GC后已分配数值，得出的值即可增长空间，取其四分之一作为分界线</li><li>上次GC后新分配字节数值如果小于第三步算出的可增长空间的1/4，则跳过本次GC转换请求。</li></ol><h4 id="写在最后"><a href="#写在最后" class="headerlink" title="写在最后"></a>写在最后</h4><p>谈到设计思想，笔者想起一句话：Talk is cheap. Show me the code!<br>每次看到这句话，都感觉被无端斥责了一番。<br>笔者曾经特地查询了下Linus说这句话的语境背景，最后得出结论Linus说这句话时，其实是在一个讨论回复中，结合当时的上下文语境，Linus说出这句时明显是带有情绪的，但是奇怪的是这句特定语境下的话，在国内却被大肆宣传甚至被一些人奉为经典。<br>笔者在实际项目上见到过太多shit一样的代码，盲目的追求代码数量，粗制滥造毫无设计可言，更不要说代码规范这些基础原则了，阅读起来你都恨不得砸了键盘。<br>如果你很崇尚“show me the code”，给你这样一堆dog shit代码，你能从中看出什么呢？<br>并不是盲目崇拜谷歌，笔者在阅读谷歌代码的提交记录过程中，能够感受到其思维之严谨，考虑之周到，修改之谨慎。所以推荐大家空闲的时候，可以多阅读谷歌的修改记录。<br>最后多说一句，笔者粗浅的认为，相比于最终的成品代码，当然前提是优秀的代码。笔者认为其思路旅程也很重要，因为是人的思想最终孕育出这块美丽的代码。</p><hr><p>只要不给社会添麻烦，做一个废柴并不丢人</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h4&gt;&lt;p&gt;从事过整机性能优化的同事，在实际项目上相信都遇到过GC引起的性能问题。有了上一篇文章&lt;android s=&quot;&quot; art=&quot;&quot; gc基础=&quot;&quot;
      
    
    </summary>
    
      <category term="ART" scheme="http://lihaizhou.top/categories/ART/"/>
    
    
  </entry>
  
  <entry>
    <title>对Android S ART GC的源码梳理</title>
    <link href="http://lihaizhou.top/2021/10/27/%E5%AF%B9Android-S-ART-GC%E7%9A%84%E6%BA%90%E7%A0%81%E6%A2%B3%E7%90%86/"/>
    <id>http://lihaizhou.top/2021/10/27/对Android-S-ART-GC的源码梳理/</id>
    <published>2021-10-27T01:58:43.000Z</published>
    <updated>2022-03-12T14:19:48.350Z</updated>
    
    <content type="html"><![CDATA[<h4 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h4><p>本文是GC系列文章的首篇，主要为下一篇《第三视角: 一个ART GC优化的故事》文章做铺垫。<br>本文将根据下面的大纲，简单的介绍下GC相关的基础知识，GC这块的内容较多，也相对较为复杂。如果想要研究清楚细节，需要花费较多的时间，也需要有读者有足够的耐心和相关知识背景。<br>本文深受<a href="https://juejin.cn/post/6875678394332217357" target="_blank" rel="noopener">ART虚拟机 | GC的触发时机和条件</a>一文的启发</p><p>文中涉及代码均摘自Android S。</p><h4 id="大纲"><a href="#大纲" class="headerlink" title="大纲"></a>大纲</h4><ul><li>研究ART GC目的</li><li>ART GC诞生背景</li><li>里程碑(引入CC)</li><li>ART GC重要特性</li><li>ART GC类别划分</li><li>Multiplier的引入</li><li>堆可分配字节数的计算</li><li>GC触发阈值的计算</li><li>从Systrace角度看GC</li><li>参数修改策略</li><li>写在最后</li><li>参考文献</li></ul><h4 id="研究ART-GC目的"><a href="#研究ART-GC目的" class="headerlink" title="研究ART GC目的"></a>研究ART GC目的</h4><p>尽管GC经过多年发展已得到显著改进，但是在实际项目中仍然会遇到很多GC引起的性能问题。<br>特别是小内存项目上(低于6G)尤为明显，遇到的大部分问题来自于应用不规范的行为，小部分是由于GC机制在特定场景下导致的性能问题。</p><p>GC性能问题主要分为两类：</p><ol><li>对于应用而言，如果代码中存在频繁分配对象、存在内存泄漏、存在主动调用GC接口等问题都有可能导致GC性能问题。<br>主要体现在GC运行的线程HeapTaskDaemon占据CPU资源较多或争抢大核，可能会引起绘制得不到及时调度，导致掉帧的情况。</li><li>另外对于GC机制本身而言，虽然Google一直在优化，但是现在仍然存在一些场景下的表现无法令我们足够满意。<br>比如高负载时争抢CPU资源，小内存进程在某些场景下的频繁触发，多进程应用启动时由于GC导致的卡顿黑屏等现象。</li></ol><h4 id="GC诞生背景"><a href="#GC诞生背景" class="headerlink" title="GC诞生背景"></a>GC诞生背景</h4><p>当我们在学习新技术的时候，了解其诞生背景及其演进变化的历程，再结合具体的代码细节，将有助于我们对这个技术形成一个连续的认知。</p><p>举个网络拥塞控制的例子，网上关于拥塞控制算法的文章铺天盖地，几乎都在讨论其中的代码细节。<br>但是其诞生的历史背景及其本质是为了解决什么问题，却很少有文章能真正解释清楚。<br><strong>为什么说历史背景至关重要</strong><br>还是以拥塞控制为例，如果你不了解1986年的网络大崩溃事件发生的原因，也就无法理解1988年Jacobson提出的TCP拥塞控制的论文。<br>进而即便你多么熟悉TCP的代码细节，你也无法理解这一切实现背后的真正的逻辑，甚至会草率错误的认为拥塞控制是为了加快发包的速度，以至于后面关于这方面的工作很可能是扯淡。</p><p>再回到本文的主题GC，聊下GC诞生的背景</p><blockquote><p><em>1960</em> 年前后诞生于 <em>MIT</em> 的 <em>Lisp</em> 语言是第一种高度依赖于动态内存分配技术的语言，<em>Lisp</em> 语言先天就具有的动态内存管理特性要求 <em>Lisp</em> 语言的设计者必须解决堆中每一个内存块的自动释放问题（否则， <em>Lisp</em> 程序员就必然被程序中不计其数的 <em>free</em> 或 <em>delete</em> 语句淹没），这直接导致了垃圾收集技术的诞生和发展。</p><p><em>J. McCarthy 作为 Lisp</em> 之父，他在发明 <em>Lisp</em> 语言的同时也第一次完整地描述了垃圾收集的算法和实现方式。</p><p>有兴趣的话可以网上搜索这篇文章, 讲的比较详细 &lt;GC技术简单而有趣的发展史&gt;</p></blockquote><h4 id="里程碑-引入CC"><a href="#里程碑-引入CC" class="headerlink" title="里程碑(引入CC)"></a>里程碑(引入CC)</h4><p><code>史前时代Dalvik-&gt;ART的诞生(Android 4.4)-&gt;发展的ART(Android 5.0 ~ 7.0)-&gt;重大变革的ART(Android 8.0 引入Concurrent Copying)-&gt;Android 10开始再次引入分代.</code><br>8.0版本上引入的Concurrent Copying是一项重大改革，大幅提升了Android手机的整机性能表现。<br>8.0版本的GC相比之前的版本改进和提升如下:</p><ul><li>GC always compacts the heap: 32% smaller heap sizes on average compared to Android 7.0.</li><li>Compaction enables thread local bump pointer object allocation: Allocations are 70% faster than in Android 7.0.</li><li>Offers 85% smaller pause times for the H2 benchmark compared to the Android 7.0 GC.</li><li>Pause times no longer scale with heap size; apps should be able to use large heaps without worrying about jank.</li><li>GC implementation detail - Read barriers:</li><li>Read barriers are a small amount of work done for each object field read.</li><li>These are optimized in the compiler, but might slow down some use cases.</li></ul><h4 id="重要特性"><a href="#重要特性" class="headerlink" title="重要特性"></a>重要特性</h4><p>下面简单介绍CC上几种主要的特性，如果阅读过程中有些名词不明其意，大可不必感到困惑。<br>知道其大概的角色作用即可，后面的GC系列文章会对每个特性展开来详细梳理。</p><h5 id="RegionTLAB"><a href="#RegionTLAB" class="headerlink" title="RegionTLAB"></a>RegionTLAB</h5><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">CC enables use of a bump-pointer allocator called RegionTLAB. </span><br><span class="line">This allocates a thread-local allocation buffer (TLAB) to each </span><br><span class="line">app thread, which can then allocate objects out of its TLAB by </span><br><span class="line">bumping the "top" pointer, without any synchronization.</span><br></pre></td></tr></table></figure><p>这里提到的TLAB 即 thread-local allocation buffer，AllocObjectWithAllocator中会先检测如果当前线程TLAB区域的剩余空间可以容纳下这次分配的对象，则在TLAB区域中直接分配。<br>分配算法采用Bump Pointer的方式，仅仅更新已分配区域的游标，简单高效。<br>art/runtime/gc/heap-inl.h<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// If we have a thread local allocation we don't need to update bytes allocated.</span></span><br><span class="line"><span class="keyword">if</span> (IsTLABAllocator(allocator) &amp;&amp; byte_count &lt;= self-&gt;TlabSize()) &#123;</span><br><span class="line">  obj = self-&gt;AllocTlab(byte_count);</span><br><span class="line">  DCHECK(obj != <span class="literal">nullptr</span>) &lt;&lt; <span class="string">"AllocTlab can't fail"</span>;</span><br><span class="line">  obj-&gt;SetClass(klass);</span><br><span class="line">  <span class="keyword">if</span> (kUseBakerReadBarrier) &#123;</span><br><span class="line">    obj-&gt;AssertReadBarrierState();</span><br><span class="line">  &#125;</span><br><span class="line">  bytes_allocated = byte_count;</span><br><span class="line">  usable_size = bytes_allocated;</span><br><span class="line">  no_suspend_pre_fence_visitor(obj, usable_size);</span><br><span class="line">  QuasiAtomic::ThreadFenceForConstructor();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>值得注意的一点是，TLAB在创建之初，它的大小已经计入了num_bytes_allocated_，所以这次虽然分配了新的对象，但num_bytes_allocated_没必要增加，这实际上是一种空间换时间的策略，代价就是会导致num_bytes_allocated_略大于真实使用的字节数。</p><p>谷歌对此修改的commit message:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">New TLAB allocator doesn&apos;t increment bytes allocated </span><br><span class="line">until we allocate a new TLAB. This increases allocation </span><br><span class="line">performance by avoiding a CAS.</span><br><span class="line"></span><br><span class="line">MemAllocTest:</span><br><span class="line">Before GSS TLAB: 3400ms.</span><br><span class="line">After GSS TLAB: 2750ms.</span><br></pre></td></tr></table></figure></p><h5 id="Read-barrier"><a href="#Read-barrier" class="headerlink" title="Read barrier"></a>Read barrier</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">CC performs heap defragmentation by concurrently copying </span><br><span class="line">objects without pausing app threads. This is achieved with </span><br><span class="line">the help of a read-barrier which intercepts reference reads </span><br><span class="line">from the heap, without the need of any intervention from </span><br><span class="line">the app developer.</span><br></pre></td></tr></table></figure><p>CC可以通过在不暂停应用线程的情况下并发复制对象来执行堆碎片整理。这是在read-barrier的帮助下实现的，read-barrier会拦截来自堆的引用读取，无需开发者进行任何干预。<br>注意对第一句话的理解，应用GC的时候不会暂停应用，也就是说这个时候可能存在分配对象的行为，说的其实正是并发。<br>后面的实际案例在计算自上次GC后新分配大小时会用到这一点，目前的GC都是支持read-barrier的，read-barrier的诞生是为了更大程度的降低GC暂停时间。</p><h5 id="一次暂停"><a href="#一次暂停" class="headerlink" title="一次暂停"></a>一次暂停</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">GC only has one small pause, which is constant in time </span><br><span class="line">with regards to the heap size.</span><br></pre></td></tr></table></figure><p>对Dalvik有所了解的话，都知道Dalvik在mark阶段需要暂停应用线程两次，sweep阶段需要暂停一次，三次的STW开销会带来明显的卡顿。<br>到了ART时代，启动 GC 后不再是两次暂停，而是一次暂停，因为（packard pre-cleaning）的存在，在暂停前就做了许多事情，减轻了暂停时的工作量。</p><h5 id="支持分代"><a href="#支持分代" class="headerlink" title="支持分代"></a>支持分代</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">CC extends to be a generational GC in Android 10 and higher. </span><br><span class="line">It enables collecting young objects, which often become </span><br><span class="line">unreachable fairly quickly, with little effort. </span><br><span class="line">This helps by increasing GC throughput and considerably </span><br><span class="line">delaying the need to perform a full-heap GC.</span><br></pre></td></tr></table></figure><p>谷歌对分代的支持历经开，关，开，具体的缘由没有细跟，不过最新Android版本支持分代，分代的好处谷歌解释为更加轻松回收存留期较短的对象，有助于提升GC的吞吐量，并且降低full GC的时机。<br>注意这里提到了一个GC吞吐量的概念，笔者之前从事过网络工作，所以自然而然的想到了WIFI的吞吐量，WIFI吞吐量可以简单的理解为单位时间内通过某个信道的数据量。</p><p>那么这里的GC 吞吐量指的又是什么呢？ <strong>可以理解为单位时间内释放的字节数</strong></p><h4 id="GC类别的划分"><a href="#GC类别的划分" class="headerlink" title="GC类别的划分"></a>GC类别的划分</h4><p>对GC的分类有不同的指标，可以从是否并发，回收力度等指标分类。</p><h5 id="回收力度划分"><a href="#回收力度划分" class="headerlink" title="回收力度划分"></a>回收力度划分</h5><p>art/runtime/gc/collector/gc_type.h<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">art/runtime/gc/collector/gc_type.h// The type of collection to be performed. //The ordering of the enum matters, it is used to determine which GCs are run first.enum GcType &#123;// Placeholder for when no GC has been performed.kGcTypeNone,// Sticky mark bits GC that attempts to only free objects allocated since the last GC.kGcTypeSticky,// Partial GC that marks the application heap but not the Zygote.kGcTypePartial,// Full GC that marks and frees in both the application and Zygote heap.kGcTypeFull,// Number of different GC types.kGcTypeMax,&#125;;</span><br></pre></td></tr></table></figure></p><p>如下摘自谷歌的一笔commit message：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">The new behaviour has that we do sticky GC until we have </span><br><span class="line">less space remaining than minimum free after the GC. </span><br><span class="line">When this occurs, we set the next GC to be a partial GC.</span><br><span class="line"></span><br><span class="line">After a partial / full GC we grow the heap and set the </span><br><span class="line">next GC to be a sticky GC. This prevents the heap from </span><br><span class="line">always growing more than the target utilization, </span><br><span class="line">while ensuring that we do sticky GC often.</span><br></pre></td></tr></table></figure></p><p>建议随着后面不断的深入学习再回过来读这段话，相信会理解的更深。<br>大概意思是我们会尽可能的使用sticky的回收方式，这种回收只会回收自上次GC以来新分配的对象，是一种轻量回收方式，但是回收力度有限。</p><p>当剩余的可用空间低于设定的最小值即min_free，此时将下次GC类别设定为partial GC，加大回收的力度，但是当我们使用partial GC或者full GC后，应该将下次GC类型设定为sticky，从而避免堆的使用率经常超过目标值(默认0.75)，所以需要经常进行sticky方式的回收。</p><h5 id="对应用影响程度划分"><a href="#对应用影响程度划分" class="headerlink" title="对应用影响程度划分"></a>对应用影响程度划分</h5><p>如果基于GC对应用状态的影响分类的话，大致可以分为并发类和阻塞类。<br>并发类GC：GC在GC回收线程(HeapTaskDaemon)执行，阻塞类GC在进程的工作线程执行。</p><p><img src="http://blog.lihaizhou.top/ART_GC/ART_GC1.png" alt="图片"><br>需要注意这里的GcCauseBackground，这里的“Background”并不是指应用切到后台才会执行GC，而是GC在运行时基本不会影响其他线程的执行，即并发GC。</p><p>有了上面的知识铺垫，下面将进入本文最重要的部分，将依次介绍Multiplier的引入，target_size计算过程，concurrent_start_bytes_计算过程这三部分。<br>这三部分相互关联，为了能够更直观的理解这三部分的关系，本地画了一个整体的概览图(花了大半小时画完…….)，后面的内容主要也是围绕下面这个图进行讲解。<br><img src="http://blog.lihaizhou.top/ART_GC/ART_GC2.png" alt="图片"><br>现在看不懂没有关系，在阅读完后面的内容之后，再回过头来看这个图，相信会理解的更加深刻。</p><h4 id="Multiplier的引入"><a href="#Multiplier的引入" class="headerlink" title="Multiplier的引入"></a>Multiplier的引入</h4><p>我们在后面计算预留内存的时候，不论是否是sticky回收，都会使用到Multiplier。<br>这个值主要是为了前台应用设定的，引入该值目的是为了提升前台应用的性能，代价是堆的利用率下降，关于对性能的影响，下面会进行说明。</p><p>先看下对于Multiplier的值来源<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">art/runtime/runtime.cc</span><br><span class="line"><span class="comment">//Extra added to the default heap growth multiplier. </span></span><br><span class="line"><span class="comment">//Used to adjust the GC ergonomics for the read barrier config.</span></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">constexpr</span> <span class="keyword">double</span> kExtraDefaultHeapGrowthMultiplier = kUseReadBarrier ? <span class="number">1.0</span> : <span class="number">0.0</span>;</span><br><span class="line"><span class="keyword">float</span> foreground_heap_growth_multiplier;</span><br><span class="line"><span class="keyword">if</span> (is_low_memory_mode_ &amp;&amp; !runtime_options.Exists(Opt::ForegroundHeapGrowthMultiplier)) &#123;</span><br><span class="line">   <span class="comment">// If low memory mode, use 1.0 as the multiplier by default.</span></span><br><span class="line">   foreground_heap_growth_multiplier = <span class="number">1.0f</span>;</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">   foreground_heap_growth_multiplier =</span><br><span class="line">   runtime_options.GetOrDefault(Opt::ForegroundHeapGrowthMultiplier) +</span><br><span class="line">   kExtraDefaultHeapGrowthMultiplier;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>后台时Multiplier为1，我们主要看下前台的值，最新Android版本上都是支持ReadBarrier的，那么kExtraDefaultHeapGrowthMultiplier值也就是1。<br>再看下ForegroundHeapGrowthMultiplier的值来源于如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">static constexpr double kDefaultHeapGrowthMultiplier = 2.0;</span><br></pre></td></tr></table></figure><p>所以对于前台应用，Multiplier默认的值是2+1=3。</p><p>下面讲的堆大小的调整，下次GC触发阈值计算都是在GrowForUtilization中发生的，而GrowForUtilization又是在CollectGarbageInternal触发的，所以有必要先介绍下CollectGarbageInternal主要做的事情:</p><ol><li>调用RequestTrim做实际的堆裁剪，将空闲内存归还给系统，这块的内容细节较多，后面会另起一篇文章进行详细的介绍；</li><li>第二步会执行SelfDeletingTask* clear = reference_processor_-&gt;CollectClearedReferences(self);</li><li>第三步也是我们本文重点介绍的一步，这一步将进行堆大小的调整以及计算下次触发GC的阈值</li></ol><p>那么什么时候会触发CollectGarbageInternal进行垃圾回收呢？<br><strong>在ART分配对象失败或者已使用内存超过某个设定的阈值就会触发</strong></p><h4 id="堆最大可分配字节数的计算"><a href="#堆最大可分配字节数的计算" class="headerlink" title="堆最大可分配字节数的计算"></a>堆最大可分配字节数的计算</h4><p>堆最大可分配字节数指的是代码中的target_size，一个仅具有指导意义的最大可分配字节数，为何说仅有指导意义，后面会解释。</p><p>在此之前，我们先了解下Sticky GC是什么？<br>谷歌对此的定义如下:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Sticky mark bits GC that attempts to only free objects </span><br><span class="line">allocated since the last GC.</span><br></pre></td></tr></table></figure></p><p>Sticky GC只会回收自上次GC以来新分配的对象，是分代GC下的一种GC类型，也可以理解为Young-generation GC，那么非kGcTypeSticky指的是哪些GC类别呢？对应Partial GC以及Full GC。</p><p>那么什么时候会使用Sticky GC，什么时候会触发Partial GC以及Full GC呢？后面GC系列文章会进行讲解，总体而言，执行Sticky GC频率最高，最低是Full GC。</p><p>下面会看下kGcTypeSticky以及非kGcTypeSticky类别GC的target_size计算过程。</p><h5 id="非kGcTypeSticky-GC"><a href="#非kGcTypeSticky-GC" class="headerlink" title="非kGcTypeSticky GC"></a>非kGcTypeSticky GC</h5><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (gc_type != collector::kGcTypeSticky) &#123;  </span><br><span class="line"><span class="comment">// Grow the heap for non sticky GC.  </span></span><br><span class="line"><span class="keyword">uint64_t</span> delta = bytes_allocated * (<span class="number">1.0</span> / GetTargetHeapUtilization() - <span class="number">1.0</span>);  </span><br><span class="line">DCHECK_LE(delta, <span class="built_in">std</span>::numeric_limits&lt;<span class="keyword">size_t</span>&gt;::max()) &lt;&lt; <span class="string">"bytes_allocated="</span> &lt;&lt;bytes_allocated  &lt;&lt; <span class="string">" target_utilization_="</span> &lt;&lt; target_utilization_;</span><br><span class="line">grow_bytes = <span class="built_in">std</span>::min(delta, <span class="keyword">static_cast</span>&lt;<span class="keyword">uint64_t</span>&gt;(max_free_));</span><br><span class="line">grow_bytes = <span class="built_in">std</span>::max(grow_bytes, <span class="keyword">static_cast</span>&lt;<span class="keyword">uint64_t</span>&gt;(min_free_));</span><br><span class="line">target_size = bytes_allocated + <span class="keyword">static_cast</span>&lt;<span class="keyword">uint64_t</span>&gt;(grow_bytes * multiplier);  </span><br><span class="line">next_gc_type_ = collector::kGcTypeSticky;&#125;</span><br></pre></td></tr></table></figure><p>注意这行代码<br><code>bytes_allocated * (1.0 / GetTargetHeapUtilization() - 1.0);</code><br>这里有一个容易陷入的误区，如果单纯的看头文件中的定义注释</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//Target ideal heap utilization ratio, implements //dalvik.system.VMRuntime.getTargetHeapUtilization.double GetTargetHeapUtilization() </span></span><br><span class="line"><span class="keyword">const</span> &#123;</span><br><span class="line">   <span class="keyword">return</span> target_utilization_;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>可能会认为这个值返回的是默认的最优值0.75，其实这个值是一个动态变化的值，当一次GC发生后，堆的大小会resize。<br>此时GetTargetHeapUtilization的值等于存活对象大小除以堆的大小，算出的delta是除去已分配的字节数后空闲的大小。<br>算出delta后，我们接着往下看，可以看到grow_bytes并不单纯由delta决定，还会受到max_free_以及min_free_的影响，最终确保grow_bytes 的值不会超出这两个值范围。<br>这里的max_free_本意是target_size与已分配内存间可允许的最大差异，差异过小会导致GC频繁，差异过大会延迟下一次GC的到来，目前很多设备将这个值设为8M，min_free_为512K。其实针对RAM超过6G的大内存设备，Google建议可以提高min_free_，用空间换时间获取更好的GC性能。</p><p>有了grow_bytes 之后，再根据如下代码<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bytes_allocated + static_cast&lt;uint64_t&gt;(grow_bytes * multiplier);</span><br></pre></td></tr></table></figure></p><p>计算出目标堆大小。<br>大致的过程可以用下图表示<br><img src="http://blog.lihaizhou.top/ART_GC/ART_GC3.png" alt="图片"></p><h5 id="kGcTypeSticky-GC"><a href="#kGcTypeSticky-GC" class="headerlink" title="kGcTypeSticky GC"></a>kGcTypeSticky GC</h5><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// If we have freed enough memory, shrink the heap back down.</span></span><br><span class="line"><span class="keyword">const</span> <span class="keyword">size_t</span> adjusted_max_free = <span class="keyword">static_cast</span>&lt;<span class="keyword">size_t</span>&gt;(max_free_ * multiplier);</span><br><span class="line"><span class="keyword">if</span> (bytes_allocated + adjusted_max_free &lt; target_footprint) &#123;</span><br><span class="line">    target_size = bytes_allocated + adjusted_max_free;  </span><br><span class="line">    grow_bytes = max_free_;</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">target_size = <span class="built_in">std</span>::max(bytes_allocated, target_footprint);  </span><br><span class="line"><span class="comment">// The same whether jank perceptible or not; just avoid the adjustment.  </span></span><br><span class="line">grow_bytes = <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>对于本次是非kGcTypeSticky回收的方式，设定下次GC类型稍微复杂一些，会涉及到吞吐量之类的指标，后面的GC系列文章中会细谈，这里只关注target_size的计算过程。</p><ul><li>如果bytes_allocated + adjusted_max_free &lt; target_footprint说明此次的GC回收效果明显，注意这里grow_bytes 的值被赋予了max_free_，表示倾向于预留max_free_的空间大小，所以对于这个判断条件中的情况，其grow_bytes 会是一个恒定的值即max_free_。</li><li>否则的话即else中的情况，target_size的值是对bytes_allocated和target_footprint两者取最大，到这里你可能会疑惑bytes_allocated较大的情况，其实是有这个可能的，因为并发的缘故，可能存在GC期间分配大小大于回收数值的情况。</li></ul><p>那么此时target_size设定为bytes_allocated，下次分配对象时，bytes_allocated 立马就超出了target_size，会不会导致分配失败的情况？<br>其实不会，唯一限制堆内存分配的只有growth_limit_，这也解释了为何我们前面说target_size只有指导意义，但是这种情况确实会立即触发一次GC。</p><p>下面是谷歌的一段commit message对OOM的解释<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Are we out of memory, and thus should force a GC or fail?</span><br><span class="line">For concurrent collectors,out of memory is defined by growth_limit_</span><br><span class="line">For nonconcurrent collectors it is defined by target_footprint_ </span><br><span class="line">unless grow is set.If grow is set, the limit is growth_limit_ </span><br><span class="line">and we adjust target_footprint_to accomodate the allocation.</span><br></pre></td></tr></table></figure></p><p>这个时候，你可能还有疑问，为啥不将此时的target_size适当的增大，其实是因为此时的GC是Sticky，只回收自上次GC以来新分配的对象，回收力度是比较小的。<br>如果它释放的空间不多，接下来还可以用Full GC来更彻底地回收。<br>换言之，只有等Full GC回收完，才决定将GC的水位提升，因为这时已经尝试了所有回收策略。</p><p><strong>再回到上面提到的问题，multiplier的引入为何能够提升前台应用的性能？</strong><br>关于target_size 的计算过程中，不论是否是kGcTypeSticky方式，都涉及到了multiplier因子，multiplier的引入直接改变了前台应用的target_size值，此时你可能会疑惑这样的话堆使用率不就下降了吗？ <strong>其实这是一种空间换时间的做法</strong></p><p>如果堆大小扩展的不多，那么对于前台应用很快就会用完，下次GC便会早早的到来，虽说现在只有一次暂停，但是仍然可能会带来性能问题。<br>引入multiplier之后，前台应用有了足够的堆空间，会延迟下次GC到来的时间，也可以理解为降低GC的频率。</p><p>画了一个堆大小调整图，针对delta处于min_free和max_free之间的情况<br><img src="http://blog.lihaizhou.top/ART_GC/ART_GC4.png" alt="图片"><br>堆空间调整过程明白了，那么下次GC触发阈值是如何计算出来的呢？</p><h4 id="GC触发阈值的计算"><a href="#GC触发阈值的计算" class="headerlink" title="GC触发阈值的计算"></a>GC触发阈值的计算</h4><p>下面我们将继续往下看，下次GC触发阈值在代码中指的是concurrent_start_bytes_。<br>当我们在Java中通过new分配对象时，VM会调用AllocObjectWithAllocator来执行真实的分配。<br>在每一次成功分配Java对象后，都会去检测是否需要进行下一次GC，这就是GcCauseBackground GC的触发时机。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">AllocObjectWithAllocator-&gt;CheckConcurrentGCForJava-&gt;ShouldConcurrentGCForJava</span><br></pre></td></tr></table></figure><p>关键代码<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">inline</span> <span class="keyword">bool</span> Heap::ShouldConcurrentGCForJava(</span><br><span class="line">    <span class="keyword">size_t</span> new_num_bytes_allocated) &#123;</span><br><span class="line">    <span class="comment">// For a Java allocation, we only check whether the number // of Java allocated bytes excceeds a threshold. </span></span><br><span class="line">    <span class="comment">// By not considering native allocation here, we (a) ensure that Java heap bounds are</span></span><br><span class="line">    <span class="comment">// maintained, and (b) reduce the cost of the check here.</span></span><br><span class="line">    <span class="keyword">return</span> new_num_bytes_allocated &gt;= concurrent_start_bytes_;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>触发的条件需要满足一个判断，就是最后一行代码new_num_bytes_allocated(所有已分配的字节数，包括此次新分配的对象) &gt;= concurrent_start_bytes_(下一次GC触发的阈值)，就请求一次新的GC。<br>new_num_bytes_alloated是当前分配时计算的，concurrent_start_bytes_是上次GC结束时计算的。</p><h5 id="更新target-footprint-值"><a href="#更新target-footprint-值" class="headerlink" title="更新target_footprint_ 值"></a>更新target_footprint_ 值</h5><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (!ignore_target_footprint_) &#123;</span><br><span class="line">    SetIdealFootprint(target_size);</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">void</span> Heap::SetIdealFootprint(<span class="keyword">size_t</span> target_footprint) &#123;</span><br><span class="line">   <span class="keyword">if</span> (target_footprint &gt; GetMaxMemory()) &#123;</span><br><span class="line">       VLOG(gc) &lt;&lt; <span class="string">"Clamp target GC heap from "</span> &lt;&lt; PrettySize(target_footprint) &lt;&lt; <span class="string">" to "</span></span><br><span class="line">       &lt;&lt; PrettySize(GetMaxMemory());</span><br><span class="line">       target_footprint = GetMaxMemory();</span><br><span class="line">   &#125;</span><br><span class="line">   target_footprint_.store(target_footprint, <span class="built_in">std</span>::memory_order_relaxed);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>存储target_size的值，并通过target_size更新target_footprint_ 的值</p><h5 id="concurrent-start-bytes"><a href="#concurrent-start-bytes" class="headerlink" title="concurrent_start_bytes_"></a>concurrent_start_bytes_</h5><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Minimum amount of remaining bytes before a concurrent GC is triggered.</span></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">constexpr</span> <span class="keyword">size_t</span> kMinConcurrentRemainingBytes = <span class="number">128</span> * KB;</span><br><span class="line"><span class="keyword">static</span> <span class="keyword">constexpr</span> <span class="keyword">size_t</span> kMaxConcurrentRemainingBytes = <span class="number">512</span> * KB;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (IsGcConcurrent()) &#123;</span><br><span class="line">    <span class="keyword">const</span> <span class="keyword">uint64_t</span> freed_bytes = current_gc_iteration_.GetFreedBytes() +</span><br><span class="line">    current_gc_iteration_.GetFreedLargeObjectBytes() +</span><br><span class="line">    current_gc_iteration_.GetFreedRevokeBytes();</span><br><span class="line">    <span class="comment">// Records the number of bytes allocated at the time of GC finish,excluding the number of</span></span><br><span class="line">    <span class="comment">// bytes allocated during GC.</span></span><br><span class="line">    num_bytes_alive_after_gc_ = UnsignedDifference(bytes_allocated_before_gc, freed_bytes);</span><br><span class="line">    <span class="comment">// Bytes allocated will shrink by freed_bytes after the GC runs, so if we want to figure out</span></span><br><span class="line">    <span class="comment">// how many bytes were allocated during the GC we need to add freed_bytes back on.</span></span><br><span class="line">    <span class="comment">// Almost always bytes_allocated + freed_bytes &gt;= bytes_allocated_before_gc.</span></span><br><span class="line">    <span class="keyword">const</span> <span class="keyword">size_t</span> bytes_allocated_during_gc =</span><br><span class="line">          UnsignedDifference(bytes_allocated + freed_bytes, bytes_allocated_before_gc);</span><br><span class="line">    <span class="comment">// Calculate when to perform the next ConcurrentGC.</span></span><br><span class="line">    <span class="comment">// Estimate how many remaining bytes we will have when we need to start the next GC.</span></span><br><span class="line">    <span class="keyword">size_t</span> remaining_bytes = bytes_allocated_during_gc;</span><br><span class="line">    remaining_bytes = <span class="built_in">std</span>::min(remaining_bytes, kMaxConcurrentRemainingBytes);</span><br><span class="line">    remaining_bytes = <span class="built_in">std</span>::max(remaining_bytes, kMinConcurrentRemainingBytes);</span><br><span class="line">    <span class="keyword">size_t</span> target_footprint = target_footprint_.load(<span class="built_in">std</span>::memory_order_relaxed);</span><br><span class="line">    <span class="keyword">if</span> (UNLIKELY(remaining_bytes &gt; target_footprint)) &#123;</span><br><span class="line">       <span class="comment">// A never going to happen situation that from the estimated allocation rate we will exceed</span></span><br><span class="line">      <span class="comment">// the applications entire footprint with the given estimated allocation rate. Schedul</span></span><br><span class="line">      <span class="comment">// another GC nearly straight away.</span></span><br><span class="line">      remaining_bytes = <span class="built_in">std</span>::min(kMinConcurrentRemainingBytes, target_footprint);</span><br><span class="line">     &#125;</span><br><span class="line">     DCHECK_LE(target_footprint_.load(<span class="built_in">std</span>::memory_order_relaxed), GetMaxMemory());</span><br><span class="line">     <span class="comment">// Start a concurrent GC when we get close to the estimated remaining bytes. When the</span></span><br><span class="line">     <span class="comment">// allocation rate is very high, remaining_bytes could tell us that we should start a GC</span></span><br><span class="line">     <span class="comment">// right away.</span></span><br><span class="line">     concurrent_start_bytes_ = <span class="built_in">std</span>::max(target_footprint - remaining_bytes, bytes_allocated);</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure><p>整个处理过程大致流程如下：</p><ol><li>num_bytes_alive_after_gc_此次GC结束后已分配的字节数，不包括GC期间新分配的字节数</li><li>bytes_allocated_during_gcGC<br>期间分配的字节数，计算很简单，通过bytes_allocated_before_gc减去freed_bytes就 是新增的，因为由于并发的缘故，分配和回收很可能是同步进行的，这个思想将贯穿整个GC机制。</li><li>remaining_bytes这个值指的是gc期间新分配对象的大小。<br>同样的，对于预留值也有范围限制，限制在128 <em> KB到512 </em> KB范围之间之间。</li></ol><p>最后再来看这个计算公式concurrent_start_bytes_ =<br><code>std::max(target_footprint - remaining_bytes, bytes_allocated);</code></p><p>之所以需要用target_footprint减去remaining_bytes，是因为在理论意义上，target_footprint_代表当前堆的最大可分配字节数。而由于是同步GC，回收的过程中可能会有其他线程依然在分配。<br>所以为了保证下次GC的顺利进行，需要将这段时间分配的内存空间预留出来。<br>总结下concurrent_start_bytes_ 的值计算过程:<br><strong>用heap resize之后计算出的target_size减去remaining_bytes后的数值，得出来的concurrent_start_bytes_ 作为下次是否触发GC的阈值。</strong></p><h5 id="Systrace角度看GC"><a href="#Systrace角度看GC" class="headerlink" title="Systrace角度看GC"></a>Systrace角度看GC</h5><p>我们平时工作中，分析GC性能问题用到最多的便是Systrace<br>下面抓取一次抖音包含启动过程的Systrace，看下GC情况以及堆大小的变化情况。<br>在启动过程中，堆的大小持续增长<br><img src="http://blog.lihaizhou.top/ART_GC/ART_GC5.png" alt="图片"></p><p>启动结束后约1s左右，有一次Background young concurrent copying GC<br><img src="http://blog.lihaizhou.top/ART_GC/ART_GC6.png" alt="图片"></p><p>可以看到heap size从59M下降到约11M<br>此时处于前台很快数值上升，并触发Background concurrent copying GC<br><img src="http://blog.lihaizhou.top/ART_GC/ART_GC7.png" alt="图片"></p><p>这两次GC类型都是并发GC，以界面显示后的第一次Background young concurrent copying GC为例<br>从Systrace大致可以看到其流程是<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">InitializePhase(995us692ns)-&gt;CopyingPhase(84ms258us385ns) -&gt;ReclaimPhase(11ms 166us 769ns)</span><br></pre></td></tr></table></figure></p><p>对应到代码中大致流程如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CollectGarbageInternal---&gt; collector---&gt;Run(开始真正的GC流程)---&gt; RunPhases(GC实际处理)</span><br></pre></td></tr></table></figure></p><h4 id="参数修改策略"><a href="#参数修改策略" class="headerlink" title="参数修改策略"></a>参数修改策略</h4><p>通过上面的梳理，我们知道GC的触发以及堆大小的调整会受到max_free_，min_free_，kDefaultTargetUtilization 这些参数影响，这些参数其实有系统属性暴露在外，厂商可以根据实际的需求进行修改。<br>以max_free为例，看了下手头的4G手机项目上默认值是8M，从前面的梳理我们知道，如果增大max_free会导致应用的预留空闲内存增大，相应的应用占用内存大小也会增大，这是带来的弊端。<br>但是好处显而易见，GC的频率会降低，性能会有所提升，所以这是一个权衡的策略。</p><p>如果项目上实测发现GC频繁触发，可以适当的增大max_free的值再进行测试，谷歌的建议是不要修改，除非有大量可靠的测试数据做支撑说明修改后的参数确实有提升。</p><p>下面是我手头4G内存手机打印的参数<br><img src="http://blog.lihaizhou.top/ART_GC/ART_GC8.png" alt="图片"></p><h4 id="写在最后"><a href="#写在最后" class="headerlink" title="写在最后"></a>写在最后</h4><p>至此，本文结合Android S源码和systrace对ART GC的基础知识介绍完毕。<br>在书写本文期间，阅读了网上一些优秀的资源，如老罗，芦航，oppo内核等人书写的ART技术文章，受益匪浅，在此感谢这些技术大咖的无私分享。<br>最后说两句，GC对Android整机性能表现起到至关重要的影响，关于ART GC的性能一直是Google在主导优化，同时也是SOC厂商，各家手机厂商长期以来一直努力优化的方向。<br>我们希望通过对ART GC领域的持续研究，为后面的实际问题分析乃至GC机制的优化修改提供技术支撑。</p><h4 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h4><ol><li>ART运行时Foreground GC和Background GC切换过程分<br><a href="https://www.kancloud.cn/alex_wsc/androids/472237" target="_blank" rel="noopener">https://www.kancloud.cn/alex_wsc/androids/472237</a></li><li>Android性能优化（31）—虚拟机调优<br><a href="https://blog.csdn.net/zhangbijun1230/article/details/79996702" target="_blank" rel="noopener">https://blog.csdn.net/zhangbijun1230/article/details/79996702</a></li><li>ART虚拟机 | GC的触发时机和条件<br><a href="https://juejin.cn/post/6875678394332217357" target="_blank" rel="noopener">https://juejin.cn/post/6875678394332217357</a></li></ol><hr><p>时间真快，不知不觉今天已经周三了，印象中上次周三的时候还是在上周</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h4&gt;&lt;p&gt;本文是GC系列文章的首篇，主要为下一篇《第三视角: 一个ART GC优化的故事》文章做铺垫。&lt;br&gt;本文将根据下面的大纲，简单的介绍下GC相
      
    
    </summary>
    
      <category term="ART" scheme="http://lihaizhou.top/categories/ART/"/>
    
    
  </entry>
  
  <entry>
    <title>对进程压缩消费Zram速度的优化</title>
    <link href="http://lihaizhou.top/2021/10/16/%E5%AF%B9%E8%BF%9B%E7%A8%8B%E5%8E%8B%E7%BC%A9%E6%B6%88%E8%B4%B9Zram%E9%80%9F%E5%BA%A6%E7%9A%84%E4%BC%98%E5%8C%96/"/>
    <id>http://lihaizhou.top/2021/10/16/对进程压缩消费Zram速度的优化/</id>
    <published>2021-10-16T02:32:08.000Z</published>
    <updated>2021-10-16T04:59:55.000Z</updated>
    
    <content type="html"><![CDATA[<h4 id="从全局看Zram"><a href="#从全局看Zram" class="headerlink" title="从全局看Zram"></a>从全局看Zram</h4><p><img src="http://blog.lihaizhou.top/%E8%BF%9B%E7%A8%8B%E5%8E%8B%E7%BC%A9%E6%B6%88%E8%80%97Zram/gaitubao_Zram.png" alt="Zram的消费"></p><h4 id="修改演变历程"><a href="#修改演变历程" class="headerlink" title="修改演变历程"></a>修改演变历程</h4><p><img src="http://blog.lihaizhou.top/%E8%BF%9B%E7%A8%8B%E5%8E%8B%E7%BC%A9%E6%B6%88%E8%80%97Zram/shuiyin_yanbian.png" alt="进程压缩对Zram的消耗修改时间线"></p><h4 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h4><p>当前的修改方案可能不是最优方案，但是解决了之前遇到的实际问题，后面如果遇到新的问题可能还会进行调整。</p><hr><p>Have a good day~</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;从全局看Zram&quot;&gt;&lt;a href=&quot;#从全局看Zram&quot; class=&quot;headerlink&quot; title=&quot;从全局看Zram&quot;&gt;&lt;/a&gt;从全局看Zram&lt;/h4&gt;&lt;p&gt;&lt;img src=&quot;http://blog.lihaizhou.top/%E8%BF%9B%
      
    
    </summary>
    
      <category term="内存" scheme="http://lihaizhou.top/categories/%E5%86%85%E5%AD%98/"/>
    
    
  </entry>
  
  <entry>
    <title>AMS锁严重竞争导致的整机卡顿</title>
    <link href="http://lihaizhou.top/2021/09/18/AMS%E9%94%81%E4%B8%A5%E9%87%8D%E7%AB%9E%E4%BA%89%E5%AF%BC%E8%87%B4%E7%9A%84%E6%95%B4%E6%9C%BA%E5%8D%A1%E9%A1%BF/"/>
    <id>http://lihaizhou.top/2021/09/18/AMS锁严重竞争导致的整机卡顿/</id>
    <published>2021-09-18T02:37:49.000Z</published>
    <updated>2021-10-16T05:13:46.000Z</updated>
    
    <content type="html"><![CDATA[<h5 id="日志抓取"><a href="#日志抓取" class="headerlink" title="日志抓取"></a>日志抓取</h5><p>在问题机器上抓了一份Systrace<br>1.操作步骤: 进入设置界面滑动再退出<br>2.问题现象: 进入设置出现较长时间白屏，退出时有拖影，下拉状态栏尤为卡顿，解锁亮屏很慢。</p><h5 id="问题分析"><a href="#问题分析" class="headerlink" title="问题分析"></a>问题分析</h5><p>从下图可以看到进入设置时，Resume耗时近400ms，主要耗费在等binder上<br><img src="http://blog.lihaizhou.top/AMS_lock/broadcast1.png" alt=""><br>来到对端1188_19线程所在区域，看下这个时间点1188_19在做什么操作？<br><img src="http://blog.lihaizhou.top/AMS_lock/broadcast2.png" alt=""><br>1188_19是SystemServer中的线程，从上图可以看出，它在等AMS锁<br>到这里大致梳理如下<br>1.进入设置应用走到onResume环节时，调用到AMS的registerReceiverWithFeature注册广播，这是应用启动过程中很常见的操作，但是此时registerReceiverWithFeature执行操作被block了，因为执行registerReceiverWithFeature需要申请到AMS锁才行。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> Intent <span class="title">registerReceiverWithFeature</span><span class="params">(IApplicationThread caller, String callerPackage,</span></span></span><br><span class="line"><span class="function"><span class="params">   String callerFeatureId, IIntentReceiver receiver, IntentFilter filter,</span></span></span><br><span class="line"><span class="function"><span class="params">   String permission, <span class="keyword">int</span> userId, <span class="keyword">int</span> flags)</span> </span>&#123;</span><br><span class="line">   <span class="comment">//省略部分代码</span></span><br><span class="line">   <span class="keyword">boolean</span> instantApp;</span><br><span class="line">   <span class="keyword">synchronized</span>(<span class="keyword">this</span>) &#123;</span><br><span class="line">      <span class="keyword">if</span> (caller != <span class="keyword">null</span>) &#123;</span><br><span class="line">          callerApp = getRecordForAppLocked(caller);</span><br><span class="line">          <span class="keyword">if</span> (callerApp == <span class="keyword">null</span>) &#123;</span><br><span class="line">              <span class="keyword">throw</span> <span class="keyword">new</span> SecurityException(</span><br><span class="line">                  <span class="string">"Unable to find app for caller "</span> + caller</span><br><span class="line">                      + <span class="string">" (pid="</span> + Binder.getCallingPid()</span><br><span class="line">                      + <span class="string">") when registering receiver "</span> + receiver);</span><br><span class="line">          &#125;</span><br><span class="line">          <span class="comment">//省略部分代码</span></span><br><span class="line">      &#125;</span><br><span class="line">    <span class="comment">//省略部分代码</span></span><br></pre></td></tr></table></figure><p>2.此时Settings的registerReceiverWithFeature在等ActivityManagerService#finishReceiver释放锁，但其实ActivityManagerService#finishReceiver本身也是在等锁，锁在1188_6这个线程手中。<br>图中有一处waiters=6说明还有其它六处加上这次调用共计7处在等AMS的锁<br>纵观整个应用操作片段，发现很多地方都在等AMS锁，这也说明了为何系统会全局卡顿。</p><p>看下真正持有锁的1188_6这个线程,这个线程持有锁的这段时间内，大部分时候都是running状态<br><img src="http://blog.lihaizhou.top/AMS_lock/broadcast3.png" alt=""><br>全局搜索了下在一分钟不到的时间内触发了197次，而且单次基本都在200ms之久。<br><img src="http://blog.lihaizhou.top/AMS_lock/broadcast4.png" alt=""><br>为此对比了下正常情况下的Systrace，两分钟的时间内共触发14次，平均一分钟7次，且每次updateOomAdj_finishReceiver执行时间都不超过1ms<br><img src="http://blog.lihaizhou.top/AMS_lock/broadcast5.png" alt=""></p><p>到这里大概整理下<br>1.<strong>为何updateOomAdj_finishReceiver会调用这么频繁?</strong><br>  updateOomAdj_finishReceiver是在广播处理结束后会触发调用，问题机器上一分钟调用197次，正常情况下一分钟调用次数是个位数.<br>2.<strong>为何updateOomAdj_finishReceiver耗时这么久?</strong><br>  单次执行都在200ms左右，这也意味着每次持有AMS锁大概200ms，也就意味着一分钟的时间finishReceiver持有AMS锁时间高达39s，这也解释了从Systrace看很多地方都在等AMS锁。<br>  测试了下正常情况下，updateOomAdj_finishReceiver单次执行时间最长一般不会超过1ms</p><p>下面先从广播来源分析，updateOomAdj_finishReceiver触发频繁的原因</p><h6 id="频繁触发原因"><a href="#频繁触发原因" class="headerlink" title="频繁触发原因"></a>频繁触发原因</h6><p>以导致设置应用resume耗时严重的这次updateOomAdj_finishReceiver为例<br><img src="http://blog.lihaizhou.top/AMS_lock/broadcast6.png" alt=""><br>1416对应的是SystemUI中线程，直接来到SystemServer区域看下广播部分<br><img src="http://blog.lihaizhou.top/AMS_lock/broadcast7.png" alt=""><br>再从全局来看<br><img src="http://blog.lihaizhou.top/AMS_lock/broadcast8.png" alt=""><br>可以看到com.android.providers.media.module以及SystemUI这两个模块在交替不间断的发送android.intent.action.MEDIA_SCANNER_SCAN_FILE这个广播，查看代码得知是com.android.providers.media.module这个模块处理扫描文件事务后会发送MEDIA_SCANNER_SCAN_FILE这个广播给SystemUI，SystemUI收到这个广播进行一系列的业务处理，然后再次发送MEDIA_SCANNER_SCAN_FILE这个广播出来。<br>这种业务设计肯定是不合理的，这里暂不继续讨论这种做法的缘由。</p><h6 id="单次处理耗时"><a href="#单次处理耗时" class="headerlink" title="单次处理耗时"></a>单次处理耗时</h6><p><img src="http://blog.lihaizhou.top/AMS_lock/broadcast9.png" alt=""><br>从上图可以看到，问题发生时，SystemUI模块中单次处理该模块耗时达到1s多，这也和问题机器上SystemUI下拉栏滑动极其卡顿能够对应上。<br>结论: SystemUI主线程中广播处理耗时导致滑动很卡顿</p><h5 id="问题结论"><a href="#问题结论" class="headerlink" title="问题结论"></a>问题结论</h5><p>主要由于如下两点原因导致:<br>1.SystemUI中不合理的高频广播，导致AMS@finishReceiver触发频繁并持有AMS锁，造成了全局AMS锁争抢极其严重。<br>2.SystemUI主线程中单次处理广播耗时较长，加剧了卡顿的现象。</p><p>PS: SystemUI这个模块比较特殊，它不像其他应用模块。对于应用模块而言，即便是一直收发广播，卡顿也只是会局限在这个应用操作环节中，不会影响到其他模块。但是SystemUI就不同了，它是可以一直运行着，并且此时你可以操作其他任何应用。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h5 id=&quot;日志抓取&quot;&gt;&lt;a href=&quot;#日志抓取&quot; class=&quot;headerlink&quot; title=&quot;日志抓取&quot;&gt;&lt;/a&gt;日志抓取&lt;/h5&gt;&lt;p&gt;在问题机器上抓了一份Systrace&lt;br&gt;1.操作步骤: 进入设置界面滑动再退出&lt;br&gt;2.问题现象: 进入设置出现较长时
      
    
    </summary>
    
      <category term="性能" scheme="http://lihaizhou.top/categories/%E6%80%A7%E8%83%BD/"/>
    
    
  </entry>
  
  <entry>
    <title>GC超时导致的后台应用崩溃问题分析</title>
    <link href="http://lihaizhou.top/2021/09/08/GC%E8%B6%85%E6%97%B6%E5%AF%BC%E8%87%B4%E7%9A%84%E5%90%8E%E5%8F%B0%E5%BA%94%E7%94%A8%E5%B4%A9%E6%BA%83%E9%97%AE%E9%A2%98%E5%88%86%E6%9E%90/"/>
    <id>http://lihaizhou.top/2021/09/08/GC超时导致的后台应用崩溃问题分析/</id>
    <published>2021-09-08T11:55:06.000Z</published>
    <updated>2022-03-12T14:32:46.809Z</updated>
    
    <content type="html"><![CDATA[<h3 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h3><p>这个问题之所以会拿出来仔细分析，一方面是因为这个问题不是简单的应用崩溃而是框架层的报错，另一方面是因为希望通过这个问题梳理下后台GC的超时检测机制怎样的，这样我们后面在应用层如果重写<code>finalize</code>方法回收时会考虑的更加全面点。</p><h3 id="问题背景"><a href="#问题背景" class="headerlink" title="问题背景"></a>问题背景</h3><p>复现概率: 偶现<br>问题版本: <code>Android R</code><br>问题现象: 处于微信界面，突然弹出王者荣耀停止运行</p><h3 id="初步分析"><a href="#初步分析" class="headerlink" title="初步分析"></a>初步分析</h3><p>拿到问题日志后，先看下报错的堆栈<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">09</span>-<span class="number">02</span> <span class="number">20</span>:<span class="number">53</span>:<span class="number">26.679</span>  <span class="number">2073</span>  <span class="number">2089</span> E AndroidRuntime: FATAL EXCEPTION: FinalizerWatchdogDaemon</span><br><span class="line"><span class="number">09</span>-<span class="number">02</span> <span class="number">20</span>:<span class="number">53</span>:<span class="number">26.679</span>  <span class="number">2073</span>  <span class="number">2089</span> E AndroidRuntime: Process: com.tencent.tmgp.sgame:xg_vip_service, PID: <span class="number">2073</span></span><br><span class="line"><span class="number">09</span>-<span class="number">02</span> <span class="number">20</span>:<span class="number">53</span>:<span class="number">26.679</span>  <span class="number">2073</span>  <span class="number">2089</span> E AndroidRuntime: java.util.concurrent.TimeoutException: android.database.BulkCursorToCursorAdaptor.finalize() timed out after <span class="number">10</span> seconds</span><br><span class="line"><span class="comment">//省略部分堆栈</span></span><br><span class="line"><span class="number">09</span>-<span class="number">02</span> <span class="number">20</span>:<span class="number">53</span>:<span class="number">26.679</span>  <span class="number">2073</span>  <span class="number">2089</span> E AndroidRuntime:at android.database.AbstractCursor.finalize(AbstractCursor.java:<span class="number">524</span>)</span><br><span class="line"><span class="number">09</span>-<span class="number">02</span> <span class="number">20</span>:<span class="number">53</span>:<span class="number">26.679</span>  <span class="number">2073</span>  <span class="number">2089</span> E AndroidRuntime:at java.lang.Daemons$FinalizerDaemon.doFinalize(Daemons.java:<span class="number">291</span>)</span><br><span class="line"><span class="number">09</span>-<span class="number">02</span> <span class="number">20</span>:<span class="number">53</span>:<span class="number">26.679</span>  <span class="number">2073</span>  <span class="number">2089</span> E AndroidRuntime:at java.lang.Daemons$FinalizerDaemon.runInternal(Daemons.java:<span class="number">278</span>)</span><br></pre></td></tr></table></figure></p><p>单单从这段堆栈看的话，<code>BulkCursorToCursorAdaptor</code>执行<code>finalize</code>超过了10s，导致<code>FinalizerWatchdogDaemon</code>报错，<code>FinalizerWatchdogDaemon</code>字面上看像是监测回收超时的守护线程。<br>看下<code>FinalizerWatchdogDaemon</code>代码中的作用解释<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * The watchdog exits the VM if the finalizer ever gets stuck. We consider</span></span><br><span class="line"><span class="comment"> * the finalizer to be stuck if it spends more than MAX_FINALIZATION_MILLIS</span></span><br><span class="line"><span class="comment"> * on one instance.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">FinalizerWatchdogDaemon</span> <span class="keyword">extends</span> <span class="title">Daemon</span> </span>&#123;</span><br><span class="line">    <span class="meta">@UnsupportedAppUsage</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> FinalizerWatchdogDaemon INSTANCE = <span class="keyword">new</span> FinalizerWatchdogDaemon();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">boolean</span> needToWork = <span class="keyword">true</span>;  <span class="comment">// Only accessed in synchronized methods.</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">long</span> finalizerTimeoutNs = <span class="number">0</span>;  <span class="comment">// Lazily initialized.</span></span><br><span class="line"></span><br><span class="line">    FinalizerWatchdogDaemon() &#123;</span><br><span class="line">        <span class="keyword">super</span>(<span class="string">"FinalizerWatchdogDaemon"</span>);</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure></p><p>简单解释下就是：如果对象的<code>finalize</code>出现阻塞超时了会导致进程退出</p><p>这个问题中对应的是数据库的关闭，当然也可以发生在其它场景下，只要重写了成员函数<code>finalize</code>的对象都有可能会遇到这个问题，所以如果再遇到GC超时的报错，报错堆栈<code>AndroidRuntime:at java.lang.Daemons$</code>上面的内容可能会不一样。<br><strong>那么对于重写了成员函数<code>finalize</code>的对象，当它们被GC决定要被回收时，会立刻回收吗？</strong><br>其实不会马上被回收，而是被放入到一个队列中，等待<code>FinalizerDaemon</code>守护线程去调用它们的成员函数<code>finalize</code>后再被回收。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * This heap management thread moves elements from the garbage collector's</span></span><br><span class="line"><span class="comment"> * pending list to the managed reference queue.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">ReferenceQueueDaemon</span> <span class="keyword">extends</span> <span class="title">Daemon</span> </span>&#123;</span><br><span class="line">    <span class="meta">@UnsupportedAppUsage</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> ReferenceQueueDaemon INSTANCE = <span class="keyword">new</span> ReferenceQueueDaemon();</span><br><span class="line"></span><br><span class="line">    ReferenceQueueDaemon() &#123;</span><br><span class="line">        <span class="keyword">super</span>(<span class="string">"ReferenceQueueDaemon"</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span> <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">runInternal</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">while</span> (isRunning()) &#123;</span><br><span class="line">            Reference&lt;?&gt; list;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                <span class="keyword">synchronized</span> (ReferenceQueue.class) &#123;</span><br><span class="line">                    <span class="keyword">while</span> (ReferenceQueue.unenqueued == <span class="keyword">null</span>) &#123;</span><br><span class="line">                        ReferenceQueue.class.wait();</span><br><span class="line">                    &#125;</span><br><span class="line">                    list = ReferenceQueue.unenqueued;</span><br><span class="line">                    ReferenceQueue.unenqueued = <span class="keyword">null</span>;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">                <span class="keyword">continue</span>;</span><br><span class="line">            &#125; <span class="keyword">catch</span> (OutOfMemoryError e) &#123;</span><br><span class="line">                <span class="keyword">continue</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            ReferenceQueue.enqueuePending(list);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="超时阈值"><a href="#超时阈值" class="headerlink" title="超时阈值"></a>超时阈值</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// This used to be final. IT IS NOW ONLY WRITTEN. We now update it when we look at the command</span></span><br><span class="line"><span class="comment">// line argument, for the benefit of mis-behaved apps that might read it.  SLATED FOR REMOVAL.</span></span><br><span class="line"><span class="comment">// There is no reason to use this: Finalizers should not rely on the value. If a finalizer takes</span></span><br><span class="line"><span class="comment">// appreciable time, the work should be done elsewhere.  Based on disassembly of Daemons.class,</span></span><br><span class="line"><span class="comment">// the value is effectively inlined, so changing the field never did have an effect.</span></span><br><span class="line"><span class="comment">// DO NOT USE. FOR ANYTHING. THIS WILL BE REMOVED SHORTLY.</span></span><br><span class="line"><span class="meta">@UnsupportedAppUsage</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">long</span> MAX_FINALIZE_NANOS = <span class="number">10L</span> * <span class="number">1000</span> * NANOS_PER_MILLI;</span><br></pre></td></tr></table></figure><p>注释中对于该值的说明是它很快将被移除，实际这个值在代码中并没有起到真正的作用了，更新它的值是为了方便在外边读取到。<br>真正的超时阈值是通过<code>VMRuntime.getFinalizerTimeoutMs</code>获取，默认值是10s.<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">finalizer_timeout_ms_ = runtime_options.GetOrDefault(Opt::FinalizerTimeoutMs);</span><br><span class="line">RUNTIME_OPTIONS_KEY (unsigned <span class="keyword">int</span>, FinalizerTimeoutMs, <span class="number">10000</span>u)</span><br></pre></td></tr></table></figure></p><h3 id="超时检测"><a href="#超时检测" class="headerlink" title="超时检测"></a>超时检测</h3><p>通过watchdog机制检测<code>finalizer</code>在超时时间内有没有成功析构回收对象<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"> * The watchdog exits the VM <span class="keyword">if</span> the finalizer ever gets stuck. We consider</span><br><span class="line"> * the finalizer to be stuck <span class="keyword">if</span> it spends more than MAX_FINALIZATION_MILLIS</span><br><span class="line"> * on one instance.</span><br><span class="line"> */</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">FinalizerWatchdogDaemon</span> <span class="keyword">extends</span> <span class="title">Daemon</span> </span>&#123;</span><br><span class="line">    <span class="meta">@UnsupportedAppUsage</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> FinalizerWatchdogDaemon INSTANCE = <span class="keyword">new</span> FinalizerWatchdogDaemon();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">boolean</span> needToWork = <span class="keyword">true</span>;  <span class="comment">// Only accessed in synchronized methods.</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">long</span> finalizerTimeoutNs = <span class="number">0</span>;  <span class="comment">// Lazily initialized.</span></span><br><span class="line"></span><br><span class="line">    FinalizerWatchdogDaemon() &#123;</span><br><span class="line">        <span class="keyword">super</span>(<span class="string">"FinalizerWatchdogDaemon"</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span> <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">runInternal</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">while</span> (isRunning()) &#123;</span><br><span class="line">            <span class="keyword">if</span> (!sleepUntilNeeded()) &#123; (<span class="number">1</span>)</span><br><span class="line">                <span class="comment">// We have been interrupted, need to see if this daemon has been stopped.</span></span><br><span class="line">                <span class="keyword">continue</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">final</span> Object finalizing = waitForFinalization();(<span class="number">2</span>)</span><br><span class="line">            <span class="keyword">if</span> (finalizing != <span class="keyword">null</span> &amp;&amp; !VMDebug.isDebuggerConnected()) &#123;</span><br><span class="line">                finalizerTimedOut(finalizing);(<span class="number">3</span>)</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure></p><h4 id="Step1-GC前的检查"><a href="#Step1-GC前的检查" class="headerlink" title="Step1 GC前的检查"></a>Step1 GC前的检查</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">        * Notify daemon that it's OK to sleep until notified that something is ready to be</span></span><br><span class="line"><span class="comment">        * finalized.</span></span><br><span class="line"><span class="comment">        */</span></span><br><span class="line">       <span class="function"><span class="keyword">private</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">goToSleep</span><span class="params">()</span> </span>&#123;</span><br><span class="line">           needToWork = <span class="keyword">false</span>;</span><br><span class="line">       &#125;</span><br><span class="line"></span><br><span class="line">       <span class="comment">/**</span></span><br><span class="line"><span class="comment">        * Notify daemon that there is something ready to be finalized.</span></span><br><span class="line"><span class="comment">        */</span></span><br><span class="line">       <span class="function"><span class="keyword">private</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">wakeUp</span><span class="params">()</span> </span>&#123;</span><br><span class="line">           needToWork = <span class="keyword">true</span>;</span><br><span class="line">           notify();</span><br><span class="line">       &#125;</span><br></pre></td></tr></table></figure><p>开启回收之前，<code>needToWork</code>会被置为true，此时<code>sleepUntilNeeded</code>返回的是true，所以线程不会<code>wait</code><br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Override</span> <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">runInternal</span><span class="params">()</span> </span>&#123;</span><br><span class="line">           <span class="comment">// This loop may be performance critical, since we need to keep up with mutator</span></span><br><span class="line">           <span class="comment">// generation of finalizable objects.</span></span><br><span class="line">           <span class="comment">// We minimize the amount of work we do per finalizable object. For example, we avoid</span></span><br><span class="line">           <span class="comment">// reading the current time here, since that involves a kernel call per object.  We</span></span><br><span class="line">           <span class="comment">// limit fast path communication with FinalizerWatchDogDaemon to what's unavoidable: A</span></span><br><span class="line">           <span class="comment">// non-volatile store to communicate the current finalizable object, e.g. for</span></span><br><span class="line">           <span class="comment">// reporting, and a release store (lazySet) to a counter.</span></span><br><span class="line">           <span class="comment">// We do stop the  FinalizerWatchDogDaemon if we have nothing to do for a</span></span><br><span class="line">           <span class="comment">// potentially extended period.  This prevents the device from waking up regularly</span></span><br><span class="line">           <span class="comment">// during idle times.</span></span><br><span class="line"></span><br><span class="line">           <span class="comment">// Local copy of progressCounter; saves a fence per increment on ARM and MIPS.</span></span><br><span class="line">           <span class="keyword">int</span> localProgressCounter = progressCounter.get();</span><br><span class="line"></span><br><span class="line">           <span class="keyword">while</span> (isRunning()) &#123;</span><br><span class="line">               <span class="keyword">try</span> &#123;</span><br><span class="line">                   <span class="comment">// Use non-blocking poll to avoid FinalizerWatchdogDaemon communication</span></span><br><span class="line">                   <span class="comment">// when busy.</span></span><br><span class="line">                   FinalizerReference&lt;?&gt; finalizingReference = (FinalizerReference&lt;?&gt;)queue.poll();</span><br><span class="line">                   <span class="keyword">if</span> (finalizingReference != <span class="keyword">null</span>) &#123;</span><br><span class="line">                       finalizingObject = finalizingReference.get();</span><br><span class="line">                       progressCounter.lazySet(++localProgressCounter);</span><br><span class="line">                   &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                       finalizingObject = <span class="keyword">null</span>;</span><br><span class="line">                       progressCounter.lazySet(++localProgressCounter);</span><br><span class="line">                       <span class="comment">// Slow path; block.</span></span><br><span class="line">                       FinalizerWatchdogDaemon.INSTANCE.goToSleep();</span><br><span class="line">                       finalizingReference = (FinalizerReference&lt;?&gt;)queue.remove();</span><br><span class="line">                       finalizingObject = finalizingReference.get();</span><br><span class="line">                       progressCounter.set(++localProgressCounter);</span><br><span class="line">                       <span class="comment">//回收之前先唤醒看门狗线程</span></span><br><span class="line">                       FinalizerWatchdogDaemon.INSTANCE.wakeUp();</span><br><span class="line">                   &#125;</span><br><span class="line">                   <span class="comment">//开始回收的流程</span></span><br><span class="line">                   doFinalize(finalizingReference);</span><br><span class="line">               &#125; <span class="keyword">catch</span> (InterruptedException ignored) &#123;</span><br><span class="line">               &#125; <span class="keyword">catch</span> (OutOfMemoryError ignored) &#123;</span><br><span class="line">               &#125;</span><br><span class="line">           &#125;</span><br><span class="line">       &#125;</span><br></pre></td></tr></table></figure></p><p>如果此时线程处于<code>wait</code>，被中断了或者有<code>OOME</code>发生时，这个时候回到开头判断下<code>isRunning()</code>，也就是看下回收对象这个线程是否为空，如果该线程为空的话，这个循环体就没有必要再继续执行下去了。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">        * Wait until something is ready to be finalized.</span></span><br><span class="line"><span class="comment">        * Return false if we have been interrupted</span></span><br><span class="line"><span class="comment">        * See also http://code.google.com/p/android/issues/detail?id=22778.</span></span><br><span class="line"><span class="comment">        */</span></span><br><span class="line">       <span class="function"><span class="keyword">private</span> <span class="keyword">synchronized</span> <span class="keyword">boolean</span> <span class="title">sleepUntilNeeded</span><span class="params">()</span> </span>&#123;</span><br><span class="line">           <span class="keyword">while</span> (!needToWork) &#123;</span><br><span class="line">               <span class="keyword">try</span> &#123;</span><br><span class="line">                   wait();</span><br><span class="line">               &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">                   <span class="comment">// Daemon.stop may have interrupted us.</span></span><br><span class="line">                   <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">               &#125; <span class="keyword">catch</span> (OutOfMemoryError e) &#123;</span><br><span class="line">                   <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">               &#125;</span><br><span class="line">           &#125;</span><br><span class="line">           <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">       &#125;</span><br></pre></td></tr></table></figure></p><h4 id="Step2-等待GC完成"><a href="#Step2-等待GC完成" class="headerlink" title="Step2 等待GC完成"></a>Step2 等待GC完成</h4><p>这一步是等待回收结束的过程，这个睡眠过程中如果被中断，说明在这个周期内完成了析构，直接返回null<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">        * Return an object that took too long to finalize or return null.</span></span><br><span class="line"><span class="comment">        * Wait VMRuntime.getFinalizerTimeoutMs.  If the FinalizerDaemon took essentially the</span></span><br><span class="line"><span class="comment">        * whole time processing a single reference, return that reference.  Otherwise return</span></span><br><span class="line"><span class="comment">        * null.  Only called from a single thread.</span></span><br><span class="line"><span class="comment">        */</span></span><br><span class="line">       <span class="function"><span class="keyword">private</span> Object <span class="title">waitForFinalization</span><span class="params">()</span> </span>&#123;</span><br><span class="line">           <span class="keyword">if</span> (finalizerTimeoutNs == <span class="number">0</span>) &#123;</span><br><span class="line">               finalizerTimeoutNs =</span><br><span class="line">                       NANOS_PER_MILLI * VMRuntime.getRuntime().getFinalizerTimeoutMs();</span><br><span class="line">               <span class="comment">// Temporary app backward compatibility. Remove eventually.</span></span><br><span class="line">               MAX_FINALIZE_NANOS = finalizerTimeoutNs;</span><br><span class="line">           &#125;</span><br><span class="line">           <span class="keyword">long</span> startCount = FinalizerDaemon.INSTANCE.progressCounter.get();</span><br><span class="line">           <span class="comment">// Avoid remembering object being finalized, so as not to keep it alive.</span></span><br><span class="line">           <span class="comment">//如果回收对象没有超时的话，这里会返回null</span></span><br><span class="line">           <span class="keyword">if</span> (!sleepForNanos(finalizerTimeoutNs)) &#123;</span><br><span class="line">               <span class="comment">// Don't report possibly spurious timeout if we are interrupted.</span></span><br><span class="line">               <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">           &#125;</span><br><span class="line">           <span class="keyword">if</span> (getNeedToWork() &amp;&amp; FinalizerDaemon.INSTANCE.progressCounter.get() == startCount) &#123;</span><br><span class="line">               <span class="comment">// We assume that only remove() and doFinalize() may take time comparable to</span></span><br><span class="line">               <span class="comment">// the finalizer timeout.</span></span><br><span class="line">               <span class="comment">// We observed neither the effect of the gotoSleep() nor the increment preceding a</span></span><br><span class="line">               <span class="comment">// later wakeUp. Any remove() call by the FinalizerDaemon during our sleep</span></span><br><span class="line">               <span class="comment">// interval must have been followed by a wakeUp call before we checked needToWork.</span></span><br><span class="line">               <span class="comment">// But then we would have seen the counter increment.  Thus there cannot have</span></span><br><span class="line">               <span class="comment">// been such a remove() call.</span></span><br><span class="line">               <span class="comment">// The FinalizerDaemon must not have progressed (from either the beginning or the</span></span><br><span class="line">               <span class="comment">// last progressCounter increment) to either the next increment or gotoSleep()</span></span><br><span class="line">               <span class="comment">// call.  Thus we must have taken essentially the whole finalizerTimeoutMs in a</span></span><br><span class="line">               <span class="comment">// single doFinalize() call.  Thus it's OK to time out.  finalizingObject was set</span></span><br><span class="line">               <span class="comment">// just before the counter increment, which preceded the doFinalize call.  Thus we</span></span><br><span class="line">               <span class="comment">// are guaranteed to get the correct finalizing value below, unless doFinalize()</span></span><br><span class="line">               <span class="comment">// just finished as we were timing out, in which case we may get null or a later</span></span><br><span class="line">               <span class="comment">// one.  In this last case, we are very likely to discard it below.</span></span><br><span class="line">               Object finalizing = FinalizerDaemon.INSTANCE.finalizingObject;</span><br><span class="line">               sleepForNanos(<span class="number">500</span> * NANOS_PER_MILLI);</span><br><span class="line">               <span class="comment">// Recheck to make it even less likely we report the wrong finalizing object in</span></span><br><span class="line">               <span class="comment">// the case which a very slow finalization just finished as we were timing out.</span></span><br><span class="line">               <span class="keyword">if</span> (getNeedToWork()</span><br><span class="line">                       &amp;&amp; FinalizerDaemon.INSTANCE.progressCounter.get() == startCount) &#123;</span><br><span class="line">                   <span class="keyword">return</span> finalizing;</span><br><span class="line">               &#125;</span><br><span class="line">           &#125;</span><br><span class="line">           <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">       &#125;</span><br></pre></td></tr></table></figure></p><p><code>sleepForNanos</code>对应的函数很简单，如果在超时时间内完成GC，就会计算传进来的超时阈值减去当前已经睡眠的时间，如果这个差值小于0，说明睡眠的时间超过了阈值<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">        * Sleep for the given number of nanoseconds, or slightly longer.</span></span><br><span class="line"><span class="comment">        * <span class="doctag">@return</span> false if we were interrupted.</span></span><br><span class="line"><span class="comment">        */</span></span><br><span class="line">       <span class="function"><span class="keyword">private</span> <span class="keyword">boolean</span> <span class="title">sleepForNanos</span><span class="params">(<span class="keyword">long</span> durationNanos)</span> </span>&#123;</span><br><span class="line">           <span class="comment">// It's important to base this on nanoTime(), not currentTimeMillis(), since</span></span><br><span class="line">           <span class="comment">// the former stops counting when the processor isn't running.</span></span><br><span class="line">           <span class="keyword">long</span> startNanos = System.nanoTime();</span><br><span class="line">           <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">               <span class="keyword">long</span> elapsedNanos = System.nanoTime() - startNanos;</span><br><span class="line">               <span class="keyword">long</span> sleepNanos = durationNanos - elapsedNanos;</span><br><span class="line">               <span class="keyword">if</span> (sleepNanos &lt;= <span class="number">0</span>) &#123;</span><br><span class="line">                   <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">               &#125;</span><br><span class="line">               <span class="comment">// Ensure the nano time is always rounded up to the next whole millisecond,</span></span><br><span class="line">               <span class="comment">// ensuring the delay is &gt;= the requested delay.</span></span><br><span class="line">               <span class="keyword">long</span> sleepMillis = (sleepNanos + NANOS_PER_MILLI - <span class="number">1</span>) / NANOS_PER_MILLI;</span><br><span class="line">               <span class="keyword">try</span> &#123;</span><br><span class="line">                   Thread.sleep(sleepMillis);</span><br><span class="line">               &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">                   <span class="keyword">if</span> (!isRunning()) &#123;</span><br><span class="line">                       <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">                   &#125;</span><br><span class="line">               &#125; <span class="keyword">catch</span> (OutOfMemoryError ignored) &#123;</span><br><span class="line">                   <span class="keyword">if</span> (!isRunning()) &#123;</span><br><span class="line">                       <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">                   &#125;</span><br><span class="line">               &#125;</span><br><span class="line">           &#125;</span><br><span class="line">       &#125;</span><br></pre></td></tr></table></figure></p><h4 id="Step3-GC处理超时"><a href="#Step3-GC处理超时" class="headerlink" title="Step3 GC处理超时"></a>Step3 GC处理超时</h4><p>如果第二步中的超时时间内析构没有完成，则返回析构的对象，触发<code>finalizerTimedOut</code>。<br>到了这一步是最不希望看到的结局，此时系统会弹出应用停止运行的报错框。</p><p>注意这个时候并没有立刻杀死进程，杀死进程的选择权交给了用户，即通过弹窗展示给用户，但对于用户来说会一头雾水</p><p><img src="http://blog.lihaizhou.top/GC_crash/GC1.png" alt=""></p><h3 id="分析结论"><a href="#分析结论" class="headerlink" title="分析结论"></a>分析结论</h3><p>这种问题其实还是比较常见的，特别是低内存的机器上。<code>RootCasue</code>就是对象回收超时了，一般是由于队列中等待<code>FinalizerDaemon</code>线程回收的对象太多导致，或者此时系统资源异常紧张比如CPU负载过高或者低内存环境下。</p><h3 id="场景实测"><a href="#场景实测" class="headerlink" title="场景实测"></a>场景实测</h3><h4 id="模拟还原现场"><a href="#模拟还原现场" class="headerlink" title="模拟还原现场"></a>模拟还原现场</h4><p>通过模拟<code>GC</code>时耗时操作，应用退到后台后10s会弹出报错框，堆栈如下</p><p><img src="http://blog.lihaizhou.top/GC_crash/GC2.png" alt=""></p><p>验证了超时时间的确是10s，同时也验证了GC时耗时的操作确实会可能触发这个现象</p><h4 id="对比机情况"><a href="#对比机情况" class="headerlink" title="对比机情况"></a>对比机情况</h4><p>在手头的小米<code>note9 pro</code>上进行场景模拟测试，模拟GC耗时100s的情况<br><img src="http://blog.lihaizhou.top/GC_crash/GC3.png" alt=""></p><p>在小米的机器上，到了默认的10s后并不会有弹窗，说明小米肯定修改了超时时间，第一次是等待了全部的100s后竟然正常回收，说明超时时间设置的比较大。紧接着下一次在达到了近80s时，进程收到<code>signal 9</code>直接被kill了，此时再点击应用是冷启动。</p><p><strong>小米修改了超时阈值(超过100s)，通过直接sig 9杀掉了进程，没有报错弹窗，所以用户无感知</strong></p><h4 id="测试机情况"><a href="#测试机情况" class="headerlink" title="测试机情况"></a>测试机情况</h4><p>同样的在我们的机器上模拟GC耗时100s的情况<br><strong>退出应用到后台，此时系统触发GC回收，达到十秒钟时，界面上直接弹出停止运行的报错框，此时只有点击了关闭应用，才会去kill进程</strong></p><h4 id="修改策略"><a href="#修改策略" class="headerlink" title="修改策略"></a>修改策略</h4><p>在GC规定的超时时间内如果没有完成析构，直接<code>sig 9</code>给对应进程</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;写在前面&quot;&gt;&lt;a href=&quot;#写在前面&quot; class=&quot;headerlink&quot; title=&quot;写在前面&quot;&gt;&lt;/a&gt;写在前面&lt;/h3&gt;&lt;p&gt;这个问题之所以会拿出来仔细分析，一方面是因为这个问题不是简单的应用崩溃而是框架层的报错，另一方面是因为希望通过这个问题梳理下
      
    
    </summary>
    
      <category term="稳定性" scheme="http://lihaizhou.top/categories/%E7%A8%B3%E5%AE%9A%E6%80%A7/"/>
    
    
  </entry>
  
  <entry>
    <title>从tcpdump看miracast的play流程(工具篇)</title>
    <link href="http://lihaizhou.top/2020/11/30/%E4%BB%8Etcpdump%E7%9C%8Bmiracast%E7%9A%84play%E6%B5%81%E7%A8%8B/"/>
    <id>http://lihaizhou.top/2020/11/30/从tcpdump看miracast的play流程/</id>
    <published>2020-11-30T03:01:15.000Z</published>
    <updated>2021-10-16T06:00:43.000Z</updated>
    
    <content type="html"><![CDATA[<p>前言：<br>基于高通平台，其他平台都是类似的<br>本文作为工具篇，记录下来的目的是以便后续如再接触投屏工作能够快速对照上手</p><p>当我们开始准备连接sink设备时，开始的时候，source会创建一个socket监听着并等待sink端过来连接，sink端会触发”connect”的socket函数并开始tcp 握手之路，这个时候source接收到之后，它会触发”accept”的socket函数来处理sink发过俩的连接请求</p><p>开始是握手 Key Message #1~#4<br><img src="http://blog.lihaizhou.top/Miracast_play/miracast-play01.png" alt=""></p><p>RTSP connect M1~M8:<br><img src="http://blog.lihaizhou.top/Miracast_play/miracast-play02.png" alt=""></p><p>DHCP ACK<br><img src="http://blog.lihaizhou.top/Miracast_play/miracast-play03.png" alt=""></p><p>如果这里DHCP Discover -&gt; DHCP ACK耗时超过 5s, 对于一些sink设备来说它就不会继续发 SYN 消息了 ，因此连接会阻塞在这里<br>所以如果遇到sink没有发送SYN的话就要看看这里的DHCP是否耗时太久了</p><p>SYN handshake Sink should send SYN message to 7236 port at this step:<br><img src="http://blog.lihaizhou.top/Miracast_play/miracast-play04.png" alt=""></p><p>Get/Set parameter<br><img src="http://blog.lihaizhou.top/Miracast_play/miracast-play05.png" alt=""></p><p>Play<br><img src="http://blog.lihaizhou.top/Miracast_play/miracast-play06.png" alt=""></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;前言：&lt;br&gt;基于高通平台，其他平台都是类似的&lt;br&gt;本文作为工具篇，记录下来的目的是以便后续如再接触投屏工作能够快速对照上手&lt;/p&gt;
&lt;p&gt;当我们开始准备连接sink设备时，开始的时候，source会创建一个socket监听着并等待sink端过来连接，sink端会触发”c
      
    
    </summary>
    
      <category term="网络" scheme="http://lihaizhou.top/categories/%E7%BD%91%E7%BB%9C/"/>
    
    
  </entry>
  
  <entry>
    <title>一次SystemServer OOM导致的系统重启分析之路</title>
    <link href="http://lihaizhou.top/2020/11/25/%E4%B8%80%E6%AC%A1SystemServer-OOM%E5%AF%BC%E8%87%B4%E7%9A%84%E7%B3%BB%E7%BB%9F%E9%87%8D%E5%90%AF%E5%88%86%E6%9E%90%E4%B9%8B%E8%B7%AF/"/>
    <id>http://lihaizhou.top/2020/11/25/一次SystemServer-OOM导致的系统重启分析之路/</id>
    <published>2020-11-25T00:59:48.000Z</published>
    <updated>2021-10-16T06:14:02.000Z</updated>
    
    <content type="html"><![CDATA[<p><strong>测试步骤</strong><br>MTBF测试跑出来的机器重启，先解释下何为MTBF？<br><code>MTBF测试(Mean Time Between Failure)</code><br>主要测试终端在连续工作状态下，出现死机、重启、冻屏、应用强制关闭等严重故障的概率。通过在一个周期内以自动化方式反复执行规定用例，记录测试过程中被测终端出现的故障数</p><p><strong>复现概率</strong><br>1/200</p><p><strong>问题现象</strong><br>机器出现重启，并自动给出源头是OOM导致的结论</p><h1 id="初步分析"><a href="#初步分析" class="headerlink" title="初步分析"></a>初步分析</h1><p>正常步骤先看bugreport确定下是否是OOM导致的重启，搜索关键字”system_server_crash”或”am_crash”<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">2020</span>-<span class="number">12</span>-<span class="number">07</span> <span class="number">10</span>:<span class="number">56</span>:<span class="number">18</span> system_server_crash (text, <span class="number">346</span> bytes)</span><br><span class="line">Process: system_server</span><br><span class="line">java.lang.OutOfMemoryError: Heap of System_Server has allocated <span class="number">666</span>MB , So trigger OutOfMemoryError crash</span><br><span class="line">at com.android.server.WatchdogInjector.checkOOMState(WatchdogInjector.java:<span class="number">98</span>)</span><br><span class="line">at com.android.server.Watchdog.run(Watchdog.java:<span class="number">776</span>)</span><br><span class="line"></span><br><span class="line"><span class="number">12</span>-<span class="number">07</span> <span class="number">10</span>:<span class="number">56</span>:<span class="number">18.313</span>  <span class="number">1000</span>  <span class="number">1614</span>  <span class="number">1703</span> I am_crash: [<span class="number">1614</span>,<span class="number">0</span>,system_server,-<span class="number">1</span>,java.lang.OutOfMemoryError,Heap of System_Server has allocated <span class="number">666</span>MB , So trigger OutOfMemoryError crash,WatchdogInjector.java,<span class="number">98</span>]</span><br><span class="line"></span><br><span class="line"><span class="number">12</span>-<span class="number">07</span> <span class="number">10</span>:<span class="number">56</span>:<span class="number">18.312</span>  <span class="number">1000</span>  <span class="number">1614</span>  <span class="number">1703</span> D OOMEventManagerFK: dumpheap success : /data/anr/system_server_1614.hprof</span><br></pre></td></tr></table></figure></p><p>上面片段中可以看出当时SystemServer确实发生了OOM，日志中没有打出具体堆栈，这个时候去看下system_server_1614.hprof，这个应该是厂商定制化输出的，比如监测到SystemServer占据内存超过一定的阀值，就dump出这个hprof文件以便于分析<br><img src="http://blog.lihaizhou.top/SystemServerOOM/SystemServerOOM1.png" alt=""><br>这个文件打开后，最大的一块是有五百多个android.app.assist.AssistStructure实例</p><p><img src="http://blog.lihaizhou.top/SystemServerOOM/SystemServerOOM2.png" alt=""></p><p>接下来顺理成章的就看下android.app.assist.AssistStructure单个实例中的引用链关系了<br>直接点击Histogram搜索android.app.assist.AssistStructure即可<br><img src="http://blog.lihaizhou.top/SystemServerOOM/SystemServerOOM3.png" alt=""><br>选择outgoing reference后如下，可以看到有529个<br><img src="http://blog.lihaizhou.top/SystemServerOOM/SystemServerOOM4.png" alt=""><br>随便点击一个右键同样的选outgoing<br><img src="http://blog.lihaizhou.top/SystemServerOOM/SystemServerOOM5.png" alt=""></p><p>每个AssistStructure实例中都包含WifiConfigActivity，WifiConfigActivity是一个什么样的界面呢？<br>是一个对话框样式的Activity，包含了可以填充数据的编辑框。<br>其实我们到这里已经大致明白了，罪魁祸首基本可以认定是WifiConfigActivity了</p><p>从bugreport中寻找关于WifiConfigActivity的线索，查找system_server OOM之前的片段<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">12</span>-<span class="number">07</span> <span class="number">10</span>:<span class="number">56</span>:<span class="number">04.383</span>  <span class="number">1000</span>  <span class="number">1614</span>  <span class="number">2419</span> I WindowManager: Input event dispatching timed out sending to com.android.settings/com.android.settings.wifi.WifiConfigActivity.  Reason: e4a42fb com.android.settings/com.android.settings.wifi.WifiConfigActivity (server) is not responding. Waited <span class="number">8001</span><span class="function">ms <span class="keyword">for</span> <span class="title">FocusEvent</span><span class="params">(hasFocus=<span class="keyword">true</span>)</span></span></span><br></pre></td></tr></table></figure></p><p>可以看到当时的WifiConfigActivity界面是卡住了，无法响应事件，可能当时系统在不停的GC，再看下WifiConfigActivity的调起记录<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">12</span>-<span class="number">07</span> <span class="number">10</span>:<span class="number">55</span>:<span class="number">09.375</span>  <span class="number">1000</span>  <span class="number">1614</span> <span class="number">12880</span> I ActivityTaskManager: START u0 &#123;flg=<span class="number">0x10000000</span> cmp=com.android.settings/.wifi.WifiConfigActivity (has extras)&#125; from uid <span class="number">1000</span></span><br><span class="line"><span class="number">12</span>-<span class="number">07</span> <span class="number">10</span>:<span class="number">55</span>:<span class="number">18.151</span>  <span class="number">1000</span>  <span class="number">1614</span>  <span class="number">4490</span> I ActivityTaskManager: START u0 &#123;flg=<span class="number">0x10000000</span> cmp=com.android.settings/.wifi.WifiConfigActivity (has extras)&#125; from uid <span class="number">1000</span></span><br><span class="line"><span class="number">12</span>-<span class="number">07</span> <span class="number">10</span>:<span class="number">55</span>:<span class="number">21.185</span>  <span class="number">1000</span>  <span class="number">1614</span> <span class="number">12880</span> I ActivityTaskManager: START u0 &#123;flg=<span class="number">0x10000000</span> cmp=com.android.settings/.wifi.WifiConfigActivity (has extras)&#125; from uid <span class="number">1000</span></span><br><span class="line"><span class="number">12</span>-<span class="number">07</span> <span class="number">10</span>:<span class="number">55</span>:<span class="number">32.439</span>  <span class="number">1000</span>  <span class="number">1614</span>  <span class="number">5665</span> I ActivityTaskManager: START u0 &#123;flg=<span class="number">0x10000000</span> cmp=com.android.settings/.wifi.WifiConfigActivity (has extras)&#125; from uid <span class="number">1000</span></span><br><span class="line"><span class="number">12</span>-<span class="number">07</span> <span class="number">10</span>:<span class="number">55</span>:<span class="number">42.120</span>  <span class="number">1000</span>  <span class="number">1614</span>  <span class="number">8959</span> I ActivityTaskManager: START u0 &#123;flg=<span class="number">0x10000000</span> cmp=com.android.settings/.wifi.WifiConfigActivity (has extras)&#125; from uid <span class="number">1000</span></span><br><span class="line"><span class="number">12</span>-<span class="number">07</span> <span class="number">10</span>:<span class="number">55</span>:<span class="number">50.421</span>  <span class="number">1000</span>  <span class="number">1614</span>  <span class="number">4063</span> I ActivityTaskManager: START u0 &#123;flg=<span class="number">0x10000000</span> cmp=com.android.settings/.wifi.WifiConfigActivity (has extras)&#125; from uid <span class="number">1000</span></span><br><span class="line"><span class="number">12</span>-<span class="number">07</span> <span class="number">10</span>:<span class="number">56</span>:<span class="number">03.812</span>  <span class="number">1000</span>  <span class="number">1614</span> <span class="number">14712</span> I ActivityTaskManager: START u0 &#123;flg=<span class="number">0x10000000</span> cmp=com.android.settings/.wifi.WifiConfigActivity (has extras)&#125; from uid <span class="number">1000</span></span><br></pre></td></tr></table></figure></p><p>WifiConfigActivity什么时候会被调起呢，是在收到一个广播后，鉴于其启动模式是singleInstance<br>查阅代码发现这个文件有重写onNewIntent，所以再多次调用的情况下，onNewIntent会被多次触发<br>该函数里有一处代码<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">new</span> AccessPoint(<span class="keyword">this</span>, wifiConfiguration);</span><br></pre></td></tr></table></figure></p><p>这里直接传入了this且该类是singleInstance，所以这个对象是无法被GC的，会导致内存持续增加，其实日志中也有Settings OOM的片段打出来  </p><h1 id="修改方案"><a href="#修改方案" class="headerlink" title="修改方案"></a>修改方案</h1><p>修改方案如下：<br>传入this的地方改为弱引用，这样在该界面退出时activity可以正常被回收掉，另外新增一个文件继承自DialogInterface.OnDismissListener<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DetachWifiDialogListener</span> <span class="keyword">implements</span> <span class="title">DialogInterface</span>.<span class="title">OnDismissListener</span></span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">static</span> String TAG = DetachWifiDialogListener.class.getSimpleName();</span><br><span class="line">    <span class="keyword">private</span> Activity mActivity;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">DetachWifiDialogListener</span><span class="params">(Activity activity)</span> </span>&#123;</span><br><span class="line">        mActivity = activity;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onDismiss</span><span class="params">(DialogInterface dialog)</span> </span>&#123;</span><br><span class="line">       Log.d(TAG,<span class="string">"Dialog onDismiss"</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">clearOnDetach</span><span class="params">(Dialog dialog)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (dialog.getWindow() == <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        dialog.getWindow()</span><br><span class="line">                .getDecorView()</span><br><span class="line">                .getViewTreeObserver()</span><br><span class="line">                .addOnWindowAttachListener(<span class="keyword">new</span> ViewTreeObserver.OnWindowAttachListener() &#123;</span><br><span class="line">                    <span class="meta">@Override</span></span><br><span class="line">                    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onWindowAttached</span><span class="params">()</span> </span>&#123;</span><br><span class="line">                       Log.d(TAG, <span class="string">"dialog Attached to Window"</span>);</span><br><span class="line">                    &#125;</span><br><span class="line">                    <span class="meta">@Override</span></span><br><span class="line">                    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onWindowDetached</span><span class="params">()</span> </span>&#123;</span><br><span class="line">                        Log.d(TAG,<span class="string">"dialog Detached to Window"</span>);</span><br><span class="line">                        <span class="keyword">if</span>(mActivity != <span class="keyword">null</span>) &#123;</span><br><span class="line">                           mActivity.finish();</span><br><span class="line">                           mActivity = <span class="keyword">null</span>;</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>在弹出Dialog后执行clearOnDetach，及时的将Activity finish掉，并且在onPause中(这里因为此处场景特殊，一般在onDestory中)将Listener置空<br>目的是剪断这个引用链<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">dismissListener = <span class="keyword">new</span> DetachWifiDialogListener(mWifiConfigActivity.get());</span><br><span class="line"><span class="comment">//....</span></span><br><span class="line">mDialog.show();</span><br><span class="line">dismissListener.clearOnDetach(mDialog);</span><br></pre></td></tr></table></figure></p><p>本地测试下来，<code>dumpsys meminfo</code>出的Activity实例个数在Dialog消失后会减少，说明不存在内存泄露了</p><h1 id="常见示例"><a href="#常见示例" class="headerlink" title="常见示例"></a>常见示例</h1><p>再例举一个最常见的非静态内部类Handler泄漏例子，延迟发送一个消息，此时在消息处理之前退出该界面，就会存在该Activity泄漏的情形</p><p>此时在onDestory内执行<code>removeCallbacksAndMessages</code>，这样的话每次退出界面后就会清空该handler上所有的callback和消息，这样就不会存在<code>MessageQueue-&gt;Handler-&gt;Activity</code>这个引用链</p><p><img src="http://blog.lihaizhou.top/SystemServerOOM/SystemServerOOM6.png" alt=""></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;strong&gt;测试步骤&lt;/strong&gt;&lt;br&gt;MTBF测试跑出来的机器重启，先解释下何为MTBF？&lt;br&gt;&lt;code&gt;MTBF测试(Mean Time Between Failure)&lt;/code&gt;&lt;br&gt;主要测试终端在连续工作状态下，出现死机、重启、冻屏、应用强制关闭
      
    
    </summary>
    
      <category term="稳定性" scheme="http://lihaizhou.top/categories/%E7%A8%B3%E5%AE%9A%E6%80%A7/"/>
    
    
  </entry>
  
</feed>
